<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Linear_algebra - Jefo</title><meta name="Description" content="Jefo"><meta property="og:title" content="Linear_algebra" />
<meta property="og:description" content="线性代数 开篇词 | 从今天起，学会线性代数 朱维刚 2020-07-27 机器学习本身没有多大难度，因为经过多年的积累后，很多规则已经成型了。对于我们来说真正难的，是机" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://qizhengzou.github.io/linear_algebra/" /><meta property="og:image" content="https://qizhengzou.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-20T10:04:29+08:00" />
<meta property="article:modified_time" content="2022-07-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://qizhengzou.github.io/logo.png"/>

<meta name="twitter:title" content="Linear_algebra"/>
<meta name="twitter:description" content="线性代数 开篇词 | 从今天起，学会线性代数 朱维刚 2020-07-27 机器学习本身没有多大难度，因为经过多年的积累后，很多规则已经成型了。对于我们来说真正难的，是机"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://qizhengzou.github.io/linear_algebra/" /><link rel="prev" href="https://qizhengzou.github.io/cp_practice/" /><link rel="next" href="https://qizhengzou.github.io/sek_geek/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Linear_algebra",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/qizhengzou.github.io\/linear_algebra\/"
        },"image": ["https:\/\/qizhengzou.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "math","wordcount":  7941 ,
        "url": "https:\/\/qizhengzou.github.io\/linear_algebra\/","datePublished": "2022-07-20T10:04:29+08:00","dateModified": "2022-07-20T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "Jefo","logo": "https:\/\/qizhengzou.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Jefo"
            },"description": ""
    }
    </script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-193031966-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-193031966-2');
</script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Jefo"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Jefo</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> All posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="https://github.com/qizhengzou" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="直接搜索更方便^-^" id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Jefo"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Jefo</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="直接搜索更方便^-^" id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">All posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="https://github.com/qizhengzou" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Linear_algebra</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Jefo</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/school-courses/"><i class="far fa-folder fa-fw"></i>School courses</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-07-20 10:04:29">2022-07-20 10:04:29</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 7941 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 16 分钟&nbsp;<span id="busuanzi_container_page_pv">
                    <i class="far fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;次阅读量</span>
                </span>
            </div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#开篇词--从今天起学会线性代数">开篇词 | 从今天起，学会线性代数</a>
      <ul>
        <li><a href="#到底该怎么学线性代数">到底该怎么学线性代数？</a></li>
      </ul>
    </li>
    <li><a href="#基础">基础</a></li>
    <li><a href="#01--导读如何在机器学习中运用线性代数工具">01 | 导读：如何在机器学习中运用线性代数工具？</a>
      <ul>
        <li><a href="#从机器学习到线性代数">从机器学习到线性代数</a></li>
        <li><a href="#鸢尾花分类问题中的线性代数">鸢尾花分类问题中的线性代数</a></li>
        <li><a href="#本节小结">本节小结</a></li>
      </ul>
    </li>
    <li><a href="#02--基本概念线性代数研究的到底是什么问题">02 | 基本概念：线性代数研究的到底是什么问题？</a>
      <ul>
        <li><a href="#代数和线性代数的基本概念">代数和线性代数的基本概念</a></li>
        <li><a href="#向量的基本概念">向量的基本概念</a></li>
        <li><a href="#线性方程组的应用">线性方程组的应用</a></li>
        <li><a href="#线性方程组的几何表达">线性方程组的几何表达</a></li>
        <li><a href="#小结">小结</a></li>
      </ul>
    </li>
    <li><a href="#03--矩阵为什么说矩阵是线性方程组的另一种表达">03 | 矩阵：为什么说矩阵是线性方程组的另一种表达？</a></li>
    <li><a href="#04--解线性方程组为什么用矩阵求解的效率这么高">04 | 解线性方程组：为什么用矩阵求解的效率这么高？</a></li>
    <li><a href="#05--线性空间如何通过向量的结构化空间在机器学习中做降维处理">05 | 线性空间：如何通过向量的结构化空间在机器学习中做降维处理？</a></li>
    <li><a href="#06--线性无关如何理解向量在n维空间的几何意义">06 | 线性无关：如何理解向量在N维空间的几何意义？</a></li>
    <li><a href="#07--基和秩为什么说它表达了向量空间中有用的向量个数">07 | 基和秩：为什么说它表达了向量空间中“有用”的向量个数？</a></li>
    <li><a href="#08--线性映射如何从坐标系角度理解两个向量空间之间的函数">08 | 线性映射：如何从坐标系角度理解两个向量空间之间的函数？</a></li>
    <li><a href="#09--仿射空间如何在图形的平移操作中大显身手">09 | 仿射空间：如何在图形的平移操作中大显身手？</a></li>
    <li><a href="#10--解析几何为什么说它是向量从抽象到具象的表达">10 | 解析几何：为什么说它是向量从抽象到具象的表达？</a></li>
    <li><a href="#应用篇">应用篇</a></li>
    <li><a href="#11--如何运用线性代数方法解决图论问题">11 | 如何运用线性代数方法解决图论问题？</a></li>
    <li><a href="#12--如何通过矩阵转换让3d图形显示到二维屏幕上">12 | 如何通过矩阵转换让3D图形显示到二维屏幕上？</a></li>
    <li><a href="#13--如何通过有限向量空间加持的希尔密码提高密码被破译的难度">13 | 如何通过有限向量空间加持的希尔密码，提高密码被破译的难度？</a></li>
    <li><a href="#14--如何在深度学习中运用数值代数的迭代法做训练">14 | 如何在深度学习中运用数值代数的迭代法做训练？</a></li>
    <li><a href="#15--如何从计算机的角度来理解线性代数">15 | 如何从计算机的角度来理解线性代数？</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="线性代数">线性代数</h1>
<h2 id="开篇词--从今天起学会线性代数">开篇词 | 从今天起，学会线性代数</h2>
<p>朱维刚 2020-07-27</p>
<p>机器学习本身没有多大难度，因为经过多年的积累后，很多规则已经成型了。对于我们来说真正难的，是机器学习背后的算法所涉及的基础数学原理，包括向量、矩阵等等。我们可以来看下机器学习的整个知识体系。单从数学角度来看，这个覆盖范围非常广，有向量积分、矩阵分解等等，但最最核心的还是线性代数。所以说，不要再问我为什么自己学不会机器学习、人工智能了，因为你没有学好线性代数。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079"
        data-srcset="https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079, https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079 1.5x, https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079"
        title="img" /></p>
<p>不过，你可千万不要觉得，学了线性代数之后，实际应用就只有机器学习。如果这么想，那就太局限了。线性代数是计算机很多领域的基础。比如，如何让 3D 图形显示到二维屏幕上？这是线性代数在图形图像学中的应用。如何提高密码被破译的难度？这个密码学问题，用线性代数中的有限向量空间可以很好地解决。线性代数的应用真的非常广泛。掌握了线性代数这样的基础学科知识，我们其实就相当于有了数学这个利器，为其他领域的实际应用打下了非常好、非常扎实的基础。最简单、最直接的利益——你不仅可以在工作中进行算法调优，还能成为公司创新团队的主力。</p>
<h3 id="到底该怎么学线性代数">到底该怎么学线性代数？</h3>
<p>既然线性代数是机器学习最底层的知识，如果我们想要在机器学习上有所作为，学会线性代数是必须的。那该怎么学呢？我估计你肯定看过外面很多书或者课程，我也看过。它们无一例外都是直接上来就给你讲机器学习的应用实践，然后里面穿插了一些数学知识，从实践的角度切入。这样编排课程当然没问题，优点是入门容易，但它的缺点也是显而易见的。这样学下来，很多时候，你只知道固定的应用场景，死记硬背几个知识点容易，但是数学知识并不牢固。当遇到实际问题的时候，你除了套公式之外，还是只能干瞪眼，根本没有真正吃透背后的原理。因此，从我自己学习的经验出发，在技术领域里，我更推荐自下而上的学习方式，也就是从底层基础概念开始，一步步循序渐进往上走，一直走到应用实践。当然，这个方式也有缺点，那就是入门的时候困难，可能会遇到很多知识阻碍，很多人都会中途放弃。这些学习经历我都深有体会。所以，我运用了自下而上的方式来进行讲解，同时，讲解每个知识点的时候，我都会加入一些和理论有关的实践讲解。这样就能够帮你由里及表，融会贯通，在搭建起知识体系的同时，可以获得螺旋式上升的学习效果。为了让你能更加系统地学习线性代数，在设计“重学线性代数”这门课时，我还真是下了一番苦功夫。下面就给你详细介绍下这门课的两大模块。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672"
        data-srcset="https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672, https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672 1.5x, https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672"
        title="img" /></p>
<p>第一个模块是基础篇，我们主要讲线性代数的理论基础。我会从最简单、也是你最熟悉的线性方程组说起，在这基础上引出向量和矩阵，并通过矩阵来讲“解线性方程组”的不同方法（有直接法，也有实践中用得最多的间接迭代法）。然后，我会在向量和矩阵的基础上讲线性空间，因为在实践中，更多的是对集合的操作，也就是对线性空间的操作。线性空间好比是容器，它包含了向量以及向量的运算。基础篇的最后，我还会为你介绍解析几何，是解析几何使得向量从抽象走向了具象，让向量具有了几何的含义，比如：计算向量的长度、之间的距离和角度，这在机器学习的主成分分析 PCA 中是非常有用的。</p>
<p>第二个模块是应用篇，我会结合线性代数的基础理论，讲解线性代数在计算机科学中的应用。有了之前的基础后，你再来看应用实践就会觉得简单很多。当其中会涉及一些线性代数以外的数学领域时，我也会给予一定的说明。特别地，我要强调一下。在每一讲最后我都特意设计了“线性代数练习场”，带你通过练习来巩固学到的知识点。所以，这个小板块一定要重视起来，期待和你一起在实践中探索。所以从整体来说，“重学线性代数”可以满足你四个层次的需求：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986"
        data-srcset="https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986, https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986 1.5x, https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986"
        title="img" /></p>
<p>第一层次：在研究应用领域时，希望能够理解数学公式的意义。第二层次：在阅读线性代数参考书时，希望理解书中的内容。第三层次：能够自己实践、自己计算。第四层次：能够踏入大规模矩阵计算的世界。</p>
<p>好了，到这里，我想说的已经差不多了，不知道你有没有准备好，跟我一起学习了呢？进入 DT 时代后，很多企业都开始着手做数字化转型。站在从业者的角度，有了数字化的基础数据，我相信，终有一天人工智能将定义下一代软件解决方案，这是一个巨大的机会。我希望在这个机会真正到来前，你能和我一起，一步步地、深入浅出地学习线性代数这门数学基础课，成为企业研究机构的创新力量之一。我也非常希望，通过这门课程的学习，你能对线性代数能有一个重新的认识，让线性代数融入到你的工作和生活中，真正改变你的工作和生活，让它成为你的翅膀。</p>
<h2 id="基础">基础</h2>
<h2 id="01--导读如何在机器学习中运用线性代数工具">01 | 导读：如何在机器学习中运用线性代数工具？</h2>
<p>在开篇词中，我和你大致讲过我自己的经历，从 2006 年开始到现在 14 年的时间里，我都专注于机器学习领域。对于线性代数在机器学习中的应用，我非常了解。而这也是线性代数最主要的应用场景之一。因此，今天第一节课，我想先和你聊一聊，如何在机器学习中运用线性代数工具，在我们开始自下而上的学习之前，先从上层来看一看。我们都知道，“数据”是机器学习的前提，机器学习的第一步就是要进行数据的收集、预处理和特征提取；而模型就是通过数据来学习的算法；学习则是一个循环过程，一个自动在数据中寻找模式，并不停调优模型参数的过程。那我们就从机器学习的三个核心概念：数据、模型和学习说起。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076"
        data-srcset="https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076, https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076 1.5x, https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076"
        title="img" /></p>
<p>你看，不论是模型，还是学习，都涉及数据，而数据加上模型和学习，就是数学的一般过程了，也就是：观察、实验、推理和抽象。所以，我认为学好数学，不仅有利于理解复杂的机器学习系统，还能调优算法参数，甚至能帮助你创建新的机器学习解决方案。</p>
<h3 id="从机器学习到线性代数">从机器学习到线性代数</h3>
<p>那机器学习和线性代数之间到底有着怎样的关系呢？我想，用一个实际的机器学习算法的例子来解释，你可能更容易搞清楚。接下来，我使用 KNN（K-Nearest Neighbor，K 最近邻分类算法）来让你简单了解一下机器学习，以及它和线性代数之间的关系。之所以选 KNN 分类算法，因为它是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。这个方法的思路是：如果一个样本在特征空间中的 K 个最相似（即特征空间中最邻近）的样本中的大多数属于某一个类别，则该样本也属于这个类别。这里有个前提，KNN 算法中，所选择的“邻居”都是已经正确分类的对象。KNN 分类算法在分类决策上只依据最邻近的一个或者几个样本的类别，来决定待分样本所属的类别。我们通过图来理解的话或许更容易一些。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079"
        data-srcset="https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079, https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079 1.5x, https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079"
        title="img" /></p>
<p>假设图片中那个绿色圆就要是我们要决策的对象，那么根据 KNN 算法它属于哪一类？是红色三角形还是蓝色四方形？如果 K=3（实线圆），也就是包含离绿色圆最近的 3 个，由于红色三角形所占比例为 2/3，绿色圆就属于红色三角形那个类。但如果 K=5（虚线圆），就是包含离绿色圆最近的 5 个，由于蓝色四方形比例为 3/5，绿色圆就属于蓝色四方形那个类。</p>
<h3 id="鸢尾花分类问题中的线性代数">鸢尾花分类问题中的线性代数</h3>
<p>通过前面这个小例子，你应该已经理解了 KNN 算法的概念。那么接下来，我们就试着使用 KNN 在给定鸢尾花特征值的情况下，给鸢尾花做花种分类，带你来实际看一下线性代数在这里起到的作用。特别说明一下，鸢尾花分类问题是一个国际上通用的案例，一般都被作为机器学习入门来使用，所以它的数据集也是公开的。</p>
<ol>
<li>数据集的收集、加载和分析首先，我们要做的是数据集的收集、加载和分析，你也可以点击<a href="https://www.kaggle.com/notlir/iriscsv" target="_blank" rel="noopener noreffer">这里</a>下载原始数据集，来看看原始数据长什么样，下面是获取和加载数据的代码，sklearn 数据集已经包含了样本数据，你可以直接用。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import pandas as pd

from sklearn import datasets
iris = datasets.load_iris()

species = [iris.target_names[x] for x in iris.target]

iris = pd.DataFrame(iris[&#39;data&#39;], columns = [&#39;Sepal_Length&#39;, &#39;Sepal_Width&#39;, &#39;Petal_Length&#39;, &#39;Petal_Width&#39;])

iris[&#39;Species&#39;] = species
</code></pre></td></tr></table>
</div>
</div><p>从显示的结果，我们能够看出鸢尾花有四个特征：花萼的长、宽和花瓣的长、宽。我们来看下这四个特征的数据类型：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">iris.dtypes
Sepal_Length    float64
Sepal_Width     float64
Petal_Length    float64
Petal_Width     float64
Species          object
dtype: object
</code></pre></td></tr></table>
</div>
</div><p>这些特征都是数值型，而且标签 Species 表示的是花种，是一个字符串类型的变量。我们继续看一下鸢尾花的分类统计：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">iris[&#39;count&#39;] = 1
iris[[&#39;Species&#39;, &#39;count&#39;]].groupby(&#39;Species&#39;).count()
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078"
        data-srcset="https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078, https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078 1.5x, https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078"
        title="img" /></p>
<p>这里我们直接能够看到，鸢尾花有三个花种，每个种类有 50 个实例，或者说 50 条数据，我们再用图来更直观地显示这三种鸢尾花。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
%matplotlib inline

def plot_iris(iris, col1, col2):
    import seaborn as sns
    import matplotlib.pyplot as plt

    sns.lmplot(x = col1, y = col2,
               data = iris,
               hue = &#34;Species&#34;,
               fit_reg = False)

    plt.xlabel(col1)

    plt.ylabel(col2)

    plt.title(&#39;Iris species shown by color&#39;)

    plt.show()

plot_iris(iris, &#39;Petal_Width&#39;, &#39;Sepal_Length&#39;)

plot_iris(iris, &#39;Sepal_Width&#39;, &#39;Sepal_Length&#39;)
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326"
        data-srcset="https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326, https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326 1.5x, https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326"
        title="img" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324"
        data-srcset="https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324, https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324 1.5x, https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324"
        title="img" /></p>
<p>蓝、黄、绿，这三种颜色分别代表了三种鸢尾花，显示还是很清楚的。</p>
<ol start="2">
<li>数据集的准备 接下来的第二步就是数据集的准备了。在训练任何机器学习模型前，数据准备都相当重要，这里也要涉及两步准备。第一步，特征数值标准化。如果我们不做标准化，后果就是大数值特征会主宰模型训练，这会导致更有意义的小数值特征被忽略。这里我们用 Z Score 标准化，使每一类特征平均值为 0，方差为 1.0，我们可以通过代码实现来看下效果。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from sklearn.preprocessing import scale

import pandas as pd

num_cols = [&#39;Sepal_Length&#39;, &#39;Sepal_Width&#39;, &#39;Petal_Length&#39;, &#39;Petal_Width&#39;]

iris_scaled = scale(iris[num_cols])

iris_scaled = pd.DataFrame(iris_scaled, columns = num_cols)

print(iris_scaled.describe().round(3))
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079"
        data-srcset="https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079, https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079 1.5x, https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079"
        title="img" /></p>
<p>你可以看到，每一列平均值为 0，标准差大约是 1.0。为了分类需要，我们用字典把花种从字符串类型转换成数字表示。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
levels = {&#39;setosa&#39;:0, &#39;versicolor&#39;:1, &#39;virginica&#39;:2}

iris_scaled[&#39;Species&#39;] = [levels[x] for x in iris[&#39;Species&#39;]]

iris_scaled.head()
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078"
        data-srcset="https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078, https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078 1.5x, https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078"
        title="img" /></p>
<p>第二步，把数据集随机分割成样本训练集和评估数据集，训练集用来训练 KNN 模型，评估集用来测试和评估 KNN 的分类结果。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
from sklearn.model_selection import train_test_split

import numpy as np

np.random.seed(3456)

iris_split = train_test_split(np.asmatrix(iris_scaled), test_size = 75)

iris_train_features = iris_split[0][:, :4]

iris_train_labels = np.ravel(iris_split[0][:, 4])

iris_test_features = iris_split[1][:, :4]

iris_test_labels = np.ravel(iris_split[1][:, 4])

print(iris_train_features.shape)

print(iris_train_labels.shape)

print(iris_test_features.shape)

print(iris_test_labels.shape)
</code></pre></td></tr></table>
</div>
</div><p>通过代码，我们得到了下面这样的结果。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">
(75, 4)
(75,)
(75, 4)
(75,)
</code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>训练模型 数据准备好后，就是第三步训练模型了。这里我们使用 K=3 来训练 KNN 模型，当然你也可以调整这个参数来进行观察和调优。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">from sklearn.neighbors import KNeighborsClassifier

KNN_mod = KNeighborsClassifier(n_neighbors = 3)

KNN_mod.fit(iris_train_features, iris_train_labels)
</code></pre></td></tr></table>
</div>
</div><ol start="4">
<li>模型测试 执行 KNN 训练后，我们来到了最后一步，模型测试，这里我们使用测试集来测试模型。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">iris_test = pd.DataFrame(iris_test_features, columns = num_cols)

iris_test[&#39;predicted&#39;] = KNN_mod.predict(iris_test_features)

iris_test[&#39;correct&#39;] = [1 if x == z else 0 for x, z in zip(iris_test[&#39;predicted&#39;], iris_test_labels)]

accuracy = 100.0 * float(sum(iris_test[&#39;correct&#39;])) / float(iris_test.shape[0])

print(accuracy)
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">96.0
</code></pre></td></tr></table>
</div>
</div><p>最终，我们得到的准确率是 96.0，说明了 KNN 的训练模型不错，适用这类场景。我们通过代码把其中的两个分类 setosa 和 versicolor 打印出来看看。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">levels = {0:&#39;setosa&#39;, 1:&#39;versicolor&#39;, 2:&#39;virginica&#39;}

iris_test[&#39;Species&#39;] = [levels[x] for x in iris_test[&#39;predicted&#39;]]

markers = {1:&#39;^&#39;, 0:&#39;o&#39;}

colors = {&#39;setosa&#39;:&#39;blue&#39;, &#39;versicolor&#39;:&#39;green&#39;,}

def plot_shapes(df, col1,col2,  markers, colors):
    import matplotlib.pyplot as plt
    import seaborn as sns

    ax = plt.figure(figsize=(6, 6)).gca() # define plot axis

    for m in markers: # iterate over marker dictioary keys
        for c in colors: # iterate over color dictionary keys
            df_temp = df[(df[&#39;correct&#39;] == m)  &amp; (df[&#39;Species&#39;] == c)]
            sns.regplot(x = col1, y = col2,
                        data = df_temp, 
                        fit_reg = False,
                        scatter_kws={&#39;color&#39;: colors[c]},
                        marker = markers[m],
                        ax = ax)
    plt.xlabel(col1)
    plt.ylabel(col2)
    plt.title(&#39;Iris species by color&#39;)
    return &#39;Done&#39;

plot_shapes(iris_test, &#39;Petal_Width&#39;, &#39;Sepal_Length&#39;, markers, colors)
plot_shapes(iris_test, &#39;Sepal_Width&#39;, &#39;Sepal_Length&#39;, markers, colors)
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168"
        data-srcset="https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168, https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168 1.5x, https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168"
        title="img" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094"
        data-srcset="https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094, https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094 1.5x, https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094"
        title="img" /></p>
<p>从显示的效果来说，分类还是挺明显的，熟悉了最基础的机器学习过程后，你可能会问，讲了半天，线性代数到底在哪里呢？关键就在 KNeighborsClassifier 模块上，这个模型算法的实现背后，其实用到了线性代数的核心原理。首先，因为每种鸢尾花都有四个特征：花萼的长、宽和花瓣的长、宽，所以每条数据都是四维向量。接着，量化样本之间的相似度，也就是计算向量之间的距离。而向量之间距离的运算有很多方式，比如：曼哈顿距离、欧式距离、切比雪夫距离、闵可夫斯基距离等等。其中，欧式距离你应该很熟悉了，因为我们初中都学过，在二维平面上计算两点之间的距离公式：</p>
<p>$$
d=\sqrt{\left(x_{1}-x_{2}\right)^{2}+\left(y_{1}-y_{2}\right)^{2}}
$$</p>
<p>扩展到我们实例中的四维向量，也是同样的算法。你看，这就是线性代数在机器学习中的一种应用场景。KNN 是一种监督学习算法，因为在样本集中有分类信息，通过计算距离来衡量样本之间相似度，算法简单，易于理解和实现。还有另一种机器学习算法是无监督学习，底层的数学原理其实也是差不多的，总的思想就是“物以类聚”。现在，你是不是有一种豁然开朗的感觉？终于看到了线性代数原来那么有意义，而且再简单的公式也是美的。</p>
<h3 id="本节小结">本节小结</h3>
<p>好了，到这里导读这一讲就结束了，最后我再总结一下前面讲解的内容。这一讲我使用机器学习的监督学习算法 KNN，在给定鸢尾花特征值的情况下，给鸢尾花做花种分类，让你了解机器学习最基本的过程外，能够真正了解其背后的线性代数真相，为你进入后面课程的学习提供一个感性的认知。机器学习中用到的线性代数知识点比比皆是，而且往往软件架构上看上去复杂的事情，在数学上反而很简单，希望你在学习了这门课程后，能够多从数学角度出发去构思解决问题的方案。</p>
<h2 id="02--基本概念线性代数研究的到底是什么问题">02 | 基本概念：线性代数研究的到底是什么问题？</h2>
<p>线性代数可以运用在很多领域，比如：工程学、计算机科学、经济学、信号处理等等。我们来看一个在经济学中常见的例子：消费矩阵。假设有 n 个行业，比如：化学、食品和石油。制造一单位的某化学品需要 0.2 单位的另一类化学品，0.3 单位的食品，以及 0.4 单位的石油，而制造一单位的某食品和某石油也同样分别需要这三类产品的输入，于是，我们就能构造这样一个消费矩阵：</p>
<p>$$
\left|\begin{array}{l}
\text { 化学输出 } \
\text { 食吕输出 } \
\text { 石油输出 }
\end{array}\right|=\left[\begin{array}{lll}
0.2 &amp; 0.3 &amp; 0.4 \
0.4 &amp; 0.4 &amp; 0.1 \
0.5 &amp; 0.1 &amp; 0.3
\end{array}\right] \mid \begin{aligned}
&amp;\text { 化学输入 } \
&amp;\text { 食吕输入 } \
&amp;\text { 石油输入 }
\end{aligned}
$$</p>
<p>当然，我们也可以用一般的线性方程组 Ax=b 的形式来表达：</p>
<p>$$
\left{\begin{array}{l}
0.2 x_{1}+0.3 x_{2}+0.4 x_{3}=b_{1} \
0.4 x_{1}+0.4 x_{2}+0.1 x_{3}=b_{2} \
0.5 x_{1}+0.1 x_{2}+0.3 x_{3}=b_{3}
\end{array}\right.
$$
从本质上来说，消费矩阵解决的是输入和输出之间的关系。不仅如此，线性代数在现实生活中的运用还有很多，比如，我们可以借用特征值和特征向量，预测若干年后的污水水平；在密码学中，可以使用矩阵及其逆矩阵对需发送的消息加密；在机器学习中，可以使用线性方程组的共轭迭代法来训练神经网络，等等。刚才我分别用矩阵和线性方程组的形式给出了消费矩阵，当然，在实际生活中，你可以灵活选择最有效的方式来解决问题。我们可以看到，线性方程组可以表示成一般形式，也就是你初中学到的 Ax=b 的形式，也可以表示成矩阵形式。矩阵是由向量组合而成的，比如刚才例子中的系数矩阵的每一行都是一个行向量，每一列都是一个列向量。</p>
<p>$$
\left[\begin{array}{lll}
0.2 &amp; 0.3 &amp; 0.4 \
0.4 &amp; 0.4 &amp; 0.1 \
0.5 &amp; 0.1 &amp; 0.3
\end{array}\right]
$$</p>
<p>从这里我们能看出，向量其实就会是线性代数最基础的核心。数学对抽象思维要求很高，简单来说，抽象思维就是抽取同类事物的共性。所以，在进入具体的线性方程组的主题前，我要先从数学抽象的角度说一说代数和线性代数，这也是深入理解后面内容的前提。</p>
<h3 id="代数和线性代数的基本概念">代数和线性代数的基本概念</h3>
<p>那什么是代数呢？百度百科的解释是这样的：</p>
<p>代数是研究数、数量、关系、结构与代数方程（组）的通用解法及其性质的数学分支。</p>
<p>但我觉得这个解释其实没有说出代数这个概念的重点。我的理解是这样的：代数是构造一系列对象和一系列操作这些对象的规则。所以你看，代数这个概念的核心就两点，对象和操作对象的规则，这样就很好理解了吧？那有了代数的定义，线性代数就很好定义了。我们类比来看，线性代数其实就是向量，以及操作这些向量的规则。这里，向量映射到对象，向量的规则映射到对象的规则，因此线性代数是代数的具像化表达。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024"
        data-srcset="https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024, https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024 1.5x, https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024"
        title="img" /></p>
<h3 id="向量的基本概念">向量的基本概念</h3>
<p>那什么是向量呢？从样子来看，向量其实就是由字母加上它上面的箭头来表示的，比如我们一版会写成 x。我估计你在高中或大学里已经接触过“几何向量”。那么，下面我用更抽象的数学观点来给你解释一下。向量，也叫欧几里得向量（Euclidean Vector），其实就是能够互相相加、被标量乘的特殊对象。而标量也叫“无向量”，它只有数值大小，没有方向。怎么理解呢？我们来看一些向量的例子，通过这些例子来深入理解向量的概念。几何向量是有向线段，在二维空间（也就是平面）中，两个几何向量能够相加，比如，向量 x 加上向量 y 等于向量 z，x+y​=z ，x 向量也能被一个标量乘。再比如，标量 λ 乘向量 x 结果也是向量，λx,λ∈R。几何向量通过大小和方向来简化向量的表达，所以，一般数学课程一开始都会拿几何向量来进行举例。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142"
        data-srcset="https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142, https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142 1.5x, https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142"
        title="img" /></p>
<p>多项式其实也是向量。两个多项式能够相加，它也能够被标量乘，结果也是多项式。矩阵的一行或一列也是向量。就比如下面这样形式的向量。</p>
<p>$$
x \in R^{3}: x=\left[\begin{array}{l}
1 \
2 \
3
\end{array}\right]
$$</p>
<p>两个向量能够相加，它也能够被标量乘，结果也是向量。它和现代大部分的编程语言中的数组一致，而且数组的运算简化了向量操作的算法实施。矢量图、音频信号也是向量。它们都能被一系列数字表示，比如，在音频信号处理中，常用到数据增强的方法，通过向量的操作就能到达目标。看了这些向量例子，不知道你现在有点感觉了吗？其实，线性代数的本质就是寻找向量之间的相似性，比如在做分类时，我们常常需要估算不同样本之间的相似性度量（Similarity Measurement），这时通常采用的方法就是计算样本间的“距离”（Distance）。</p>
<p>可以看出来，向量非常重要，我们后面很多内容都是从向量延伸而来的，比如矩阵和求解线性方程组。下面我用一张图来表达和向量有关的所有概念，也就是线性代数所有的核心内容，其中大部分内容你都会学到，希望通过这个图，你对线性代数有个大概的认知。相信学习完所有课程后，你再回过头来看时，肯定会有一些新的认知。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472"
        data-srcset="https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472, https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472 1.5x, https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472"
        title="img" /></p>
<p>从图中最左侧这一列，我们可以看出，向量组合成矩阵，矩阵可以表示成线性方程组，而线性方程组可以通过高斯消元法求解，也可以求逆矩阵。同时，向量又可以组合成向量空间，向量空间和矩阵都可以做线性映射或者线性变换，线性映射在实践中可以用在解析几何和分类问题中。而且，向量和线性独立是强相关的，也就是说，线性独立指的是向量的线性独立，而线性独立又可以引出能够生成整个空间的基（Basis），基在实践中可以用在分类和降维中。这里，我再额外提一个非常重要的、在数学中经常用到的概念——封闭性，或者俗称闭包（Closure）。封闭性的定义是，如果我们要对某个集合的成员进行一种运算，生成的仍然是这个集合的成员，那这个集合就可以称为在这个运算下闭合。我为什么要提这个概念呢？这是因为，向量的线性运算是封闭的，也就是说向量的加法、数乘结果仍属于向量空间，即向量的任意线性组合仍属于向量空间。</p>
<h3 id="线性方程组的应用">线性方程组的应用</h3>
<p>……</p>
<h3 id="线性方程组的几何表达">线性方程组的几何表达</h3>
<p>……</p>
<h3 id="小结">小结</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021"
        data-srcset="https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021, https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021 1.5x, https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021"
        title="img" /></p>
<h2 id="03--矩阵为什么说矩阵是线性方程组的另一种表达">03 | 矩阵：为什么说矩阵是线性方程组的另一种表达？</h2>
<p>在开始学习之前，我想先问你个问题，你觉得，学习矩阵有什么用呢？你可以先自己想一想。之后我们讲任何一个知识的时候，你都可以从这个角度出发，自己先思考一下，这样有助于你对所学内容理解得更深刻。对于刚才那个问题，我的答案很简单，就一句话，从我们程序员的角度去理解的话，矩阵可以极大地提高计算机的运算效率。怎么说呢？我给你举一个例子。在机器学习中（特别是深度学习，或者更具体一点，神经网络），并行计算是非常昂贵的。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661"
        data-srcset="https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661, https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661 1.5x, https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661"
        title="img" /></p>
<p>上图是一个典型的神经网络架构，在这时候，矩阵就能发挥用武之地了，计算 H 隐藏层输出的公式是：H=f(W.x+b)，其中 W 是权重矩阵，f 是激活函数，b 是偏差，x 是输入层矩阵。而这个计算过程就叫做向量化（Vectorization），这也是 GPU 在深度学习中非常重要的原因，因为 GPU 非常擅长做类似矩阵乘之类的运算。</p>
<p>不过，矩阵也不仅仅局限于神经网络的应用，同时它也可以用在计算机图形图像的应用中，比如，三维物体从取景到屏幕的显示，就需要经历一系列的空间变换，才能生成二维图像显示在显示器上。在这个计算过程中，我们都需要用到矩阵。矩阵是非常实用的，但它正式作为数学中的研究对象出现，其实是在行列式的研究发展起来之后。英国数学家 Arthur Cayley 被公认为矩阵论的创立人，他提出的矩阵概念可能来自于行列式。但我相信另一种说法，提出矩阵是为了更简单地表达线性方程组，也就是说，矩阵是线性方程组的另一种表达。</p>
<p>只有相邻阶数匹配的矩阵才能相乘，例如，一个 n×k 矩阵 A 和一个 k×m 矩阵 B 相乘，最后得出 n×m 矩阵 C，而这里的 k 就是相邻阶数。</p>
<h2 id="04--解线性方程组为什么用矩阵求解的效率这么高">04 | 解线性方程组：为什么用矩阵求解的效率这么高？</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948"
        data-srcset="https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948, https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948 1.5x, https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948"
        title="img" /></p>
<h2 id="05--线性空间如何通过向量的结构化空间在机器学习中做降维处理">05 | 线性空间：如何通过向量的结构化空间在机器学习中做降维处理？</h2>
<h2 id="06--线性无关如何理解向量在n维空间的几何意义">06 | 线性无关：如何理解向量在N维空间的几何意义？</h2>
<h2 id="07--基和秩为什么说它表达了向量空间中有用的向量个数">07 | 基和秩：为什么说它表达了向量空间中“有用”的向量个数？</h2>
<h2 id="08--线性映射如何从坐标系角度理解两个向量空间之间的函数">08 | 线性映射：如何从坐标系角度理解两个向量空间之间的函数？</h2>
<h2 id="09--仿射空间如何在图形的平移操作中大显身手">09 | 仿射空间：如何在图形的平移操作中大显身手？</h2>
<h2 id="10--解析几何为什么说它是向量从抽象到具象的表达">10 | 解析几何：为什么说它是向量从抽象到具象的表达？</h2>
<h2 id="应用篇">应用篇</h2>
<h2 id="11--如何运用线性代数方法解决图论问题">11 | 如何运用线性代数方法解决图论问题？</h2>
<h2 id="12--如何通过矩阵转换让3d图形显示到二维屏幕上">12 | 如何通过矩阵转换让3D图形显示到二维屏幕上？</h2>
<h2 id="13--如何通过有限向量空间加持的希尔密码提高密码被破译的难度">13 | 如何通过有限向量空间加持的希尔密码，提高密码被破译的难度？</h2>
<h2 id="14--如何在深度学习中运用数值代数的迭代法做训练">14 | 如何在深度学习中运用数值代数的迭代法做训练？</h2>
<h2 id="15--如何从计算机的角度来理解线性代数">15 | 如何从计算机的角度来理解线性代数？</h2>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2022-07-20 00:00:00</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://qizhengzou.github.io/linear_algebra/" data-title="Linear_algebra" data-hashtags="math"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://qizhengzou.github.io/linear_algebra/" data-hashtag="math"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Reddit" data-sharer="reddit" data-url="https://qizhengzou.github.io/linear_algebra/"><i class="fab fa-reddit fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="https://qizhengzou.github.io/linear_algebra/" data-title="Linear_algebra"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://qizhengzou.github.io/linear_algebra/" data-title="Linear_algebra"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="https://qizhengzou.github.io/linear_algebra/" data-title="Linear_algebra"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/baidu.svg"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/math/">math</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/cp_practice/" class="prev" rel="prev" title="Cp_practice"><i class="fas fa-angle-left fa-fw"></i>Cp_practice</a>
            <a href="/sek_geek/" class="next" rel="next" title="SEK_geek.md">SEK_geek.md<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://jefos-blog.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"J0OW8CCKJZ","algoliaIndex":"JF","algoliaSearchKey":"3b4a19e831c95174aca4c03fcdf95f5c","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
