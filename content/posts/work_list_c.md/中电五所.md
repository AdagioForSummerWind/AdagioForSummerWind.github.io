
## 0323
即兴发言容易卡壳，简单的说，**说话都说不清楚**
1. 介绍一下个人独立开发，还是和大团队共同开发 团队开发
2. 开源社区踪迹 github和stackoverflow
3. 平时的关注点 让我介绍一下云原生 我说云原生整个架构很复杂，我最近在学kubernetes。容器编排相关的（就是说，你说一个名词，最好能够解释好它）
4. 未来打算，技术专家还是技术团队管理 纵向发展

提问，大概未来就是，可以提前实习，然后晋升助理工程师后确定方向继续发展，本科硕士博士区别对待。






## 自我介绍
面试官您好，我叫邹啟正，是一名哈尔滨工业大学深圳本科应届生，非常有幸能够参加贵所的面试。

因为希望从事软件开发相关工作，我现在简要介绍一下我的编程历程，大学接触编程，大一的时候和小组用Java 写了一个简单的安卓app，后面大二的时候用C++和同学一起开发了一款简单的回合策略游戏，大三中段的时候了解到了golang。第一次用 go 写项目是数据库的大作业，设计实现一个实验室软件管理系统，当时就用go 写了服务端代码，算是入门了go web 开发，去年暑假前参加了字节后端青训营，参与了极简抖音后端API的开发，也是使用go语言，不过当时小组开发的是单体项目。后来我将这个抖音后端项目重构成了微服务的项目。

总得来说呢，我对技术还是挺有热情的，喜欢探索新技术，学习新知识。就像我最近的话在学习kubernetes，这是用于容器编排的技术，因为微服务是围绕着容器来开发、部署和运行，我觉得微服务是未来的一个趋势。然后呢我也比较注重团队合作和沟通，像之前小组开发安卓APP，小组开发小游戏，沟通合作都没有什么问题。

最后呢，我对贵所，也就是赛宝实验室感兴趣，作为中国第一个专业的质量可靠性研究所，因为我认为这是一个充满机遇和挑战的地方。也非常希望能够在这里工作学习成长，谢谢。



## 你介绍一下你的项目吧 
DYTT 是我做的一个基于 Gin 和 gRPC 开发的抖音后端项目，包括 API 网关以及一些业务服务，（比如 用户 服务实现了用户登陆注册获取用户主页信息的接口。一个简单的流程就是，API 服务接受 RESTful 请求，路由交给相应的 handler 处理，handler 经过参数验证后又传给 RPC 客户端，然后 RPC 客户端通过 rpc 框架发送请求数据给某个服务，并接受响应数据，然后便继续将数据向上传，最后响应 json 序列化的数据。）DAL层提供数据层实现。API服务使用Gin开放HTTP端口，同时封装了各个业务服务的RPC客户端，用来和各个业务服务进行通讯。

RPC微服务实现：接受客户端请求，在各自的command中实现与数据库交互的业务逻辑

DAL提供数据层实现，pack层将数据库的输出封装为服务端的响应结构体

难点以及怎么克服：坦白说，因为是首次构建微服务项目，遇到了很多技术细节上的麻烦，不过我通过google，或者在stackoverflow上提问都能得到一定程度的解决。

password 采用了 Argon2id 的算法去加密，本来打算用MD5,后来了解到这个密码更安全就用这个了
1. 采用 (HTTP API 层 + RPC Service 层+Dal 层) 项目结构；

2. 使用 x.509 证书对服务间通信进行加密和认证；
   首先安装证书签发工具，创建 CA 配置文件，用来配置根证书的使用场景和具体参数。然后创建证书签名请求文件 CSR 配置文件。然后通过 CFSSL工具创建 CA 证书和私钥，创建的同时会生成 csr 文件，也就是证书签名请求。用于交叉签名或者重新签名。创建完根证书以及私钥之后，创建业务服务的 csr 配置文件，最后利用根证书和私钥创建各服务的 CA 证书和私钥。

3. 使用 [go-grpc-middleware](https://github.com/grpc-ecosystem/go-grpc-middleware)中的日志记录、认证、和恢复；
   拦截器的话客户端和服务端都可以设置，分为流式拦截器和一元拦截器，根据请求调用的类型决定，请求如果是流式的用到的就是流式拦截器。grpc本身的话一种类型的拦截器只能设置一个，不用这个grpc中间件的话只能将所有逻辑耦合在一起，代码结构就不清晰了。具体的话，自己实现一下go-grpc-middleware每个拦截器相应函数类型然后传进去就行了。
   日志记录其实就是自己实现一个可以返回zap.Logger实例的 grpc-middleware ZapInterceptor 的拦截器函数， 认证的话采用了bearer令牌认证，bearer token 服务端根据密钥生成。客户端在请求服务端时，必须在请求头中包含Authorization: Bearer 。服务端收到请求后，进行解析并校验。使用bearer token是规范了与HTTP请求的对接，毕竟gRPC也可以同时支持HTTP请求。然后恢复的话把gRPC中的panic转成error，从而恢复程序。

4. 使用 **JWT** 进行用户token的校验；
   简单地实现了两个方法，创建 token 解析token，在用户注册或者登陆时创建token 在需要验证身份的时候进行解析验证
   
5. 使用 **ETCD** 进行服务发现和服务注册；（https://blog.51cto.com/u_15314183/5457223）
   服务实例定义以及一些工具函数、服务注册、服务发现
   先构造一个etcd的结构体，包括名称、地址、版本、和权重（后续做降级熔断的话会用到），工具函数包括注册路径，判断一个服务是否存在之类的
   服务注册：定义注册对象结构体，存储全部的实例信息，包括连接超时时间，etcd服务，clientv3实例等，客户端实例的grant方法能创建lease租约,相当于一个TTL存活时间，用于对etcd客户端和服务端之间进行活性检测。在到达TTL时间之前，etcd服务端不会删除相关租约上绑定的键值对；超过TTL时间就会删除，需要在TTL到来之前续租才能实现etcd服务端和客户端之间的保活。具体注册服务的时候先定义一个node存放服务信息，然后调用Register进行注册。
   服务发现：构造服务发现结构体，用了grpc/resolver这个库做解析器，创建一个基于etcd的resolver。然后有一些操作，比如服务发现，watch机制，更新节点操作，同步获取所有地址信息

6. 使用 **Minio** 实现视频文件和图片的对象存储；
   为什么使用minio：性能比较高，比较适合存储图片、视频之类的，采用golang实现，整个系统运行在用户态。

7. 使用 **Gorm** 对 MySQL 进行 ORM 操作；
   orm object-relational mapping。我觉得最大的优点是能够更好的构建查询，能相对简单地动态构造出复杂的sql语句。单纯用sql的话只是字符串意义上的拼接。
   当然也可以防sql注入，gorm通过占位符的形式一定程度上减少了sql注入
   不足：不能明确sql的内容

8. 使用 **Zipkin** 分布式追踪系统实现链路跟踪；(https://zhuanlan.zhihu.com/p/453190067)
   可以收集服务的一些计时数据，可以用于一些延迟问题的故障排除。
   reporter报告器：将服务之间的请求调用信息报告给zipkin后台，用于生成链路追踪和依赖图。包括http报告器和log报告器，HTTP报告器将请求调用信息封装为span异步报告给zipkin服务器，log报告器将服务调用信息打印到控制台。
   Endpoint: 一个标记信息，标记此服务的服务名以及地址信息，用于zipkin后台画图和分析
   Tracer追踪器：解析服务调用之间的上下文信息context,将链路信息封装为span
   grpc整合zipkin：把创建追踪器的过程封装为一个方法，进行一些初始化即可

9.  数据库表建立了索引和外键约束，对于具有关联性的操作一旦出错立刻回滚，保证数据一致性和安全性；

10. HTTP 服务和 RPC 服务的优雅停止。（https://leileiluoluo.com/posts/golang-shutdown-server-gracefully.html）
    用一个goroutine启动服务，为了不让这个启动过程阻塞后面的优雅停止。
    http服务主要就是使用 http.Server 的 Shutdown 方法结合 signal.Notify 来优雅的终止服务
    初始化一个channel，利用signal.Notify等待系统中断信号，不然就一直阻塞，当中断信号来了的时候，开始优雅关闭，关闭http.server的话直接调用标准库net/http包的Shutdown方法（由文档可知，可以优雅地终止服务，但不会直接中断活跃连接，先关闭所有闲置连接，等待活跃连接闲置后才终止服务）


数据库表建立了索引和外键约束，对于具有关联性的操作一旦出错立刻回滚，保证数据一致性和安全性；


## go
### GMP

#### GMP 模型中的 GMP 指的是什么
G（Goroutine）：我们所说的协程，为用户级的轻量级线程，每个 Goroutine对象中的 sched 保存着其上下文信息。

M（Machine）：对内核级线程的封装，数量对应真实的 CPU 数（真正干活的对象）。

P（Processor）：即为 G 和 M 的调度对象，用来调度 G 和 M 之间的关联关系，其数量可通过 GOMAXPROCS()来设置，默认为核心数。

其中 M 可能会自旋，也有可能会休眠，GC 会把一些休眠的线程销毁。 
#### GMP 模型中有什么组件

除开 GMP ，还有 P 的 G 本地队列， G 的全局队列，P 列表（MAXPROCS 决定），M 列表（最大限定 1W，runtime/debug 可以设置） 

#### GMP 调度流程
![](https://raw.githubusercontent.com/JF-011101/Image_hosting_rep/main/20221118183008.png)

- 每个 P 有个局部队列，局部队列保存待执行的 goroutine（流程 2），当 M 绑定的 P 的局部队列已经满了之后就会把 goroutine 放到全局队列（流程 2-1）
- 每个 P 和一个 M 绑定，M 是真正的执行 P 中 goroutine 的实体（流程 3），M 从绑定的 P 中的局部队列获取 G 来执行
- 当 M 绑定的 P 的局部队列为空时，M 会从全局队列获取到本地队列来执行 G（流程 3.1），当从全局队列中没有获取到可执行的 G 时候，M 会从其他 P
的局部队列中偷取 G 来执行（流程 3.2），这种从其他 P 偷的方式称为work stealing
- 当 G 因系统调用（syscall）阻塞时会阻塞 M，此时 P 会和 M 解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M 就会新建一个 M（流程 5.1）
- 当 G 因 channel 或者 network I/O 阻塞时，不会阻塞 M，M 会寻找其他 runnable 的 G；当阻塞的 G 恢复后会重新进入 runnable 进入 P 队列等待执
行（流程 5.3）
#### 5、GMP 中 work stealing 机制
获取 P 本地队列，当从绑定 P 本地 runq 上找不到可执行的 g，尝试从全局链表中拿，再拿不到从 netpoll 和事件池里拿，最后会从别的 P 里偷任务。P
此时去唤醒一个 M。P 继续执行其它的程序。M 寻找是否有空闲的 P，如果有则将该 G 对象移动到它本身。接下来 M 执行一个调度循环（调用 G 对象->执行->
清理线程→继续找新的 Goroutine 执行）

#### 6、GMP 中 hand off 机制
当本线程 M 因为 G 进行的系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的 M 执行。
细节：当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go 调度器 M 的栈保存在 G 对象上，只需要将 M 所需要的寄存
器（SP、PC 等）保存到 G 对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时
G 任务还没有执行完，M 可以将任务重新丢到 P 的任务队列，等待下一次被调度执行。当再次被调度执行时，M 通过访问 G 的 vdsoSP、vdsoPC 寄存器进行现场
恢复（从上次中断位置继续执行）

### GC
#### 常用的垃圾回收的方法:

1. **引用计数**（reference counting）
这是最简单的一种垃圾回收算法，和之前提到的智能指针异曲同工。**对每个对象维护一个引用计数，当引用该对象的对象被销毁或更新时被引用对象的引用计数自动减一，当被引用对象被创建或被赋值给其他对象时引用计数自动加一。当引用计数为0时则立即回收对象。**
这种方法的优点是实现简单，并且内存的回收很及时。这种算法在内存比较紧张和实时性比较高的系统中使用的比较广泛，如ios cocoa框架，php，python等。
但是简单引用计数算法也有明显的缺点：

**频繁更新引用计数降低了性能。**
一种简单的解决方法就是编译器将相邻的引用计数更新操作合并到一次更新；还有一种方法是针对频繁发生的临时变量引用不进行计数，而是在引用达到0时通过扫描堆栈确认是否还有临时对象引用而决定是否释放，等等还有很多其他方法。
**循环引用。**
当对象间发生循环引用时引用链中的对象都无法得到释放。最明显的解决办法是避免产生循环引用，如cocoa引入了strong指针和weak指针两种指针类型。或者系统检测循环引用并主动打破循环链。当然这也增加了垃圾回收的复杂度。

2. **标记-清除**（mark and sweep）
标记-清除（mark and sweep）分为两步，**标记从根变量开始迭代到遍历所有被引用的对象**，对能够通过应用遍历访问到的对象都进行标记为“被引用”；**标记完成后进行清除操作**，对没有标记过的内存进行回收（**回收同时可能伴有碎片整理操作**）。这种方法解决了引用计数的不足，但是也有比较明显的问题：**每次启动垃圾回收都会暂停当前所有的正常代码执行，回收使系统响应能力大大降低**！当然后续也出现了很多mark&sweep算法的变种（如三色标记法）优化了这个问题。

3. **分代搜集**（generation）
java的jvm 就使用的分代回收的思路。在面向对象编程语言中，绝大多数对象的生命周期都非常短。分代收集的基本思想是，**将堆划分为两个或多个称为代（generation）的空间。新创建的对象存放在称为新生代（young generation）中（一般来说，新生代的大小会比 老年代小很多），随着垃圾回收的重复执行，生命周期较长的对象会被提升（promotion）到老年代中**（这里用到了一个分类的思路，这个是也是科学思考的一个基本思路）。
因此，新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生，分别用于对各自空间中的对象执行垃圾回收。新生代垃圾回收的速度非常快，比老年代快几个数量级，即使新生代垃圾回收的频率更高，执行效率也仍然比老年代垃圾回收强，这是因为大多数对象的生命周期都很短，根本无需提升到老年代。
**Gc =并发标记清除垃圾回收算法。三色标记法**

原理：
首先把所有的对象都放到白色的集合中
- 从根节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中
- 遍历灰色集合中的对象，把灰色对象引用的白色集合的对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色的集合中
- 不断循环，直到灰色集合中没有对象
- 最后，白色集合中的对象就是不可达对象，也就是垃圾，进行回收

## 了解 Gin，Gorm，gRPC 等框架使用，了解 C，Python 等其他编程语言
gin是使用Go语言编写的轻量级高性能Web框架
- 高性能：GIN 在处理 HTTP 请求时采用了高性能的路由引擎，能够快速地匹配路由，并执行相应的处理函数。此外，它还支持使用协程（goroutine）来处理 HTTP 请求，从而提高并发处理能力。
- 易用性：GIN 提供了简洁、易用的 API，开发者可以很方便地创建路由、定义中间件、处理 HTTP 请求等，同时也支持自定义 HTTP 处理器和中间件。
- 轻量级：GIN 是一款轻量级的 Web 框架，使用了很少的依赖，从而减小了项目的体积，并提高了运行效率。
- 强大的功能：GIN 提供了很多强大的功能，例如路由组、请求处理、参数解析、模板渲染、日志记录、错误处理等，能够满足大部分 Web 开发的需求。

ORM（Object Relational Mapping）即对象关系映射。它是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。ORM通过使用描述对象和数据之间映射的元数据，将程序中的对象自动持久化到关系数据库中。ORM需要解决的问题是，能否把对象的数据直接保存到数据库中，又能否直接从数据库中拿到一个对象？要想做到上面两点，则必须要有映射关系。

gRPC是一种跨语言的高性能、开源的远程过程调用（RPC）框架，由Google开发。它允许客户端应用像调用本地对象一样直接调用另一台不同机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多RPC系统类似，gRPC也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个gRPC服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。

gRPC的基本通信流程如下：

客户端（gRPC Stub）调用服务端方法，发起RPC调用。
使用Protobuf对请求信息进行对象序列化压缩（IDL）。
服务端（gRPC Server）接收到请求后，解码请求体，进行业务逻辑处理并返回。
对响应结果使用Protobuf进行对象序列化压缩（IDL）。
客户端接受到服务端响应，解码请求体。回调被调用的客户端方法，唤醒正在等待响应（阻塞）的客户端调用并返回响应结果。[0]

C语言
C 语言是一种面向过程的编程语言，被广泛应用于系统编程和嵌入式系统开发等领域。它的优缺点包括：
- 运行速度快：C 语言直接编译成机器码
- 静态类型检查：C 语言是静态类型语言，
- 接近硬件：C 语言能够直接操作内存和硬件，可以实现一些底层操作，比如操作系统和驱动程序开发。
- 安全问题：C 语言没有内置的内存安全机制，容易出现内存泄漏、缓冲区溢出等安全问题。
- 不适合大型项目：C 语言的编程范式是面向过程的，对于大型项目来说，结构化的代码可能会变得复杂和难以维护。

Python 是一种面向对象的高级编程语言，被广泛应用于数据科学、机器学习、人工智能等领域。它的优点包括：
- 简单易学
- 功能强大
- 运行速度慢：Python 语言需要解释器来解释代码，因此运行速度相对较慢。
- 动态类型：Python 语言是动态类型语言，类型检查在运行时进行，容易出现一些类型错误。
- 不适合高并发：Python 语言在高并发情况下可能会有性能瓶颈，需要采取一些措施来解决。

Go 是一种静态类型的编译型语言，被广泛应用于网络编程、分布式系统等领域。原生支持并发。
## 排序
好的，以下是各个排序算法的时间复杂度和空间复杂度表格：

| 排序算法 | 时间复杂度（平均） | 时间复杂度（最坏） | 时间复杂度（最好） | 空间复杂度 | 稳定性 |
| --- | --- | --- | --- | --- | --- |
| 冒泡排序 | O(n^2) | O(n^2) | O(n) | O(1) | 稳定 |
| 选择排序 | O(n^2) | O(n^2) | O(n^2) | O(1) | 不稳定 |
| 插入排序 | O(n^2) | O(n^2) | O(n) | O(1) | 稳定 |
| 希尔排序 | O(n log n) | O(n^2) | O(n log n) | O(1) | 不稳定 |
| 归并排序 | O(n log n) | O(n log n) | O(n log n) | O(n) | 稳定 |
| 快速排序 | O(n log n) | O(n^2) | O(n log n) | O(log n) | 不稳定 |
| 堆排序 | O(n log n) | O(n log n) | O(n log n) | O(1) | 不稳定 |
| 计数排序 | O(n + k) | O(n + k) | O(n + k) | O(k) | 稳定 |
| 桶排序 | O(n + k) | O(n^2) | O(n) | O(n + k) | 稳定 |
| 基数排序 | O(nk) | O(nk) | O(nk) | O(n + k) | 稳定 |

其中，n表示待排序元素的数量，k表示元素的取值范围（桶排序和计数排序中使用）。
## 查找
查找算法时间复杂度

<table width="595" border="1" cellpadding="0"><tbody><tr><td><p align="center">查找</p></td><td><p align="left">平均时间复杂度</p></td><td><p align="left">查找条件</p></td><td><p align="left">算法描述</p></td></tr><tr><td><p align="center">顺序查找</p></td><td><p align="center">O(n)</p></td><td><p align="center">无序或有序队列</p></td><td><p align="center">按顺序比较每个元素，直到找到关键字为止</p></td></tr><tr><td><p align="center">二分查找（折半查找）</p></td><td><p align="center">O(logn)</p></td><td><p align="center">有序数组</p></td><td><p align="center">查找过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。　如果在某一步骤数组为空，则代表找不到。</p></td></tr><tr><td><p align="center">二叉排序树查找</p></td><td><p align="center">O(logn)</p></td><td><p align="center">二叉排序树</p></td><td><p align="center">在二叉查找树b中查找x的过程为：</p><p>1. 若b是空树，则搜索失败</p><p align="center">2. 若x等于b的根节点的数据域之值，则查找成功；</p><p align="center">3. 若x小于b的根节点的数据域之值，则搜索左子树</p><p>4. 查找右子树。</p></td></tr><tr><td><p align="center">哈希表法（散列表）</p></td><td><p align="center">O(1)</p></td><td><p align="center">先创建哈希表（散列表）</p></td><td><p align="center">根据键值方式(Key value)进行查找，通过散列函数，定位数据元素。</p></td></tr><tr><td><p align="center">分块查找</p></td><td><p align="center">O(logn)</p></td><td><p align="center">无序或有序队列</p></td><td><p align="center">将n个数据元素"按块有序"划分为m块（m ≤ n）。</p><p align="center">每一块中的结点不必有序，但块与块之间必须"按块有序"；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，……。然后使用二分查找及顺序查找。</p></td></tr></tbody></table>

## 三次握手
### 三次握手
TCP连接的不是主机、IP地址、应用进程。而是socket(IP+端口号)

- 连接前，CLOSED状态
* 第一次握手：建立连接时，客户端发送一个报文段（seq=x, SYN=1的报文段）到服务器，并进入SYN_SENT状态，等待服务器确认；
* 第二次握手：服务器收到这个报文段后，如果同意建立连接的话就回复一个报文段（seq=y, ack=x+1，SYN=1, ACK=1），此时服务器进入SYN_RECV状态；
* 第三次握手：客户端收到服务器的这个报文段后，向服务器发送确认报文段(seq=x+1，ack=y+1，ACK=1），此包发送完毕，客户端进入ESTABLISHED状态，服务器收到后也进入ESTABLISH状态。完成三次握手。
* 服务器更易受到SYN泛洪攻击


**为什么三次：**  主要是为了建立可靠的通信信道，保证客户端与服务端同时具备发送、接收数据的能力。

**为什么两次不行？**

1. 防止已失效的请求报文又传送到了服务端，建立了多余的链接，浪费资源。

2. **两次握手只能保证单向连接是畅通的。**（为了实现可靠数据传输， `TCP `协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。三次握手的过程即是通信双方 相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤；如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认）。

### 为什么不能两次握手

TCP是一个双向通信协议，通信双方都有能力发送信息，并接收响应。如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认

## 四次挥手

1. 客户端进程发出连接释放报文段，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文段，发出确认报文段，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。此时客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ACK=1, ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。**注意**此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命，也就是一个报文段来回时间）的时间后，客户端撤销相应的TCB(传输控制块)后，才进入CLOSED状态。如果在此过程中，服务端在规定时间内未收到确认报文段，会重复发送FIN报文段给客户端。
6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些


**为什么四次：**因为需要确保客户端与服务端的数据能够完成传输。

**CLOSE-WAIT：** 这种状态的含义其实是表示在**等待关闭**。

**TIME-WAIT：** 为了解决网络的丢包和网络不稳定所带来的其他问题，确保连接方能在时间范围内，关闭自己的连接。(为什么要有 TIME_WAIT 状态？因为客户端最后向服务器发送的确认 ACK 是有可能丢失的，当出现超时，服务端会再次发送 FIN 报文段，如果客户端已经关闭了就收不到了。)
### 为什么连接的时候是三次握手，关闭的时候却是四次握手

由于 TCP 的半关闭（half-close）特性，TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。所以简单地说两次握手就可以释放一端到另一端的 TCP 连接，完全释放连接一共需要四次握手。
而建立连接时服务器可以把ACK报文段和SYN报文段（ACK报文段起确认作用，即确认客户端的连接建立请求；SYN报文段起同步作用）放在一起发送，所以是3次。


## 索引

#### 1. 索引是什么？

索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。

索引是一种数据结构。数据库索引，是数据库管理系统中一个[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。而且索引是一个文件，它是要占据物理空间的。

MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，然后找到对应字典页码，这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。

#### 2. 索引有哪些优缺点？

**索引的优点**

- 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。
- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

**索引的缺点**

- 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；
- 空间方面：索引需要占物理空间。

#### 3. MySQL有哪几种索引类型？

主键索引: 
数据列不允许重复，不允许为 NULL，一个表只能有一个主键。

唯一索引: 
数据列不允许重复，允许为 NULL 值，一个表允许多个列创建唯一索引。
- 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索
引。
- 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创
建唯一组合索引。

普通索引: 
基本的索引类型，没有唯一性的限制，允许为 NULL 值。
- 可以通过 ALTER TABLE table_name ADD INDEX index_name (column);创建
普通索引
- 可以通过 ALTER TABLE table_name ADD INDEX index_name(column1, 
column2, column3);创建组合索引。

全文索引：是目前搜索引擎使用的一种关键技术。
- 可以通过 ALTER TABLE table_name ADD FULLTEXT (column);创建全文索
引。

```
1、从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式，

2、从应用层次来分：普通索引，唯一索引，复合索引。

- 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引
- 唯一索引：索引列的值必须唯一，但允许有空值
- 复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
- 聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。
- 非聚簇索引： 不是聚簇索引，就是非聚簇索引

3、根据中数据的物理顺序与键值的逻辑（索引）顺序关系： 聚集索引，非聚集索引。
```
## 索引底层

#### 4. 说一说索引的底层实现？

**Hash索引**

基于[哈希表](https://www.nowcoder.com/jump/super-jump/word?word=哈希表)实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。

> 图片来源：https://www.javazhiyin.com/40232.html

![img](https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752261/image-20210411215012443.png)

**B-Tree索引**（MySQL使用B+Tree）

B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。

![img](https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752112/image-20210411215023820.png)

**B+Tree索引**

是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。

B+tree性质：

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- B+ 树中，数据对象的插入和删除仅在叶节点上进行。
- B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

![img](https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752195/image-20210411215044332.png)

#### 5. 为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)，[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)？

B-tree： 从两个方面来回答

- B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对`IO读写次数就降低`了。
- 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在`区间查询`的情况，所以通常B+树用于数据库索引。

Hash：

- 虽然可以快速定位，但是没有顺序，IO复杂度高；
- 基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；
- 适合**等值查询**，如=、in()、<=>，不支持范围查询 ；
- 因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成排序 ；
- Hash索引在查询等值时非常快 ；
- 因为Hash索引始终索引的**所有列的全部内容**，所以不支持部分索引列的匹配查找 ；
- 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。

[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)： 树的高度随着数据量增加而增加，IO代价高。

## 事务

#### 1. 什么是数据库事务？

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。

事务最经典也经常被拿出来说例子就是转账了。

假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

#### 2. 介绍一下事务具有的四个特征

事务就是一组原子性的操作，这些操作要么全部发生，要么全部不发生。事务把数据库从一种一致性状态转换成另一种一致性状态。

- 原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做
- 一致性。事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。
- 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的//操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。

## 隔离级别

- Read Uncommitted（读取未提交内容）

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

- Read Committed（读取提交内容）

这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓 的 不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。

- Repeatable Read（可重读）

这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。

- Serializable（可串行化）

通过强制事务[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

![image-20210822180308501](https://uploadfiles.nowcoder.com/files/20210822/540390845_1629637246843/image-20210822180308501.png)

MySQL 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别

事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。

InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。

#### 4. 什么是脏读？幻读？不可重复读？

1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据

2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。

3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。

不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。

## 锁
锁
#### 9、MySQL 中有哪几种锁？
- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概
率最高，并发度最低。
- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概
率最低，并发度也最高。
- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界
于表锁和行锁之间，并发度一般。
#### 1. 为什么要加锁?

当多个用户并发地存取数据时，在[数据库](https://cloud.tencent.com/solution/database?from=10680)中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。

保证多用户环境下保证数据库完整性和一致性。

#### 2. 按照锁的粒度分数据库锁有哪些？

在关系型数据库中，可以**按照锁的粒度把数据库锁分**为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。

行级锁

- 行级锁是[MySQL](https://cloud.tencent.com/product/cdb?from=10680)中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
- 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

表级锁

- 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
- 开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

页级锁

- 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁
- 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

**MyISAM和InnoDB存储引擎使用的锁：**

- MyISAM采用表级锁(table-level locking)。
- InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁

#### 3. 从锁的类别上分MySQL都有哪些锁呢？

从锁的类别上来讲，有共享锁和排他锁。

- 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。
- 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。

用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。

锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。

他们的加锁开销从大到小，并发能力也是从大到小。


## os
### 进程和线程

1. 进程是操作系统资源分配的最小单位，线程是CPU任务调度的最小单位。一个进程可以包含多个线程，所以进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。
2. 不同进程间数据很难共享，同一进程下不同线程间数据很易共享。
3. 每个进程都有**独立的代码和数据空间**，进程要比线程消耗更多的计算机资源。线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己**独立的运行栈和程序计数器**，线程之间切换的开销小。
4. 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉。
5. 系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。

### 2、协程与线程的区别？
- 一个线程可以多个协程，一个进程也可以单独拥有多个协程
- 线程和进程都是同步机制(对于多个任务，按部就班，一个一个来)，而协程是异步机制（在处理一个任务的期间，可以去响应其他的任务，用户体验感较好）。
- 线程（同进程）是抢占式，而协程是非抢占式的。需要用户释放使用权切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。
- 协程不被操作系统内核管理，而完全是由程序控制。线程是被分割的 CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器Interceptor关联任意线程或线程池。
- 协程能保留上一次调用时的状态。

### 4、进程与线程的切换流程？
进程切换分两步：
1. 切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。（保证了进程回到用户空间之后能够访问到自己的指令和数据（其中包括减小tlb清空的ASID机制（ASID(Ａddress Space Identifer 地址空间标识符)，用于区别不同进程的页表项）））
2. 切换内核栈和硬件上下文。（保证了进程内核栈和执行流的切换，会将当前进程的硬件上下文保存在进程所管理的一块内存，然后将即将执行的进程的硬件上下文从内存中恢复到寄存器）

对于 linux 来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1 步是不需要做的，第 2 步是进程和线程切换都要做的。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

## 容器
### 2、 Docker 是什么？
Docker 是一个容器化平台，它包装你所有开发环境依赖成一个整体，像一个容器。

### 简述什么是Kubernetes

Kubernetes是一个全新的基于容器技术的分布式系统支撑平台。是Google开源的容器集群管理系统（谷歌内部：Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。并且具有完备的集群管理能力，多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。  

## 关系型数据库和非关系型数据库
关系型数据库适合用来存储结构化数据

关系型数据库的优势：
- 事务的一致性：关系型数据库的最大优点就是事务的一致性，这个特性，使得关系型数据库中可以适用于一切要求一致性比较高的系统中。比如：银行系统。[0]
- 适合存储比较复杂的数据：关系型数据库适合存储比较复杂的数据。[0]
可靠的处理事务并且保持事务的完整性：SQL数据库依然强大，可以可靠的处理事务并且保持事务的完整性。[0]

关系型数据库的劣势：
- 读写性能比较差：关系型数据库为了维护一致性所付出的巨大代价就是读写性能比较差。[0]
- 不适合海量数据的存储：像微博、facebook这类应用，对于并发读写能力要求极高，关系型数据库已经无法应付。[0]
- 不易横向扩展：在基于web的结构中，数据库是最难以横向拓展的。[0]

非关系型数据库的优势：
- 横向扩展：NoSql通过横向拓展，非关系型数据库天然是分布式的，所以可以通过集群来实现负载均衡。[0]
- 存储效率更高：非关系型是平面数据集合中，数据经常可以重复，单个数据库很少被分开，而是存储成为一个整体，这种整块读取数据效率更高。[0]
- 适合存储海量、简单的数据：NoSql适合存储非结构化数据，比如文章、评论等数据。这些数据是海量的，并且增长的速度是难以预期的。[0]

非关系型数据库的劣势：
- 不支持事务处理：非关系型数据库不支持事务处理，无法进行事务回滚。[2]
- 查询效率不如关系型数据库：关系型数据库存储于磁盘，非关系型数据库存储于缓存，但是对于join或其他结构化查询的支持就比较差。[0]
- 存储方式单一：关系型数据库只支持单一的存储方式，而非关系型数据库的存储方式则更加多样化。[2]

综上所述，关系型数据库和非关系型数据库各有优劣，选择哪种数据库取决于具体的业务需求和数据特点。如果需要处理复杂的数据并且需要事务支持，则应该选择关系型数据库；如果需要存储海量、简单的数据并且需要横向扩展，则应该选择非关系型数据库。
## mongodb
MongoDB是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。

MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

