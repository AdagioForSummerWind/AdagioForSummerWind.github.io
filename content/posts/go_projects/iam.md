---
title: "iam_intro"
date: 2022-07-07T15:18:12+08:00
lastmod: 2022-07-07
tags: [go projects]
categories: [go]
slug: iam
draft: true
---


# go项目实战--孔令飞


- [go项目实战--孔令飞](#go项目实战--孔令飞)
  - [介绍](#介绍)
    - [重要性](#重要性)
    - [问题](#问题)
    - [概述](#概述)
  - [课前](#课前)
  - [1 | IAM系统概述](#1--iam系统概述)
    - [项目背景：为什么选择 IAM 系统作为实战项目？](#项目背景为什么选择-iam-系统作为实战项目)
    - [IAM 系统是什么？](#iam-系统是什么)
    - [IAM 系统的架构长啥样？](#iam-系统的架构长啥样)
    - [IAM 使用流程](#iam-使用流程)
    - [IAM 软件架构模式](#iam-软件架构模式)
      - [前后端分离架构](#前后端分离架构)
      - [MVC 架构](#mvc-架构)
  - [2 | 配置go开发环境](#2--配置go开发环境)
    - [Linux 服务器申请和配置](#linux-服务器申请和配置)
    - [依赖安装和配置](#依赖安装和配置)
    - [Go 编译环境安装和配置](#go-编译环境安装和配置)
      - [ProtoBuf 编译环境安装](#protobuf-编译环境安装)
    - [Go 开发 IDE 安装和配置](#go-开发-ide-安装和配置)
  - [3 | 快速部署](#3--快速部署)
    - [安装和配置数据库](#安装和配置数据库)
    - [安装和配置 IAM 系统](#安装和配置-iam-系统)
      - [准备工作](#准备工作)
      - [安装和配置 iam-apiserver](#安装和配置-iam-apiserver)
      - [安装 iamctl](#安装-iamctl)
      - [安装和配置 iam-authz-server](#安装和配置-iam-authz-server)
      - [安装和配置 iam-pump](#安装和配置-iam-pump)
      - [安装 man 文件](#安装-man-文件)
  - [标准设计](#标准设计)
  - [4 | 规范设计（上）：项目开发杂乱无章，如何规范？（开源规范、文档规范和版本规范）](#4--规范设计上项目开发杂乱无章如何规范开源规范文档规范和版本规范)
    - [需要制定规范的地方](#需要制定规范的地方)
    - [开源规范](#开源规范)
      - [开源规范详细列表](#开源规范详细列表)
      - [开源协议](#开源协议)
    - [文档规范](#文档规范)
    - [版本规范](#版本规范)
    - [总结](#总结)
  - [5 | 规范设计（下）：commit 信息风格迥异、难以阅读，如何规范？](#5--规范设计下commit-信息风格迥异难以阅读如何规范)
    - [Commit Message 的规范有哪些？](#commit-message-的规范有哪些)
      - [Header](#header)
      - [Body](#body)
      - [Footer](#footer)
      - [Revert Commit](#revert-commit)
      - [Commit 相关的 3 个重要内容](#commit-相关的-3-个重要内容)
      - [修改 Commit Message](#修改-commit-message)
      - [Commit Message 规范自动化](#commit-message-规范自动化)
    - [总结](#总结-1)
  - [6 | 目录结构设计：如何组织一个可维护、可扩展的代码目录？](#6--目录结构设计如何组织一个可维护可扩展的代码目录)
    - [平铺式目录结构](#平铺式目录结构)
    - [结构化目录结构](#结构化目录结构)
    - [Go 应用 ：主要存放前后端代码](#go-应用-主要存放前后端代码)
    - [Go 应用：主要存放测试相关的文件和代码](#go-应用主要存放测试相关的文件和代码)
    - [Go 应用：存放跟应用部署相关的文件](#go-应用存放跟应用部署相关的文件)
    - [项目管理：存放用来管理 Go 项目的各类文件](#项目管理存放用来管理-go-项目的各类文件)
    - [文档：主要存放项目的各类文档](#文档主要存放项目的各类文档)
    - [不**建议**的目录](#不建议的目录)
    - [一些**建议**](#一些建议)
  - [7 | 工作流设计：如何设计合理的多人开发模式？](#7--工作流设计如何设计合理的多人开发模式)
    - [集中式工作流](#集中式工作流)
    - [功能分支工作流](#功能分支工作流)
    - [Git Flow 工作流](#git-flow-工作流)
      - [Git Flow 开发流程](#git-flow-开发流程)
    - [Forking 工作流](#forking-工作流)
    - [回顾](#回顾)
  - [8 | 研发流程设计（上）：如何设计 Go 项目的开发流程？](#8--研发流程设计上如何设计-go-项目的开发流程)
    - [在设计研发流程时，需要关注哪些点？](#在设计研发流程时需要关注哪些点)
    - [业界相对标准的研发流程，长啥样？](#业界相对标准的研发流程长啥样)
    - [需求阶段](#需求阶段)
    - [设计阶段](#设计阶段)
    - [开发阶段](#开发阶段)
    - [测试阶段](#测试阶段)
    - [发布阶段](#发布阶段)
    - [运营阶段](#运营阶段)
    - [总结](#总结-2)
  - [9 | 研发流程设计（下）：如何管理应用的生命周期？](#9--研发流程设计下如何管理应用的生命周期)
    - [应用生命周期管理技术有哪些？](#应用生命周期管理技术有哪些)
    - [研发模式](#研发模式)
      - [瀑布模式](#瀑布模式)
      - [迭代模式](#迭代模式)
      - [敏捷模式](#敏捷模式)
    - [CI/CD：自动化构建和部署应用](#cicd自动化构建和部署应用)
    - [DevOps：研发运维一体化](#devops研发运维一体化)
      - [AIOps：智能运维](#aiops智能运维)
      - [ChatOps：聊着天就把事情给办了](#chatops聊着天就把事情给办了)
      - [GitOps： 一种实现云原生的持续交付模型](#gitops-一种实现云原生的持续交付模型)
      - [NoOps：无运维](#noops无运维)
    - [如何选择合适的应用生命周期管理技术？](#如何选择合适的应用生命周期管理技术)
    - [总结](#总结-3)
  - [10 | 设计方法：怎么写出优雅的 Go 项目？](#10--设计方法怎么写出优雅的-go-项目)
    - [如何写出优雅的 Go 项目？](#如何写出优雅的-go-项目)
    - [编写高质量的 Go 应用](#编写高质量的-go-应用)
      - [代码结构](#代码结构)
      - [代码规范](#代码规范)
      - [代码质量](#代码质量)
      - [编程哲学](#编程哲学)
    - [软件设计方法](#软件设计方法)
    - [高效管理项目](#高效管理项目)
      - [高效的开发流程](#高效的开发流程)
      - [使用 Makefile 管理项目](#使用-makefile-管理项目)
      - [自动生成代码](#自动生成代码)
      - [善于借助工具](#善于借助工具)
      - [对接 CI/CD](#对接-cicd)
    - [编写高质量的项目文档](#编写高质量的项目文档)
    - [总结](#总结-4)
  - [11 | 设计模式：Go常用设计模式概述](#11--设计模式go常用设计模式概述)
    - [创建型模式](#创建型模式)
      - [单例模式](#单例模式)
      - [工厂模式](#工厂模式)
    - [结构型模式](#结构型模式)
      - [策略模式](#策略模式)
      - [模版模式](#模版模式)
    - [行为型模式](#行为型模式)
      - [代理模式](#代理模式)
      - [选项模式](#选项模式)
    - [总结](#总结-5)
  - [基础功能](#基础功能)
  - [12 | API 风格（上）：如何设计RESTful API？](#12--api-风格上如何设计restful-api)
    - [RESTful API 介绍](#restful-api-介绍)
    - [RESTful API 设计原则](#restful-api-设计原则)
      - [URI 设计](#uri-设计)
      - [REST 资源操作映射为 HTTP 方法](#rest-资源操作映射为-http-方法)
      - [统一的返回格式](#统一的返回格式)
      - [API 版本管理](#api-版本管理)
      - [API 命名](#api-命名)
      - [统一分页 / 过滤 / 排序 / 搜索功能](#统一分页--过滤--排序--搜索功能)
      - [域名](#域名)
      - [REST 示例](#rest-示例)
    - [总结](#总结-6)
  - [13 | API 风格（下）：RPC API介绍](#13--api-风格下rpc-api介绍)
    - [RPC 介绍](#rpc-介绍)
    - [gRPC 介绍](#grpc-介绍)
    - [Protocol Buffers 介绍](#protocol-buffers-介绍)
    - [gRPC 示例](#grpc-示例)
    - [RESTful VS gRPC](#restful-vs-grpc)
  - [14 | 项目管理：如何编写高质量的Makefile？](#14--项目管理如何编写高质量的makefile)
    - [熟练掌握 Makefile 语法](#熟练掌握-makefile-语法)
    - [规划 Makefile 要实现的功能](#规划-makefile-要实现的功能)
    - [设计合理的 Makefile 结构](#设计合理的-makefile-结构)
    - [掌握 Makefile 编写技巧](#掌握-makefile-编写技巧)
      - [技巧 1：善用通配符和自动变量](#技巧-1善用通配符和自动变量)
      - [技巧 2：善用函数](#技巧-2善用函数)
      - [技巧 3：依赖需要用到的工具](#技巧-3依赖需要用到的工具)
      - [技巧 4：把常用功能放在 /Makefile 中，不常用的放在分类 Makefile 中](#技巧-4把常用功能放在-makefile-中不常用的放在分类-makefile-中)
      - [技巧 5：编写可扩展的 Makefile](#技巧-5编写可扩展的-makefile)
      - [技巧 6：将所有输出存放在一个目录下，方便清理和查找](#技巧-6将所有输出存放在一个目录下方便清理和查找)
      - [技巧 7：使用带层级的命名方式](#技巧-7使用带层级的命名方式)
      - [技巧 8：做好目标拆分](#技巧-8做好目标拆分)
      - [技巧 9：设置 OPTIONS](#技巧-9设置-options)
      - [技巧 10：定义环境变量](#技巧-10定义环境变量)
      - [技巧 11：自己调用自己](#技巧-11自己调用自己)
    - [总结](#总结-7)
  - [15 | 研发流程实战：IAM项目是如何进行研发流程管理的？](#15--研发流程实战iam项目是如何进行研发流程管理的)
    - [开发阶段](#开发阶段-1)
      - [代码开发](#代码开发)
      - [代码提交](#代码提交)
    - [测试阶段](#测试阶段-1)
    - [IAM 项目的 Makefile 项目管理技巧](#iam-项目的-makefile-项目管理技巧)
      - [help 自动解析](#help-自动解析)
      - [Options 中指定变量值](#options-中指定变量值)
      - [自动生成 CHANGELOG](#自动生成-changelog)
      - [自动生成版本号](#自动生成版本号)
      - [保持行为一致](#保持行为一致)
    - [总结](#总结-8)
  - [16 | 代码检查：如何进行静态代码检查？](#16--代码检查如何进行静态代码检查)
    - [为什么选择 golangci-lint 做静态代码检查？](#为什么选择-golangci-lint-做静态代码检查)
    - [golangci-lint 提供了哪些命令和选项？](#golangci-lint-提供了哪些命令和选项)
      - [run 命令](#run-命令)
      - [cache 命令](#cache-命令)
      - [completion 命令](#completion-命令)
      - [config 命令](#config-命令)
      - [linters 命令](#linters-命令)
      - [golangci-lint 配置](#golangci-lint-配置)
    - [如何使用 golangci-lint 进行静态代码检查？](#如何使用-golangci-lint-进行静态代码检查)
      - [golangci-lint 使用技巧](#golangci-lint-使用技巧)
    - [总结](#总结-9)
  - [17 | API 文档：如何生成 Swagger API 文档 ？](#17--api-文档如何生成-swagger-api-文档-)
    - [Swagger 介绍](#swagger-介绍)
    - [Swagger 和 OpenAPI 的区别](#swagger-和-openapi-的区别)
    - [用 go-swagger 来生成 Swagger API 文档](#用-go-swagger-来生成-swagger-api-文档)
      - [安装 Swagger 工具](#安装-swagger-工具)
      - [swagger 命令行工具介绍](#swagger-命令行工具介绍)
      - [如何使用 swagger 命令生成 Swagger 文档？](#如何使用-swagger-命令生成-swagger-文档)
      - [解析注释生成 Swagger 文档](#解析注释生成-swagger-文档)
      - [go-swagger 其他常用功能介绍](#go-swagger-其他常用功能介绍)
    - [IAM Swagger 文档](#iam-swagger-文档)
    - [总结](#总结-10)
  - [18 | 错误处理（上）：如何设计一套科学的错误码？](#18--错误处理上如何设计一套科学的错误码)
    - [期望错误码实现的功能](#期望错误码实现的功能)
    - [常见的错误码设计方式](#常见的错误码设计方式)
    - [错误码设计**建议**](#错误码设计建议)
    - [业务 Code 码设计](#业务-code-码设计)
    - [如何设置 HTTP Status Code](#如何设置-http-status-code)
    - [IAM 项目错误码设计规范](#iam-项目错误码设计规范)
      - [Code 设计规范](#code-设计规范)
      - [IAM API 接口返回值说明](#iam-api-接口返回值说明)
    - [总结](#总结-11)
  - [19 | 错误处理（下）：如何设计错误包？](#19--错误处理下如何设计错误包)
    - [错误包需要具有哪些功能？](#错误包需要具有哪些功能)
    - [错误包实现](#错误包实现)
    - [如何记录错误？](#如何记录错误)
    - [一个错误码的具体实现](#一个错误码的具体实现)
    - [错误码实际使用方法示例](#错误码实际使用方法示例)
    - [总结](#总结-12)
  - [20 | 日志处理（上）：如何设计日志包并记录日志？](#20--日志处理上如何设计日志包并记录日志)
    - [如何设计日志包](#如何设计日志包)
    - [基础功能](#基础功能-1)
    - [高级功能](#高级功能)
    - [可选功能](#可选功能)
    - [设计日志包时需要关注的点](#设计日志包时需要关注的点)
    - [如何记录日志？](#如何记录日志)
      - [在何处打印日志？](#在何处打印日志)
      - [在哪个日志级别打印日志？](#在哪个日志级别打印日志)
      - [如何记录日志内容？](#如何记录日志内容)
    - [记录日志的“最佳”实践总结](#记录日志的最佳实践总结)
    - [拓展内容：分布式日志解决方案（EFK/ELK）](#拓展内容分布式日志解决方案efkelk)
    - [总结](#总结-13)
  - [21 | 日志处理（下）：手把手教你从 0 编写一个日志包](#21--日志处理下手把手教你从-0-编写一个日志包)
    - [有哪些优秀的开源日志包？](#有哪些优秀的开源日志包)
      - [标准库 log 包](#标准库-log-包)
      - [glog](#glog)
      - [logrus](#logrus)
      - [zap](#zap)
    - [开源日志包选择](#开源日志包选择)
    - [从 0 编写一个日志包](#从-0-编写一个日志包)
      - [定义日志级别和日志选项](#定义日志级别和日志选项)
      - [创建 Logger 及各级别日志打印方法](#创建-logger-及各级别日志打印方法)
      - [将日志输出到支持的输出中](#将日志输出到支持的输出中)
      - [自定义日志输出格式](#自定义日志输出格式)
      - [测试日志包](#测试日志包)
    - [IAM 项目日志包设计](#iam-项目日志包设计)
    - [总结](#总结-14)
  - [22 | 应用构建三剑客：Pflag、Viper、Cobra 核心功能介绍](#22--应用构建三剑客pflagvipercobra-核心功能介绍)
    - [如何构建应用框架](#如何构建应用框架)
    - [命令行参数解析工具：Pflag 使用介绍](#命令行参数解析工具pflag-使用介绍)
      - [Pflag 包 Flag 定义](#pflag-包-flag-定义)
      - [Pflag 包 FlagSet 定义](#pflag-包-flagset-定义)
      - [Pflag 使用方法](#pflag-使用方法)
    - [配置解析神器：Viper 使用介绍](#配置解析神器viper-使用介绍)
      - [读入配置](#读入配置)
      - [读取配置](#读取配置)
    - [现代化的命令行框架：Cobra 全解](#现代化的命令行框架cobra-全解)
      - [使用 Cobra 库创建命令](#使用-cobra-库创建命令)
      - [使用标志](#使用标志)
      - [非选项参数验证](#非选项参数验证)
      - [PreRun and PostRun Hooks](#prerun-and-postrun-hooks)
    - [总结](#总结-15)
  - [23 | 应用构建实战：如何构建一个优秀的企业应用框架？](#23--应用构建实战如何构建一个优秀的企业应用框架)
    - [构建应用的基础：应用的三大基本功能](#构建应用的基础应用的三大基本功能)
    - [iam-apiserver 是如何构建应用框架的？](#iam-apiserver-是如何构建应用框架的)
      - [App 包设计和实现](#app-包设计和实现)
      - [第 1 步：构建应用](#第-1-步构建应用)
      - [第 2 步：命令行程序构建](#第-2-步命令行程序构建)
      - [第 3 步：命令行参数解析](#第-3-步命令行参数解析)
      - [第 4 步：配置文件解析](#第-4-步配置文件解析)
    - [这样构建的应用程序，有哪些优秀特性？](#这样构建的应用程序有哪些优秀特性)
    - [如果你想自己构建应用，需要**注意**些什么？](#如果你想自己构建应用需要注意些什么)
    - [总结](#总结-16)
  - [服务开发](#服务开发)
  - [24 | Web 服务：Web 服务核心功能有哪些，如何实现？](#24--web-服务web-服务核心功能有哪些如何实现)
    - [Web 服务的核心功能](#web-服务的核心功能)
    - [为什么选择 Gin 框架？](#为什么选择-gin-框架)
    - [Gin 是如何支持 Web 服务基础功能的？](#gin-是如何支持-web-服务基础功能的)
      - [HTTP/HTTPS 支持](#httphttps-支持)
      - [JSON 数据格式支持](#json-数据格式支持)
      - [路由匹配](#路由匹配)
      - [路由分组](#路由分组)
      - [一进程多服务](#一进程多服务)
      - [参数解析、参数校验、逻辑处理、返回结果](#参数解析参数校验逻辑处理返回结果)
    - [Gin 是如何支持 Web 服务高级功能的？](#gin-是如何支持-web-服务高级功能的)
      - [中间件](#中间件)
      - [认证、RequestID、跨域](#认证requestid跨域)
      - [优雅关停](#优雅关停)
    - [总结](#总结-17)
  - [25 | 认证机制：应用程序如何进行访问认证？](#25--认证机制应用程序如何进行访问认证)
    - [认证和授权有什么区别？](#认证和授权有什么区别)
    - [四种基本的认证方式](#四种基本的认证方式)
      - [Basic](#basic)
      - [Digest](#digest)
        - [OAuth](#oauth)
      - [Bearer](#bearer)
    - [基于 JWT 的 Token 认证机制实现](#基于-jwt-的-token-认证机制实现)
      - [JWT 简介](#jwt-简介)
      - [JWT 认证流程](#jwt-认证流程)
      - [JWT 格式](#jwt-格式)
    - [总结](#总结-18)
  - [26 | IAM项目是如何设计和实现访问认证功能的？](#26--iam项目是如何设计和实现访问认证功能的)
    - [如何设计 IAM 项目的认证功能？](#如何设计-iam-项目的认证功能)
    - [IAM 项目是如何实现 Basic 认证的？](#iam-项目是如何实现-basic-认证的)
    - [IAM 项目是如何实现 Bearer 认证的？](#iam-项目是如何实现-bearer-认证的)
      - [iam-authz-server Bearer 认证实现](#iam-authz-server-bearer-认证实现)
      - [iam-apiserver Bearer 认证实现](#iam-apiserver-bearer-认证实现)
    - [IAM 项目认证功能设计技巧](#iam-项目认证功能设计技巧)
      - [技巧 1：面向接口编程](#技巧-1面向接口编程)
      - [技巧 2：使用抽象工厂模式](#技巧-2使用抽象工厂模式)
      - [技巧 3：使用策略模式](#技巧-3使用策略模式)
    - [总结](#总结-19)
  - [27 | 权限模型：5大权限模型是如何进行资源授权的？](#27--权限模型5大权限模型是如何进行资源授权的)
    - [权限相关术语介绍](#权限相关术语介绍)
    - [权限模型介绍](#权限模型介绍)
      - [简单的权限模型：权限控制列表（ACL）](#简单的权限模型权限控制列表acl)
      - [基于 ACL 下放权限的权限模型：自主访问控制（DAC）](#基于-acl-下放权限的权限模型自主访问控制dac)
      - [基于 ACL 且安全性更高的权限模型：强制访问控制（MAC）](#基于-acl-且安全性更高的权限模型强制访问控制mac)
      - [最普及的权限模型：基于角色的访问控制（RBAC）](#最普及的权限模型基于角色的访问控制rbac)
      - [最强大的权限模型：基于属性的权限验证（ABAC）](#最强大的权限模型基于属性的权限验证abac)
    - [相关开源项目](#相关开源项目)
      - [Casbin](#casbin)
      - [keto](#keto)
      - [go-admin](#go-admin)
      - [LyricTian/gin-admin](#lyrictiangin-admin)
      - [gin-vue-admin](#gin-vue-admin)
    - [选择建议](#选择建议)
    - [总结](#总结-20)
  - [28 | 控制流（上）：通过iam-apiserver设计，看Web服务的构建](#28--控制流上通过iam-apiserver设计看web服务的构建)
    - [iam-apiserver 服务介绍](#iam-apiserver-服务介绍)
    - [iam-apiserver 功能介绍](#iam-apiserver-功能介绍)
    - [iam-apiserver 使用方法介绍](#iam-apiserver-使用方法介绍)
    - [iam-apiserver 代码实现](#iam-apiserver-代码实现)
      - [iam-apiserver 配置处理](#iam-apiserver-配置处理)
      - [iam-apiserver 启动流程设计](#iam-apiserver-启动流程设计)
      - [iam-apiserver 的 REST API 请求处理流程](#iam-apiserver-的-rest-api-请求处理流程)
      - [iam-apiserver 代码架构](#iam-apiserver-代码架构)
    - [总结](#总结-21)
  - [29｜控制流（下）：iam-apiserver服务核心功能实现讲解](#29控制流下iam-apiserver服务核心功能实现讲解)
    - [应用框架相关的特性](#应用框架相关的特性)
      - [优雅关停](#优雅关停-1)
      - [健康检查](#健康检查)
      - [插件化加载中间件](#插件化加载中间件)
    - [编程规范相关的特性](#编程规范相关的特性)
      - [API 版本](#api-版本)
      - [统一的资源元数据](#统一的资源元数据)
      - [统一的返回](#统一的返回)
      - [并发处理模板](#并发处理模板)
    - [其他特性](#其他特性)
      - [插件化选择 JSON 库](#插件化选择-json-库)
      - [调用链实现](#调用链实现)
      - [数据一致性](#数据一致性)
    - [总结](#总结-22)
  - [30 | ORM：CURD 神器 GORM 包介绍及实战](#30--ormcurd-神器-gorm-包介绍及实战)
    - [GORM 基础知识介绍](#gorm-基础知识介绍)
    - [通过示例学习 GORM](#通过示例学习-gorm)
    - [GORM 常用操作讲解](#gorm-常用操作讲解)
      - [模型定义](#模型定义)
      - [连接数据库](#连接数据库)
      - [创建记录](#创建记录)
      - [删除记录](#删除记录)
      - [更新记录](#更新记录)
      - [查询数据](#查询数据)
      - [高级查询](#高级查询)
      - [原生 SQL](#原生-sql)
      - [GORM 钩子](#gorm-钩子)
    - [iam-apiserver 中的 CURD 操作实战](#iam-apiserver-中的-curd-操作实战)
    - [总结](#总结-23)
  - [31 | 数据流：通过iam-authz-server设计，看数据流服务的设计](#31--数据流通过iam-authz-server设计看数据流服务的设计)
    - [iam-authz-server 的功能介绍](#iam-authz-server-的功能介绍)
    - [github.com/ory/ladon 包介绍](#githubcomoryladon-包介绍)
    - [iam-authz-server 使用方法介绍](#iam-authz-server-使用方法介绍)
    - [iam-authz-server 的代码实现](#iam-authz-server-的代码实现)
      - [iam-authz-server 的配置处理](#iam-authz-server-的配置处理)
      - [iam-authz-server 启动流程设计](#iam-authz-server-启动流程设计)
      - [iam-authz-server 的 RESTful API 请求处理流程](#iam-authz-server-的-restful-api-请求处理流程)
      - [iam-authz-server 的代码架构](#iam-authz-server-的代码架构)
    - [iam-authz-server 关键代码分析](#iam-authz-server-关键代码分析)
      - [资源授权](#资源授权)
      - [缓存设计](#缓存设计)
      - [数据一致性](#数据一致性-1)
    - [总结](#总结-24)
  - [32 | 数据处理：如何高效处理应用程序产生的数据？](#32--数据处理如何高效处理应用程序产生的数据)
    - [数据采集方式的分类](#数据采集方式的分类)
    - [数据采集系统设计](#数据采集系统设计)
      - [设计数据采集系统时需要解决的核心问题](#设计数据采集系统时需要解决的核心问题)
      - [数据上报功能设计](#数据上报功能设计)
      - [数据采集功能设计](#数据采集功能设计)
      - [数据采集应用模型](#数据采集应用模型)
    - [数据采集系统落地项目：iam-authz-server + iam-pump](#数据采集系统落地项目iam-authz-server--iam-pump)
      - [iam-authz-server：数据上报](#iam-authz-server数据上报)
      - [启动服务：启动数据上报服务](#启动服务启动数据上报服务)
      - [运行服务：异步上报授权日志](#运行服务异步上报授权日志)
      - [关停服务：优雅关停数据上报](#关停服务优雅关停数据上报)
    - [iam-pump：数据采集](#iam-pump数据采集)
      - [初始化服务：数据采集插件定义](#初始化服务数据采集插件定义)
      - [初始化服务：初始化数据采集插件](#初始化服务初始化数据采集插件)
      - [初始化服务：健康检查](#初始化服务健康检查)
      - [运行服务：启动 Loop 周期性消费 Redis 数据](#运行服务启动-loop-周期性消费-redis-数据)
      - [关停服务：优雅关停数据采集服务](#关停服务优雅关停数据采集服务)
    - [总结](#总结-25)
  - [33 | SDK 设计（上）：如何设计出一个优秀的 Go SDK？](#33--sdk-设计上如何设计出一个优秀的-go-sdk)
    - [什么是 SDK？首先，我们来看下什么是 SDK。](#什么是-sdk首先我们来看下什么是-sdk)
    - [SDK 设计方法](#sdk-设计方法)
    - [如何给 SDK 命名？](#如何给-sdk-命名)
    - [SDK 的目录结构](#sdk-的目录结构)
    - [SDK 设计方法](#sdk-设计方法-1)
    - [公有云厂商采用的 SDK 设计方式](#公有云厂商采用的-sdk-设计方式)
    - [API 层：创建客户端实例](#api-层创建客户端实例)
    - [基础层：构建并执行 HTTP 请求](#基础层构建并执行-http-请求)
      - [第一步，Builder：构建请求参数。](#第一步builder构建请求参数)
      - [第二步，Signer：签发并添加认证头。](#第二步signer签发并添加认证头)
      - [第三步，Request：执行 HTTP请求。](#第三步request执行-http请求)
      - [第四步，处理 HTTP请求返回结果。](#第四步处理-http请求返回结果)
    - [总结](#总结-26)
  - [34 | SDK 设计（下）：IAM项目Go SDK设计和实现](#34--sdk-设计下iam项目go-sdk设计和实现)
    - [marmotedu-sdk-go 设计](#marmotedu-sdk-go-设计)
    - [marmotedu-sdk-go 客户端设计](#marmotedu-sdk-go-客户端设计)
      - [项目级别客户端创建](#项目级别客户端创建)
      - [应用级别客户端创建](#应用级别客户端创建)
      - [服务级别客户端创建](#服务级别客户端创建)
    - [marmotedu-sdk-go 的实现](#marmotedu-sdk-go-的实现)
    - [RESTClient 客户端实现](#restclient-客户端实现)
      - [第一步，创建rest.Config类型的变量。](#第一步创建restconfig类型的变量)
      - [第二步，根据 rest.Config 类型的变量，创建 RESTClient 客户端。](#第二步根据-restconfig-类型的变量创建-restclient-客户端)
    - [Request 模块实现](#request-模块实现)
      - [第一步，构建 HTTP URL。](#第一步构建-http-url)
      - [第二步，构建 HTTP Method。](#第二步构建-http-method)
      - [第三步，构建 HTTP Body。](#第三步构建-http-body)
      - [第四步，执行 HTTP 请求。](#第四步执行-http-请求)
      - [第五步，保存 HTTP 返回结果。](#第五步保存-http-返回结果)
    - [请求认证](#请求认证)
    - [总结](#总结-27)
  - [35 | 效率神器：如何设计和实现一个命令行客户端工具？](#35--效率神器如何设计和实现一个命令行客户端工具)
    - [常见客户端介绍](#常见客户端介绍)
    - [大型系统客户端（xxxctl）的特点](#大型系统客户端xxxctl的特点)
    - [iamctl 的核心实现](#iamctl-的核心实现)
      - [iamctl 的功能](#iamctl-的功能)
      - [代码结构](#代码结构-1)
      - [命令行选项](#命令行选项)
      - [配置文件解析](#配置文件解析)
    - [iamctl 中子命令是如何构建的？](#iamctl-中子命令是如何构建的)
      - [命令构建](#命令构建)
      - [自动生成命令](#自动生成命令)
      - [命令自动补全](#命令自动补全)
      - [更友好的输出](#更友好的输出)
    - [iamctl 是如何进行 API 调用的？](#iamctl-是如何进行-api-调用的)
    - [客户端配置文件](#客户端配置文件)
    - [SDK 调用](#sdk-调用)
    - [REST API 调用](#rest-api-调用)
    - [总结](#总结-28)
  - [服务测试](#服务测试)
  - [36 | 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？](#36--代码测试上如何编写-go-语言单元测试和性能测试用例)
    - [如何测试 Go 代码？](#如何测试-go-代码)
    - [测试命名规范](#测试命名规范)
      - [测试文件的命名规范](#测试文件的命名规范)
      - [包的命名规范](#包的命名规范)
      - [函数的命名规范](#函数的命名规范)
      - [变量的命名规范](#变量的命名规范)
    - [单元测试](#单元测试)
      - [多个输入的测试用例](#多个输入的测试用例)
      - [自动生成单元测试用例](#自动生成单元测试用例)
    - [性能测试](#性能测试)
    - [总结](#总结-29)
  - [37 | 代码测试（下）：Go 语言其他测试类型及 IAM 测试介绍](#37--代码测试下go-语言其他测试类型及-iam-测试介绍)
    - [示例测试](#示例测试)
      - [示例测试命名规范](#示例测试命名规范)
      - [大型示例](#大型示例)
      - [TestMain 函数](#testmain-函数)
    - [Mock 测试](#mock-测试)
      - [安装 GoMock](#安装-gomock)
      - [mockgen 工具介绍](#mockgen-工具介绍)
      - [通过注释使用 mockgen](#通过注释使用-mockgen)
      - [使用 Mock 代码编写单元测试用例](#使用-mock-代码编写单元测试用例)
    - [Fake 测试](#fake-测试)
    - [何时编写和执行单元测试用例？](#何时编写和执行单元测试用例)
      - [编码前：TDD](#编码前tdd)
      - [与编码同步进行：增量](#与编码同步进行增量)
      - [编码后：存量](#编码后存量)
      - [测试覆盖率](#测试覆盖率)
    - [IAM 项目测试实战](#iam-项目测试实战)
      - [IAM 项目是如何运行测试用例的？](#iam-项目是如何运行测试用例的)
      - [IAM 项目测试案例分享](#iam-项目测试案例分享)
    - [其他测试工具 / 包](#其他测试工具--包)
      - [测试框架](#测试框架)
      - [Mock 工具](#mock-工具)
    - [总结](#总结-30)
  - [38｜性能分析（上）：如何分析 Go 语言代码的性能？](#38性能分析上如何分析-go-语言代码的性能)
    - [生成性能数据文件](#生成性能数据文件)
      - [通过命令行生成性能数据文件](#通过命令行生成性能数据文件)
      - [通过代码生成性能数据文件](#通过代码生成性能数据文件)
      - [通过net/http/pprof生成性能数据文件](#通过nethttppprof生成性能数据文件)
      - [性能分析](#性能分析)
      - [pprof 工具介绍](#pprof-工具介绍)
      - [生成性能数据](#生成性能数据)
    - [CPU 性能分析](#cpu-性能分析)
      - [方法一：分析采样图](#方法一分析采样图)
      - [方法二：分析火焰图](#方法二分析火焰图)
      - [方法三：用go tool pprof交互模式查看详细数据](#方法三用go-tool-pprof交互模式查看详细数据)
      - [内存性能分析](#内存性能分析)
    - [总结](#总结-31)
  - [39｜性能分析（下）：API Server性能测试和调优实战](#39性能分析下api-server性能测试和调优实战)
    - [API 性能测试指标](#api-性能测试指标)
    - [API 性能测试方法](#api-性能测试方法)
      - [wrk 安装方法](#wrk-安装方法)
      - [wrk 使用简介](#wrk-使用简介)
    - [API Server 性能测试实践](#api-server-性能测试实践)
      - [性能测试脚本介绍](#性能测试脚本介绍)
      - [关闭 Debug 配置选项](#关闭-debug-配置选项)
      - [使用 wrktest.sh 测试 IAM API 接口性能](#使用-wrktestsh-测试-iam-api-接口性能)
    - [API Server 性能分析](#api-server-性能分析)
    - [API 接口性能参考](#api-接口性能参考)
    - [API Server 性能测试注意事项](#api-server-性能测试注意事项)
    - [Web 框架性能](#web-框架性能)
    - [API 接口性能](#api-接口性能)
    - [测试环境](#测试环境)
    - [总结](#总结-32)
  - [服务部署](#服务部署)
  - [40 | 软件部署实战（上）：部署方案及负载均衡、高可用组件介绍](#40--软件部署实战上部署方案及负载均衡高可用组件介绍)
    - [部署方案](#部署方案)
    - [Nginx 安装和配置](#nginx-安装和配置)
      - [Nginx 功能简介](#nginx-功能简介)
      - [Nginx 安装步骤](#nginx-安装步骤)
    - [Keepalived 安装和配置](#keepalived-安装和配置)
      - [Keepalived 安装步骤](#keepalived-安装步骤)
      - [Keepalived 配置文件解析](#keepalived-配置文件解析)
    - [总结](#总结-33)
  - [41 | 软件部署实战（中）：IAM 系统生产环境部署实战](#41--软件部署实战中iam-系统生产环境部署实战)
    - [部署 IAM 应用](#部署-iam-应用)
      - [在10.0.4.20服务器上部署 IAM 应用](#在100420服务器上部署-iam-应用)
      - [在10.0.4.21服务器上部署 IAM 应用](#在100421服务器上部署-iam-应用)
    - [配置 Nginx 作为反向代理](#配置-nginx-作为反向代理)
      - [第一步，配置 iam-apiserver。](#第一步配置-iam-apiserver)
      - [第二步，配置 iam-authz-server。](#第二步配置-iam-authz-server)
      - [第三步，配置完 Nginx 后，重启 Nginx：](#第三步配置完-nginx-后重启-nginx)
      - [第四步，在 /etc/hosts 中追加下面两行：](#第四步在-etchosts-中追加下面两行)
      - [第五步，发送 HTTP 请求：](#第五步发送-http-请求)
    - [配置 Nginx 作为负载均衡](#配置-nginx-作为负载均衡)
      - [10.0.4.20服务器配置](#100420服务器配置)
      - [10.0.4.21服务器配置](#100421服务器配置)
      - [测试负载均衡](#测试负载均衡)
    - [配置 Keepalived](#配置-keepalived)
      - [第一步：创建腾讯云 HAVIP](#第一步创建腾讯云-havip)
      - [第二步：主服务器配置](#第二步主服务器配置)
      - [第三步：备服务器配置](#第三步备服务器配置)
      - [第四步：测试 Keepalived](#第四步测试-keepalived)
      - [第五步：VIP 绑定公网 IP](#第五步vip-绑定公网-ip)
      - [第六步：测试公网访问](#第六步测试公网访问)
    - [总结](#总结-34)
  - [42 | 软件部署实战（下）：IAM系统安全加固、水平扩缩容实战](#42--软件部署实战下iam系统安全加固水平扩缩容实战)
    - [IAM 应用安全性加固](#iam-应用安全性加固)
    - [iptables 简介](#iptables-简介)
    - [网络数据包处理流程](#网络数据包处理流程)
    - [iptables 工具使用方式介绍](#iptables-工具使用方式介绍)
    - [IAM 安全加固（内网不安全）](#iam-安全加固内网不安全)
      - [第一步，设置防火墙规则。](#第一步设置防火墙规则)
      - [第二步，设置重启自动加载 iptables 规则。](#第二步设置重启自动加载-iptables-规则)
      - [第三步，自动化。](#第三步自动化)
    - [IAM 安全加固（内网安全）](#iam-安全加固内网安全)
    - [弹性伸缩](#弹性伸缩)
      - [系统扩容](#系统扩容)
      - [系统缩容](#系统缩容)
    - [总结](#总结-35)
  - [43｜技术演进（上）：虚拟化技术演进之路](#43技术演进上虚拟化技术演进之路)
    - [我们为什么使用云？](#我们为什么使用云)
    - [虚拟化技术的演进](#虚拟化技术的演进)
      - [物理机阶段](#物理机阶段)
      - [虚拟机阶段](#虚拟机阶段)
      - [虚拟化漏洞](#虚拟化漏洞)
      - [Hypervisor 技术的演进](#hypervisor-技术的演进)
      - [容器阶段](#容器阶段)
      - [容器引擎 Docker](#容器引擎-docker)
      - [容器编排技术 Kubernetes](#容器编排技术-kubernetes)
      - [Serverless 阶段](#serverless-阶段)
    - [总结](#总结-36)
  - [44｜技术演进（下）：软件架构和应用生命周期技术演进之路](#44技术演进下软件架构和应用生命周期技术演进之路)
    - [软件架构的演进](#软件架构的演进)
      - [单体架构](#单体架构)
      - [SOA 架构](#soa-架构)
      - [微服务架构](#微服务架构)
      - [Service Mesh](#service-mesh)
      - [FaaS 架构](#faas-架构)
    - [应用生命周期管理技术：监控告警、日志、调用链](#应用生命周期管理技术监控告警日志调用链)
      - [监控告警组件：Prometheus](#监控告警组件prometheus)
      - [统一日志管理框架：EFK](#统一日志管理框架efk)
      - [调用链跟踪组件：Jaeger](#调用链跟踪组件jaeger)
    - [总结](#总结-37)
  - [45｜基于Kubernetes的云原生架构设计](#45基于kubernetes的云原生架构设计)
    - [云原生简介](#云原生简介)
    - [CNCF（云原生计算基金会）简介](#cncf云原生计算基金会简介)
    - [什么是云原生？](#什么是云原生)
    - [什么是云原生应用？](#什么是云原生应用)
    - [云原生架构包含很多内容，如何学习？](#云原生架构包含很多内容如何学习)
    - [系统资源层的云原生架构设计](#系统资源层的云原生架构设计)
      - [Kubernetes 集群高可用方案设计](#kubernetes-集群高可用方案设计)
      - [Kubernetes 应用的高可用](#kubernetes-应用的高可用)
    - [应用层的云原生架构设计](#应用层的云原生架构设计)
      - [微服务实现](#微服务实现)
      - [微服务架构设计](#微服务架构设计)
      - [微服务高可用架构设计](#微服务高可用架构设计)
    - [云原生架构鸟瞰图](#云原生架构鸟瞰图)
    - [公有云版云原生架构](#公有云版云原生架构)
    - [总结](#总结-38)
  - [46 | 如何制作Docker镜像？](#46--如何制作docker镜像)
    - [Docker 镜像的构建原理和方式](#docker-镜像的构建原理和方式)
      - [通过docker commit命令构建镜像](#通过docker-commit命令构建镜像)
      - [通过Dockerfile来构建镜像](#通过dockerfile来构建镜像)
      - [其他制作镜像方式](#其他制作镜像方式)
    - [Dockerfile 指令介绍](#dockerfile-指令介绍)
    - [Dockerfile指令详解](#dockerfile指令详解)
    - [Dockerfile 最佳实践](#dockerfile-最佳实践)
    - [总结](#总结-39)
  - [47 | 如何编写Kubernetes资源定义文件？](#47--如何编写kubernetes资源定义文件)
    - [为什么选择 YAML 格式来定义 Kubernetes 资源？](#为什么选择-yaml-格式来定义-kubernetes-资源)
    - [Kubernetes 资源定义概述](#kubernetes-资源定义概述)
    - [常用的 Kubernetes 资源定义](#常用的-kubernetes-资源定义)
      - [Pod 资源定义](#pod-资源定义)
      - [Deployment 资源定义](#deployment-资源定义)
      - [ConfigMap 资源定义](#configmap-资源定义)
      - [Service 资源定义](#service-资源定义)
    - [YAML 文件编写技巧](#yaml-文件编写技巧)
    - [使用 Kubernetes YAML 时的一些推荐工具](#使用-kubernetes-yaml-时的一些推荐工具)
      - [kubeval](#kubeval)
      - [kube-score](#kube-score)
    - [总结](#总结-40)
  - [48 | 基于腾讯云 EKS 的容器化部署实战](#48--基于腾讯云-eks-的容器化部署实战)
    - [准备工作](#准备工作-1)
    - [开通腾讯云容器服务镜像仓库](#开通腾讯云容器服务镜像仓库)
      - [第一步，开通个人版镜像仓库。](#第一步开通个人版镜像仓库)
      - [第二步，登录到腾讯云 Registry（镜像仓库）。](#第二步登录到腾讯云-registry镜像仓库)
      - [第三步，新建镜像仓库命名空间。](#第三步新建镜像仓库命名空间)
    - [安装 Docker](#安装-docker)
      - [第一步，安装 Docker 前置条件检查。](#第一步安装-docker-前置条件检查)
      - [第二步，安装 docker。](#第二步安装-docker)
      - [第三步，安装后配置。](#第三步安装后配置)
    - [安装docker-compose](#安装docker-compose)
    - [准备一个 Kubernetes 集群](#准备一个-kubernetes-集群)
      - [EKS 简介](#eks-简介)
      - [EKS 费用](#eks-费用)
      - [申请 EKS 集群](#申请-eks-集群)
    - [安装 IAM 应用](#安装-iam-应用)
    - [测试 IAM 应用](#测试-iam-应用)
    - [销毁 EKS 集群及其资源](#销毁-eks-集群及其资源)
    - [总结](#总结-41)
  - [49 | 服务编排（上）：Helm服务编排基础知识](#49--服务编排上helm服务编排基础知识)
    - [Helm 基础知识介绍](#helm-基础知识介绍)
      - [Helm 是什么？](#helm-是什么)
      - [Helm 中的三大基本概念](#helm-中的三大基本概念)
      - [我们为什么要使用 Helm？](#我们为什么要使用-helm)
    - [Helm 基本操作实战](#helm-基本操作实战)
      - [前置条件](#前置条件)
      - [安装 Helm](#安装-helm)
    - [Helm 快速入门](#helm-快速入门)
      - [第一步，初始化一个 Helm Chart 仓库。](#第一步初始化一个-helm-chart-仓库)
      - [第三步，安装前自定义 Chart。](#第三步安装前自定义-chart)
      - [第四步，查看当前集群安装了哪些 Release。](#第四步查看当前集群安装了哪些-release)
      - [第五步，升级 Release，并且在失败时恢复。](#第五步升级-release并且在失败时恢复)
      - [第六步，卸载 Release。](#第六步卸载-release)
    - [Helm 命令](#helm-命令)
    - [总结](#总结-42)
  - [50 | 服务编排（下）：基于Helm的服务编排部署实战](#50--服务编排下基于helm的服务编排部署实战)
    - [制作 IAM Chart 包](#制作-iam-chart-包)
    - [IAM Chart 部署](#iam-chart-部署)
    - [IAM 应用多环境部署](#iam-应用多环境部署)
    - [总结](#总结-43)
  - [51 | 基于 GitHub Actions 的 CI 实战](#51--基于-github-actions-的-ci-实战)
    - [GitHub Actions 的基本用法](#github-actions-的基本用法)
    - [GitHub Actions 的基本概念](#github-actions-的基本概念)
      - [workflow 文件介绍](#workflow-文件介绍)
    - [GitHub Actions 的进阶用法](#github-actions-的进阶用法)
      - [为工作流加一个 Badge](#为工作流加一个-badge)
      - [使用构建矩阵](#使用构建矩阵)
      - [使用 Secrets](#使用-secrets)
      - [使用 Artifact 保存构建产物](#使用-artifact-保存构建产物)
    - [GitHub Actions 实战](#github-actions-实战)
    - [IAM GitHub Actions 实战](#iam-github-actions-实战)
    - [总结](#总结-44)
  - [加餐](#加餐)
  - [特别放送 | 给你一份清晰、可直接套用的Go编码规范](#特别放送--给你一份清晰可直接套用的go编码规范)
    - [1. 代码风格](#1-代码风格)
      - [1.1 代码格式](#11-代码格式)
      - [1.2 声明、初始化和定义](#12-声明初始化和定义)
      - [1.3 错误处理](#13-错误处理)
      - [1.4 panic 处理](#14-panic-处理)
      - [1.5 单元测试](#15-单元测试)
      - [1.6 类型断言失败处理](#16-类型断言失败处理)
    - [2. 命名规范](#2-命名规范)
      - [2.1 包命名](#21-包命名)
      - [2.2 函数命名](#22-函数命名)
      - [2.3 文件命名](#23-文件命名)
      - [2.4 结构体命名](#24-结构体命名)
      - [2.5 接口命名](#25-接口命名)
      - [2.6 变量命名](#26-变量命名)
      - [2.7 常量命名](#27-常量命名)
      - [2.8 Error 的命名](#28-error-的命名)
    - [3. 注释规范](#3-注释规范)
      - [3.1 包注释](#31-包注释)
      - [3.2 变量 / 常量注释](#32-变量--常量注释)
      - [3.3 结构体注释](#33-结构体注释)
      - [3.4 方法注释](#34-方法注释)
      - [3.5 类型注释](#35-类型注释)
    - [4. 类型](#4-类型)
      - [4.1 字符串](#41-字符串)
      - [4.2 切片](#42-切片)
      - [4.3 结构体](#43-结构体)
    - [5. 控制结构](#5-控制结构)
      - [5.1 if](#51-if)
      - [5.2 for](#52-for)
      - [5.3 range](#53-range)
      - [5.4 switch](#54-switch)
      - [5.5 goto](#55-goto)
    - [6. 函数](#6-函数)
      - [6.1 函数参数](#61-函数参数)
      - [6.2 defer](#62-defer)
      - [6.3 方法的接收器](#63-方法的接收器)
      - [6.4 嵌套](#64-嵌套)
      - [6.5 变量命名](#65-变量命名)
    - [7.   GOPATH 设置规范](#7---gopath-设置规范)
    - [8. 依赖管理](#8-依赖管理)
    - [9. 最佳实践](#9-最佳实践)
      - [9.1 性能](#91-性能)
      - [9.2 注意事项](#92-注意事项)
    - [总结](#总结-45)
  - [特别放送 | 给你一份Go项目中最常用的Makefile核心语法](#特别放送--给你一份go项目中最常用的makefile核心语法)
    - [Makefile 的使用方法](#makefile-的使用方法)
    - [Makefile 规则介绍](#makefile-规则介绍)
      - [规则语法](#规则语法)
    - [伪目标](#伪目标)
    - [order-only 依赖](#order-only-依赖)
    - [Makefile 语法概览](#makefile-语法概览)
      - [命令](#命令)
      - [变量](#变量)
      - [条件语句](#条件语句)
      - [函数](#函数)
    - [引入其他 Makefile](#引入其他-makefile)
    - [总结](#总结-46)
  - [特别放送 | Go Modules依赖包管理全讲](#特别放送--go-modules依赖包管理全讲)
    - [Go Modules 简介](#go-modules-简介)
    - [Go 包管理的历史](#go-包管理的历史)
      - [Go1.5 版本前：GOPATH](#go15-版本前gopath)
      - [Go1.5 版本：Vendoring](#go15-版本vendoring)
      - [“百花齐放”：多种 Go 依赖包管理工具出现](#百花齐放多种-go-依赖包管理工具出现)
      - [Go1.9 版本：Dep](#go19-版本dep)
      - [Go1.11 版本之后：Go Modules](#go111-版本之后go-modules)
      - [包（package）和模块（module）](#包package和模块module)
    - [Go Modules 命令](#go-modules-命令)
    - [Go Modules 开关](#go-modules-开关)
    - [模块下载](#模块下载)
      - [通过代理来下载模块](#通过代理来下载模块)
      - [指定版本号下载](#指定版本号下载)
      - [按最小版本下载](#按最小版本下载)
    - [go.mod 和 go.sum 介绍](#gomod-和-gosum-介绍)
      - [go.mod 文件介绍](#gomod-文件介绍)
      - [go.sum 文件介绍](#gosum-文件介绍)
    - [模块下载流程](#模块下载流程)
    - [总结](#总结-47)
  - [特别放送 | IAM排障指南](#特别放送--iam排障指南)
    - [如何排障？](#如何排障)
      - [发现问题](#发现问题)
      - [定位问题](#定位问题)
        - [查看日志定位问题](#查看日志定位问题)
        - [使用 Go 调试工具 Delve 来定位问题](#使用-go-调试工具-delve-来定位问题)
        - [添加 Debug 日志定位问题](#添加-debug-日志定位问题)
        - [解决问题](#解决问题)
    - [IAM 常见故障及解决办法](#iam-常见故障及解决办法)
    - [总结](#总结-48)
  - [特别放送 | Go Modules实战](#特别放送--go-modules实战)
    - [准备一个演示项目](#准备一个演示项目)
    - [配置 Go Modules](#配置-go-modules)
    - [初始化 Go 包为 Go 模块](#初始化-go-包为-go-模块)
    - [Go 包依赖管理](#go-包依赖管理)
    - [总结](#总结-49)
  - [特别放送 | 分布式作业系统设计和实现](#特别放送--分布式作业系统设计和实现)
    - [任务分类](#任务分类)
    - [作业系统的常见实现](#作业系统的常见实现)
      - [Linux crontab](#linux-crontab)
    - [使用开源的作业系统](#使用开源的作业系统)
      - [github.com/robfig/cron使用介绍](#githubcomrobfigcron使用介绍)
      - [github.com/go-redsync/redsync使用介绍](#githubcomgo-redsyncredsync使用介绍)
    - [IAM 作业系统特点](#iam-作业系统特点)
    - [IAM 作业系统实现](#iam-作业系统实现)
      - [task watcher 实现解读](#task-watcher-实现解读)
    - [总结](#总结-50)

## 介绍
### 重要性
“云”是大势所趋，而 Go 是云时代的语言最近几年，我发现腾讯很多团队的开发语言都在转 Go。其实，不光腾讯，像阿里、华为和百度这类国内一线大厂也都在积极转 Go。甚至不少团队，所有项目都是用 Go 构建的。伴随而来的，就是各个公司对 Go 研发工程师的需求越来越旺盛。那么， Go 为什么会变得这么火热呢？我认为，原因主要有两个方面。一方面，Go 是一门非常优秀的语言，它具有很多核心优势，例如：语言简单、语言层面支持并发编程、跨平台编译和自带垃圾回收机制等，这些优势是这些团队选择 Go 最根本的原因。另一方面，也因为 Go 是云时代的语言。为什么这么说呢？下面，我来详细说说。随着云计算平台的逐渐成熟，应用上云已经成为一个不可逆转的趋势了，很多公司都选择将基础架构 / 业务架构云化，例如阿里、腾讯都在将公司内部业务全面云化。可以说，全面云化已经是公司层面的核心 KPI 了，我们甚至可以理解为以后所有的技术都会围绕着云来构建。**而云目前是朝着云原生架构的方向演进的，云原生架构中具有统治力（影响力）的项目绝大部分又是用 Go 构建的**。我们从下面这张云原生技术栈语言组成图中可以看到，有 63% 的具有统治力的云原生项目都是用 Go 来构建的。

![img](https://static001.geekbang.org/resource/image/c6/51/c608623543c26b8f088bea958856f551.png?wh=5703*4942)

完整的云原生技术栈可参考[云原生技术图谱](https://landscape.cncf.io/images/landscape.png)

因此，想要把基础架构 / 业务架构云化，离不开对这些云原生开源项目的学习、改造。而一个团队为了节省成本，技术栈最好统一。


### 问题
比如说，有个开发者写的代码依赖数据库连接，没法写单元测试。细问之后，我发现他参考的文章没有将数据库层跟业务层通过接口解耦。再比如说，还有一些开发者开发的项目很难维护，项目中出现了大量的 common、util、const 这类 Go 包。只看包名，我完全不知道包所实现的功能，问了之后才发现他是参考了一个带有 dao、model、controller、service 目录的、不符合 Go 设计哲学的项目。

我们在学习 Go 项目开发时会面临以下 4 大类问题。
知识盲区：Go 项目开发会涉及很多知识点，但自己对这些知识点却一无所知。想要学习，却发现网上很多文章结构混乱、讲解不透彻。想要搜索一遍优秀的文章，又要花费很多时间，劳神劳力。
学不到最佳实践，能力提升有限：网上有很多文章会介绍 Go 项目的构建方法，但很多都不是最佳实践，学完之后不能在能力和认知上带来最佳提升，还要自己花时间整理学习，事倍功半。
不知道如何完整地开发一个 Go 项目：学了很多 Go 开发相关的知识点、构建方法，但都不体系、不全面、不深入。学完之后，自己并不能把它们有机结合成一个 Go 项目研发体系，真正开发的时候还是一团乱，效率也很低。
缺乏一线项目练手，很难检验学习效果：为了避免闭门造车，我们肯定想学习一线大厂的大型项目构建和研发经验，来检验自己的学习成果，但自己平时又很难接触到，没有这样的学习途径。


### 概述
围绕一个可部署、可运行的企业应用源码，为你详细讲解实际开发流程中会涉及的技能点，让你彻底学会如何构建企业级 Go 应用，并解决 Go 项目开发所面临的各类问题。


![img](https://static001.geekbang.org/resource/image/c4/8c/c4a4bdfc103f193d292b54e44510f28c.jpg?wh=6375*2250)

除此之外，专栏中的每个技能点我都会尽可能朝着“最佳实践”的方向去设计。例如，我使用的 Go 包都是业界采纳度最高的包，而且设计时，我也会尽可能遵循 Go 设计模式、Go 开发规范、Go 最佳实践、go clean architecture 等。同时，我也会尽量把我自己做一线 Go 项目研发的经验，融合到讲解的过程中，给你最靠谱的**建议**，这些经验和**建议**可以让你在构建应用的过程中，少走很多弯路。


为了让你更好地学习这门课程，我把整个专栏划分为了 6 个模块。其中，第 1 个模块是实战环境准备，第 2 到第 6 个模块我会带着你按照研发的流程来实际构建一个应用。实战准备：我会先手把手带你准备一个实验环境，再带你部署我们的实战项目。加深你对实战项目的理解的同时，给你讲解一些部署的技能点，包括如何准备开发环境、制作 CA 证书，安装和配置用到的数据库、应用，以及 Shell 脚本编写技巧等。

实战第 1 站：规范设计：我会详细介绍开发中常见的 10 大规范，例如目录规范、日志规范、错误码规范、Commit 规范等。通过本模块，你能够学会如何设计常见的规范，为高效开发一个高质量、易阅读、易维护的 Go 应用打好基础。

实战第 2 站：基础功能设计或开发：我会教你设计或开发一些 Go 应用开发中的基础功能，这些功能会影响整个应用的构建方式，例如日志包、错误包、错误码等。

实战第 3 站：服务开发：我会带你一起解析一个企业级的 Go 项目代码，让你学会如何开发 Go 应用。在解析的过程中，我也会详细讲解 Go 开发阶段的各个技能点，例如怎么设计和开发 API 服务、Go SDK、客户端工具等。

实战第 4 站：服务测试：我会围绕实战项目来讲解进行单元测试、功能测试、性能分析和性能调优的方法，最终让你交付一个性能和稳定性都经过充分测试的、生产级可用的服务。

实战第 5 站：服务部署：本模块通过实战项目的部署，来告诉你如何部署一个高可用、安全、具备容灾能力，又可以轻松水平扩展的企业应用。这里，我会重点介绍 2 种部署方式：传统部署方式和容器化部署方式，每种方式在部署方法、复杂度和能力上都有所不同。

## 课前
## 1 | IAM系统概述
### 项目背景：为什么选择 IAM 系统作为实战项目？
我们在做 Go 项目开发时，绕不开的一个话题是安全，如何保证 Go 应用的安全，是每个开发者都要解决的问题。虽然 Go 应用的安全包含很多方面，但大体可分为如下 2 类：
- 服务自身的安全：为了保证服务的安全，需要禁止非法用户访问服务。这可以通过服务器层面和软件层面来解决。服务器层面可以通过物理隔离、网络隔离、防火墙等技术从底层保证服务的安全性，软件层面可以通过 HTTPS、用户认证等手段来加强服务的安全性。服务器层面一般由运维团队来保障，软件层面则需要开发者来保障。
- 服务资源的安全：服务内有很多资源，为了避免非法访问，开发者要避免 UserA 访问到 UserB 的资源，也即需要对资源进行授权。通常，我们可以通过资源授权系统来对资源进行授权。

总的来说，为了保障 Go 应用的安全，我们需要对访问进行认证，对资源进行授权。那么，我们要如何实现访问认证和资源授权呢？认证功能不复杂，我们可以通过 JWT （JSON Web Token）认证来实现。授权功能比较复杂，授权功能的复杂性使得它可以囊括很多 Go 开发技能点。因此，在这个专栏中，我将认证和授权的功能实现升级为 IAM 系统，通过讲解它的构建过程，给你讲清楚 Go 项目开发的全部流程。

### IAM 系统是什么？
IAM（Identity and Access Management，身份识别与访问管理）系统是用 Go 语言编写的一个 Web 服务，用于给第三方用户提供访问控制服务。IAM 系统可以帮用户解决的问题是：在特定的条件下，谁能够 / 不能够对哪些资源做哪些操作（Who is able to do what on something given some context），也即完成资源授权功能。那么，IAM 系统是如何进行资源授权的呢？下面，我们通过 IAM 系统的资源授权的流程，来看下它是如何工作的，整个过程可以分为 4 步。![img](https://static001.geekbang.org/resource/image/ee/50/eed75fcd91d6e726ca74315d65193150.jpg?wh=2513*1134)

用户需要提供昵称、密码、邮箱、电话等信息注册并登录到 IAM 系统，这里是以用户名和密码作为唯一的身份标识来访问 IAM 系统，并且完成认证。因为访问 IAM 的资源授权接口是通过密钥（secretID/secretKey）的方式进行认证的，所以用户需要在 IAM 中创建属于自己的密钥资源。因为 IAM 通过授权策略完成授权，所以用户需要在 IAM 中创建授权策略。请求 IAM 提供的授权接口，IAM 会根据用户的请求内容和授权策略来决定一个授权请求是否被允许。

我们可以看到，在上面的流程中，IAM 使用到了 3 种系统资源：用户（User）、密钥（Secret）和策略（Policy），它们映射到程序设计中就是 3 种 RESTful 资源：用户（User）：实现对用户的增、删、改、查、修改密码、批量修改等操作。密钥（Secret）：实现对密钥的增、删、改、查操作。策略（Policy）：实现对策略的增、删、改、查、批量删除操作。

### IAM 系统的架构长啥样？
知道了 IAM 的功能之后，我们再来详细说说 IAM 系统的架构，架构图如下：

![img](https://static001.geekbang.org/resource/image/0a/42/0a5f6fd67af1eda1c690c8216dc5e042.jpg?wh=3197*2063)

总的来说，IAM 架构中包括 9 大组件和 3 大数据库。我将这些组件和功能都总结在下面的表格中。这里面，我们主要记住 5 个核心组件，包括 iam-apiserver、iam-authz-server、iam-pump、marmotedu-sdk-go 和 iamctl 的功能，还有 3 个数据库 Redis、MySQL 和 MongoDB 的功能。

![img](https://static001.geekbang.org/resource/image/6c/71/6cdbde36255c7fb2d4f2e718c9077a71.jpeg?wh=1920*1043)

此外，IAM 系统为存储数据使用到的 3 种数据库的说明如下所示。

![img](https://static001.geekbang.org/resource/image/e6/f2/e68c21e1991c74becc4b8a6a8bf5a8f2.jpeg?wh=1818*496)

### IAM 使用流程
第 1 步，创建平台资源。用户通过 iam-webconsole（RESTful API）或 iamctl（sdk marmotedu-sdk-go）客户端请求 iam-apiserver 提供的 RESTful API 接口完成用户、密钥、授权策略的增删改查，iam-apiserver 会将这些资源数据持久化存储在 MySQL 数据库中。而且，为了确保通信安全，客户端访问服务端都是通过 HTTPS 协议来访问的。

第 2 步，请求 API 完成资源授权。用户可以通过请求 iam-authz-server 提供的 /v1/authz 接口进行资源授权，请求 /v1/authz 接口需要通过密钥认证，认证通过后 /v1/authz 接口会查询授权策略，从而决定资源请求是否被允许。为了提高 /v1/authz 接口的性能，iam-authz-server 将密钥和策略信息缓存在内存中，以便实现快速查询。那密钥和策略信息是如何实现缓存的呢？首先，iam-authz-server 通过调用 iam-apiserver 提供的 gRPC 接口，将密钥和授权策略信息缓存到内存中。同时，为了使内存中的缓存信息和 iam-apiserver 中的信息保持一致，当 iam-apiserver 中有密钥或策略被更新时，iam-apiserver 会往特定的 Redis Channel（iam-authz-server 也会订阅该 Channel）中发送 PolicyChanged 和 SecretChanged 消息。这样一来，当 iam-authz-server 监听到有新消息时就会获取并解析消息，根据消息内容判断是否需要重新调用 gRPC 接来获取密钥和授权策略信息，再更新到内存中。

第 3 步，授权日志数据分析。iam-authz-server 会将授权日志上报到 Redis 高速缓存中，然后 iam-pump 组件会异步消费这些授权日志，再把清理后的数据保存在 MongoDB 中，供运营系统 iam-operating-system 查询。这里还有一点你要**注意**：iam-authz-server 将授权日志保存在 Redis 高性能 key-value 数据库中，可以最大化减少写入延时。不保存在内存中是因为授权日志量我们没法预测，当授权日志量很大时，很可能会将内存耗尽，造成服务中断。

第 4 步，运营平台授权数据展示。iam-operating-system 是 IAM 的运营系统，它可以通过查询 MongoDB 获取并展示运营数据，比如某个用户的授权 / 失败次数、授权失败时的授权信息等。此外，我们也可以通过 iam-operating-system 调用 iam-apiserver 服务来做些运营管理工作。比如，以上帝视角查看某个用户的授权策略供排障使用，或者调整用户可创建密钥的最大个数，再或者通过白名单的方式，让某个用户不受密钥个数限制的影响等等。

### IAM 软件架构模式
在设计软件时，我们首先要做的就是选择一种软件架构模式，它对软件后续的开发方式、软件维护成本都有比较大的影响。因此，这里我也会和你简单聊聊 2 种最常用的软件架构模式，分别是前后端分离架构和 MVC 架构。

#### 前后端分离架构
因为 IAM 系统采用的就是前后端分离的架构，所以我们就以 IAM 的运营系统 iam-operating-system 为例来详细说说这个架构。一般来说，运营系统的功能可多可少，对于一些具有复杂功能的运营系统，我们可以采用前后端分离的架构。其中，前端负责页面的展示以及数据的加载和渲染，后端只负责返回前端需要的数据。iam-operating-system 前后端分离架构如下图所示。

![img](https://static001.geekbang.org/resource/image/a2/76/a2e1f1cc135debd86611yya1f221c476.jpg?wh=2519*1447)

采用了前后端分离架构之后，当你通过浏览器请求前端 ops-webconsole 时，ops-webconsole 会先请求静态文件服务器加载静态文件，比如 HTML、CSS 和 JavaScript，然后它会执行 JavaScript，通过负载均衡请求后端数据，最后把后端返回的数据渲染到前端页面中。采用前后端分离的架构，让前后端通过 RESTful API 通信，会带来以下 5 点好处：可以让前、后端人员各自专注在自己业务的功能开发上，让专业的人做专业的事，来提高代码质量和开发效率前后端可并行开发和发布，这也能提高开发和发布效率，加快产品迭代速度前后端组件、代码分开，职责分明，可以增加代码的维护性和可读性，减少代码改动引起的 Bug 概率，同时也能快速定位 Bug前端 JavaScript 可以处理后台的数据，减少对后台服务器的压力可根据需要选择性水平扩容前端或者后端来节约成本

#### MVC 架构
但是，如果运营系统功能比较少，采用前后端分离框架的弊反而大于利，比如前后端分离要同时维护 2 个组件会导致部署更复杂，并且前后端分离将人员也分开了，这会增加一定程度的沟通成本。同时，因为代码中也需要实现前后端交互的逻辑，所以会引入一定的开发量。这个时候，我们可以尝试直接采用 MVC 软件架构，MVC 架构如下图所示。

![img](https://static001.geekbang.org/resource/image/a2/eb/a23b8ba92705710c694fd7cb99812feb.jpg?wh=1753*869)
MVC 的全名是 Model View Controller，它是一种架构模式，分为 Model、View、Controller 三层，每一层的功能如下：View（视图）：提供给用户的操作界面，用来处理数据的显示。Controller（控制器）：根据用户从 View 层输入的指令，选取 Model 层中的数据，然后对其进行相应的操作，产生最终结果。Model（模型）：应用程序中用于处理数据逻辑的部分。

MVC 架构的好处是通过控制器层将视图层和模型层分离之后，当更改视图层代码后时，我们就不需要重新编译控制器层和模型层的代码了。同样，如果业务流程发生改变也只需要变更模型层的代码就可以。在实际开发中为了更好的 UI 效果，视图层需要经常变更，但是通过 MVC 架构，在变更视图层时，我们根本不需要对业务逻辑层的代码做任何变化，这不仅减少了风险还能提高代码变更和发布的效率。

除此之外，还有一种跟 MVC 比较相似的软件开发架构叫三层架构，它包括 UI 层、BLL 层和 DAL 层。其中，UI 层表示用户界面，BLL 层表示业务逻辑，DAL 层表示数据访问。在实际开发中很多人将 MVC 当成三层架构在用，比如说，很多人喜欢把软件的业务逻辑放在 Controller 层里，将数据库访问操作的代码放在 Model 层里，软件最终的代码放在 View 层里，就这样硬生生将 MVC 架构变成了伪三层架构。这种代码不仅不伦不类，同时也失去了三层架构和 MVC 架构的核心优势，也就是：通过 Controller 层将 Model 层和 View 层解耦，从而使代码更容易维护和扩展。因此在实际开发中，我们也要**注意**遵循 MVC 架构的开发规范，发挥 MVC 的核心价值。

## 2 | 配置go开发环境

![img](https://static001.geekbang.org/resource/image/28/8e/28e52b697e735ecd58770c5fede7e58e.jpg?wh=2588*1894)

### Linux 服务器申请和配置
毫无疑问，要安装一个 Go 开发环境，你首先需要有一个 Linux 服务器。Linux 服务器有很多操作系统可供选择，例如：CentOS、Ubuntu、RHEL、Debian 等，但目前生产环境用得最多的还是 CentOS 系统，为了跟生产环境保持一致，我们选择当前最新的 CentOS 版本：CentOS 8.2。因为本专栏的所有操作都是在 CentOS 8.2 系统上进行的，为了避免环境不一致导致的操作失败，我**建议**你也使用 CentOS 8.2。安装一个 Linux 服务器需要两步：服务器申请和配置。

Linux 服务器申请：
我们可以通过以下 3 种方式来安装一个 CentOS 8.2 系统。在物理机上安装一个 CentOS 8.2 系统。在 Windows/MacBook 上安装虚拟机管理软件，用虚拟机管理软件创建 CentOS 8.2 虚拟机。其中，Windows **建议**用 VMWare Workstation 来创建虚拟机，MacBook **建议**用 VirtualBox 来创建虚拟机。在诸如腾讯云、阿里云、华为云等平台上购买一个虚拟机，并预装 CentOS 8.2 系统。

Linux 服务器配置：
申请完 Linux 服务之后，我们需要通过 SecureCRT 或 Xshell 等工具登录 Linux 服务器，并对服务器做一些简单必要的配置，包括创建普通用户、添加 sudoers、配置 $HOME/.bashrc 文件。接下来，我们一一来说。

第一步，用 Root 用户登录 Linux 系统，并创建普通用户。一般来说，一个项目会由多个开发人员协作完成，为了节省企业成本，公司不会给每个开发人员都配备一台服务器，而是让所有开发人员共用一个开发机，通过普通用户登录开发机进行开发。因此，为了模拟真实的企业开发环境，我们也通过一个普通用户的身份来进行项目的开发，创建方法如下：

```bash
# useradd going # 创建 going 用户，通过 going 用户登录开发机进行开发
# passwd going # 设置密码
Changing password for user going.
New password:
Retype new password:
passwd: all authentication tokens updated successfully.
```
不仅如此，使用普通用户登录和操作开发机也可以保证系统的安全性，这是一个比较好的习惯，所以我们在日常开发中也要尽量避免使用 Root 用户。

第二步，添加 sudoers。我们知道很多时候，普通用户也要用到 Root 的一些权限，但 Root 用户的密码一般是由系统管理员维护并定期更改的，每次都向管理员询问密码又很麻烦。因此，我**建议**你将普通用户加入到 sudoers 中，这样普通用户就可以通过 sudo 命令来暂时获取 Root 的权限。具体来说，你可以执行如下命令添加：

```bash
sed -i '/^root.*ALL=(ALL).*ALL/a\going\tALL=(ALL) \tALL' /etc/sudoers
```
替换 CentOS 8.4 系统中自带的 Yum 源
由于 Red Hat 提前宣布 CentOS 8 于 2021 年 12 月 31 日停止维护，官方的 Yum 源已不可使用，所以需要切换官方的 Yum 源，这里选择阿里提供的 Yum 源。切换命令如下：
```bash
mv /etc/yum.repos.d /etc/yum.repos.d.bak # 先备份原有的 Yum 源
mkdir /etc/yum.repos.d 
wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo
yum clean all && yum makecache
```
第三步，用新的用户名（going）和密码登录 Linux 服务器。这一步也可以验证普通用户是否创建成功。第四步，配置 $HOME/.bashrc 文件。我们登录新服务器后的第一步就是配置 $HOME/.bashrc 文件，以使 Linux 登录 shell 更加易用，例如配置 LANG 解决中文乱码，配置 PS1 可以避免整行都是文件路径，并将 $HOME/bin 加入到 PATH 路径中。配置后的内容如下：

```
mkdir workspace
```
```
sh
# .bashrc
 
# User specific aliases and functions
 
alias rm='rm -i'
alias cp='cp -i'
alias mv='mv -i'
 
# Source global definitions
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi
 
# User specific environment
# Basic envs
export LANG="en_US.UTF-8" # 设置系统语言为 en_US.UTF-8，避免终端出现中文乱码
export PS1='[\u@dev \W]\$ ' # 默认的 PS1 设置会展示全部的路径，为了防止过长，这里只展示："用户名@dev 最后的目录名"
export WORKSPACE="$HOME/workspace" # 设置工作目录
export PATH=$HOME/bin:$PATH # 将 $HOME/bin 目录加入到 PATH 变量中
 
# Default entry folder
cd $WORKSPACE # 登录系统，默认进入 workspace 目录
```
有一点需要我们**注意**，在 export PATH 时，最好把 $PATH 放到最后，因为我们添加到目录中的命令是期望被优先搜索并使用的。配置完 $HOME/.bashrc 后，我们还需要创建工作目录 workspace。将工作文件统一放在 $HOME/workspace 目录中，有几点好处。可以使我们的$HOME目录保持整洁，便于以后的文件查找和分类。如果哪一天 /分区空间不足，可以将整个 workspace 目录 mv 到另一个分区中，并在 /分区中保留软连接，例如：/home/going/workspace -> /data/workspace/。如果哪天想备份所有的工作文件，可以直接备份 workspace。

具体的操作指令是$ mkdir -p $HOME/workspace。配置好 $HOME/.bashrc 文件后，我们就可以执行 bash 命令将配置加载到当前 shell 中了。



### 依赖安装和配置
在 Linux 系统上安装 IAM 系统会依赖一些 RPM 包和工具，有些是直接依赖，有些是间接依赖。为了避免后续的操作出现依赖错误，例如，因为包不存在而导致的编译、命令执行错误等，我们先统一依赖安装和配置。安装和配置步骤如下。

第一步，安装依赖。首先，我们在 CentOS 系统上通过 yum 命令来安装所需工具的依赖，安装命令如下：

```bash
sudo yum -y install make autoconf automake cmake perl-CPAN libcurl-devel libtool gcc gcc-c++ glibc-headers zlib-devel git-lfs telnet ctags lrzsz jq expat-devel openssl-devel
```
第二步，安装 Git。因为安装 IAM 系统、执行 go get 命令、安装 protobuf 工具等都是通过 Git 来操作的，所以接下来我们还需要安装 Git。由于低版本的 Git 不支持--unshallow 参数，而 go get 在安装 Go 包时会用到 git fetch --unshallow 命令，因此我们要确保安装一个高版本的 Git，具体的安装方法如下：

```bash
cd /tmp
wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.30.2.tar.gz
tar -xvzf git-2.30.2.tar.gz
cd git-2.30.2/
./configure
make
sudo make install
git --version          # 输出 git 版本号，说明安装成功
```
把 Git 的二进制目录添加到 PATH 路径中

```bash
tee -a $HOME/.bashrc <<'EOF'
# Configure for git
export PATH=/usr/local/libexec/git-core:$PATH
EOF
```
第三步，配置 Git。我们直接执行如下命令配置 Git：

```bash
git config --global user.name "JF-011101"    # 用户名改成自己的
git config --global user.email "2838264218@qq.com"    # 邮箱改成自己的
git config --global credential.helper store    # 设置 Git，保存用户名和密码
git config --global core.longpaths true # 解决 Git 中 'Filename too long' 的错误
```
在 Git 中，我们会把非 ASCII 字符叫做 Unusual 字符。这类字符在 Git 输出到终端的时候默认是用 8 进制转义字符输出的（以防乱码），但现在的终端多数都支持直接显示非 ASCII 字符，所以我们可以关闭掉这个特性，具体的命令如下：

```bash
git config --global core.quotepath off
```
GitHub 限制最大只能克隆 100M 的单个文件，为了能够克隆大于 100M 的文件，我们还需要安装 Git Large File Storage，安装方式如下：

```bash
git lfs install --skip-repo
```

### Go 编译环境安装和配置
我们知道，Go 是一门编译型语言，所以在部署 IAM 系统之前，我们需要将代码编译成可执行的二进制文件。因此我们需要安装 Go 编译环境。除了 Go，我们也会用 gRPC 框架展示 RPC 通信协议的用法，所以我们也需要将 ProtoBuf 的.proto 文件编译成 Go 语言的接口。因此，我们也需要安装 ProtoBuf 的编译环境。



安装 Go 语言相对来说比较简单，我们只需要下载源码包、设置相应的环境变量即可。首先，我们从 Go 语言官方网站下载对应的 Go 安装包以及源码包，这里我下载的是 go1.17.2 版本：

```bash
wget https://golang.google.cn/dl/go1.17.2.linux-amd64.tar.gz -O /tmp/go1.17.2.linux-amd64.tar.gz
# 解压安装
mkdir -p $HOME/go
tar -xvzf /tmp/go1.17.2.linux-amd64.tar.gz -C $HOME/go
mv $HOME/go/go $HOME/go/go1.17.2
# 将下列环境变量追加到$HOME/.bashrc 文件中
tee -a $HOME/.bashrc <<'EOF'
# Go envs
export GOVERSION=go1.17.2 # Go 版本设置
export GO_INSTALL_DIR=$HOME/go # Go 安装目录
export GOROOT=$GO_INSTALL_DIR/$GOVERSION # GOROOT 设置
export GOPATH=$WORKSPACE/golang # GOPATH 设置
export PATH=$GOROOT/bin:$GOPATH/bin:$PATH # 将 Go 语言自带的和通过 go install 安装的二进制文件加入到 PATH 路径中
export GO111MODULE="on" # 开启 Go moudles 特性
export GOPROXY=https://goproxy.cn,direct # 安装 Go 模块时，代理服务器设置
export GOPRIVATE=
export GOSUMDB=off # 关闭校验 Go 依赖包的哈希值
EOF
```
go 语言是通过一系列的环境变量来控制 Go 编译器行为的。因此，我们一定要理解每一个环境变量的含义。

![img](https://static001.geekbang.org/resource/image/4b/c1/4bde380dc05cd9900ec56dc7027c15c1.jpeg?wh=1920*1080)

因为 Go 以后会用 Go modules 来管理依赖，所以我**建议**你将 GO111MODULE 设置为 on。在使用模块的时候，$GOPATH 是无意义的，不过它还是会把下载的依赖储存在 $GOPATH/pkg/mod 目录中，也会把 go install 的二进制文件存放在 $GOPATH/bin 目录中。另外，我们还要将$GOPATH/bin、$GOROOT/bin 加入到 Linux 可执行文件搜索路径中。这样一来，我们就可以直接在 bash shell 中执行 go 自带的命令，以及通过 go install 安装的命令。最后就是进行测试了，如果我们执行 go version 命令可以成功输出 Go 的版本，就说明 Go 编译环境安装成功。具体的命令如下：

```go
bash
bash
go version
```
#### ProtoBuf 编译环境安装
接着，我们再来安装 protobuf 的编译器 protoc。protoc 需要 protoc-gen-go 来完成 Go 语言的代码转换，因此我们需要安装 protoc 和 protoc-gen-go 这 2 个工具。它们的安装方法比较简单，你直接看我下面给出的代码和操作注释就可以了。

```bash
# 第一步：安装 protobuf
cd /tmp/
git clone --depth=1 https://github.com/protocolbuffers/protobuf
cd protobuf
./autogen.sh
./configure
make
sudo make install
protoc --version # 查看 protoc 版本，成功输出版本号，说明安装成功
libprotoc 3.15.6

# 第二步：安装 protoc-gen-go
$ go get -u github.com/golang/protobuf/protoc-gen-go
```
win:

https://www.cnblogs.com/cxt618/p/15467428.html





### Go 开发 IDE 安装和配置

编译环境准备完之后，我们还需要一个代码编辑器才能开始 Go 项目开发，并且为了提高开发效率，我们需要将这个编辑器配置成 Go IDE。目前，GoLand、VSCode 这些 IDE 都很优秀，我们使用的也很多，但它们都是 Windows 系统下的 IDE。因此，在 Linux 环境下我们可以选择将 Vim 配置成 Go IDE，熟悉 Vim IDE 的操作之后，它的开发效率不输 GoLand 和 VSCode。比如说，我们可以通过 SpaceVim 将 Vim 配置成一个 Go IDE。SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全、 语法检查、格式化、调试、REPL 等特性。我们只需要载入相关语言的模块就能得到一个开箱即用的 Vim IDE 了。Vim 可以选择 NeoVim，NeoVim 是基于 Vim 的一个 fork 分支，它主要解决了 Vim8 之前版本中的异步执行、开发模式等问题，对 Vim 的兼容性很好。同时对 vim 的代码进行了大量地清理和重构，去掉了对老旧系统的支持，添加了新的特性。

虽然 Vim8 后来也新增了异步执行等特性，在使用层面两者差异不大，但是**NeoVim 开发更激进，新特性更多，架构也相对更合理，所以我选择了 NeoVim**，你也可以根据个人爱好来选择（都是很优秀的编辑器，这里不做优缺点比较）。Vim IDE 的安装和配置主要分五步：

第一步，安装 NeoVim。我们直接执行 pip3 和 yum 命令安装即可，安装方法如下：

```bash
sudo pip3 install pynvim
sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm
sudo yum -y install neovim
```
第二步，配置 $HOME/.bashrc。先配置 nvim 的别名为 vi，这样当我们执行 vi 时，Linux 系统就会默认调用 nvim。同时，配置 EDITOR 环境变量可以使一些工具，例如 Git 默认使用 nvim。配置方法如下：

```bash
tee -a $HOME/.bashrc <<'EOF'
# Configure for nvim
export EDITOR=nvim # 默认的编辑器（git 会用到）
alias vi="nvim"
EOF
```
第三步，检查 nvim 是否安装成功。我们可以通过查看 NeoVim 版本来确认是否成功安装，如果成功输出版本号，说明 NeoVim 安装成功。


```bash
bash
vi --version # 输出 NVIM v0.3.8 说明安装成功
NVIM v0.3.8
Build type: RelWithDebInfo
...
```
第四步，离线安装 SpaceVim。安装 SpaceVim 步骤稍微有点复杂，为了简化你的安装，同时消除网络的影响，我将安装和配置 SpaceVim 的步骤做成了一个离线安装包 [marmotVim](https://github.com/marmotedu/marmotVim) 。marmotVim 可以进行 SpaceVim 的安装、卸载、打包等操作，安装步骤如下：

```bash
cd /tmp
wget https://marmotedu-1254073058.cos.ap-beijing.myqcloud.com/tools/marmotVim.tar.gz
tar -xvzf marmotVim.tar.gz
cd marmotVim
./marmotVimCtl install
```
SpaceVim 配置文件为：$HOME/.SpaceVim.d/init.toml 和$HOME/.SpaceVim.d/autoload/custom_init.vim，你可自行配置（配置文件中有配置说明）：init.toml：SpaceVim 的配置文件custom_init.vim：兼容 vimrc，用户自定义的配置文件SpaceVim Go IDE 常用操作的按键映射如下表所示：

![img](https://static001.geekbang.org/resource/image/f1/d9/f1ec06569a411be4369byy7b8c7469d9.jpeg?wh=1920*1080)

第五步，Go 工具安装。SpaceVim 会用到一些 Go 工具，比如在函数跳转时会用到 guru、godef 工具，在格式化时会用到 goimports，所以我们也需要安装这些工具。安装方法有 2 种：Vim 底线命令安装：vi test.go，然后执行：:GoInstallBinaries 安装。拷贝工具：直接将整理好的工具文件拷贝到$GOPATH/bin 目录下。为了方便，你可以直接拷贝我已经打包好的 Go 工具到指定目录下：

```bash
cd /tmp
wget https://marmotedu-1254073058.cos.ap-beijing.myqcloud.com/tools/gotools-for-spacevim.tgz
mkdir -p $GOPATH/bin
tar -xvzf gotools-for-spacevim.tgz -C $GOPATH/bin
```
## 3 | 快速部署
总的来说，我把部署过程分成 2 大步。安装和配置数据库：我们需要安装和配置 MariaDB、Redis 和 MongoDB。安装和配置 IAM 服务：我们需要安装和配置 iam-apiserver、iam-authz-server、iam-pump、iamctl 和 man 文件。

[一键部署（卸载） IAM 系统](https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/installation/README.md)：

```bash

$ mkdir -p $WORKSPACE/golang/src/github.com/marmotedu
$ cd $WORKSPACE/golang/src/github.com/marmotedu
$ git clone --depth=1 https://github.com/marmotedu/iam

# 善用 alias，将常用操作配置成 alias，方便以后操作

$ tee -a $HOME/.bashrc << 'EOF'
# Alias for quick access
export GOWORK="$WORKSPACE/golang/src"
export IAM_ROOT="$GOWORK/github.com/marmotedu/iam"
export LINUX_PASSWORD='iam59!z$'
alias mm="cd $GOWORK/github.com/marmotedu"
alias i="cd $GOWORK/github.com/marmotedu/iam"
EOF
$ bash
```
### 安装和配置数据库
因为 IAM 系统用到了 MariaDB、Redis、MongoDB 数据库来存储数据，而 IAM 服务在启动时会先尝试连接这些数据库，所以为了避免启动时连接数据库失败，这里我们先来安装需要的数据库。

安装和配置 MariaDBIAM：
IAM 会把 REST 资源的定义信息存储在关系型数据库中，关系型数据库我选择了 MariaDB。为啥选择 MariaDB，而不是 MySQL 呢？。选择 MariaDB 一方面是因为它是发展最快的 MySQL 分支，相比 MySQL，它加入了很多新的特性，并且它能够完全兼容 MySQL，包括 API 和命令行。另一方面是因为 MariaDB 是开源的，而且迭代速度很快。首先，我们可以通过以下命令安装和配置 MariaDB，并将 Root 密码设置为 iam59!z$：

```bash
$ cd $IAM_ROOT
$ ./scripts/install/mariadb.sh iam::mariadb::install
$ mysql -h127.0.0.1 -uroot -p'iam59!z$'
MariaDB [(none)]>
```
安装和配置 Redis：
在 IAM 系统中，由于 iam-authz-server 是从 iam-apiserver 拉取并缓存用户的密钥 / 策略信息的，因此同一份密钥 / 策略数据会分别存在 2 个服务中，这可能会出现数据不一致的情况。数据不一致会带来一些问题，例如当我们通过 iam-apiserver 创建了一对密钥，但是这对密钥还没有被 iam-authz-server 缓存，这时候通过这对密钥访问 iam-authz-server 就会访问失败。为了保证数据的一致性，我们可以使用 Redis 的发布订阅 (pub/sub) 功能进行消息通知。同时，iam-authz-server 也会将授权审计日志缓存到 Redis 中，所以也需要安装 Redis key-value 数据库。我们可以通过以下命令来安装和配置 Redis，并将 Redis 的初始密码设置为 iam59!z$ ：

```bash
$ cd $IAM_ROOT
$ ./scripts/install/redis.sh iam::redis::install
$ redis-cli -h 127.0.0.1 -p 6379 -a 'iam59!z$' # 连接 Redis，-h 指定主机，-p 指定监听端口，-a 指定登录密码
```
安装和配置 MongoDB因为 iam-pump 会将 iam-authz-server 产生的数据处理后存储在 MongoDB 中，所以我们也需要安装 MongoDB 数据库。主要分两步安装：首先安装 MongoDB，然后再创建 MongoDB 账号。

第 1 步，安装 MongoDB
首先，我们可以通过以下 4 步来安装 MongoDB。配置 MongoDB yum 源，并安装 MongoDB。CentOS8.x 系统默认没有配置安装 MongoDB 需要的 yum 源，所以我们需要先配置好 yum 源再安装：

```bash
$ sudo tee /etc/yum.repos.d/mongodb-org-4.4.repo<<'EOF'
[mongodb-org-4.4]
name=MongoDB Repository
baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.4/x86_64/
gpgcheck=1
enabled=1
gpgkey=https://www.mongodb.org/static/pgp/server-4.4.asc
EOF

$ sudo yum install -y mongodb-org
```
关闭 SELinux。在安装的过程中，SELinux 有可能会阻止 MongoDB 访问 /sys/fs/cgroup，所以我们还需要关闭 SELinux：

```bash
$ sudo setenforce 0
$ sudo sed -i 's/^SELINUX=.*$/SELINUX=disabled/' /etc/selinux/config # 永久关闭 SELINUX
```
开启外网访问权限和登录验证。MongoDB 安装完之后，默认情况下是不会开启外网访问权限和登录验证，为了方便使用，我**建议**你先开启这些功能，执行如下命令开启：

```bash
$ sudo sed -i '/bindIp/{s/127.0.0.1/0.0.0.0/}' /etc/mongod.conf
$ sudo sed -i '/^#security/a\security:\n  authorization: enabled' /etc/mongod.conf
```
配置完 MongoDB 之后，我们就可以启动它了，具体的命令如下：

```bash
$ sudo systemctl start mongod
$ sudo systemctl enable mongod # 设置开机启动
$ sudo systemctl status mongod # 查看 mongod 运行状态，如果输出中包含 active (running)字样说明 mongod 成功启动
# 登陆
$ mongo --quiet "mongodb://127.0.0.1:27017"
>
```
第 2 步，创建 MongoDB 账号安装完 MongoDB 之后，默认是没有用户账号的，为了方便 IAM 服务使用，我们需要先创建好管理员账号，通过管理员账户登录 MongoDB，我们可以执行创建普通用户、数据库等操作。创建管理员账户。首先，我们通过 use admin 指令切换到 admin 数据库，再通过 db.auth("用户名"，"用户密码") 验证用户登录权限。如果返回 1 表示验证成功；如果返回 0 表示验证失败。具体的命令如下：

```bash
$ mongo --quiet "mongodb://127.0.0.1:27017"
> use admin
switched to db admin
> db.createUser({user:"root",pwd:"iam59!z$",roles:["root"]})
Successfully added user: { "user" : "root", "roles" : [ "root" ] }
> db.auth("root", "iam59!z$")
1
```
此外，如果想删除用户，可以使用 db.dropUser("用户名") 命令。db.createUser 用到了以下 3 个参数。user: 用户名。pwd: 用户密码。roles: 用来设置用户的权限，比如读、读写、写等。

因为 admin 用户具有 MongoDB 的 Root 权限，权限过大安全性会降低。为了提高安全性，我们还需要创建一个 iam 普通用户来连接和操作 MongoDB。

```bash
$ mongo --quiet mongodb://root:'iam59!z$'@127.0.0.1:27017/iam_analytics?authSource=admin # 用管理员账户连接 MongoDB
> use iam_analytics
switched to db iam_analytics
> db.createUser({user:"iam",pwd:"iam59!z$",roles:["dbOwner"]})
Successfully added user: { "user" : "iam", "roles" : [ "dbOwner" ] }
> db.auth("iam", "iam59!z$")
1

# 用iam用户登陆
$ mongo --quiet mongodb://iam:'iam59!z$'@127.0.0.1:27017/iam_analytics?authSource=iam_analytics
```
### 安装和配置 IAM 系统

![img](https://static001.geekbang.org/resource/image/05/ae/05de7498aaba1fddd1ae6ec3cb5b2fae.jpg?wh=2778*1741)

要想完成 IAM 系统的安装，我们还需要安装和配置 iam-apiserver、iam-authz-server、iam-pump 和 iamctl。


#### 准备工作
5步：初始化 MariaDB 数据库，创建 iam 数据库。配置 scripts/install/environment.sh。创建需要的目录。创建 CA 根证书和密钥。配置 hosts。


第 1 步，初始化 MariaDB 数据库，创建 iam 数据库。安装完 MariaDB 数据库之后，我们需要在 MariaDB 数据库中创建 IAM 系统需要的数据库、表和存储过程，以及创建 SQL 语句保存在 IAM 代码仓库中的 configs/iam.sql 文件中。具体的创建步骤如下。登录数据库并创建 iam 用户。

```bash
$ cd $IAM_ROOT
$ mysql -h127.0.0.1 -P3306 -uroot -p'iam59!z$' # 连接 MariaDB，-h 指定主机，-P 指定监听端口，-u 指定登录用户，-p 指定登录密码
MariaDB [(none)]> grant all on iam.* TO iam@127.0.0.1 identified by 'iam59!z$';
Query OK, 0 rows affected (0.000 sec)
MariaDB [(none)]> flush privileges;
Query OK, 0 rows affected (0.000 sec)
```
用 iam 用户登录 MariaDB，执行 iam.sql 文件，创建 iam 数据库。

```bash
$ mysql -h127.0.0.1 -P3306 -uiam -p'iam59!z$'
MariaDB [(none)]> source configs/iam.sql;
MariaDB [iam]> show databases;
+--------------------+
| Database           |
+--------------------+
| iam                |
| information_schema |
+--------------------+
2 rows in set (0.000 sec)
```
上面的命令会创建 iam 数据库，并创建以下数据库资源。表：user 是用户表，用来存放用户信息；secret 是密钥表，用来存放密钥信息；policy 是策略表，用来存放授权策略信息；policy_audit 是策略历史表，被删除的策略会被转存到该表。admin 用户：在 user 表中，我们需要创建一个管理员用户，用户名是 admin，密码是 Admin@2021。存储过程：删除用户时会自动删除该用户所属的密钥和策略信息。

第 2 步，配置 scripts/install/environment.sh。IAM 组件的安装配置都是通过环境变量文件 scripts/install/environment.sh 进行配置的，所以我们要先配置好 scripts/install/environment.sh 文件。这里，你可以直接使用默认值，提高你的安装效率。

第 3 步，创建需要的目录。在安装和运行 IAM 系统的时候，我们需要将配置、二进制文件和数据文件存放到指定的目录。所以我们需要先创建好这些目录，创建步骤如下。

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ sudo mkdir -p ${IAM_DATA_DIR}/{iam-apiserver,iam-authz-server,iam-pump} # 创建 Systemd WorkingDirectory 目录
$ sudo mkdir -p ${IAM_INSTALL_DIR}/bin #创建 IAM 系统安装目录
$ sudo mkdir -p ${IAM_CONFIG_DIR}/cert # 创建 IAM 系统配置文件存放目录
$ sudo mkdir -p ${IAM_LOG_DIR} # 创建 IAM 日志文件存放目录
```
第 4 步， 创建 CA 根证书和密钥。为了确保安全，IAM 系统各组件需要使用 x509 证书对通信进行加密和认证。所以，这里我们需要先创建 CA 证书。CA 根证书是所有组件共享的，只需要创建一个 CA 证书，后续创建的所有证书都由它签名。我们可以使用 CloudFlare 的 PKI 工具集 cfssl 来创建所有的证书。安装 cfssl 工具集。我们可以直接安装 cfssl 已经编译好的二进制文件，cfssl 工具集中包含很多工具，这里我们需要安装 cfssl、cfssljson、cfssl-certinfo，功能如下。cfssl：证书签发工具。cfssljson：将 cfssl 生成的证书（json 格式）变为文件承载式证书。这两个工具的安装方法如下：

```bash
$ cd $IAM_ROOT
$ ./scripts/install/install.sh iam::install::install_cfssl
```
创建配置文件。CA 配置文件是用来配置根证书的使用场景 (profile) 和具体参数 (usage、过期时间、服务端认证、客户端认证、加密等)，可以在签名其它证书时用来指定特定场景：

```bash
$ cd $IAM_ROOT
$ tee ca-config.json << EOF
{
  "signing": {
    "default": {
      "expiry": "87600h"
    },
    "profiles": {
      "iam": {
        "usages": [
          "signing",
          "key encipherment",
          "server auth",
          "client auth"
        ],
        "expiry": "876000h"
      }
    }
  }
}
EOF
```
上面的 JSON 配置中，有一些字段解释如下。signing：表示该证书可用于签名其它证书（生成的 ca.pem 证书中 CA=TRUE）。server auth：表示 client 可以用该证书对 server 提供的证书进行验证。client auth：表示 server 可以用该证书对 client 提供的证书进行验证。expiry：876000h，证书有效期设置为 100 年。

创建证书签名请求文件。我们创建用来生成 CA 证书签名请求（CSR）的 JSON 配置文件：

```bash
$ cd $IAM_ROOT
$ tee ca-csr.json << EOF
{
  "CN": "iam-ca",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "marmotedu",
      "OU": "iam"
    }
  ],
  "ca": {
    "expiry": "876000h"
  }
}
EOF
```
上面的 JSON 配置中，有一些字段解释如下。C：Country，国家。ST：State，省份。L：Locality (L) or City，城市。CN：Common Name，iam-apiserver 从证书中提取该字段作为请求的用户名 (User Name) ，浏览器使用该字段验证网站是否合法。O：Organization，iam-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)。OU：Company division (or Organization Unit – OU)，部门 / 单位。

除此之外，还有两点需要我们**注意**。不同证书 csr 文件的 CN、C、ST、L、O、OU 组合必须不同，否则可能出现 PEER'S CERTIFICATE HAS AN INVALID SIGNATURE 错误。后续创建证书的 csr 文件时，CN、OU 都不相同（C、ST、L、O 相同），以达到区分的目的。

创建 CA 证书和私钥 首先，我们通过 cfssl gencert 命令来创建：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca
$ ls ca*
ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem
$ sudo mv ca* ${IAM_CONFIG_DIR}/cert # 需要将证书文件拷贝到指定文件夹下（分发证书），方便各组件引用
```
上述命令会创建运行 CA 所必需的文件 ca-key.pem（私钥）和 ca.pem（证书），还会生成 ca.csr（证书签名请求），用于交叉签名或重新签名。创建完之后，我们可以通过 cfssl certinfo 命名查看 cert 和 csr 信息：

```bash
$ cfssl certinfo -cert ${IAM_CONFIG_DIR}/cert/ca.pem # 查看 cert(证书信息)
$ cfssl certinfo -csr ${IAM_CONFIG_DIR}/cert/ca.csr # 查看 CSR(证书签名请求)信息
```
第 5 步，配置 hosts。iam 通过域名访问 API 接口，因为这些域名没有注册过，还不能在互联网上解析，所以需要配置 hosts，具体的操作如下：

```bash
$ sudo tee -a /etc/hosts <<EOF
127.0.0.1 iam.api.marmotedu.com
127.0.0.1 iam.authz.marmotedu.com
EOF
```
#### 安装和配置 iam-apiserver
完成了准备工作之后，我们就可以安装 IAM 系统的各个组件了。首先我们通过以下 3 步来安装 iam-apiserver 服务。

第 1 步，创建 iam-apiserver 证书和私钥。其它服务为了安全都是通过 HTTPS 协议访问 iam-apiserver，所以我们要先创建 iam-apiserver 证书和私钥。创建证书签名请求：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ tee iam-apiserver-csr.json <<EOF
{
  "CN": "iam-apiserver",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "marmotedu",
      "OU": "iam-apiserver"
    }
  ],
  "hosts": [
    "127.0.0.1",
    "localhost",
    "iam.api.marmotedu.com"
  ]
}
EOF
```
代码中的 hosts 字段是用来指定授权使用该证书的 IP 和域名列表，上面的 hosts 列出了 iam-apiserver 服务的 IP 和域名。

生成证书和私钥：

```bash
$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \
  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \
  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \
  -profile=iam iam-apiserver-csr.json | cfssljson -bare iam-apiserver
$ sudo mv iam-apiserver*pem ${IAM_CONFIG_DIR}/cert # 将生成的证书和私钥文件拷贝到配置文件目录
```
第 2 步，安装并运行 iam-apiserver。iam-apiserver 作为 iam 系统的核心组件，需要第一个安装。安装 iam-apiserver 可执行程序：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ make build BINS=iam-apiserver
$ sudo cp _output/platforms/linux/amd64/iam-apiserver ${IAM_INSTALL_DIR}/bin

# 生成并安装 iam-apiserver 的配置文件（iam-apiserver.yaml）
$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-apiserver.yaml > iam-apiserver.yaml
$ sudo mv iam-apiserver.yaml ${IAM_CONFIG_DIR}
# 创建并安装 iam-apiserver systemd unit 文件：
$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-apiserver.service > iam-apiserver.service
$ sudo mv iam-apiserver.service /etc/systemd/system/
# 启动 iam-apiserver 服务：
$ sudo systemctl daemon-reload
$ sudo systemctl enable iam-apiserver
$ sudo systemctl restart iam-apiserver
$ systemctl status iam-apiserver # 查看 iam-apiserver 运行状态，如果输出中包含 active (running)字样说明 iam-apiserver 成功启动
```
第 3 步，测试 iam-apiserver 是否成功安装。测试 iam-apiserver 主要是测试 RESTful 资源的 CURD：用户 CURD、密钥 CURD、授权策略 CURD。首先，我们需要获取访问 iam-apiserver 的 Token，请求如下 API 访问：

```bash
$ curl -s -XPOST -H'Content-Type: application/json' -d'{"username":"admin","password":"Admin@2021"}' http://127.0.0.1:8080/login | jq -r .token
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA
```
代码中下面的 HTTP 请求通过-H'Authorization: Bearer ' 指定认证头信息，将上面请求的 Token 替换 。

用户 CURD  创建用户、列出用户、获取用户详细信息、修改用户、删除单个用户、批量删除用户，请求方法如下：

```bash
# 创建用户
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"password":"User@2021","metadata":{"name":"colin"},"nickname":"colin","email":"colin@foxmail.com","phone":"1812884xxxx"}' http://127.0.0.1:8080/v1/users

# 列出用户
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' 'http://127.0.0.1:8080/v1/users?offset=0&limit=10'

# 获取 colin 用户的详细信息
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/users/colin

# 修改 colin 用户
$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"nickname":"colin","email":"colin_modified@foxmail.com","phone":"1812884xxxx"}' http://127.0.0.1:8080/v1/users/colin

# 删除 colin 用户
$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/users/colin

# 批量删除用户
$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' 'http://127.0.0.1:8080/v1/users?name=colin&name=mark&name=john'
```
密钥 CURD创建密钥、列出密钥、获取密钥详细信息、修改密钥、删除密钥请求方法如下：

```bash
# 创建 secret0 密钥
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"metadata":{"name":"secret0"},"expires":0,"description":"admin secret"}' http://127.0.0.1:8080/v1/secrets

# 列出所有密钥
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets

# 获取 secret0 密钥的详细信息
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets/secret0

# 修改 secret0 密钥
$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"metadata":{"name":"secret0"},"expires":0,"description":"admin secret(modified)"}' http://127.0.0.1:8080/v1/secrets/secret0

# 删除 secret0 密钥
$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets/secret0
```
这里我们要**注意**，因为密钥属于重要资源，被删除会导致所有的访问请求失败，所以密钥不支持批量删除。

授权策略 CURD创建策略、列出策略、获取策略详细信息、修改策略、删除策略请求方法如下：

```bash
# 创建策略
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"metadata":{"name":"policy0"},"policy":{"description":"One policy to rule them all.","subjects":["users:<peter|ken>","users:maria","groups:admins"],"actions":["delete","<create|update>"],"effect":"allow","resources":["resources:articles:<.*>","resources:printer"],"conditions":{"remoteIPAddress":{"type":"CIDRCondition","options":{"cidr":"192.168.0.1/16"}}}}}' http://127.0.0.1:8080/v1/policies

# 列出所有策略
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies

# 获取 policy0 策略的详细信息
$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies/policy0

# 修改 policy0 策略
$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{"metadata":{"name":"policy0"},"policy":{"description":"One policy to rule them all(modified).","subjects":["users:<peter|ken>","users:maria","groups:admins"],"actions":["delete","<create|update>"],"effect":"allow","resources":["resources:articles:<.*>","resources:printer"],"conditions":{"remoteIPAddress":{"type":"CIDRCondition","options":{"cidr":"192.168.0.1/16"}}}}}' http://127.0.0.1:8080/v1/policies/policy0

# 删除 policy0 策略
$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies/policy0

```
#### 安装 iamctl
上面，我们安装了 iam 系统的 API 服务。但是想要访问 iam 服务，我们还需要安装客户端工具 iamctl。具体来说，我们可以通过 3 步完成 iamctl 的安装和配置。

第 1 步，创建 iamctl 证书和私钥。iamctl 使用 https 协议与 iam-apiserver 进行安全通信，iam-apiserver 对 iamctl 请求包含的证书进行认证和授权。iamctl 后续用于 iam 系统访问和管理，所以这里创建具有最高权限的 admin 证书。创建证书签名请求。下面创建的证书只会被 iamctl 当作 client 证书使用，所以 hosts 字段为空。代码如下：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ cat > admin-csr.json <<EOF
{
  "CN": "admin",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "marmotedu",
      "OU": "iamctl"
    }
  ],
  "hosts": []
}
EOF
# 生成证书和私钥：
$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \
  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \
  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \
  -profile=iam admin-csr.json | cfssljson -bare admin
$ mkdir -p $(dirname ${CONFIG_USER_CLIENT_CERTIFICATE}) $(dirname ${CONFIG_USER_CLIENT_KEY}) # 创建客户端证书存放的目录
$ mv admin.pem ${CONFIG_USER_CLIENT_CERTIFICATE} # 安装 TLS 的客户端证书
$ mv admin-key.pem ${CONFIG_USER_CLIENT_KEY} # 安装 TLS 的客户端私钥文件
```
第 2 步，安装 iamctl。iamctl 是 IAM 系统的客户端工具，其安装位置和 iam-apiserver、iam-authz-server、iam-pump 位置不同，为了能够在 shell 下直接运行 iamctl 命令，我们需要将 iamctl 安装到$HOME/bin 下，同时将 iamctl 的配置存放在默认加载的目录下：$HOME/.iam。主要分 2 步进行。安装 iamctl 可执行程序：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ make build BINS=iamctl
$ cp _output/platforms/linux/amd64/iamctl $HOME/bin
# 生成并安装 iamctl 的配置文件（iamctl.yaml）：
$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iamctl.yaml> iamctl.yaml
$ mkdir -p $HOME/.iam
$ mv iamctl.yaml $HOME/.iam
```
因为 iamctl 是一个客户端工具，可能会在多台机器上运行。为了简化部署 iamctl 工具的复杂度，我们可以把 config 配置文件中跟 CA 认证相关的 CA 文件内容用 base64 加密后，放置在 config 配置文件中。具体的思路就是把 config 文件中的配置项 client-certificate、client-key、certificate-authority 分别用如下配置项替换 client-certificate-data、client-key-data、certificate-authority-data。这些配置项的值可以通过对 CA 文件使用 base64 加密获得。假如，certificate-authority 值为/etc/iam/cert/ca.pem，则 certificate-authority-data 的值为 cat "/etc/iam/cert/ca.pem" | base64 | tr -d '\r\n'，其它-data 变量的值类似。这样当我们再部署 iamctl 工具时，只需要拷贝 iamctl 和配置文件，而不用再拷贝 CA 文件了。

第 3 步，测试 iamctl 是否成功安装。执行 iamctl user list 可以列出预创建的 admin 用户，如下所示：
```bash
[going@dev workspace]$ iamctl user list
NAME    NICKNAME   EMAIL               PHONE         CREATED               UPDATED
admin  admin     admin@foxmail.com  1812884xxxx  2021-05-27 18:01:40  2022-07-07 16:32:18
```
#### 安装和配置 iam-authz-server
接下来，我们需要安装另外一个核心组件：iam-authz-server，可以通过以下 3 步来安装。

第 1 步，创建 iam-authz-server 证书和私钥。创建证书签名请求：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ tee iam-authz-server-csr.json <<EOF
{
  "CN": "iam-authz-server",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "marmotedu",
      "OU": "iam-authz-server"
    }
  ],
  "hosts": [
    "127.0.0.1",
    "localhost",
    "iam.authz.marmotedu.com"
  ]
}
EOF
```
代码中的 hosts 字段指定授权使用该证书的 IP 和域名列表，上面的 hosts 列出了 iam-authz-server 服务的 IP 和域名。生成证书和私钥：

```bash
$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \
  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \
  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \
  -profile=iam iam-authz-server-csr.json | cfssljson -bare iam-authz-server
$ sudo mv iam-authz-server*pem ${IAM_CONFIG_DIR}/cert # 将生成的证书和私钥文件拷贝到配置文件目录
```
第 2 步，安装并运行 iam-authz-server。安装 iam-authz-server 步骤和安装 iam-apiserver 步骤基本一样，也需要 4 步。安装 iam-authz-server 可执行程序：

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ make build BINS=iam-authz-server
$ sudo cp _output/platforms/linux/amd64/iam-authz-server ${IAM_INSTALL_DIR}/bin
# 生成并安装 iam-authz-server 的配置文件（iam-authz-server.yaml）：
$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-authz-server.yaml > iam-authz-server.yaml
$ sudo mv iam-authz-server.yaml ${IAM_CONFIG_DIR}
# 创建并安装 iam-authz-server systemd unit 文件：
$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-authz-server.service > iam-authz-server.service
$ sudo mv iam-authz-server.service /etc/systemd/system/
# 启动 iam-authz-server 服务：
$ sudo systemctl daemon-reload
$ sudo systemctl enable iam-authz-server
$ sudo systemctl restart iam-authz-server
$ systemctl status iam-authz-server # 查看 iam-authz-server 运行状态，如果输出中包含 active (running)字样说明 iam-authz-server 成功启动。
```
第 3 步，测试 iam-authz-server 是否成功安装。重新登陆系统，并获取访问令牌

```bash
$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{"username":"admin","password":"Admin@2021"}' http://127.0.0.1:8080/login | jq -r .token`

# 创建授权策略
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"policy":{"description":"One policy to rule them all.","subjects":["users:<peter|ken>","users:maria","groups:admins"],"actions":["delete","<create|update>"],"effect":"allow","resources":["resources:articles:<.*>","resources:printer"],"conditions":{"remoteIPAddress":{"type":"CIDRCondition","options":{"cidr":"192.168.0.1/16"}}}}}' http://127.0.0.1:8080/v1/policies

# 创建密钥，并从命令的输出中提取 secretID 和 secretKey
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"expires":0,"description":"admin secret"}' http://127.0.0.1:8080/v1/secrets
{"metadata":{"id":23,"name":"authztest","createdAt":"2021-04-08T07:24:50.071671422+08:00","updatedAt":"2021-04-08T07:24:50.071671422+08:00"},"username":"admin","secretID":"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox","secretKey":"7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8","expires":0,"description":"admin secret"}

# 生成访问 iam-authz-server 的 token  iamctl 提供了 jwt sigin 命令，可以根据 secretID 和 secretKey 签发 Token，方便你使用。
$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey
eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ

# 如果你的开发过程中有些重复性的操作，为了方便使用，也可以将这些操作以 iamctl 子命令的方式集成到 iamctl 命令行中。

# 测试资源授权是否通过我们可以通过请求 /v1/authz 来完成资源授权：如果授权通过会返回：{"allowed":true} 。
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{"subject":"users:maria","action":"delete","resource":"resources:articles:ladon-introduction","context":{"remoteIPAddress":"192.168.0.5"}}' http://127.0.0.1:9090/v1/authz
{"allowed":true}
```
#### 安装和配置 iam-pump
安装 iam-pump 步骤和安装 iam-apiserver、iam-authz-server 步骤基本一样，具体步骤如下。第 1 步，安装 iam-pump 可执行程序。

```bash
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ make build BINS=iam-pump
$ sudo cp _output/platforms/linux/amd64/iam-pump ${IAM_INSTALL_DIR}/bin

# 生成并安装 iam-pump 的配置文件（iam-pump.yaml）。
$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-pump.yaml > iam-pump.yaml
$ sudo mv iam-pump.yaml ${IAM_CONFIG_DIR}

# 创建并安装 iam-pump systemd unit 文件。
$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-pump.service > iam-pump.service
$ sudo mv iam-pump.service /etc/systemd/system/

# 启动 iam-pump 服务。
$ sudo systemctl daemon-reload
$ sudo systemctl enable iam-pump
$ sudo systemctl restart iam-pump
$ systemctl status iam-pump # 查看 iam-pump 运行状态，如果输出中包含 active (running)字样说明 iam-pump 成功启动。

# 测试 iam-pump 是否成功安装。
$ curl http://127.0.0.1:7070/healthz
{"status": "ok"}
```
#### 安装 man 文件
IAM 系统通过组合调用包：github.com/cpuguy83/go-md2man/v2/md2man 和 github.com/spf13/cobra 的相关函数生成了各个组件的 man1 文件，主要分 3 步实现。
```bash
# 第 1 步，生成各个组件的 man1 文件。
$ cd $IAM_ROOT
$ ./scripts/update-generated-docs.sh
# 第 2 步，安装生成的 man1 文件。
$ sudo cp docs/man/man1/* /usr/share/man/man1/
# 第 3 步，检查是否成功安装 man1 文件。
$ man iam-apiserver
```
执行 man iam-apiserver 命令后，会弹出 man 文档界面



IAM 系统所有组件都已经安装成功了，你可以通过 iamctl version 查看客户端和服务端版本，代码如下：

```bash
$ iamctl version -o yaml
clientVersion:
  buildDate: "2021-04-08T01:56:20Z"
  compiler: gc
  gitCommit: 1d682b0317396347b568a3ef366c1c54b3b0186b
  gitTreeState: dirty
  gitVersion: v0.6.1-5-g1d682b0
  goVersion: go1.16.2
  platform: linux/amd64
serverVersion:
  buildDate: "2021-04-07T22:30:53Z"
  compiler: gc
  gitCommit: bde163964b8c004ebb20ca4abd8a2ac0cd1f71ad
  gitTreeState: dirty
  gitVersion: bde1639
  goVersion: go1.16.2
  platform: linux/amd64
```

## 标准设计

## 4 | 规范设计（上）：项目开发杂乱无章，如何规范？（开源规范、文档规范和版本规范）
规范问题：
**代码风格不一**：代码仓库中有多种代码风格，读 / 改他人的代码都是一件痛苦的事情，整个代码库也会看起来很乱。**目录杂乱无章**：相同的功能被放在不同的目录，或者一个目录你根本不知道它要完成什么功能，新开发的代码你也不知道放在哪个目录或文件。这些都会严重降低代码的可维护性。**接口不统一**：对外提供的 API 接口不统一，例如修改用户接口为/v1/users/colin，但是修改密钥接口为/v1/secret?name=secret0，难以理解和记忆。**错误码不规范**：错误码会直接暴露给用户，主要用于展示错误类型，以定位错误问题。错误码不规范会导致难以辨别错误类型，或者同类错误拥有不同错误码，增加理解难度。

在设计阶段、编码之前，我们需要一个好的规范来约束开发者。

### 需要制定规范的地方
非编码类规范，主要包括开源规范、文档规范、版本规范、Commit 规范和发布规范。编码类规范，则主要包括目录规范、代码规范、接口规范、日志规范和错误码规范。

![img](https://static001.geekbang.org/resource/image/db/4e/dbcb06d2c406446418778d07d917604e.png?wh=1981*1091)

### 开源规范

为什么一定要知道开源规范呢？原因主要有两方面：一是，开源项目在代码质量、代码规范、文档等方面，要比非开源项目要求更高，在项目开发中按照开源项目的要求来规范自己的项目，可以更好地驱动项目质量的提高；二是，一些大公司为了不重复造轮子，会要求公司团队能够将自己的项目开源，所以提前按开源标准来驱动 Go 项目开发，也会为我们日后代码开源省去不少麻烦

#### 开源规范详细列表

- 项目结构：一个开源项目应该有一个合理、专业的、符合语言特色的项目结构。
- 严格遵循代码规范：开源的代码，面向的人群是所有的开发者，一个不规范的代码，可读性差，不利于其他开发者阅读和贡献代码。
- 代码质量：开源的代码，一定要保证代码的质量，一个低质量的代码，不仅隐藏了很多性能和功能缺陷，而且还会影响开源项目的品牌，进而影响开源效果。
- 单元测试覆盖率：一个开源的 Go 项目，要保证整个项目的单元测试覆盖率，这样一方面可以保证代码的质量，另一方面可以使开源项目更专业，也能让你更加安心的发布版本。
- 版本发布规范：开源项目要遵循既定的版本规范，整个项目的更新迭代，要有版本号，目前用的比较多的是语义化的版本规范。
- 向下兼容：代码要做到向下兼容，这样可以尽可能减少发布变更的影响，遵循语义化的版本规范，可以在一定程度上保证代码的向下兼容能力。

- 详细的文档说明：要保证代码能够被其他开发者很容易的阅读和贡献代码，所以不仅要保证文档的质量和数量，还要确保有某些需要的文档：
  - LICENSE（如果是开源项目，LICENSE 是必选的）：软件协议，声明该开源项目遵循什么软件协议。
  - README.md：README 文件，放在项目的根目录下，包含项目的描述、依赖项、安装方法、使用方法、贡献方法、作者和遵循的软件协议等。
  - CHANGELOG：目录，用来存放版本的变更历史，方便其他开发者了解新版本或旧版本的变更内容。 
  - Makefile：对于一个复杂的项目，通常也会包含一个 Makefile 文件，用来对项目进行构建、测试、安装等操作。
  - CONTRIBUTING.md：用来说明如何给本项目贡献代码，包含贡献流程和流程中每个环节的详细操作。
  - docs：目录，用来存放本项目所有文档，例如：安装文档、使用文档、开发文档等。一些重要的文档，可以链接到项目根目录的 README.md 文档中。这些文档要确保开发者能够轻松的理解、部署和使用该项目。
  - examples：存放一些示例代码。
- 安全：开源的代码，要保证整个代码库和提交记录中，不能出现类似内部 IP、内部域名、密码、密钥这类信息。
- 完善的 examples：完善的 examples，可以帮助用户快速学习和使用开源项目。
- 好的 Commit Message 记录：开源项目在 commit 时，要遵循一定的规范，这样其他开发者才能够快速浏览和理解变更历史，减小学习成本，本项目遵循 Angular commit message 规范。
- 发布可用的版本：要确保每一次发布都经过充分的测试，每一个发布的版本都是可用的。
- 持续的更新：一个好的开源项目，应该能够持续的更新功能，修复 Bug。对于一些已经结项、不维护的开源项目，需要及时的对项目进行归档，并在项目描述中加以说明。
- 及时的处理 pull request、issue、评论等：当项目被别的开发者提交 pull request、issue、评论时，要及时的处理，一方面可以确保项目不断被更新，另一方面也可以激发其他开发者贡献代码的积极性。
- 建立讨论小组：如果条件允许，最好和贡献者建立讨论小组，每周或每月组织讨论，共同维护。
- 做好推广：如果有条件，可以宣传运营开源项目，让更多的人知道，更多的人用，更多的人贡献代码。例如：在掘金、简书等平台发表文章，创建 QQ、微信交流群等。
- Git 工作流：选择合适的 Git 工作流，并遵循 GIt 工作流使用规范，例如 Gitflow 工作流。


#### 开源协议


经常使用的 6 种开源协议

GPL： General Public License，开源项目最常用的许可证，衍生代码的分发需开源并且也要遵守此协议。该协议也有很多变种，不同变种要求会略微不同。
MPL： MPL 协议允许免费重发布、免费修改，但要求修改后的代码版权归软件的发起者，这种授权维护了商业软件的利益，它要求基于这种软件的修改无偿贡献版权给该软件。
LGPL： Lesser General Public Licence，是 GPL 的一个为主要为类库使用设计的开源协议。LGPL 允许商业软件通过类库引用的方式使用 LGPL 类库而不需要开源商业软件的代码。但是如果修改 LGPL 协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用 LGPL 协议。
Apache： Apache 协议是 Apache 软件基金会发布的一个自由软件许可证，Apache 2.0 协议除了为用户提供版权许可之外，还有专利许可，非常适合涉及专利内容的项目。
BSD： BSD（Berkeley Software Distribution，伯克利软件发行版）。BSD 协议在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制，该协议还禁止用开源代码的作者/机构名字和原来产品的名字做市场推广。
MIT： 协议的主要内容为：该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版权和许可提示。MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。![img](https://static001.geekbang.org/resource/image/61/00/61b4d5da6c8327b738e9657c6c144000.png?wh=6503*2466)

在上图中，右边的协议比左边的协议宽松，在选择时，你可以根据菱形框中的选择项从上到下进行选择。为了使你能够毫无负担地使用 IAM 项目提供的源码，我选择了最宽松的 MIT 协议。另外，因为 Apache 是对商业应用友好的协议，使用者也可以在需要的时候修改代码来满足需要，并作为开源或商业产品发布 / 销售，所以大型公司的开源项目通常会采用 Apache 2.0 开源协议。

### 文档规范
工作中我发现，很多开发者非常注重代码产出，但不注重文档产出。他们觉得，即使没有软件文档也没太大关系，不影响软件交付。我要说的是，这种看法是错误的！因为文档属于软件交付的一个重要组成部分，没有文档的项目很难理解、部署和使用。因此，编写文档是一个必不可少的开发工作。那么一个项目需要编写哪些文档，又该如何编写呢？我认为项目中最需要的 3 类文档是 README 文档、项目文档和 API 接口文档。下面，我们一一来说它们的编写规范。

README 规范
README 文档是项目的门面，它是开发者学习项目时第一个阅读的文档，会放在项目的根目录下。因为它主要是用来介绍项目的功能、安装、部署和使用的，所以它是可以规范化的。下面，我们直接通过一个 README 模板，来看一下 README 规范中的内容：

```
# 项目名称

<!-- 写一段简短的话描述项目 -->

## 功能特性

<!-- 描述该项目的核心功能点 -->

## 软件架构(可选)

<!-- 可以描述下项目的架构 -->

## 快速开始

### 依赖检查

<!-- 描述该项目的依赖，比如依赖的包、工具或者其他任何依赖项 -->

### 构建

<!-- 描述如何构建该项目 -->

### 运行

<!-- 描述如何运行该项目 -->

## 使用指南

<!-- 描述如何使用该项目 -->

## 如何贡献

<!-- 告诉其他开发者如果给该项目贡献源码 -->

## 社区(可选)

<!-- 如果有需要可以介绍一些社区相关的内容 -->

## 关于作者

<!-- 这里写上项目作者 -->

## 谁在用(可选)

<!-- 可以列出使用本项目的其他有影响力的项目，算是给项目打个广告吧 -->

## 许可证

<!-- 这里链接上该项目的开源许可证 -->
```
[例子](https://raw.githubusercontent.com/marmotedu/iam/master/README.md)

项目文档规范
项目文档包括一切需要文档化的内容，它们通常集中放在 /docs 目录下。当我们在创建团队的项目文档时，通常会预先规划并创建好一些目录，用来存放不同的文档。因此，在开始 Go 项目开发之前，我们也要制定一个软件文档规范。好的文档规范有 2 个优点：易读和可以快速定位文档。不同项目有不同的文档需求，在制定文档规范时，你可以考虑包含两类文档。开发文档：用来说明项目的开发流程，比如如何搭建开发环境、构建二进制文件、测试、部署等。用户文档：软件的使用文档，对象一般是软件的使用者，内容可根据需要添加。比如，可以包括 API 文档、SDK 文档、安装文档、功能介绍文档、最佳实践、操作指南、常见问题等。为了方便全球开发者和用户使用，开发文档和用户文档，可以预先规划好英文和中文 2 个版本。为了加深你的理解，这里我们来看下实战项目的文档目录结构：

```
docs
├── devel                            # 开发文档，可以提前规划好，英文版文档和中文版文档
│   ├── en-US/                       # 英文版文档，可以根据需要组织文件结构
│   └── zh-CN                        # 中文版文档，可以根据需要组织文件结构
│       └── development.md           # 开发手册，可以说明如何编译、构建、运行项目
├── guide                            # 用户文档
│   ├── en-US/                       # 英文版文档，可以根据需要组织文件结构
│   └── zh-CN                        # 中文版文档，可以根据需要组织文件结构
│       ├── api/                     # API文档
│       ├── best-practice            # 最佳实践，存放一些比较重要的实践文章
│       │   └── authorization.md
│       ├── faq                      # 常见问题
│       │   ├── iam-apiserver
│       │   └── installation
│       ├── installation             # 安装文档
│       │   └── installation.md
│       ├── introduction/            # 产品介绍文档
│       ├── operation-guide          # 操作指南，里面可以根据RESTful资源再划分为更细的子目录，用来存放系统核心/全部功能的操作手册
│       │   ├── policy.md
│       │   ├── secret.md
│       │   └── user.md
│       ├── quickstart               # 快速入门
│       │   └── quickstart.md
│       ├── README.md                # 用户文档入口文件
│       └── sdk                      # SDK文档
│           └── golang.md
└── images                           # 图片存放目录
    └── 部署架构v1.png
```
API 接口文档规范
接口文档又称为 API 文档，一般由后台开发人员编写，用来描述组件提供的 API 接口，以及如何调用这些 API 接口。在项目初期，接口文档可以解耦前后端，让前后端并行开发：前端只需要按照接口文档实现调用逻辑，后端只需要按照接口文档提供功能。当前后端都开发完成之后，我们就可以直接进行联调，提高开发效率。在项目后期，接口文档可以提供给使用者，不仅可以降低组件的使用门槛，还能够减少沟通成本。显然，一个有固定格式、结构清晰、内容完善的接口文档，就非常重要了。那么我们该如何编写接口文档，它又有什么规范呢？接口文档有四种编写方式，包括编写 Word 格式文档、借助工具编写、通过注释生成和编写 Markdown 格式文档。具体的实现方式见下表：

![img](https://static001.geekbang.org/resource/image/91/63/912fe30a70df0866d168ef1c0a50cb63.jpeg?wh=1920*1080)

其中，通过注释生成和编写 Markdown 格式文档这 2 种方式用得最多。在这个专栏，我采用编写 Markdown 格式文档的方式，原因如下：相比通过注释生成的方式，编写 Markdown 格式的接口文档，能表达更丰富的内容和格式，不需要在代码中添加大量注释。相比 Word 格式的文档，Markdown 格式文档占用的空间更小，能够跟随代码仓库一起发布，方便 API 文档的分发和查找。相比在线 API 文档编写工具，Markdown 格式的文档免去了第三方平台依赖和网络的限制。

API 接口文档又要遵循哪些规范呢？其实，一个规范的 API 接口文档，通常需要包含一个完整的 API 接口介绍文档、API 接口变更历史文档、通用说明、数据结构说明、错误码描述和 API 接口使用文档。API 接口使用文档中需要包含接口描述、请求方法、请求参数、输出参数和请求示例。当然，根据不同的项目需求，API 接口文档会有不同的格式和内容。我以这门课的实战项目采用的 API 接口文档规范为例，和你解释下。

接口文档拆分为以下几个 Markdown 文件，并存放在目录 docs/guide/zh-CN/api 中：
- README.md ：API 接口介绍文档，会分类介绍 IAM 支持的 API 接口，并会存放相关 API 接口文档的链接，方便开发者查看。
- CHANGELOG.md ：API 接口文档变更历史，方便进行历史回溯，也可以使调用者决定是否进行功能更新和版本更新。
- generic.md ：用来说明通用的请求参数、返回参数、认证方法和请求方法等。
- struct.md ：用来列出接口文档中使用的数据结构。这些数据结构可能被多个 API 接口使用，会在 user.md、secret.md、policy.md 文件中被引用。
- user.md 、 secret.md 、 policy.md ：API 接口文档，相同 REST 资源的接口会存放在一个文件中，以 REST 资源名命名文档名。
- error_code.md ：错误码描述，通过程序自动生成。

这里我拿 user.md 接口文档为例，和你解释下接口文档是如何写的。user.md 文件记录了用户相关的接口，每个接口按顺序排列，包含如下 5 部分。

接口描述：描述接口实现了什么功能。请求方法：接口的请求方法，格式为 HTTP 方法 请求路径，例如 POST /v1/users。在 通用说明中的请求方法部分，会说明接口的请求协议和请求地址。输入参数：接口的输入字段，它又分为 Header 参数、Query 参数、Body 参数、Path 参数。每个字段通过：参数名称、必选、类型 和 描述 4 个属性来描述。如果参数有限制或者默认值，可以在描述部分注明。输出参数：接口的返回字段，每个字段通过 参数名称、类型 和 描述 3 个属性来描述。请求示例：一个真实的 API 接口请求和返回示例。

[更详细的API接口文档](https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/api)


### 版本规范
在做 Go 项目开发时，我**建议**你把所有组件都加入版本机制。原因主要有两个：一是通过版本号，我们可以很明确地知道组件是哪个版本，从而定位到该组件的功能和代码，方便我们定位问题。二是发布组件时携带版本号，可以让使用者知道目前的项目进度，以及使用版本和上一个版本的功能差别等。目前业界主流的版本规范是语义化版本规范，也是 IAM 系统采用的版本规范。那什么是语义化版本规范呢？

语义化版本规范（SemVer，Semantic Versioning）是 GitHub 起草的一个具有指导意义的、统一的版本号表示规范。它规定了版本号的表示、增加和比较方式，以及不同版本号代表的含义。在这套规范下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。语义化版本格式为：主版本号.次版本号.修订号（X.Y.Z），其中 X、Y 和 Z 为非负的整数，且禁止在数字前方补零。

版本号可按以下规则递增：主版本号（MAJOR）：当做了不兼容的 API 修改。次版本号（MINOR）：当做了向下兼容的功能性新增及修改。这里有个不成文的约定需要你**注意**，偶数为稳定版本，奇数为开发版本。修订号（PATCH）：当做了向下兼容的问题修正。

你可能还看过这么一种版本号：v1.2.3-alpha.1+001。这其实是把先行版本号（Pre-release）和版本编译元数据，作为延伸加到了主版本号.次版本号.修订号的后面，格式为 X.Y.Z[-先行版本号][+版本编译元数据]

先行版本号意味着，该版本不稳定，可能存在兼容性问题，格式为：X.Y.Z-[一连串以句点分隔的标识符] ，比如下面这几个例子：

```
1.0.0-alpha
1.0.0-alpha.1
1.0.0-0.3.7
1.0.0-x.7.z.92
```
编译版本号，一般是编译器在编译过程中自动生成的，我们只定义其格式，并不进行人为控制。下面是一些编译版本号的示例：

```
1.0.0-alpha+001
1.0.0+20130313144700
1.0.0-beta+exp.sha.5114f85
```
先行版本号和编译版本号只能是字母、数字，且不可以有空格。

语义化版本控制规范
语义化版本控制规范比较多，这里我给你介绍几个比较重要的。如果你需要了解更详细的规范，可以参考 [这个链接](https://semver.org/lang/zh-CN/) 的内容。

标记版本号的软件发行后，禁止改变该版本软件的内容，任何修改都必须以新版本发行。主版本号为零（0.y.z）的软件处于开发初始阶段，一切都可能随时被改变，这样的公共 API 不应该被视为稳定版。1.0.0 的版本号被界定为第一个稳定版本，之后的所有版本号更新都基于该版本进行修改。修订号 Z（x.y.Z | x > 0）必须在只做了向下兼容的修正时才递增，这里的修正其实就是 Bug 修复。次版本号 Y（x.Y.z | x > 0）必须在有向下兼容的新功能出现时递增，在任何公共 API 的功能被标记为弃用时也必须递增，当有改进时也可以递增。其中可以包括修订级别的改变。每当次版本号递增时，修订号必须归零。主版本号 X（X.y.z | X > 0）必须在有任何不兼容的修改被加入公共 API 时递增。其中可以包括次版本号及修订级别的改变。每当主版本号递增时，次版本号和修订号必须归零。

如何确定版本号？说了这么多，我们到底该如何确定版本号呢？这里我给你总结了这么几个经验：第一，在实际开发的时候，我**建议**你使用 0.1.0 作为第一个开发版本号，并在后续的每次发行时递增次版本号。第二，当我们的版本是一个稳定的版本，并且第一次对外发布时，版本号可以定为 1.0.0。

第三，当我们严格按照 Angular commit message 规范提交代码时，版本号可以这么来确定：fix 类型的 commit 可以将修订号 +1。feat 类型的 commit 可以将次版本号 +1。带有 BREAKING CHANGE 的 commit 可以将主版本号 +1。

### 总结
一个项目的规范设计主要包括编码类和非编码类这两类规范。今天我们一起学习了开源规范、文档规范和版本规范，现在我们回顾一下重点内容吧。新开发的项目最好按照开源标准来规范，以驱动其成为一个高质量的项目。开发之前，最好提前规范好文档目录，并选择一种合适的方式来编写 API 文档。在这门课的实战项目中，我采用的是 Markdown 格式，也**推荐**你使用这种方式。项目要遵循版本规范，目前业界主流的版本规范是语义化版本规范，也是我**推荐**的版本规范。


## 5 | 规范设计（下）：commit 信息风格迥异、难以阅读，如何规范？
在 Go 项目开发时，一个好的 Commit Message 至关重要：
- 可以使自己或者其他开发人员能够清晰地知道每个 commit 的变更内容，方便快速浏览变更历史，比如可以直接略过文档类型或者格式化类型的代码变更。
- 可以基于这些 Commit Message 进行过滤查找，比如只查找某个版本新增的功能：git log --oneline --grep "^feat|^fix|^perf"。
- 可以基于规范化的 Commit Message 生成 Change Log。
- 可以依据某些类型的 Commit Message 触发构建或者发布流程，比如当 type 类型为 feat、fix 时我们才触发 CI 流程。
- 确定语义化版本的版本号。比如 fix 类型可以映射为 PATCH 版本，feat 类型可以映射为 MINOR 版本。带有 BREAKING CHANGE 的 commit，可以映射为 MAJOR 版本。在这门课里，我就是通过这种方式来自动生成版本号。

接下来，我们来看下如何规范 Commit Message。另外，除了 Commit Message 之外，我还会介绍跟 Commit 相关的 3 个重点，以及如何通过自动化流程来保证 Commit Message 的规范化。



### Commit Message 的规范有哪些？

毫无疑问，我们可以根据需要自己来制定 Commit Message 规范，但是我更**建议**你采用开源社区中比较成熟的规范。一方面，可以避免重复造轮子，提高工作效率。另一方面，这些规范是经过大量开发者验证的，是科学、合理的。目前，社区有多种 Commit Message 的规范，例如 jQuery、Angular 等。我将这些规范及其格式绘制成下面一张图片，供你参考：

![img](https://static001.geekbang.org/resource/image/16/48/1699f5c1933cfe72803dfb038152fc48.png?wh=973*172)

在这些规范中，**Angular 规范在功能上能够满足开发者 commit 需求，在格式上清晰易读，目前也是用得最多的**。Angular 规范其实是一种语义化的提交规范（Semantic Commit Messages），所谓语义化的提交规范包含以下内容：
- Commit Message 是语义化的：Commit Message 都会被归为一个有意义的类型，用来说明本次 commit 的类型。
- Commit Message 是规范化的：Commit Message 遵循预先定义好的规范，比如 Commit Message 格式固定、都属于某个类型，这些规范不仅可被开发者识别也可以被工具识别。

为了方便你理解 Angular 规范，我们直接看一个遵循 Angular 规范的 commit 历史记录，见下图：

![img](https://static001.geekbang.org/resource/image/e2/fe/e227e4976406daaa039438feb5affefe.png?wh=825*420)

再来看一个完整的符合 Angular 规范的 Commit Message，如下图所示：


![img](https://static001.geekbang.org/resource/image/da/cb/da69572c5605556b8144eb4ee281c4cb.png?wh=1877*406)

通过上面 2 张图，我们可以看到符合 Angular Commit Message 规范的 commit 都是有一定格式，有一定语义的。

那我们该怎么写出符合 Angular 规范的 Commit Message 呢？在 Angular 规范中，Commit Message 包含三个部分，分别是 Header、Body 和 Footer，格式如下：

```
<type>[optional scope]: <description>
// 空行
[optional body]
// 空行
[optional footer(s)]
```
其中，Header 是必需的，Body 和 Footer 可以省略。在以上规范中，必须用括号 () 括起来， [] 后必须紧跟冒号 ，冒号后必须紧跟空格，2 个空行也是必需的。

在实际开发中，为了使 Commit Message 在 GitHub 或者其他 Git 工具上更加易读，我们往往会限制每行 message 的长度。根据需要，可以限制为 50/72/100 个字符，这里我将长度限制在 72 个字符以内（也有一些开发者会将长度限制为 100，你可根据需要自行选择）。以下是一个符合 Angular 规范的 Commit Message：

```
fix($compile): couple of unit tests for IE9
# Please enter the Commit Message for your changes. Lines starting
# with '#' will be ignored, and an empty message aborts the commit.
# On branch master
# Changes to be committed:
# ...

Older IEs serialize html uppercased, but IE9 does not...
Would be better to expect case insensitive, unfortunately jasmine does
not allow to user regexps for throw expectations.

Closes #392
Breaks foo.bar api, foo.baz should be used instead
```
接下来，我们详细看看 Angular 规范中 Commit Message 的三个部分。

#### Header
Header 部分只有一行，包括三个字段：type（必选）、scope（可选）和 subject（必选）。我们先来说 type，它用来说明 commit 的类型。为了方便记忆，我把这些类型做了归纳，它们主要可以归为 Development 和 Production 共两类。它们的含义是：
- Development：这类修改一般是项目管理类的变更，不会影响最终用户和生产环境的代码，比如 CI 流程、构建方式等的修改。遇到这类修改，通常也意味着可以免测发布。
- Production：这类修改会影响最终的用户和生产环境的代码。所以对于这种改动，我们一定要慎重，并在提交前做好充分的测试。

我在这里列出了 Angular 规范中的常见 type 和它们所属的类别，你在提交 Commit Message 的时候，一定要**注意**区分它的类别。举个例子，我们在做 Code Review 时，如果遇到 Production 类型的代码，一定要认真 Review，因为这种类型，会影响到现网用户的使用和现网应用的功能。

![img](https://static001.geekbang.org/resource/image/89/27/89c618a7415c0c38b09d86d7f882a427.png?wh=726*511)

有这么多 type，我们该如何确定一个 commit 所属的 type 呢？这里我们可以通过下面这张图来确定。

![img](https://static001.geekbang.org/resource/image/35/a7/3509bd169ce285f59fbcfa6ebea75aa7.png?wh=2513*1078)


如果我们变更了应用代码，比如某个 Go 函数代码，那这次修改属于代码类。在代码类中，有 4 种具有明确变更意图的类型：feat、fix、perf 和 style；如果我们的代码变更不属于这 4 类，那就全都归为 refactor 类，也就是优化代码。如果我们变更了非应用代码，例如更改了文档，那它属于非代码类。在非代码类中，有 3 种具有明确变更意图的类型：test、ci、docs；如果我们的非代码变更不属于这 3 类，那就全部归入到 chore 类。

Angular 的 Commit Message 规范提供了大部分的 type，在实际开发中，我们可以使用部分 type，或者扩展添加我们自己的 type。但无论选择哪种方式，我们一定要保证一个项目中的 type 类型一致。

接下来，我们说说 Header 的第二个字段 scope。

scope 是用来说明 commit 的影响范围的，它必须是名词。显然，不同项目会有不同的 scope。在项目初期，我们可以设置一些粒度比较大的 scope，比如可以按组件名或者功能来设置 scope；后续，如果项目有变动或者有新功能，我们可以再用追加的方式添加新的 scope。我们这门课采用的 scope，主要是根据组件名和功能来设置的。例如，支持 apiserver、authzserver、user 这些 scope。

这里想强调的是，scope 不适合设置太具体的值。太具体的话，一方面会导致项目有太多的 scope，难以维护。另一方面，开发者也难以确定 commit 属于哪个具体的 scope，导致错放 scope，反而会使 scope 失去了分类的意义。当然了，在指定 scope 时，也需要遵循我们预先规划的 scope，所以我们要将 scope 文档化，放在类似 devel 这类文档中。这一点你可以参考下 IAM 项目的 scope 文档： [IAM commit message scope](https://github.com/marmotedu/iam/blob/master/docs/devel/zh-CN/scope.md) 。

最后，我们再说说 subject。subject 是 commit 的简短描述，必须以动词开头、使用现在时。比如，我们可以用 change，却不能用 changed 或 changes，而且这个动词的第一个字母必须是小写。通过这个动词，我们可以明确地知道 commit 所执行的操作。此外我们还要**注意**，subject 的结尾不能加英文句号。

#### Body
Header 对 commit 做了高度概括，可以方便我们查看 Commit Message。那我们如何知道具体做了哪些变更呢？答案就是，可以通过 Body 部分，它是对本次 commit 的更详细描述，是可选的。Body 部分可以分成多行，而且格式也比较自由。不过，和 Header 里的一样，它也要以动词开头，使用现在时。此外，它还必须要包括修改的动机，以及和跟上一版本相比的改动点。我在下面给出了一个范例，你可以看看：

```
The body is mandatory for all commits except for those of scope "docs". When the body is required it must be at least 20 characters long.
```
#### Footer
Footer 部分不是必选的，可以根据需要来选择，主要用来说明本次 commit 导致的后果。在实际应用中，Footer 通常用来说明不兼容的改动和关闭的 Issue 列表，格式如下：

```
BREAKING CHANGE: <breaking change summary>
// 空行
<breaking change description + migration instructions>
// 空行
// 空行
Fixes #<issue number>
```
接下来，我给你详细说明下这两种情况：
- 不兼容的改动：如果当前代码跟上一个版本不兼容，需要在 Footer 部分，以 BREAKING CHANG: 开头，后面跟上不兼容改动的摘要。Footer 的其他部分需要说明变动的描述、变动的理由和迁移方法，例如：

```
BREAKING CHANGE: isolate scope bindings definition has changed and
    the inject option for the directive controller injection was removed.

    To migrate the code follow the example below:

    Before:

    scope: {
      myAttr: 'attribute',
    }

    After:

    scope: {
      myAttr: '@',
    }
    The removed `inject` wasn't generaly useful for directives so there should be no code using it.
```
- 关闭的 Issue 列表：关闭的 Bug 需要在 Footer 部分新建一行，并以 Closes 开头列出，例如：Closes #123。如果关闭了多个 Issue，可以这样列出：Closes #123, #432, #886。例如:

```
Change pause version value to a constant for image
    
    Closes #1137
```
#### Revert Commit
除了 Header、Body 和 Footer 这 3 个部分，Commit Message 还有一种特殊情况：如果当前 commit 还原了先前的 commit，则应以 revert: 开头，后跟还原的 commit 的 Header。而且，在 Body 中必须写成 This reverts commit ，其中 hash 是要还原的 commit 的 SHA 标识。例如：

```
revert: feat(iam-apiserver): add 'Host' option

This reverts commit 079360c7cfc830ea8a6e13f4c8b8114febc9b48a.
```
为了更好地遵循 Angular 规范，****建议**你在提交代码时养成不用 git commit -m，即不用 -m 选项的习惯，而是直接用 git commit 或者 git commit -a 进入交互界面编辑 Commit Message。这样可以更好地格式化 Commit Message**。但是除了 Commit Message 规范之外，在代码提交时，我们还需要关注 3 个重点内容：提交频率、合并提交和 Commit Message 修改。

#### Commit 相关的 3 个重要内容
我们先来看下提交频率。

提交频率
在实际项目开发中，如果是个人项目，随意 commit 可能影响不大，但如果是多人开发的项目，随意 commit 不仅会让 Commit Message 变得难以理解，还会让其他研发同事觉得你不专业。因此，我们要规定 commit 的提交频率。那到底什么时候进行 commit 最好呢？

我认为主要可以分成两种情况。一种情况是，只要我对项目进行了修改，一通过测试就立即 commit。比如修复完一个 bug、开发完一个小功能，或者开发完一个完整的功能，测试通过后就提交。另一种情况是，我们规定一个时间，定期提交。这里我**建议**代码下班前固定提交一次，并且要确保本地未提交的代码，延期不超过 1 天。这样，如果本地代码丢失，可以尽可能减少丢失的代码量。

按照上面 2 种方式提交代码，你可能会觉得代码 commit 比较多，看起来比较随意。或者说，我们想等开发完一个完整的功能之后，放在一个 commit 中一起提交。这时候，我们可以在最后合并代码或者提交 Pull Request 前，执行 git rebase -i 合并之前的所有 commit。那么如何合并 commit 呢？接下来，我来详细说说。

合并提交
合并提交，就是将多个 commit 合并为一个 commit 提交。这里，我**建议**你把新的 commit 合并到主干时，只保留 2~3 个 commit 记录。那具体怎么做呢？在 Git 中，我们主要使用 git rebase 命令来合并。git rebase 也是我们日后开发需要经常使用的一个命令，所以我们一定要掌握好它的使用方法。

git rebase 命令介绍git rebase 的最大作用是它可以重写历史。我们通常会通过 git rebase -i 使用 git rebase 命令，-i 参数表示交互（interactive），该命令会进入到一个交互界面中，其实就是 Vim 编辑器。在该界面中，我们可以对里面的 commit 做一些操作，交互界面如图所示：

![img](https://static001.geekbang.org/resource/image/c6/ac/c63a8682c03862802e5eacf1641b86ac.png?wh=1345*866)

这个交互界面会首先列出给定之前（不包括，越下面越新）的所有 commit，每个 commit 前面有一个操作命令，默认是 pick。我们可以选择不同的 commit，并修改 commit 前面的命令，来对该 commit 执行不同的变更操作。

git rebase 支持的变更操作如下：

![img](https://static001.geekbang.org/resource/image/5f/f2/5f5a79a5d2bde029d4de9d98026ef3f2.png?wh=629*393)

在上面的 7 个命令中，squash 和 fixup 可以用来合并 commit。例如用 squash 来合并，我们只需要把要合并的 commit 前面的动词，改成 squash（或者 s）即可。你可以看看下面的示例：

```
pick 07c5abd Introduce OpenPGP and teach basic usage
s de9b1eb Fix PostChecker::Post#urls
s 3e7ee36 Hey kids, stop all the highlighting
pick fa20af3 git interactive rebase, squash, amend
```
rebase 后，第 2 行和第 3 行的 commit 都会合并到第 1 行的 commit。这个时候，我们提交的信息会同时包含这三个 commit 的提交信息：

```
# This is a combination of 3 commits.
# The first commit's message is:
Introduce OpenPGP and teach basic usage

# This is the 2ndCommit Message:
Fix PostChecker::Post#urls

# This is the 3rdCommit Message:
Hey kids, stop all the highlighting
```
如果我们将第 3 行的 squash 命令改成 fixup 命令：

```
pick 07c5abd Introduce OpenPGP and teach basic usage
s de9b1eb Fix PostChecker::Post#urls
f 3e7ee36 Hey kids, stop all the highlighting
pick fa20af3 git interactive rebase, squash, amend
```
rebase 后，还是会生成两个 commit，第 2 行和第 3 行的 commit，都合并到第 1 行的 commit。但是，新的提交信息里面，第 3 行 commit 的提交信息会被注释掉：

```
# This is a combination of 3 commits.
# The first commit's message is:
Introduce OpenPGP and teach basic usage

# This is the 2ndCommit Message:
Fix PostChecker::Post#urls

# This is the 3rdCommit Message:
# Hey kids, stop all the highlighting
```
除此之外，我们在使用 git rebase 进行操作的时候，还需要**注意**以下几点：删除某个 commit 行，则该 commit 会丢失掉。删除所有的 commit 行，则 rebase 会被终止掉。可以对 commits 进行排序，git 会从上到下进行合并。

**为了加深你的理解，我给你完整演示一遍合并提交。**
合并提交操作示例
假设我们需要研发一个新的模块：user，用来在平台里进行用户的注册、登录、注销等操作，当模块完成开发和测试后，需要合并到主干分支，具体步骤如下。

首先，我们新建一个分支。我们需要先基于 master 分支新建并切换到 feature 分支：

```
$ git checkout -b feature/user
Switched to a new branch 'feature/user'
```
这是我们的所有 commit 历史：

```
$ git log --oneline
7157e9e docs(docs): append test line 'update3' to README.md
5a26aa2 docs(docs): append test line 'update2' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
接着，我们在 feature/user分支进行功能的开发和测试，并遵循规范提交 commit，功能开发并测试完成后，Git 仓库的 commit 记录如下：

```
$ git log --oneline
4ee51d6 docs(user): update user/README.md
176ba5d docs(user): update user/README.md
5e829f8 docs(user): add README.md for user
f40929f feat(user): add delete user function
fc70a21 feat(user): add create user function
7157e9e docs(docs): append test line 'update3' to README.md
5a26aa2 docs(docs): append test line 'update2' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
可以看到我们提交了 5 个 commit。接下来，我们需要将 feature/user分支的改动合并到 master 分支，但是 5 个 commit 太多了，我们想将这些 commit 合并后再提交到 master 分支。接着，我们合并所有 commit。在上一步中，我们知道 fc70a21是 feature/user分支的第一个 commit ID，其父 commit ID 是 7157e9e，我们需要将7157e9e之前的所有分支 进行合并，这时我们可以执行：

```
$ git rebase -i 7157e9e
```
执行命令后，我们会进入到一个交互界面，在该界面中，我们可以将需要合并的 4 个 commit，都执行 squash 操作，如下图所示：

![img](https://static001.geekbang.org/resource/image/6e/4e/6e41e61c27ca2a46e55e8801c47cd04e.png?wh=1097*320)
修改完成后执行:wq 保存，会跳转到一个新的交互页面，在该页面，我们可以编辑 Commit Message，编辑后的内容如下图所示：
![img](https://static001.geekbang.org/resource/image/73/87/73a884bac481236969ba2a219a2e9187.png?wh=1184*399)

#开头的行是 git 的注释，我们可以忽略掉，在 rebase 后，这些行将会消失掉。修改完成后执行:wq 保存，就完成了合并提交操作。除此之外，这里有 2 个点需要我们**注意**：
- git rebase -i 这里的一定要是需要合并 commit 中最旧 commit 的父 commit ID。
- 我们希望将 feature/user 分支的 5 个 commit 合并到一个 commit，在 git rebase 时，需要保证其中最新的一个 commit 是 pick 状态，这样我们才可以将其他 4 个 commit 合并进去。

然后，我们用如下命令来检查 commits 是否成功合并。可以看到，我们成功将 5 个 commit 合并成为了一个 commit：d6b17e0。

```
$ git log --oneline
d6b17e0 feat(user): add user module with all function implements
7157e9e docs(docs): append test line 'update3' to README.md
5a26aa2 docs(docs): append test line 'update2' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
最后，我们就可以将 feature 分支 feature/user 的改动合并到主干分支，从而完成新功能的开发。

```
$ git checkout master
$ git merge feature/user
$ git log --oneline
d6b17e0 feat(user): add user module with all function implements
7157e9e docs(docs): append test line 'update3' to README.md
5a26aa2 docs(docs): append test line 'update2' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
这里给你一个小提示，如果你有太多的 commit 需要合并，那么可以试试这种方式：先撤销过去的 commit，然后再建一个新的。

```
$ git reset HEAD~3
$ git add .
$ git commit -am "feat(user): add user resource"
```
需要说明一点：除了 commit 实在太多的时候，一般情况下我不**建议**用这种方法，有点粗暴，而且之前提交的 Commit Message 都要重新整理一遍。


#### 修改 Commit Message
即使我们有了 Commit Message 规范，但仍然可能会遇到提交的 Commit Message 不符合规范的情况，这个时候就需要我们能够修改之前某次 commit 的 Commit Message。

具体来说，我们有两种修改方法，分别对应两种不同情况：git commit --amend：修改最近一次 commit 的 message；git rebase -i：修改某次 commit 的 message。

接下来，我们分别来说这两种方法。

**git commit --amend：修改最近一次 commit 的 message**有时候，我们刚提交完一个 commit，但是发现 commit 的描述不符合规范或者需要纠正，这时候，我们可以通过 git commit --amend 命令来修改刚刚提交 commit 的 Commit Message。具体修改步骤如下：

查看当前分支的日志记录。

```
$ git log –oneline
418bd4 docs(docs): append test line 'update$i' to README.md
89651d4 docs(doc): add README.md
```
可以看到，最近一次的 Commit Message 是 docs(docs): append test line 'update$i' to README.md，其中 update$i 正常应该是 update1。

更新最近一次提交的 Commit Message
在当前 Git 仓库下执行命令：git commit --amend，后会进入一个交互界面，在交互界面中，修改最近一次的 Commit Message，如下图所示：

![img](https://static001.geekbang.org/resource/image/9e/a3/9ea39c153fccdbfd951a990e131ddea3.png?wh=1362*466)

修改完成后执行:wq 保存，退出编辑器之后，会在命令行显示，该 commit 的 message 的更新结果如下：

```
[master 55892fa] docs(docs): append test line 'update1' to README.md
 Date: Fri Sep 18 13:40:42 2020 +0800
 1 file changed, 1 insertion(+)
```
查看最近一次的 Commit Message 是否被更新

```
$ git log --oneline
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
可以看到最近一次 commit 的 message 成功被修改为期望的内容。

**git rebase -i：修改某次 commit 的 message**如果我们想修改的 Commit Message 不是最近一次的 Commit Message，可以通过 git rebase -i <父 commit ID>命令来修改。这个命令在实际开发中使用频率比较高，我们一定要掌握。具体来说，使用它主要分为 4 步。

查看当前分支的日志记录。

```
$ git log --oneline
1d6289f docs(docs): append test line 'update3' to README.md
a38f808 docs(docs): append test line 'update$i' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
可以看到倒数第 3 次提交的 Commit Message 是：docs(docs): append test line 'update$i' to README.md，其中 update$i 正常应该是 update2。

修改倒数第 3 次提交 commit 的 message。在 Git 仓库下直接执行命令 git rebase -i 55892fa，然后会进入一个交互界面。在交互界面中，修改最近一次的 Commit Message。这里我们使用 reword 或者 r，保留倒数第 3 次的变更信息，但是修改其 message，如下图所示：

![img](https://static001.geekbang.org/resource/image/9e/b9/9e8344df0dd8f66f63a307b5a6487fb9.png?wh=1319*273)

修改完成后执行:wq 保存，还会跳转到一个新的交互页面，如下图所示：


![img](https://static001.geekbang.org/resource/image/0e/24/0ef693d6fc195ebd179b7992e0776f24.png?wh=1392*359)

修改完成后执行:wq 保存，退出编辑器之后，会在命令行显示该 commit 的 message 的更新结果：

```
[detached HEAD 5a26aa2] docs(docs): append test line 'update2' to README.md
 Date: Fri Sep 18 13:45:54 2020 +0800
 1 file changed, 1 insertion(+)
Successfully rebased and updated refs/heads/master.
```
Successfully rebased and updated refs/heads/master.说明 rebase 成功，其实这里完成了两个步骤：更新 message，更新该 commit 的 HEAD 指针。**注意**：这里一定要传入想要变更 Commit Message 的父 commit ID：git rebase -i <父 commit ID>。

查看倒数第 3 次 commit 的 message 是否被更新。

```
$ git log --oneline
7157e9e docs(docs): append test line 'update3' to README.md
5a26aa2 docs(docs): append test line 'update2' to README.md
55892fa docs(docs): append test line 'update1' to README.md
89651d4 docs(doc): add README.md
```
可以看到，倒数第 3 次 commit 的 message 成功被修改为期望的内容。这里有两点需要你**注意**：
- Commit Message 是 commit 数据结构中的一个属性，如果 Commit Message 有变更，则 commit ID 一定会变，git commit --amend 只会变更最近一次的 commit ID，但是 git rebase -i 会变更父 commit ID 之后所有提交的 commit ID。
- 如果当前分支有未 commit 的代码，需要先执行 git stash 将工作状态进行暂存，当修改完成后再执行 git stash pop 恢复之前的工作状态。

#### Commit Message 规范自动化
其实，到这里我们也就意识到了一点：Commit Message 规范如果靠文档去约束，就会严重依赖开发者的代码素养，并不能真正保证提交的 commit 是符合规范的。那么，有没有一种方式可以确保我们提交的 Commit Message 一定是符合规范的呢？有的，我们可以通过一些工具，来自动化地生成和检查 Commit Message 是否符合规范。另外，既然 Commit Message 是规范的，那么我们能不能利用这些规范来实现一些更酷的功能呢？答案是有的，我将可以围绕着 Commit Message 实现的一些自动化功能绘制成了下面一张图。

![img](https://static001.geekbang.org/resource/image/87/be/87cd05c48ac90ec93c379b568a6006be.png?wh=2141*1219)

这些自动化功能可以分为以下 2 类：Commit Message 生成和检查功能：生成符合 Angular 规范的 Commit Message、Commit Message 提交前检查、历史 Commit Message 检查。基于 Commit Message 自动生成 CHANGELOG 和 SemVer 的工具。

我们可以通过下面这 5 个工具自动的完成上面的功能：commitizen-go：使你进入交互模式，并根据提示生成 Commit Message，然后提交。commit-msg：githooks，在 commit-msg 中，指定检查的规则，commit-msg 是个脚本，可以根据需要自己写脚本实现。这门课的 commit-msg 调用了 go-gitlint 来进行检查。go-gitlint：检查历史提交的 Commit Message 是否符合 Angular 规范，可以将该工具添加在 CI 流程中，确保 Commit Message 都是符合规范的。gsemver：语义化版本自动生成工具。git-chglog：根据 Commit Message 生成 CHANGELOG。

这些工具你先有个印象就好了，在后面的课程内容中，我会带你通过实际使用来熟悉它们的用法。

### 总结
今天我向你介绍了 Commit Message 规范，主要讲了业界使用最多的 Angular 规范。Angular 规范中，Commit Message 包含三个部分：Header、Body 和 Footer。Header 对 commit 做了高度概括，Body 部分是对本次 commit 的更详细描述，Footer 部分主要用来说明本次 commit 导致的后果。格式如下：
```
<type>[optional scope]: <description>
// 空行
[optional body]
// 空行
[optional footer(s)]
```
另外，我们也需要控制 commit 的提交频率，比如可以在开发完一个功能、修复完一个 bug、下班前提交 commit。最后，我们也需要掌握一些常见的提交操作，例如通过 git rebase -i 来合并提交 commit，通过 git commit --amend 或 git rebase -i 来修改 commit message。
## 6 | 目录结构设计：如何组织一个可维护、可扩展的代码目录？
那具体怎么组织一个好的代码目录呢？在今天这一讲，我会从 2 个维度来解答这个问题。首先，我会介绍组织目录的一些基本原则，这些原则可以指导你去组织一个好的代码目录。然后，我会向你介绍一些具体的、优秀的目录结构。你可以通过学习它们，提炼总结出你自己的目录结构设计方法，或者你也可以直接用它们作为你的目录结构规范，也就是说结构即规范。

一个好的目录结构至少要满足以下几个要求。
- 命名清晰：目录命名要清晰、简洁，不要太长，也不要太短，目录名要能清晰地表达出该目录实现的功能，并且目录名最好用单数。一方面是因为单数足以说明这个目录的功能，另一方面可以统一规范，避免单复混用的情况。
- 功能明确：一个目录所要实现的功能应该是明确的、并且在整个项目目录中具有很高的辨识度。也就是说，当需要新增一个功能时，我们能够非常清楚地知道把这个功能放在哪个目录下。
- 全面性：目录结构应该尽可能全面地包含研发过程中需要的功能，例如文档、脚本、源码管理、API 实现、工具、第三方包、测试、编译产物等。
- 可预测性：项目规模一定是从小到大的，所以一个好的目录结构应该能够在项目变大时，仍然保持之前的目录结构。
- 可扩展性：每个目录下存放了同类的功能，在项目变大时，这些目录应该可以存放更多同类功能。举个例子，有如下目录结构：

```
$ ls internal/
app  pkg  README.md
```
internal 目录用来实现内部代码，app 和 pkg 目录下的所有文件都属于内部代码。如果 internal 目录不管项目大小，永远只有 2 个文件 app 和 pkg，那么就说明 internal 目录是不可扩展的。相反，如果 internal 目录下直接存放每个组件的源码目录（一个项目可以由一个或多个组件组成），当项目变大、组件增多时，可以将新增加的组件代码存放到 internal 目录，这时 internal 目录就是可扩展的。例如：

```
$ ls internal/
apiserver  authzserver  iamctl  pkg  pump  watcher
```
刚才我讲了目录结构的总体规范，现在来看 2 个具体的、可以作为目录规范的目录结构。通常，根据功能，我们可以将目录结构分为**结构化目录结构和平铺式目录结构两种**。结构化目录结构主要用在 Go 应用中，相对来说比较复杂；而平铺式目录结构主要用在 Go 包中，相对来说比较简单。


### 平铺式目录结构
一个 Go 项目可以是一个应用，也可以是一个代码框架 / 库，当项目是代码框架 / 库时，比较适合采用平铺式目录结构。平铺方式就是在项目的根目录下存放项目的代码，整个目录结构看起来更像是一层的，这种方式在很多框架 / 库中存在，使用这种方式的好处是引用路径长度明显减少，比如 github.com/marmotedu/log/pkg/options，可缩短为 github.com/marmotedu/log/options。例如 log 包 github.com/golang/glog 就是平铺式的，目录如下：

```
$ ls glog/
glog_file.go  glog.go  glog_test.go  LICENSE  README
```
### 结构化目录结构
当前 Go 社区比较**推荐**的结构化目录结构是 project-layout 。虽然它并不是官方和社区的规范，但因为组织方式比较合理，被很多 Go 开发人员接受。所以，我们可以把它当作是一个事实上的规范。

首先，我们来看下在开发一个 Go 项目时，通常应该包含的功能。这些功能内容比较多，我放在了 GitHub 的 Go 项目通常包含的功能 里，我们设计的目录结构应该能够包含这些功能。我结合 project-layout，以及上面列出的 Go 项目常见功能，总结出了一套 Go 的代码结构组织方式，也就是 IAM 项目使用的目录结构。这种方式保留了 project-layout 优势的同时，还加入了一些我个人的理解，希望为你提供一个拿来即用的目录结构规范。接下来，我们一起看看这门课的实战项目所采用的 Go 目录结构。因为实战项目目录比较多，这里只列出了一些重要的目录和文件，你可以快速浏览以加深理解。

```
├── api
│   ├── openapi
│   └── swagger
├── build
│   ├── ci
│   ├── docker
│   │   ├── iam-apiserver
│   │   ├── iam-authz-server
│   │   └── iam-pump
│   ├── package
├── CHANGELOG
├── cmd
│   ├── iam-apiserver
│   │   └── apiserver.go
│   ├── iam-authz-server
│   │   └── authzserver.go
│   ├── iamctl
│   │   └── iamctl.go
│   └── iam-pump
│       └── pump.go
├── configs
├── CONTRIBUTING.md
├── deployments
├── docs
│   ├── devel
│   │   ├── en-US
│   │   └── zh-CN
│   ├── guide
│   │   ├── en-US
│   │   └── zh-CN
│   ├── images
│   └── README.md
├── examples
├── githooks
├── go.mod
├── go.sum
├── init
├── internal
│   ├── apiserver
│   │   ├── api
│   │   │   └── v1
│   │   │       └── user
│   │   ├── apiserver.go
│   │   ├── options
│   │   ├── service
│   │   ├── store
│   │   │   ├── mysql
│   │   │   ├── fake
│   │   └── testing
│   ├── authzserver
│   │   ├── api
│   │   │   └── v1
│   │   │       └── authorize
│   │   ├── options
│   │   ├── store
│   │   └── testing
│   ├── iamctl
│   │   ├── cmd
│   │   │   ├── completion
│   │   │   ├── user
│   │   └── util
│   ├── pkg
│   │   ├── code
│   │   ├── options
│   │   ├── server
│   │   ├── util
│   │   └── validation
├── LICENSE
├── Makefile
├── _output
│   ├── platforms
│   │   └── linux
│   │       └── amd64
├── pkg
│   ├── util
│   │   └── genutil
├── README.md
├── scripts
│   ├── lib
│   ├── make-rules
├── test
│   ├── testdata
├── third_party
│   └── forked
└── tools
```
看到这一长串目录是不是有些晕？没关系，这里我们一起给这个大目录分下类，然后再具体看看每一类目录的作用，你就清楚了。在我看来，一个 Go 项目包含 3 大部分：Go 应用 、项目管理和文档。所以，我们的项目目录也可以分为这 3 大类。同时，Go 应用又贯穿开发阶段、测试阶段和部署阶段，相应的应用类的目录，又可以按开发流程分为更小的子类。当然了，这些是我**建议**的目录，Go 项目目录中还有一些不**建议**的目录。所以整体来看，我们的目录结构可以按下图所示的方式来分类：

![img](https://static001.geekbang.org/resource/image/94/a3/94e521c6eb884096ea107fc4c36f30a3.png?wh=2248x1832)

接下来你就先专心跟着我走一遍每个目录、每个文件的作用，等你下次组织代码目录的时候，可以再回过头来看看，那时你一定会理解得更深刻。

### Go 应用 ：主要存放前后端代码
首先，我们来说说开发阶段所涉及到的目录。我们开发的代码包含前端代码和后端代码，可以分别存放在前端目录和后端目录中。



/web前端代码存放目录，主要用来存放 Web 静态资源，服务端模板和单页应用（SPAs）。

/cmd**一个项目有很多组件，可以把组件 main 函数所在的文件夹统一放在/cmd 目录下**，例如：

```
$ ls cmd/
gendocs  geniamdocs  genman  genswaggertypedocs  genyaml  iam-apiserver  iam-authz-server  iamctl  iam-pump

$ ls cmd/iam-apiserver/
apiserver.go
```
每个组件的目录名应该跟你期望的可执行文件名是一致的。这里要保证 /cmd/<组件名> 目录下不要存放太多的代码，**如果你认为代码可以导入并在其他项目中使用，那么它应该位于 /pkg 目录中**。**如果代码不是可重用的，或者你不希望其他人重用它，请将该代码放到 /internal 目录中。**

**/internal存放私有应用和库代码**。如果一些代码，你不希望在其他应用和库中被导入，可以将这部分代码放在/internal 目录下。在引入其它项目 internal 下的包时，Go 语言会在编译时报错：

```
An import of a path containing the element “internal” is disallowed
if the importing code is outside the tree rooted at the parent of the
"internal" directory.
```
可以通过 Go 语言本身的机制来约束其他项目 import 项目内部的包。/internal 目录**建议**包含如下目录：
- /internal/apiserver：该目录中存放真实的应用代码。这些应用的共享代码存放在/internal/pkg 目录下。
- /internal/pkg：**存放项目内可共享，项目外不共享的包。这些包提供了比较基础、通用的功能，例如工具、错误码、用户验证等功能。**

**我的**建议**是，一开始将所有的共享代码存放在 /internal/pkg 目录下，当该共享代码做好了对外开发的准备后，再转存到/pkg目录下**。下面，我详细介绍下 IAM 项目的 internal目录 ，来加深你对 internal 的理解，目录结构如下：

```
├── apiserver
│   ├── api
│   │   └── v1
│   │       └── user
│   ├── options
│   ├── config
│   ├── service
│   │   └── user.go
│   ├── store
│   │   ├── mysql
│   │   │   └── user.go
│   │   ├── fake
│   └── testing
├── authzserver
│   ├── api
│   │   └── v1
│   ├── options
│   ├── store
│   └── testing
├── iamctl
│   ├── cmd
│   │   ├── cmd.go
│   │   ├── info
└── pkg
    ├── code
    ├── middleware
    ├── options
    └── validation
```
/internal 目录大概分为 3 类子目录：
- /internal/pkg：**内部共享包**存放的目录。
- /internal/authzserver、/internal/apiserver、/internal/pump、/internal/iamctl：应用目录，里面包含**应用程序的实现代码**。
- /internal/iamctl：对于一些大型项目，可能还会需要一个**客户端工具**。

在每个应用程序内部，也会有一些目录结构，这些目录结构主要**根据功能来划分**：
- /internal/apiserver/api/v1：HTTP API 接口的具体实现，主要用来做 HTTP 请求的解包、参数校验、业务逻辑处理、返回。**注意**这里的业务逻辑处理应该是轻量级的，如果业务逻辑比较复杂，代码量比较多，**建议**放到 /internal/apiserver/service 目录下。该源码文件主要用来串流程。
- /internal/apiserver/options：应用的 command flag。
- /internal/apiserver/config：根据命令行参数创建应用配置。
- /internal/apiserver/service：存放应用复杂业务处理代码。
- /internal/apiserver/store/mysql：一个应用可能要持久化的存储一些数据，这里主要存放跟数据库交互的代码，比如 Create、Update、Delete、Get、List 等。

/internal/pkg 目录存放项目内可共享的包，通常可以包含如下目录：
- /internal/pkg/code：项目业务 Code 码。
- /internal/pkg/validation：一些通用的验证函数。
- /internal/pkg/middleware：HTTP 处理链。

/pkg

/pkg 目录是 Go 语言项目中非常常见的目录，我们几乎能够在所有知名的开源项目（非框架）中找到它的身影，例如 Kubernetes、Prometheus、Moby、Knative 等。该目录中存放可以被外部应用使用的代码库，其他项目可以直接通过 import 导入这里的代码。所以，我们在将代码库放入该目录时一定要慎重。

/vendor项目依赖，可通过 go mod vendor 创建。需要**注意**的是，**如果是一个 Go 库，不要提交 vendor 依赖包。**

/third_party外部帮助工具，分支代码或其他第三方应用（例如 Swagger UI）。**比如我们 fork 了一个第三方 go 包，并做了一些小的改动，我们可以放在目录 /third_party/forked 下**。一方面可以很清楚的知道该包是 fork 第三方的，另一方面又能够方便地和 upstream 同步。

### Go 应用：主要存放测试相关的文件和代码
接着，我们再来看下测试阶段相关的目录，它可以存放测试相关的文件。

**/test用于存放其他外部测试应用和测试数据**。/test 目录的构建方式比较灵活：对于大的项目，有一个数据子目录是有意义的。例如，如果需要 Go 忽略该目录中的内容，可以使用 /test/data 或 /test/testdata 目录。需要**注意**的是，Go 也会忽略以“.”或 “_” 开头的目录或文件。这样在命名测试数据目录方面，可以具有更大的灵活性。

### Go 应用：存放跟应用部署相关的文件

接着，我们再来看下与部署阶段相关的目录，这些目录可以存放部署相关的文件。

/configs这个目录用来配置文件模板或默认配置。例如，可以在这里存放 confd 或 consul-template 模板文件。这里有一点要**注意**，配置中不能携带敏感信息，这些敏感信息，我们可以用占位符来替代，例如：

```
apiVersion: v1    
user:    
  username: ${CONFIG_USER_USERNAME} # iam 用户名    
  password: ${CONFIG_USER_PASSWORD} # iam 密码
```
/deployments用来存放 Iaas、PaaS 系统和容器编排部署配置和模板（Docker-Compose，Kubernetes/Helm，Mesos，Terraform，Bosh）。在一些项目，特别是用 Kubernetes 部署的项目中，这个目录可能命名为 deploy。为什么要将这类跟 Kubernetes 相关的目录放到目录结构中呢？主要是**因为当前软件部署基本都在朝着容器化的部署方式去演进**。

/init存放初始化系统（systemd，upstart，sysv）和进程管理配置文件（runit，supervisord）。比如 sysemd 的 unit 文件。这类文件，在非容器化部署的项目中会用到。

### 项目管理：存放用来管理 Go 项目的各类文件
在做项目开发时，还有些目录用来存放项目管理相关的文件，这里我们一起来看下。

/Makefile虽然 Makefile 是一个很老的项目管理工具，但它仍然是最优秀的项目管理工具。所以，一个 Go 项目在其根目录下应该有一个 Makefile 工具，用来对项目进行管理，**Makefile 通常用来执行静态代码检查、单元测试、编译**等功能。其他常见功能：
- 静态代码检查(lint)：**推荐**用 golangci-lint。
- 单元测试(test)：运行 go test ./...。
- 编译(build)：编译源码，支持不同的平台，不同的 CPU 架构。
- 镜像打包和发布(image/image.push)：现在的系统比较**推荐**用 Docker/Kubernetes 进行部署，所以一般也要有镜像构建功能。
- 清理（clean）:清理临时文件或者编译后的产物。
- 代码生成（gen）：比如要编译生成 protobuf pb.go 文件。
- 部署（deploy，可选）：一键部署功能，方便测试。
- 发布（release）：发布功能，比如：发布到 Docker Hub、github 等。
- 帮助（help）:告诉 Makefile 有哪些功能，如何执行这些功能。
- 版权声明（add-copyright）：如果是开源项目，可能需要在每个文件中添加版权头，这可以通过 Makefile 来添加。
- API 文档（swagger）：如果使用 swagger 来生成 API 文档，这可以通过 Makefile 来生成。

我还有一条**建议**：直接执行 make 时，执行如下各项 format -> lint -> test -> build，如果是有代码生成的操作，还可能需要首先生成代码 gen -> format -> lint -> test -> build。**在实际开发中，我们可以将一些重复性的工作自动化，并添加到 Makefile 文件中统一管理**。

/scripts该目录主要用来存放脚本文件，实现**构建、安装、分析**等不同功能。不同项目，里面可能存放不同的文件，但通常可以考虑包含以下 3 个目录：
- /scripts/make-rules：用来存放 makefile 文件，实现 /Makefile 文件中的各个功能。Makefile 有很多功能，为了保持它的简洁，我**建议**你将各个功能的具体实现放在/scripts/make-rules 文件夹下。
- /scripts/lib：shell 库，用来存放 shell 脚本。一个大型项目中有很多自动化任务，比如发布、更新文档、生成代码等，所以要写很多 shell 脚本，这些 shell 脚本会有一些通用功能，可以抽象成库，存放在/scripts/lib 目录下，比如 logging.sh，util.sh 等。
- /scripts/install：如果项目支持自动化部署，可以将自动化部署脚本放在此目录下。如果部署脚本简单，也可以直接放在 /scripts 目录下。

另外，shell 脚本中的函数名，**建议**采用语义化的命名方式，例如 iam::log::info 这种语义化的命名方式，可以使调用者轻松的辨别出函数的功能类别，便于函数的管理和引用。在 Kubernetes 的脚本中，就大量采用了这种命名方式。

/build这里存放安装包和持续集成相关的文件。这个目录下有 3 个大概率会使用到的目录，在设计目录结构时可以考虑进去。
- /build/package：存放容器（Docker）、系统（deb, rpm, pkg）的包配置和脚本。
- /build/ci：存放 CI（travis，circle，drone）的配置文件和脚本。
- /build/docker：存放子项目各个组件的 Dockerfile 文件。

/tools存放这个项目的支持工具。这些工具可导入来自 /pkg 和 /internal 目录的代码。

/githooksGit 钩子。比如，我们可以将 commit-msg 存放在该目录。

/assets项目使用的其他资源 (图片、CSS、JavaScript 等)。

/website如果你不使用 GitHub 页面，那么可以在这里放置项目网站相关的数据。

### 文档：主要存放项目的各类文档
一个项目，也包含一些文档，这些文档有很多类别，也需要一些目录来存放这些文档，这里我们也一起来看下。

/README.md项目的 README 文件一般包含了项目的介绍、功能、快速安装和使用指引、详细的文档链接以及开发指引等。有时候 README 文档会比较长，为了能够快速定位到所需内容，需要添加 markdown toc 索引，可以借助工具 tocenize 来完成索引的添加。这里还有个**建议**，前面我们也介绍过 README 是可以规范化的，所以这个 README 文档，可以通过脚本或工具来自动生成。

/docs存放设计文档、开发文档和用户文档等（除了 godoc 生成的文档）。**推荐**存放以下几个子目录：
- /docs/devel/{en-US,zh-CN}：存放开发文档、hack 文档等。
- /docs/guide/{en-US,zh-CN}: 存放用户手册，安装、quickstart、产品文档等，分为中文文档和英文文档。
- /docs/images：存放图片文件。

/CONTRIBUTING.md如果是一个开源就绪的项目，最好还要有一个 CONTRIBUTING.md 文件，用来说明如何贡献代码，如何开源协同等等。CONTRIBUTING.md 不仅能够规范协同流程，还能降低第三方开发者贡献代码的难度。

/api    /api 目录中存放的是当前项目对外提供的各种不同类型的 API 接口定义文件，其中可能包含类似 /api/protobuf-spec、/api/thrift-spec、/api/http-spec、openapi、swagger 的目录，这些目录包含了当前项目对外提供和依赖的所有 API 文件。例如，如下是 IAM 项目的 /api 目录：

```
├── openapi/
│   └── README.md
└── swagger/
    ├── docs/
    ├── README.md
    └── swagger.yaml
```
二级目录的主要作用，就是在一个项目同时提供了多种不同的访问方式时，可以分类存放。用这种方式可以避免潜在的冲突，也能让项目结构更加清晰。

/LICENSE版权文件可以是私有的，也可以是开源的。常用的开源协议有：Apache 2.0、MIT、BSD、GPL、Mozilla、LGPL。有时候，公有云产品为了打造品牌影响力，会对外发布一个本产品的开源版本，所以在项目规划初期最好就能规划下未来产品的走向，选择合适的 LICENSE。为了声明版权，你可能会需要将 LICENSE 头添加到源码文件或者其他文件中，这部分工作可以通过工具实现自动化，**推荐**工具： **addlicense** 。当代码中引用了其它开源代码时，需要在 LICENSE 中说明对其它源码的引用，这就需要知道代码引用了哪些源码，以及这些源码的开源协议，可以借助工具来进行检查，**推荐**工具： **glice** 。至于如何说明对其它源码的引用，大家可以参考下 IAM 项目的 LICENSE 文件。

/CHANGELOG当项目有更新时，为了方便了解当前版本的更新内容或者历史更新内容，需要将更新记录存放到 CHANGELOG 目录。编写 CHANGELOG 是一个复杂、繁琐的工作，我们可以**结合 Angular 规范 和 git-chglog 来自动生成 CHANGELOG。**

/examples存放应用程序或者公共包的示例代码。这些示例代码可以降低使用者的上手门槛。

### 不**建议**的目录
除了上面这些我们**建议**的目录，在 Go 项目中，还有一些目录是不**建议**包含的，这些目录不符合 Go 的设计哲学。

/src/一些开发语言，例如 Java 项目中会有 src 目录。在 Java 项目中， src 目录是一种常见的模式，但在 Go 项目中，不**建议**使用 src 目录。其中一个重要的原因是：在默认情况下，Go 语言的项目都会被放置到$GOPATH/src 目录下。这个目录中存放着所有代码，如果我们在自己的项目中使用/src 目录，这个包的导入路径中就会出现两个 src，例如：

```
$GOPATH/src/github.com/marmotedu/project/src/main.go
```
这样的目录结构看起来非常怪。

xxs/在 Go 项目中，要避免使用带复数的目录或者包。**建议**统一使用单数。

### 一些**建议**
上面介绍的目录结构包含很多目录，但一个小型项目用不到这么多目录。对于小型项目，可以考虑先包含 cmd、pkg、internal 3 个目录，其他目录后面按需创建，例如：

```
$ tree --noreport -L 2 tms
tms
├── cmd
├── internal
├── pkg
└── README.md
```
另外，在设计目录结构时，一些空目录无法提交到 Git 仓库中，但我们又想将这个空目录上传到 Git 仓库中，以保留目录结构。这时候，可以在空目录下加一个 .keep 文件，例如：

```
$ ls -A build/ci/ 
.keep
```
## 7 | 工作流设计：如何设计合理的多人开发模式？
一个企业级项目是由多人合作完成的，不同开发者在本地开发完代码之后，可能提交到同一个代码仓库，同一个开发者也可能同时开发几个功能特性。这种多人合作开发、多功能并行开发的特性如果处理不好，就会带来诸如丢失代码、合错代码、代码冲突等问题。所以，在编码之前，我们需要设计一个合理的开发模式。又因为目前开发者基本都是基于 Git 进行开发的，所以本节课，我会教你怎么基于 Git 设计出一个合理的开发模式。

那么如何设计工作流呢？你可以根据需要，自己设计工作流，也可以采用业界沉淀下来的、设计好的、受欢迎的工作流。一方面，这些工作流经过长时间的实践，被证明是合理的；另一方面，采用一种被大家熟知且业界通用的工作流，会减少团队内部磨合的时间。在这一讲中，我会为你介绍 4 种受欢迎的工作流，你可以选择其中一种作为你的工作流设计。

在使用 Git 开发时，有 4 种常用的工作流，也叫开发模式，按演进顺序分为集中式工作流、功能分支工作流、Git Flow 工作流和 Forking 工作流。接下来，我会按演进顺序分别介绍这 4 种工作流。

### 集中式工作流
我们先来看看集中式工作流，它是最简单的一种开发方式。集中式工作流的工作模式如下图所示：![img](https://static001.geekbang.org/resource/image/31/eb/3174a9e1373ed2d6d14471164dcb13eb.png?wh=2100*1144)


A、B、C 为 3 位开发者，每位开发者都在本地有一份远程仓库的拷贝：本地仓库。A、B、C 在本地的 master 分支开发完代码之后，将修改后的代码 commit 到远程仓库，如果有冲突就先解决本地的冲突再提交。在进行了一段时间的开发之后，远程仓库 master 分支的日志可能如下图所示：

![img](https://static001.geekbang.org/resource/image/fb/c7/fbcc75ba5b91223f6bf243f0bc08bac7.png?wh=2922*391)

集中式工作流是最简单的开发模式，但它的缺点也很明显：不同开发人员的提交日志混杂在一起，难以定位问题。如果同时开发多个功能，不同功能同时往 master 分支合并，代码之间也会相互影响，从而产生代码冲突。

和其他工作流相比，集中式工作流程的代码管理较混乱，容易出问题，因此适合用在团队人数少、开发不频繁、不需要同时维护多个版本的小项目中。当我们想要并行开发多个功能时，这种工作流就不适用了，这时候怎么办呢？我们接下来看功能分支工作流。

### 功能分支工作流
功能分支工作流基于集中式工作流演进而来。在开发新功能时，基于 master 分支新建一个功能分支，在功能分支上进行开发，而不是直接在本地的 master 分支开发，开发完成之后合并到 master 分支，如下图所示：

![img](https://static001.geekbang.org/resource/image/1c/0b/1c0b08a1c9032c87c35b85de6ca6820b.png?wh=3809*834)
相较于集中式工作流，这种工作流让不同功能在不同的分支进行开发，只在最后一步合并到 master 分支，不仅可以避免不同功能之间的相互影响，还可以使提交历史看起来更加简洁。还有，在合并到 master 分支时，需要提交 PR（pull request），而不是直接将代码 merge 到 master 分支。PR 流程不仅可以把分支代码提供给团队其他开发人员进行 CR（Code Review），还可以在 PR 页面讨论代码。通过 CR ，我们可以确保合并到 master 的代码是健壮的；通过 PR 页面的讨论，可以使开发者充分参与到代码的讨论中，有助于提高代码的质量，并且提供了一个代码变更的历史回顾途径。

那么，功能分支工作流具体的开发流程是什么呢？我们一起来看下。

基于 master 分支新建一个功能分支，功能分支可以取一些有意义的名字，便于理解，例如 feature/rate-limiting。

```
$ git checkout -b feature/rate-limiting
```
在功能分支上进行代码开发，开发完成后 commit 到功能分支。

```
$ git add limit.go
$ git commit -m "add rate limiting"
```
将本地功能分支代码 push 到远程仓库。

```
$ git push origin feature/rate-limiting
```
在远程仓库上创建 PR（例如：GitHub）。进入 GitHub 平台上的项目主页，点击 Compare & pull request 提交 PR，如下图所示。

![img](https://static001.geekbang.org/resource/image/db/ac/dbcd25542515788c7f4f2f592d0029ac.png?wh=1700*552)
点击 Compare & pull request 后会进入 PR 页面，在该页面中可以根据需要填写评论，最后点击 Create pull request 提交 PR。

代码管理员收到 PR 后，可以 CR 代码，CR 通过后，再点击 Merge pull request 将 PR 合并到 master，如下图所示。


![img](https://static001.geekbang.org/resource/image/48/c6/48aaa3a94108de765cb07bd34d899fc6.png?wh=1673*1107)


图中的“Merge pull request” 提供了 3 种 merge 方法：
- Create a merge commit：GitHub 的底层操作是 git merge --no-ff。feature 分支上所有的 commit 都会加到 master 分支上，并且会生成一个 merge commit。这种方式可以让我们清晰地知道是谁做了提交，做了哪些提交，回溯历史的时候也会更加方便。
- Squash and merge：GitHub 的底层操作是 git merge --squash。Squash and merge 会使该 pull request 上的所有 commit 都合并成一个 commit ，然后加到 master 分支上，但原来的 commit 历史会丢失。如果开发人员在 feature 分支上提交的 commit 非常随意，没有规范，那么我们可以选择这种方法来丢弃无意义的 commit。但是在大型项目中，每个开发人员都应该是遵循 commit 规范的，因此我不**建议**你在团队开发中使用 Squash and merge。
- Rebase and merge：GitHub 的底层操作是 git rebase。这种方式会将 pull request 上的所有提交历史按照原有顺序依次添加到 master 分支的头部（HEAD）。因为 git rebase 有风险，在你不完全熟悉 Git 工作流时，我不**建议** merge 时选择这个。

通过分析每个方法的优缺点，在实际的项目开发中，我比较**推荐**你使用 Create a merge commit 方式。

从刚才讲完的具体开发流程中，我们可以感受到，功能分支工作流上手比较简单，不仅能使你并行开发多个功能，还可以添加 code review，从而保障代码质量。当然它也有缺点，就是无法给分支分配明确的目的，不利于团队配合。它适合用在开发团队相对固定、规模较小的项目中。接下来我们要讲的 Git Flow 工作流以功能分支工作流为基础，较好地解决了上述问题。

### Git Flow 工作流
Git Flow 工作流是一个非常成熟的方案，也是非开源项目中最常用到的工作流。它定义了一个围绕项目发布的严格分支模型，通过为代码开发、发布和维护分配独立的分支来让项目的迭代流程更加顺畅，比较适合大型的项目或者迭代速度快的项目。接下来，我会通过介绍 Git Flow 的 5 种分支和工作流程，来给你讲解 GIt Flow 是如何工作的。

Git Flow 的 5 种分支
Git Flow 中定义了 5 种分支，分别是 master、develop、feature、release 和 hotfix。其中，master 和 develop 为常驻分支，其他为非常驻分支，不同的研发阶段会用到不同的分支。这 5 种分支的详细介绍见下表：

![img](https://static001.geekbang.org/resource/image/fa/d9/fa611f83053afd77cf3ddf83561ba1d9.png?wh=942*568)

#### Git Flow 开发流程
这里我们用一个实际的例子来演示下 Git Flow 的开发流程。场景如下：

a. 当前版本为：0.9.0。b. 需要新开发一个功能，使程序执行时向标准输出输出“hello world”字符串。c. 在开发阶段，线上代码有 Bug 需要紧急修复。

假设我们的 Git 项目名为 gitflow-demo，项目目录下有 2 个文件，分别是 README.md 和 main.go，内容如下。

```
package main

import "fmt"

func main() {
  fmt.Println("callmainfunction")
}
```
具体的开发流程有 12 步，你可以跟着以下步骤操作练习。创
```bash
# 建一个常驻的分支：develop。
$ git checkout -b develop master
# 基于 develop 分支，新建一个功能分支：feature/print-hello-world。
$ git checkout -b feature/print-hello-world develop
```
feature/print-hello-world 分支中，在 main.go 文件中添加一行代码fmt.Println("Hello")，添加后的代码如下。

```
package main

import "fmt"

func main() {
  fmt.Println("callmainfunction")
  fmt.Println("Hello")
}
```
紧急修复 Bug。我们正处在新功能的开发中（只完成了 fmt.Println("Hello")而非 fmt.Println("Hello World")）突然线上代码发现了一个 Bug，我们要立即停止手上的工作，修复线上的 Bug，步骤如下。

```
$ git stash # 1. 开发工作只完成了一半，还不想提交，可以临时保存修改至堆栈区
$ git checkout -b hotfix/print-error master # 2. 从 master 建立 hotfix 分支
$ vi main.go # 3. 修复 bug，callmainfunction -> call main function
$ git commit -a -m 'fix print message error bug' # 4. 提交修复
$ git checkout develop # 5. 切换到 develop 分支
$ git merge --no-ff hotfix/print-error # 6. 把 hotfix 分支合并到 develop 分支
$ git checkout master # 7. 切换到 master 分支
$ git merge --no-ff hotfix/print-error # 8. 把 hotfix 分支合并到 master
$ git tag -a v0.9.1 -m "fix log bug" # 9. master 分支打 tag
$ go build -v . # 10. 编译代码，并将编译好的二进制更新到生产环境
$ git branch -d hotfix/print-error # 11. 修复好后，删除 hotfix/xxx 分支
$ git checkout feature/print-hello-world # 12. 切换到开发分支下
$ git merge --no-ff develop # 13. 因为 develop 有更新，这里最好同步更新下
$ git stash pop # 14. 恢复到修复前的工作状态
```
继续开发。在 main.go 中加入 fmt.Println("Hello World")。

提交代码到 feature/print-hello-world 分支。

```
$ git commit -a -m "print 'hello world'"
```
在 feature/print-hello-world 分支上做 code review。首先，我们需要将 feature/print-hello-world push 到代码托管平台，例如 GitHub 上。

```
$ git push origin feature/print-hello-world
```
然后，我们在 GitHub 上，基于 feature/print-hello-world 创建 pull request，如下图所示。

![img](https://static001.geekbang.org/resource/image/ac/ea/ac70d5ab86887e47f78c48d1df42f2ea.png?wh=1637*729)

创建完 pull request 之后，我们就可以指定 Reviewers 进行 code review，如下图所示。


![img](https://static001.geekbang.org/resource/image/bc/50/bc5168fe73abc257ba35342764647250.png?wh=2420*813)

code review 通过后，由代码仓库 matainer 将功能分支合并到 develop 分支。


```
$ git checkout develop
$ git merge --no-ff feature/print-hello-world
```
基于 develop 分支，创建 release 分支，测试代码。


```
$ git checkout -b release/1.0.0 develop
$ go build -v . # 构建后，部署二进制文件，并测试
```
测试失败，因为我们要求打印“hello world”，但打印的是“Hello World”，修复的时候，我们直接在 release/1.0.0 分支修改代码，修改完成后，提交并编译部署。

```
$ git commit -a -m "fix bug"
$ go build -v .
```
测试通过后，将功能分支合并到 master 分支和 develop 分支。

```
$ git checkout develop
$ git merge --no-ff release/1.0.0
$ git checkout master
$ git merge --no-ff release/1.0.0
$ git tag -a v1.0.0 -m "add print hello world" # master 分支打 tag
```
删除 feature/print-hello-world 分支，也可以选择性删除 release/1.0.0 分支。

```
$ git branch -d feature/print-hello-world
```
亲自操作一遍之后，你应该会更了解这种模式的优缺点。它的缺点，就是你刚才已经体会到的，它有一定的上手难度。不过 Git Flow 工作流还是有很多优点的：Git Flow 工作流的每个分支分工明确，这可以最大程度减少它们之间的相互影响。因为可以创建多个分支，所以也可以并行开发多个功能。另外，和功能分支工作流一样，它也可以添加 code review，保障代码质量。

**因此，Git Flow 工作流比较适合开发团队相对固定，规模较大的项目。**


### Forking 工作流
上面讲的 Git Flow 是非开源项目中最常用的，而在开源项目中，最常用到的是 Forking 工作流，例如 Kubernetes、Docker 等项目用的就是这种工作流。这里，我们先来了解下 fork 操作。fork 操作是在个人远程仓库新建一份目标远程仓库的副本，比如在 GitHub 上操作时，在项目的主页点击 fork 按钮（页面右上角），即可拷贝该目标远程仓库。Forking 工作流的流程如下图所示。

![img](https://static001.geekbang.org/resource/image/63/ea/63419f767c61c9580861b59445b90fea.png?wh=2213*1019)


假设开发者 A 拥有一个远程仓库，如果开发者 B 也想参与 A 项目的开发，B 可以 fork 一份 A 的远程仓库到自己的 GitHub 账号下。后续 B 可以在自己的项目进行开发，开发完成后，B 可以给 A 提交一个 PR。这时候 A 会收到通知，得知有新的 PR 被提交，A 会去查看 PR 并 code review。如果有问题，A 会直接在 PR 页面提交评论，B 看到评论后会做进一步的修改。最后 A 通过 B 的 PR 请求，将代码合并进了 A 的仓库。这样就完成了 A 代码仓库新特性的开发。如果有其他开发者想给 A 贡献代码，也会执行相同的操作。

GitHub 中的 Forking 工作流详细步骤共有 6 步（假设目标仓库为 gitflow-demo），你可以跟着以下步骤操作练习。

Fork 远程仓库到自己的账号下。访问https://github.com/marmotedu/gitflow-demo ，点击 fork 按钮。fork 后的仓库地址为：https://github.com/colin404fork/gitflow-demo 。

2) 克隆 fork 的仓库到本地。

```
$ git clone https://github.com/colin404fork/gitflow-demo
$ cd gitflow-demo
$ git remote add upstream https://github.com/marmotedu/gitflow-demo
$ git remote set-url --push upstream no_push # Never push to upstream master
$ git remote -v # Confirm that your remotes make sense
origin  https://github.com/colin404fork/gitflow-demo (fetch)
origin  https://github.com/colin404fork/gitflow-demo (push)
upstream  https://github.com/marmotedu/gitflow-demo (fetch)
upstream  https://github.com/marmotedu/gitflow-demo (push)
```
创建功能分支。首先，要同步本地仓库的 master 分支为最新的状态（跟 upstream master 分支一致）。

```
$ git fetch upstream
$ git checkout master
$ git rebase upstream/master
```
然后，创建功能分支。

```
$ git checkout -b feature/add-function
```
提交 commit。在 feature/add-function 分支上开发代码，开发完代码后，提交 commit。

```
$ git fetch upstream # commit 前需要再次同步 feature 跟 upstream/master
$ git rebase upstream/master
$ git add <file>
$ git status
$ git commit
```
分支开发完成后，可能会有一堆 commit，但是合并到主干时，我们往往希望只有一个（或最多两三个）commit，这可以使功能修改都放在一个或几个 commit 中，便于后面的阅读和维护。这个时候，我们可以用 git rebase 来合并和修改我们的 commit，操作如下：

```
$ git rebase -i origin/master
```
第 5 讲已经介绍过了git rebase -i 的使用方法 ，如果你有疑问可以再去看看，这里不再说明。还有另外一种合并 commit 的简便方法，就是先撤销过去 5 个 commit，然后再建一个新的：

```
$ git reset HEAD~5
$ git add .
$ git commit -am "Here's the bug fix that closes #28"
$ git push --force
```
squash 和 fixup 命令，还可以当作命令行参数使用，自动合并 commit。

```
$ git commit --fixup
$ git rebase -i --autosquash
```
push 功能分支到个人远程仓库。在完成了开发，并 commit 后，需要将功能分支 push 到个人远程代码仓库，代码如下：

```
$ git push -f origin feature/add-function
```
在个人远程仓库页面创建 pull request。提交到远程仓库以后，我们就可以创建 pull request，然后请求 reviewers 进行代码 review，确认后合并到 master。这里要**注意**，创建 pull request 时，base 通常选择目标远程仓库的 master 分支。

我们已经讲完了 Forking 工作流的具体步骤，你觉得它有什么优缺点呢？

结合操作特点，我们来看看它的优点：Forking 工作流中，项目远程仓库和开发者远程仓库完全独立，开发者通过提交 Pull Request 的方式给远程仓库贡献代码，项目维护者选择性地接受任何开发者的提交，通过这种方式，可以避免授予开发者项目远程仓库的权限，从而提高项目远程仓库的安全性，这也使得任意开发者都可以参与项目的开发。但 Forking 工作流也有局限性，就是对于职能分工明确且不对外开源的项目优势不大。

Forking 工作流比较适用于以下三种场景：（1）开源项目中；（2）开发者有衍生出自己的衍生版的需求；（3）开发者不固定，可能是任意一个能访问到项目的开发者。

### 回顾
这一讲中，我基于 Git 向你介绍了 4 种开发模式，现在跟我回顾一下吧。

集中式工作流：开发者直接在本地 master 分支开发代码，开发完成后 push 到远端仓库 master 分支。功能分支工作流：开发者基于 master 分支创建一个新分支，在新分支进行开发，开发完成后合并到远端仓库 master 分支。Git Flow 工作流：Git Flow 工作流为不同的分支分配一个明确的角色，并定义分支之间什么时候、如何进行交互，比较适合大型项目的开发。Forking 工作流：开发者先 fork 项目到个人仓库，在个人仓库完成开发后，提交 pull request 到目标远程仓库，远程仓库 review 后，合并 pull request 到 master 分支。

集中式工作流是最早的 Git 工作流，功能分支工作流以集中式工作流为基础，Git Flow 工作流又是以功能分支工作流为基础，Forking 工作流在 Git Flow 工作流基础上，解耦了个人远端仓库和项目远端仓库。

每种开发模式各有优缺点，适用于不同的场景，我总结在下表中：

![img](https://static001.geekbang.org/resource/image/55/07/5503ce60f7c2ae5d7628222a4d87cc07.png?wh=820*505)

总的来说，在选择工作流时，我的**推荐**如下：非开源项目采用 Git Flow 工作流。开源项目采用 Forking 工作流。因为这门课的实战项目对于项目开发者来说是一个偏大型的非开源项目，所以采用了 Git Flow 工作流。

## 8 | 研发流程设计（上）：如何设计 Go 项目的开发流程？
一个不合理的研发流程会带来很多问题，例如：**代码管理混乱**。合并代码时出现合错、合丢、代码冲突等问题。**研发效率低**。编译、测试、静态代码检查等全靠手动操作，效率低下。甚至，因为没有标准的流程，一些开发者会漏掉测试、静态代码检查等环节。**发布效率低**。发布周期长，以及发布不规范造成的现网问题频发。

项目研发流程会因为团队、项目、需求等的不同而不同，很难概括出一个方法论让你去设计研发流程。

在这一讲中，我会介绍一种业界已经设计好的、相对标准的研发流程，来告诉你怎么设计研发流程。通过学习它，你不仅能够了解到项目研发的通用流程，而且还可以基于这个流程来优化、定制，满足你自己的流程需求。

### 在设计研发流程时，需要关注哪些点？
在看具体的研发流程之前，我们需要先思考一个问题：你觉得，一个好的流程应该是什么样子的？虽然我们刚才说了，不同团队、项目、需求的研发流程不会一成不变，但为了最大限度地提高研发效能，这些不同的流程都会遵循下面这几个原则。
- 发布效率高：研发流程应该能提高发布效率，减少发布时间和人工介入的工作量。
- 发布质量高：研发流程应该能够提高发布质量，确保发布出去的代码是经过充分测试的，并且完全避免人为因素造成的故障。
- 迭代速度快：整个研发流程要能支持快速迭代，产品迭代速度越快，意味着产品的竞争力越强，在互联网时代越能把握先机。
- 明确性：整个研发流程中角色的职责、使用的工具、方法和流程都应该是明确的，这可以增强流程的可执行性。
- 流程合理：研发流程最终是供产品、开发、测试、运维等人员使用的，所以整个流程设计不能是反人类的，要能够被各类参与人员接受并执行。
- 柔性扩展：研发流程应该是柔性且可扩展的，能够灵活变通，并适应各类场景。
- 输入输出：研发流程中的每个阶段都应该有明确的输入和输出，这些输入和输出标志着上一个阶段的完成，下一个阶段的开始。

明确了这些关注点，我们就有了设计、优化研发流程的抓手了。接下来，我们就可以一起去学习一套业界相对标准的研发流程了。在学习的过程中，你也能更好地理解我对各个流程的一些经验和**建议**了。

### 业界相对标准的研发流程，长啥样？
一个项目从立项到结项，中间会经历很多阶段。业界相对标准的划分，是把研发流程分为六个阶段，分别是需求阶段、设计阶段、开发阶段、测试阶段、发布阶段、运营阶段。其中，开发人员需要参与的阶段有 4 个：设计阶段、开发阶段、测试阶段和发布阶段。下图就是业界相对比较标准的流程：

![img](https://static001.geekbang.org/resource/image/ab/3b/ab6ac57696c0e90cf82624f78a82333b.png?wh=7309*2306)


每个阶段结束时，都需要有一个最终的产出物，可以是文档、代码或者部署组件等。这个产出物既是当前阶段的结束里程碑，又是下一阶段的输入。所以说，各个阶段不是割裂的，而是密切联系的整体。每个阶段又细分为很多步骤，这些步骤是需要不同的参与者去完成的工作任务。在完成任务的过程中，可能需要经过多轮的讨论、修改，最终形成定稿。

这里有个点我们一定要**注意**：研发流程也是一种规范，很难靠开发者的自觉性去遵守。为了让项目参与人员尽可能地遵守规范，需要借助一些工具、系统来对他们进行强约束。所以，在我们设计完整个研发流程之后，需要认真思考下，有哪些地方可以实现自动化，有哪些地方可以靠工具、系统来保障规范的执行。这些自动化工具会在第 16 讲 中详细介绍。接下来，咱们就具体看看研发的各个阶段，以及每个阶段的具体内容。

### 需求阶段
需求阶段是将一个抽象的产品思路具化成一个可实施产品的阶段。在这个阶段，产品人员会讨论产品思路、调研市场需求，并对需求进行分析，整理出一个比较完善的需求文档。最后，产品人员会组织相关人员对需求进行评审，如果评审通过，就会进入设计阶段。

需求阶段，一般不需要研发人员参与。但这里，我还是**建议**你积极参与产品需求的讨论。虽然我们是研发，但我们的视野和对团队的贡献，可以不仅仅局限在研发领域。这里有个点需要提醒你，如果你们团队有测试人员，这个阶段也需要拉测试人员旁听下。因为了解产品设计，对测试阶段测试用例的编写和功能测试等都很有帮助。需求阶段的产出物是一个通过评审的详细的需求文档。

### 设计阶段
设计阶段，是整个产品研发过程中非常重要的阶段，包括的内容也比较多，你可以看一下这张表：

![img](https://static001.geekbang.org/resource/image/81/1b/81296e3f9f0f90e77dd771ee4f61b71b.png?wh=642*458)

这里的每一个设计项都应该经过反复的讨论、打磨，最终在团队内达成共识。这样可以确保设计是合理的，并减少返工的概率。**这里想提醒你的是，技术方案和实现都要经过认真讨论，并获得一致通过，否则后面因为技术方案设计不当，需要返工，你要承担大部分责任。**对于后端开发人员，在设计技术方案之前，要做好充足的调研。一个技术方案，不仅要调研业界优秀的实现，还要了解友商相同技术的实现。只有这样，才可以确保我们的技术用最佳的方式实现。

除此之外，在这个阶段一些设计项可以并行，以缩短设计阶段的耗时。例如，产品设计和技术设计可以并行展开。另外，如果你们团队有测试人员，研发阶段最好也拉上测试人员旁听下，有利于后面的测试。该阶段的产出物是一系列的设计文档，这些文档会指导后面的整个研发流程。

### 开发阶段
开发阶段，从它的名字你就知道了，这是开发人员的主战场，同时它可能也是持续时间最长的阶段。在这一阶段，开发人员根据技术设计文档，编码实现产品需求。开发阶段是整个项目的核心阶段，包含很多工作内容，而且每一个 Go 项目具体的步骤是不同的。我把开发阶段的常见步骤总结在了下图中，帮助你对它进行整体把握。

![img](https://static001.geekbang.org/resource/image/13/57/137a2a20067d1472c9f00c6387a30857.png?wh=2225*2031)

让我们来详细看下这张图里呈现的步骤。开发阶段又可以分为“开发”和“构建”两部分，我们先来看开发。首先，我们需要制定一个所有研发人员共同遵循的 Git 工作流规范。最常使用的是 Git Flow 工作流或者 Forking 工作流。

为了提高开发效率，越来越多的开发者采用生成代码的方式来生成一部分代码，所以在真正编译之前可能还需要先生成代码，比如生成.pb.go 文件、API 文档、测试用例、错误码等。**我的**建议**是，在项目开发中，你要思考怎么尽可能自动生成代码**。这样不仅能提高研发效率，还能减少错误。

对于一个开源项目，我们可能还需要检查新增的文件是否有版权信息。此外，根据项目不同，开发阶段还可能有其它不同的步骤。在流程的最后，通常会进行静态代码检查、单元测试和编译。编译之后，我们就可以启动服务，并进行自测了。自测之后，我们可以遵循 Git Flow 工作流，将开发分支 push 到代码托管平台进行 code review。code review 通过之后，我们就可以将代码 merge 到 develop 分支上。

接下来进入构建阶段。这一阶段最好借助 CI/CD 平台实现自动化，提高构建效率。合并到 develop 分支的代码同样需要进行代码扫描、单元测试，并编译打包。最后，我们需要进行归档，也就是将编译后的二进制文件或 Docker 镜像上传到制品库或镜像仓库。

我刚刚带着你完整走了一遍开发阶段的常见步骤。可以看到，整个开发阶段步骤很多，而且都是高频的操作。那怎么提高效率呢？这里我**推荐**你两种方法：
- 将开发阶段的步骤通过 Makefile 实现集中管理；
- 将构建阶段的步骤通过 CI/CD 平台实现自动化。

**你还需要特别**注意**这一点：在最终合并代码到 master 之前，要确保代码是经过充分测试的。**这就要求我们一定要借助代码管理平台提供的 Webhook 能力，在代码提交时触发 CI/CD 作业，对代码进行扫描、测试，最终编译打包，并以整个作业的成功执行作为合并代码的先决条件。

开发阶段的产出物是满足需求的源代码、开发文档，以及编译后的归档文件。

### 测试阶段
测试阶段由测试工程师（也叫质量工程师）负责，这个阶段的主要流程是：测试工程师根据需求文档创建测试计划、编写测试用例，并拉研发同学一起评审测试计划和用例。评审通过后，测试工程师就会根据测试计划和测试用例对服务进行测试。

**为了提高整个研发效率，测试计划的创建和测试用例的编写可以跟开发阶段并行**。研发人员在交付给测试时，要提供自测报告、自测用例和安装部署文档。**这里我要强调的是：在测试阶段，为了不阻塞测试，确保项目按时发布，研发人员应该优先解决测试同学的 Bug，至少是阻塞类的 Bug。为了减少不必要的沟通和排障，安装部署文档要尽可能详尽和准确。**

另外，你也可以及时跟进测试，了解测试同学当前遇到的卡点。因为实际工作中，一些测试同学在遇到卡点时，不善于或者不会及时地跟你同步卡点，往往研发 1 分钟就可以解决的问题，可能要花测试同学几个小时或者更久的时间去解决。

当然，测试用例几乎不可能涵盖整个变更分支，所以对于一些难测，隐藏的测试，需要研发人员自己加强测试。最后，一个大特性测试完，请测试同学吃个饭吧，大家唠唠家常，联络联络感情，下次合作会更顺畅。测试阶段的产出物是满足产品需求、达到发布条件的源代码，以及编译后的归档文件。

### 发布阶段
发布阶段主要是将软件部署上线，为了保证发布的效率和质量，我们需要遵循一定的发布流程，如下图所示：

![img](https://static001.geekbang.org/resource/image/37/88/37yy6e0896daa8f97883631624996388.png?wh=2288*1938)

发布阶段按照时间线排序又分为代码发布、发布审批和服务发布 3 个子阶段。接下来，我详细给你介绍下这 3 个子阶段。我们先来看一下代码发布。




首先，开发人员首先需要将经过测试后的代码合并到主干，通常是 master 分支，并生成版本号，然后给最新的 commit 打上版本标签。之后，可以将代码 push 到代码托管平台，并触发 CI 流程，CI 流程一般会执行代码扫描、单元测试、编译，最后将构建产物发布到制品库。CI 流程中，我们可以根据需要添加任意功能。



接着，进入到发布审批阶段。首先需要申请资源，**资源申请周期可能会比较久，所以申请得越早越好，甚至资源申请可以在测试阶段发起**。在资源申请阶段，可以申请诸如服务器、MySQL、Redis、Kafka 之类资源。资源申请通常是开发人员向运维人员提需求，由运维人员根据需求，在指定的时间前准备好各类资源。如果是物理机通常申请周期会比较久，但当前越来越多的项目选择容器化部署，这可以极大地缩短资源的申请周期。如果在像腾讯云弹性容器这类 Serverless 容器平台上部署业务，甚至可以秒申请资源。所以这里，我也**建议**优先采用容器化部署。




发布之前需要创建发布计划，里面需要详细描述本次的变更详情，例如变更范围、发布方案、测试结果、验证和回滚方案等。这里需要你**注意**，**在创建发布计划时，一定要全面梳理这次变更的影响点**。例如，是否有不兼容的变更，是否需要变更配置，是否需要变更数据库等。任何一个遗漏，都可能造成现网故障，影响产品声誉和用户使用。



接下来，需要创建发布单，在发布单中可以附上发布计划，并根据团队需求填写其它发布内容，发布计划需要跟相关参与者对齐流程、明确职责。发布单最终提交给审批人（通常是技术 leader）对本次发布进行审批，审批通过后，才可以进行部署。


最后，就可以进入到服务发布阶段，将服务发布到现网。在正式部署的时候，应用需要先部署到预发环境。在预发环境，产品人员、测试人员和研发人员会分别对产品进行验证。其中，产品人员主要验证产品功能的体验是否流畅，开发和测试人员主要验证产品是否有 Bug。预发环境验证通过，产品才能正式发布到现网。



这里，我强烈**建议**，**编写一些自动化的测试用例，在服务发布到现网之后，对现网服务做一次比较充分的回归测试。**通过这个自动化测试，可以以最小的代价，最快速地验证现网功能，从而保障发布质量。



另外，我们还要**注意**，**现网可能有多个地域，每个地域发布完成之后都要进行现网验证**。发布阶段的产出物是正式上线的软件。


### 运营阶段
研发流程的最后一个阶段是运营阶段，该阶段主要分为产品运营和运维两个部分。
- 产品运营：通过一系列的运营活动，比如线下的技术沙龙、线上的免费公开课、提高关键词排名或者输出一些技术推广文章等方式，来推高整个产品的知名度，提高产品的用户数量，并提高月活和日活。
- 运维：由运维工程师负责，核心目标是确保系统稳定的运行，如果系统异常，能够及时发现并修复问题。长期目标是通过技术手段或者流程来完善整个系统架构，减少人力投入、提高运维效率，并提高系统的健壮性和恢复能力。



从上面可以看到，运维属于技术类，运营属于产品类，这二者不要搞混。为了加深你的理解和记忆，我将这些内容，总结在了下面一张图中。![img](https://static001.geekbang.org/resource/image/e0/b5/e0a4d8ed5f3a6a8a4bc4035e261881b5.png?wh=2519*1431)



在运营阶段，研发人员的主要职责就是协助运维解决现网 Bug，优化部署架构。当然，研发人员可能也需要配合运营人员开发一些运营接口，供运营人员使用。

到这里，业界相对标准的这套研发流程，我们就学完了。在学习过程中，你肯定也发现了，整个研发流程会涉及很多角色，不同角色参与不同的阶段，负责不同的任务。这里我再给你额外扩展一个点，就是这些核心角色和分工是啥样的。这些扩展内容，我放在了一张图和一张表里。这些角色和分工比较好理解，也不需要你背下来，只要先有一个大概的印象就可以了。

![img](https://static001.geekbang.org/resource/image/d1/da/d1797845f4105476c99ecc22cc7562da.png?wh=3088*1325)

具体分工如下表所示。



![img](https://static001.geekbang.org/resource/image/40/d5/40a1e20b153bb3ba1005cea4aefe62d5.png?wh=754*815)

### 总结
在开发 Go 项目时，掌握项目的研发流程很重要。掌握研发流程，会让项目研发对我们更加白盒，并且有利于我们制定详细的工作任务。那么如何设计项目研发流程呢？你可以根据需要自行设计。自行设计时有些点是一定要关注的，例如我们的流程需要支持高的发布效率和发布质量，支持快速迭代，流程是合理、可扩展的，等等。如果你不想自己设计，也可以。在这一讲中，我介绍了一套相对通用、标准的研发流程，如果合适可以直接拿来作为自己设计的研发流程。这套研发流程包含 6 个阶段：需求阶段、设计阶段、开发阶段、测试阶段、发布阶段和运营阶段。这里我将这些流程和每个流程的核心点总结在下面一张图中。

![img](https://static001.geekbang.org/resource/image/dd/0f/ddb314275ba1bab28413221bc56ac80f.png?wh=3225*1256)

## 9 | 研发流程设计（下）：如何管理应用的生命周期？

应用的生命周期管理，怎么理解呢？**其实，就是指采用一些好的工具或方法在应用的整个生命周期中对应用进行管理，以提高应用的研发效率和质量。**

这一讲我们就一起学习下，业界在不同时期沉淀下来的优秀管理手段，以及我对这些管理手段的经验和**建议**，帮助你选到一个最合适的。

### 应用生命周期管理技术有哪些？
那么，有哪些应用生命周期管理技术呢？在这里我先整体介绍一下，你先有个大致的印象，一会我们再一个个细讲。我们可以**从两个维度来理解应用生命周期管理技术。**

第一个维度是演进维度。应用生命周期，最开始主要是通过研发模式来管理的，按时间线先后出现了瀑布模式、迭代模式、敏捷模式。接着，为了解决研发模式中的一些痛点出现了另一种管理技术，也就是 CI/CD 技术。随着 CI/CD 技术的成熟，又催生了另一种更高级的管理技术 DevOps。


第二个维度是管理技术的类别。应用生命周期管理技术可以分为两类：
- 研发模式，用来确保整个研发流程是高效的。DevOps，主要通过协调各个部门之间的合作，来提高软件的发布效率和质量。
- DevOps 中又包含了很多种技术，主要包括 CI/CD 和多种 Ops，例如 AIOps、ChatOps、GitOps、NoOps 等。其中，CI/CD 技术提高了软件的发布效率和质量，而 Ops 技术则提高了软件的运维和运营效率。


尽管这些应用生命周期管理技术有很多不同，但是它们彼此支持、相互联系。研发模式专注于开发过程，DevOps 技术里的 CI/CD 专注于流程，Ops 则专注于实战。为了帮助你理解，我总结出了下面这张图供你参考。

![img](https://static001.geekbang.org/resource/image/9a/a3/9a290c28b0c238dd69e24dcc9f5c7ea3.png?wh=5241*2222)

这两个维度涉及的管理技术虽然不少，但一共就是那几类。所以，**为了能够逻辑清晰地给你讲解明白这些技术，我会从演进维度来展开，也就是按照这样的顺序：研发模式（瀑布模式 -> 迭代模式 -> 敏捷模式） -> CI/CD -> DevOps。**

接下来，我们就详细说说这些应用生命周期的管理方法，先来看专注于开发过程的研发模式部分。

### 研发模式
研发模式主要有三种，演进顺序为瀑布模式 -> 迭代模式 -> 敏捷模式，现在我们逐一看下。

#### 瀑布模式
在早期阶段，软件研发普遍采用的是瀑布模式，像我们熟知的 RHEL、Fedora 等系统就是采用瀑布模式。**瀑布模式按照预先规划好的研发阶段来推进研发进度**。比如，按照需求阶段、设计阶段、开发阶段、测试阶段、发布阶段、运营阶段的顺序串行执行开发任务。每个阶段完美完成之后，才会进入到下一阶段，阶段之间通过文档进行交付。整个过程如下图所示。

![img](https://static001.geekbang.org/resource/image/7c/89/7ccc702a02cf24e2295cc50a506e6289.png?wh=2466*1272)


瀑布模式最大的优点是简单。它严格按照研发阶段来推进研发进度，流程清晰，适合按项目交付的应用。

但它的缺点也很明显，最突出的就是这两个：**只有在项目研发的最后阶段才会交付给客户**。**交付后，如果客户发现问题，变更就会非常困难，代价很大**。**研发周期比较长**，很难适应互联网时代对产品快速迭代的诉求。

为了解决这两个问题，迭代式研发模式诞生了。

#### 迭代模式
迭代模式，是一种与瀑布式模式完全相反的开发过程：**研发任务被切分为一系列轮次，每一个轮次都是一个迭代，每一次迭代都是一个从设计到实现的完整过程**。它**不要求每一个阶段的任务都做到最完美，而是先把主要功能搭建起来，然后再通过客户的反馈信息不断完善**。迭代开发可以帮助产品改进和把控进度，它的灵活性极大地提升了适应需求变化的能力，克服了高风险、难变更、复用性低的特点。但是，**迭代模式的问题在于比较专注于开发过程，很少从项目管理的视角去加速和优化项目开发过程。**接下来要讲的敏捷模式，就弥补了这个缺点。


#### 敏捷模式
敏捷模式把一个大的需求分成多个、可分阶段完成的小迭代，每个迭代交付的都是一个可使用的软件。在开发过程中，软件要一直处于可使用状态。敏捷模式中具有代表性的开发模式，是 Scrum 开发模型。Scrum 开发模型网上有很多介绍，你可以去看看。在敏捷模式中，我们**会把一个大的需求拆分成很多小的迭代**，这意味着开发过程中会有很多个开发、构建、测试、发布和部署的流程。这种高频度的操作会给研发、运维和测试人员带来很大的工作量，降低了工作效率。为了解决这个问题，CI/CD 技术诞生了。


### CI/CD：自动化构建和部署应用
CI/CD 技术通过自动化的手段，来快速执行代码检查、测试、构建、部署等任务，从而提高研发效率，解决敏捷模式带来的弊端。

CI/CD 包含了 3 个核心概念。CI：Continuous Integration，持续集成。CD：Continuous Delivery，持续交付。CD：Continuous Deployment，持续部署。


CI 容易理解，但两个 CD 很多开发者区分不开。这里，我来详细说说这 3 个核心概念。

首先是持续集成。它的含义为：**频繁地（一天多次）将开发者的代码合并到主干上**。它的流程为：**在开发人员完成代码开发，并 push 到 Git 仓库后，CI 工具可以立即对代码进行扫描、（单元）测试和构建，并将结果反馈给开发者**。持续集成通过后，会将代码合并到主干。CI 流程可以使应用软件的问题在开发阶段就暴露出来，这会让开发人员交付代码时更有信心。因为 CI 流程内容比较多，而且执行比较频繁，所以 CI 流程需要有自动化工具来支撑。


其次是持续交付，它指的是一种能够使软件在较短的循环中可靠发布的软件方法。**持续交付在持续集成的基础上，将构建后的产物自动部署在目标环境中**。这里的目标环境，可以是测试环境、预发环境或者现网环境。通常来说，持续部署可以自动地将服务部署到测试环境或者预发环境。因为部署到现网环境存在一定的风险，所以如果部署到现网环境，需要手工操作。手工操作的好处是，可以使相关人员评估发布风险，确保发布的正确性。



最后是持续部署，持续部署在持续交付的基础上，将经过充分测试的代码自动部署到生产环境，整个流程不再需要相关人员的审核。**持续部署强调的是自动化部署**，是交付的最高阶段。我们可以借助下面这张图，来了解持续集成、持续交付、持续部署的关系。


![img](https://static001.geekbang.org/resource/image/96/d0/963b9983543de3d66379567ba491d7d0.png?wh=6709*2328)
持续集成、持续交付和持续部署强调的是持续性，也就是能够支持频繁的集成、交付和部署，这离不开自动化工具的支持，离开了这些工具，CI/CD 就不再具有可实施性。持续集成的核心点在代码，持续交付的核心点在可交付的产物，持续部署的核心点在自动部署。

### DevOps：研发运维一体化
CI/CD 技术的成熟，加速了 DevOps 这种应用生命周期管理技术的成熟和落地。DevOps（Development 和 Operations 的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序 / 软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。这 3 个部门的相互协作，可以提高软件质量、快速发布软件。如下图所示：




![img](https://static001.geekbang.org/resource/image/c8/79/c81a361fb98500cec8c866f465f14679.png?wh=1800*1650)

要实现 DevOps，需要一些工具或者流程的支持，CI/CD 可以很好地支持 DevOps 这种软件开发模式，如果没有 CI/CD 自动化的工具和流程，DevOps 就是没有意义的，CI/CD 使得 DevOps 变得可行。


听到这里是不是有些晕？你可能想问，DevOps 跟 CI/CD 到底是啥区别呢？其实，这也是困扰很多开发者的问题。这里，我们可以这么理解：DevOps ！= CI/CD。DevOps 是一组过程、方法和系统的统称，而 CI/CD 只是一种软件构建和发布的技术。


DevOps 技术之前一直有，但是落地不好，因为没有一个好的工具来实现 DevOps 的理念。但是随着容器、CI/CD 技术的诞生和成熟，DevOps 变得更加容易落地。也就是说，这几年越来越多的人采用 DevOps 手段来提高研发效能。

随着技术的发展，目前已经诞生了很多 Ops 手段，来实现运维和运营的高度自动化。下面，我们就来看看 DevOps 中的四个 Ops 手段：**AIOps、ChatOps、GitOps、NoOps。**


#### AIOps：智能运维
在 2016 年，Gartner 提出利用 AI 技术的新一代 IT 运维，即 AIOps（智能运维）。通过 AI 手段，来智能化地运维 IT 系统。AIOps 通过搜集海量的运维数据，并利用机器学习算法，智能地定位并修复故障。


也就是说，AIOps 在自动化的基础上，增加了智能化，从而进一步推动了 IT 运维自动化，减少了人力成本。随着 IT 基础设施规模和复杂度的倍数增长，企业应用规模、数量的指数级增长，传统的人工 / 自动化运维，已经无法胜任愈加沉重的运维工作，而 AIOps 提供了一个解决方案。在腾讯、阿里等大厂很多团队已经在尝试和使用 AIOps，并享受到了 AIOps 带来的红利。例如，故障告警更加灵敏、准确，一些常见的故障，可以自动修复，无须运维人员介入等。

#### ChatOps：聊着天就把事情给办了
随着企业微信、钉钉等企业内通讯工具的兴起，最近几年出现了一个新的概念 ChatOps。简单来说，ChatOps 就是在一个聊天工具中，发送一条命令给 ChatBot 机器人，然后 ChatBot 会执行预定义的操作。这些操作可以是执行某个工具、调用某个接口等，并返回执行结果。


这种新型智能工作方式的优势是什么呢？它可以利用 ChatBot 机器人让团队成员和各项辅助工具连接在一起，以沟通驱动的方式完成工作。ChatOps 可以解决人与人、人与工具、工具与工具之间的信息孤岛，从而提高协作体验和工作效率。ChatOps 的工作流程如下图所示（网图）：


![img](https://static001.geekbang.org/resource/image/29/6e/292372572f1fa8cae9a44891bd233a6e.png?wh=1080*489)

开发 / 运维 / 测试人员通过 @聊天窗口中的机器人 Bot 来触发任务，机器人后端会通过 API 接口调用等方式对接不同的系统，完成不同的任务，例如持续集成、测试、发布等工作。机器人可以是我们自己研发的，也可以是开源的。目前，业界有很多流行的机器人可供选择，常用的有 Hubot、Lita、Errbot、StackStorm 等。使用 ChatOps 可以带来以下几点好处。

- 友好、便捷：所有的操作均在同一个聊天界面中，通过 @机器人以聊天的方式发送命令，免去了打开不同系统，执行不同操作的繁琐操作，方式更加友好和便捷。
- 信息透明：在同一个聊天界面中的所有同事都能够看到其他同事发送的命令，以及命令执行的结果，可以消除沟通壁垒，工作历史有迹可循，团队合作更加顺畅。
- 移动友好：可以在移动端向机器人发送命令、执行任务，让移动办公变为可能。
- DevOps 文化打造：通过与机器人对话，可以降低项目开发中，各参与人员的理解和使用成本，从而使 DevOps 更容易落地和推广。


#### GitOps： 一种实现云原生的持续交付模型
GitOps 是一种持续交付的方式。它的核心思想是将应用系统的声明性基础架构（YAML）和应用程序存放在 Git 版本库中。将 Git 作为交付流水线的核心，每个开发人员都可以提交拉取请求（Pull Request），并使用 Gi​​t 来加速和简化 Kubernetes 的应用程序部署和运维任务。通过 Git 这样的工具，开发人员可以将精力聚焦在功能开发，而不是软件运维上，以此提高软件的开发效率和迭代速度。


使用 GitOps 可以带来很多优点，其中最核心的是：当使用 Git 变更代码时，GitOps 可以自动将这些变更应用到程序的基础架构上。因为整个流程都是自动化的，所以部署时间更短；又因为 Git 代码是可追溯的，所以我们部署的应用也能够稳定且可重现地回滚。我们可以从概念和流程上来理解 GitOps，它有 3 个关键概念。

- 声明性容器编排：通过 Kubernetes YAML 格式的资源定义文件，来定义如何部署应用。
- 不可变基础设施：基础设施中的每个组件都可以自动的部署，组件在部署完成后，不能发生变更。如果需要变更，则需要重新部署一个新的组件。例如，Kubernetes 中的 Pod 就是一个不可变基础设施。
- 连续同步：不断地查看 Git 存储库，将任何状态更改反映到 Kubernetes 集群中。


![img](https://static001.geekbang.org/resource/image/2f/8d/2f1b427674e7da60668b2af42cf7338d.png?wh=3981*1244)

GitOps 的工作流程如下：**首先，开发人员开发完代码后推送到 Git 仓库，触发 CI 流程，CI 流程通过编译构建出 Docker 镜像，并将镜像 push 到 Docker 镜像仓库中。Push 动作会触发一个 push 事件，通过 webhook 的形式通知到 Config Updater 服务，Config Updater 服务会从 webhook 请求中获取最新 push 的镜像名，并更新 Git 仓库中的 Kubernetes YAML 文件。**

**然后，GitOps 的 Deploy Operator 服务，检测到 YAML 文件的变动，会重新从 Git 仓库中提取变更的文件，并将镜像部署到 Kubernetes 集群中。Config Updater 和 Deploy Operator 两个组件需要开发人员设计开发。**


#### NoOps：无运维
NoOps 即无运维，完全自动化的运维。在 NoOps 中不再需要开发人员、运营运维人员的协同，把微服务、低代码、无服务全都结合了起来，开发者在软件生命周期中只需要聚焦业务开发即可，所有的维护都交由云厂商来完成。


毫无疑问，NoOps 是运维的终极形态，在我看来它像 DevOps 一样，更多的是一种理念，需要很多的技术和手段来支撑。当前整个运维技术的发展，也是朝着 NoOps 的方向去演进的，例如 GitOps、AIOps 可以使我们尽可能减少运维，Serverless 技术甚至可以使我们免运维。相信未来 NoOps 会像现在的 Serverless 一样，成为一种流行的、可落地的理念。


### 如何选择合适的应用生命周期管理技术？
好了，到这里我们就把主要的应用生命周期管理技术，学得差不多了。那在实际开发中，如何选择适合自己的呢？在我看来，你可以从这么几个方面考虑。



首先，根据团队、项目选择一个合适的研发模式。如果项目比较大，需求变更频繁、要求快速迭代，**建议**选择敏捷开发模式。敏捷开发模式，也是很多大公司选择的研发模式，在互联网时代很受欢迎。接着，要建立自己的 CI/CD 流程。任何变更代码在合并到 master 分支时，一定要通过 CI/CD 的流程的验证。我**建议**，你在 CI/CD 流程中设置质量红线，确保合并代码的质量。接着，除了建立 CI/CD 系统，我还**建议**将 ChatOps 带入工作中，尽可能地将可以自动化的工作实现自动化，并通过 ChatOps 来触发自动化流程。随着企业微信、钉钉等企业聊天软件成熟和发展，ChatOps 变得流行和完善。最后，GitOps、AIOps 可以将部署和运维自动化做到极致，在团队有人力的情况下，值得探索。


到这里你可能会问了，大厂是如何管理应用生命周期的？大厂普遍采用敏捷开发的模式，来适应互联网对应用快速迭代的诉求。例如，腾讯的TAPD、Coding的 Scrum 敏捷管理就是一个敏捷开发平台。CI/CD 强制落地，ChatOps 已经广泛使用，AIOps 也有很多落地案例，GitOps 目前还在探索阶段，NoOps 还处在理论阶段。


### 总结
这一讲，我从技术演进的维度介绍了应用生命周期管理技术，这些技术可以提高应用的研发效率和质量。应用生命周期管理最开始是通过研发模式来管理的。在研发模式中，我按时间线分别介绍了瀑布模式、迭代模式和敏捷模式，其中的敏捷模式适应了互联网时代对应用快速迭代的诉求，所以用得越来越多。在敏捷模式中，我们需要频繁构建和发布我们的应用，这就给开发人员带来了额外的工作量，为了解决这个问题，出现了 CI/CD 技术。CI/CD 可以将代码的检查、测试、构建和部署等工作自动化，不仅提高了研发效率，还从一定程度上保障了代码的质量。另外，CI/CD 技术使得 DevOps 变得可行，当前越来越多的团队采用 DevOps 来管理应用的生命周期。

另外，这一讲中我也介绍了几个大家容易搞混的概念。
- 持续交付和持续部署。二者都是持续地部署应用，但是持续部署整个过程是自动化的，而持续交付中，应用在发布到现网前需要人工审批是否允许发布。
- - CI/CD 和 DevOps。DevOps 是一组过程、方法与系统的统称，其中也包含了 CI/CD 技术。而 CI/CD 是一种自动化的技术，DevOps 理念的落地需要 CI/CD 技术的支持。

最后，关于如何管理应用的生命周期，我给出了一些**建议**：研发模式**建议**选择敏捷模式，因为它更能胜任互联网时代快速迭代的诉求。DevOps 则要优先确保落地 CI/CD 技术，接着尝试落地 ChatOps 技术，如果有条件可以积极探索 AIOps 和 GitOps。

## 10 | 设计方法：怎么写出优雅的 Go 项目？

Go 语言简单易学，对于大部分开发者来说，编写可运行的代码并不是一件难事，**但如果想真正成为 Go 编程高手，你需要花很多精力去研究 Go 的编程哲学。**


在我的 Go 开发生涯中，我见过各种各样的代码问题，例如：**代码不规范，难以阅读；函数共享性差，代码重复率高；不是面向接口编程，代码扩展性差，代码不可测；代码质量低下。**究其原因，是因为这些代码的开发者很少花时间去认真研究如何开发一个优雅的 Go 项目，更多时间是埋头在需求开发中。


其实，我们之前所学的各种规范设计，也都是为了写出一个优雅的 Go 项目。在这一讲，我又补充了一些内容，从而形成了一套“写出优雅 Go 项目”的方法论。这一讲内容比较多，但很重要。


### 如何写出优雅的 Go 项目？
那么，如何写出一个优雅的 Go 项目呢？在回答这个问题之前，我们先来看另外两个问题：为什么是 Go 项目，而不是 Go 应用？一个优雅的 Go 项目具有哪些特点？


先来看第一个问题。Go 项目是一个偏工程化的概念，不仅包含了 Go 应用，还包含了项目管理和项目文档：


![img](https://static001.geekbang.org/resource/image/24/aa/24ba3548f8574a747b51e291224097aa.png?wh=2175x834)
这就来到了第二个问题，一个优雅的 Go 项目，不仅要求我们的 Go 应用是优雅的，还要确保我们的项目管理和文档也是优雅的。这样，我们根据前面几讲学到的 Go 设计规范，很容易就能总结出一个优雅的 Go 应用需要具备的特点：

符合 Go 编码规范和最佳实践；**易阅读、易理解，易维护；易测试、易扩展；代码质量高。**


解决了这两个问题，让我们回到这一讲的核心问题：如何写出优雅的 Go 项目？写出一个优雅的 Go 项目，在我看来，就是用“最佳实践”的方式去实现 Go 项目中的 Go 应用、项目管理和项目文档。具体来说，就是编写高质量的 Go 应用、高效管理项目、编写高质量的项目文档。

为了协助你理解，我将这些逻辑绘制成了下面一张图。

![img](https://static001.geekbang.org/resource/image/77/03/77d541223576135df4c3d511abbfe603.png?wh=3131x1488)

接下来，我们就看看如何根据前面几讲学习的 Go 项目设计规范，实现一个优雅的 Go 项目。我们先从编写高质量的 Go 应用看起。


### 编写高质量的 Go 应用
基于我的研发经验，要编写一个高质量的 Go 应用，其实可以归纳为 5 个方面：**代码结构、代码规范、代码质量、编程哲学和软件设计**方法，见下图。


![img](https://static001.geekbang.org/resource/image/23/69/2392d94feb95d3d64d765abe7d6e5e69.png?wh=3544x766)
接下来，我们详细说说这些内容。


#### 代码结构
为什么先说代码结构呢？因为组织合理的代码结构是一个项目的门面。我们可以通过两个手段来组织代码结构。

第一个手段是，组织一个好的目录结构。关于如何组合一个好的目录结构，你可以回顾 06 讲 的内容。第二个手段是，选择一个好的模块拆分方法。做好模块拆分，可以使项目内模块职责分明，做到低耦合高内聚。

那么 Go 项目开发中，如何拆分模块呢？目前业界有两种拆分方法，分别是**按层拆分和按功能拆分。**


首先，我们看下按层拆分，最典型的是 MVC 架构中的模块拆分方式。在 MVC 架构中，我们将服务中的不同组件按访问顺序，拆分成了 Model、View 和 Controller 三层。

![img](https://static001.geekbang.org/resource/image/ed/46/ed0c3dfyy52ac82539cb602eec9f0146.png?wh=497x625)

每层完成不同的功能：View（视图）是提供给用户的操作界面，用来处理数据的显示。Controller（控制器），负责根据用户从 View 层输入的指令，选取 Model 层中的数据，然后对其进行相应的操作，产生最终结果。Model（模型），是应用程序中用于处理数据逻辑的部分。

我们看一个典型的按层拆分的目录结构：

```
$ tree --noreport -L 2 layers
layers
├── controllers
│   ├── billing
│   ├── order
│   └── user
├── models
│   ├── billing.go
│   ├── order.go
│   └── user.go
└── views
    └── layouts
```
在 Go 项目中，按层拆分会带来很多问题。最大的问题是**循环引用**：相同功能可能在不同层被使用到，而这些功能又分散在不同的层中，很容易造成循环引用。所以，**你只要大概知道按层拆分是什么意思就够了，在 Go 项目中我**建议**你使用的是按功能拆分的方法，这也是 Go 项目中最常见的拆分方法。**
那什么是按功能拆分呢？我给你看一个例子你就明白了。比如，一个订单系统，我们可以根据不同功能将其拆分成用户（user）、订单（order）和计费（billing）3 个模块，每一个模块提供独立的功能，功能更单一：

![img](https://static001.geekbang.org/resource/image/0d/a5/0d65eb1363bf8055e209bc24d1d99ca5.png?wh=625x572)
下面是该订单系统的代码目录结构：

```
$ tree pkg
$ tree --noreport -L 2 pkg
pkg
├── billing
├── order
│   └── order.go
└── user
```
相较于按层拆分，按功能拆分模块带来的好处也很好理解：不同模块，功能单一，可以实现高内聚低耦合的设计哲学。因为所有的功能只需要实现一次，引用逻辑清晰，会大大减少出现循环引用的概率。


所以，有很多优秀的 Go 项目采用的都是按功能拆分的模块拆分方式，例如 Kubernetes、Docker、Helm、Prometheus 等。除了组织合理的代码结构这种方式外，编写高质量 Go 应用的另外一个行之有效的方法，是遵循 Go 语言代码规范来编写代码。在我看来，这也是最容易出效果的方式。


#### 代码规范
那我们要遵循哪些代码规范来编写 Go 应用呢？在我看来，其实就两类：**编码规范和最佳实践。**

首先，我们的代码要符合 Go 编码规范，这是最容易实现的途径。Go 社区有很多这类规范可供参考，其中，比较受欢迎的是Uber Go 语言编码规范。阅读这些规范确实有用，也确实花时间、花精力。所以，我在参考了已有的很多规范后，结合自己写 Go 代码的经验，特地为你整理了一篇 Go 编码规范作为加餐，也就是“特别放送 | 给你一份清晰、可直接套用的 Go 编码规范”。

有了可以参考的编码规范之后，我们需要扩展到团队、部门甚至公司层面。只有大家一起参与、遵守，规范才会变得有意义。其实，我们都清楚，要开发者靠自觉来遵守所有的编码规范，不是一件容易的事儿。这时候，我们可以使用静态代码检查工具，来约束开发者的行为。


有了静态代码检查工具后，不仅可以确保开发者写出的每一行代码都是符合 Go 编码规范的，还可以将静态代码检查集成到 CI/CD 流程中。这样，在代码提交后自动地检查代码，就保证了只有符合编码规范的代码，才会被合入主干。

Go 语言的静态代码检查工具有很多，目前用的最多的是golangci-lint，这也是我极力**推荐**你使用的一个工具。关于这个工具的使用，我会在第 15 讲和你详细介绍。


除了遵循编码规范，要想成为 Go 编程高手，你还得学习并遵循一些最佳实践。“最佳实践”是社区经过多年探索沉淀下来的、符合 Go 语言特色的经验和共识，它可以帮助你开发出一个高质量的代码。这里我给你**推荐**几篇介绍 Go 语言最佳实践的文章，供你参考：


Effective Go：高效 Go 编程，由 Golang 官方编写，里面包含了编写 Go 代码的一些**建议**，也可以理解为最佳实践。Go Code Review Comments：Golang 官方编写的 Go 最佳实践，作为 Effective Go 的补充。Style guideline for Go packages：包含了如何组织 Go 包、如何命名 Go 包、如何写 Go 包文档的一些**建议**。


#### 代码质量
有了组织合理的代码结构、符合 Go 语言代码规范的 Go 应用代码之后，我们还需要通过一些手段来确保我们开发出的是一个高质量的代码，这可以通过单元测试和 Code Review 来实现。


单元测试非常重要。我们开发完一段代码后，第一个执行的测试就是单元测试。它可以保证我们的代码是符合预期的，一些异常变动能够被及时感知到。进行单元测试，不仅需要编写单元测试用例，还需要我们确保代码是可测试的，以及具有一个高的单元测试覆盖率。


接下来，我就来介绍下如何编写一个可测试的代码。如果我们要对函数 A 进行测试，并且 A 中的所有代码均能够在单元测试环境下按预期被执行，那么函数 A 的代码块就是可测试的。我们来看下一般的单元测试环境有什么特点：

可能无法连接数据库。可能无法访问第三方服务。

如果函数 A 依赖数据库连接、第三方服务，那么在单元测试环境下执行单元测试就会失败，函数就没法测试，函数是不可测的。解决方法也很简单：将依赖的数据库、第三方服务等抽象成接口，在被测代码中调用接口的方法，在测试时传入 mock 类型，从而将数据库、第三方服务等依赖从具体的被测函数中解耦出去。如下图所示：


![img](https://static001.geekbang.org/resource/image/0c/97/0cef423ec1a4f06f6f4715bd0b9f4497.png?wh=1500x438)

为了提高代码的可测性，降低单元测试的复杂度，对 function 和 mock 的要求是：要尽可能减少 function 中的依赖，让 function 只依赖必要的模块。编写一个功能单一、职责分明的函数，会有利于减少依赖。依赖模块应该是易 Mock 的。


为了协助你理解，我们先来看一段不可测试的代码：


```go
package post

import "google.golang.org/grpc"

type Post struct {
  Name    string
  Address string
}

func ListPosts(client *grpc.ClientConn) ([]*Post, error) {
  return client.ListPosts()
}
```
这段代码中的 ListPosts 函数是不可测试的。因为 ListPosts 函数中调用了client.ListPosts()方法，该方法依赖于一个 gRPC 连接。而我们在做单元测试时，可能因为没有配置 gRPC 服务的地址、网络隔离等原因，导致没法建立 gRPC 连接，从而导致 ListPosts 函数执行失败。下面，我们把这段代码改成可测试的，如下：


```go
package main

type Post struct {
  Name    string
  Address string
}

type Service interface {
  ListPosts() ([]*Post, error)
}

func ListPosts(svc Service) ([]*Post, error) {
  return svc.ListPosts()
}
```
上面代码中，ListPosts 函数入参为 Service 接口类型，只要我们传入一个实现了 Service 接口类型的实例，ListPosts 函数即可成功运行。因此，我们可以在单元测试中可以实现一个不依赖任何第三方服务的 fake 实例，并传给 ListPosts。上述可测代码的单元测试代码如下：


```go
package main

import "testing"

type fakeService struct {
}

func NewFakeService() Service {
  return &fakeService{}
}

func (s *fakeService) ListPosts() ([]*Post, error) {
  posts := make([]*Post, 0)
  posts = append(posts, &Post{
    Name:    "colin",
    Address: "Shenzhen",
  })
  posts = append(posts, &Post{
    Name:    "alex",
    Address: "Beijing",
  })
  return posts, nil
}

func TestListPosts(t *testing.T) {
  fake := NewFakeService()
  if _, err := ListPosts(fake); err != nil {
    t.Fatal("list posts failed")
  }
}
```
当我们的代码可测之后，就可以借助一些工具来 Mock 需要的接口了。常用的 Mock 工具，有这么几个：
- golang/mock，是官方提供的 Mock 框架。它实现了基于 interface 的 Mock 功能，能够与 Golang 内置的 testing 包做很好的集成，是最常用的 Mock 工具。golang/mock 提供了 mockgen 工具用来生成 interface 对应的 Mock 源文件。
- sqlmock，可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。
- httpmock，可以用来 Mock HTTP 请求。
- bouk/monkey，猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果 golang/mock、sqlmock 和 httpmock 这几种方法都不能满足我们的需求，我们可以尝试通过猴子补丁的方式来 Mock 依赖。可以这么说，猴子补丁提供了单元测试 Mock 依赖的最终解决方案。


接下来，我们再一起看看如何提高我们的单元测试覆盖率。当我们编写了可测试的代码之后，接下来就需要编写足够的测试用例，用来提高项目的单元测试覆盖率。这里我有以下两个**建议**供你参考：


使用 gotests 工具自动生成单元测试代码，减少编写单元测试用例的工作量，将你从重复的劳动中解放出来。定期检查单元测试覆盖率。你可以通过以下方法来检查：


```
$ go test -race -cover  -coverprofile=./coverage.out -timeout=10m -short -v ./...
$ go tool cover -func ./coverage.out
```
执行结果如下：


![img](https://static001.geekbang.org/resource/image/d2/89/d2fae0aca602c7c33466411e39c49489.png?wh=2162x412)

在提高项目的单元测试覆盖率时，我们可以先提高单元测试覆盖率低的函数，之后再检查项目的单元测试覆盖率；如果项目的单元测试覆盖率仍然低于期望的值，可以再次提高单元测试覆盖率低的函数的覆盖率，然后再检查。以此循环，最终将项目的单元测试覆盖率优化到预期的值为止。这里要**注意**，对于一些可能经常会变动的函数单元测试，覆盖率要达到 100%。


说完了单元测试，我们再看看如何通过 Code Review 来保证代码质量。Code Review 可以提高代码质量、交叉排查缺陷，并且促进团队内知识共享，是保障代码质量非常有效的手段。在我们的项目开发中，一定要建立一套持久可行的 Code Review 机制。



但在我的研发生涯中，发现很多团队没有建立有效的 Code Review 机制。这些团队都认可 Code Review 机制带来的好处，但是因为流程难以遵守，慢慢地 Code Review 就变成了形式主义，最终不了了之。其实，建立 Code Review 机制很简单，主要有 3 点：


首先，确保我们使用的代码托管平台有 Code Review 的功能。比如，GitHub、GitLab 这类代码托管平台都具备这种能力。接着，建立一套 Code Review 规范，规定如何进行 Code Review。最后，也是最重要的，每次代码变更，相关开发人员都要去落实 Code Review 机制，并形成习惯，直到最后形成团队文化。


**到这里我们可以小结一下：组织一个合理的代码结构、编写符合 Go 代码规范的代码、保证代码质量，在我看来都是编写高质量 Go 代码的外功。那内功是什么呢？就是编程哲学和软件设计方法。**


#### 编程哲学
那编程哲学是什么意思呢？在我看来，编程哲学，其实就是要编写符合 Go 语言设计哲学的代码。Go 语言有很多设计哲学，对代码质量影响比较大的，我认为有两个：面向接口编程和面向“对象”编程。


我们先来看下面向接口编程。Go 接口是一组方法的集合。任何类型，只要实现了该接口中的方法集，那么就属于这个类型，也称为实现了该接口。接口的作用，其实就是**为不同层级的模块提供一个定义好的中间层**。**这样，上游不再需要依赖下游的具体实现，充分地对上下游进行了解耦**。很多流行的 Go 设计模式，就是通过面向接口编程的思想来实现的。


我们看一个面向接口编程的例子。下面这段代码定义了一个Bird接口，Canary 和 Crow 类型均实现了Bird接口。

```go
package main

import "fmt"

// 定义了一个鸟类
type Bird interface {
  Fly()
  Type() string
}

// 鸟类：金丝雀
type Canary struct {
  Name string
}

func (c *Canary) Fly() {
  fmt.Printf("我是%s，用黄色的翅膀飞\n", c.Name)
}
func (c *Canary) Type() string {
  return c.Name
}

// 鸟类：乌鸦
type Crow struct {
  Name string
}

func (c *Crow) Fly() {
  fmt.Printf("我是%s，我用黑色的翅膀飞\n", c.Name)
}

func (c *Crow) Type() string {
  return c.Name
}

// 让鸟类飞一下
func LetItFly(bird Bird) {
  fmt.Printf("Let %s Fly!\n", bird.Type())
  bird.Fly()
}

func main() {
  LetItFly(&Canary{"金丝雀"})
  LetItFly(&Crow{"乌鸦"})
}
```
这段代码中，因为 Crow 和 Canary 都实现了 Bird 接口声明的 Fly、Type 方法，所以可以说 Crow、Canary 实现了 Bird 接口，属于 Bird 类型。在函数调用时，可以传入 Bird 类型，并在函数内部调用 Bird 接口提供的方法，以此来解耦 Bird 的具体实现。好了，我们总结下使用接口的好处吧：



代码扩展性更强了。例如，同样的 Bird，可以有不同的实现。在开发中用的更多的是，将数据库的 CURD 操作抽象成接口，从而可以实现同一份代码对接不同数据库的目的。可以解耦上下游的实现。例如，LetItFly 不用关注 Bird 是如何 Fly 的，只需要调用 Bird 提供的方法即可。提高了代码的可测性。因为接口可以解耦上下游实现，我们在单元测试需要依赖第三方系统 / 数据库的代码时，可以利用接口将具体实现解耦，实现 fake 类型。代码更健壮、更稳定了。例如，如果要更改 Fly 的方式，只需要更改相关类型的 Fly 方法即可，完全影响不到 LetItFly 函数。


所以，**我**建议**你，在 Go 项目开发中，一定要多思考，那些可能有多种实现的地方，要考虑使用接口。**


接下来，我们再来看下面向“对象”编程。面向对象编程（OOP）有很多优点，例如可以使我们的代码变得易维护、易扩展，并能提高开发效率等，所以一个高质量的 Go 应用在需要时，也应该采用面向对象的方法去编程。那什么叫“在需要时”呢？就是我们在开发代码时，**如果一个功能可以通过接近于日常生活和自然的思考方式来实现，这时候就应该考虑使用面向对象的编程方法。**

**Go 语言不支持面向对象编程，但是却可以通过一些语言级的特性来实现类似的效果**。面向对象编程中，有几个核心特性：**类、实例、抽象，封装、继承、多态、构造函数、析构函数、方法重载、this 指针**。在 Go 中可以通过以下几个方式来实现类似的效果：


类、抽象、封装通过结构体来实现。实例通过结构体变量来实现。继承通过组合来实现。这里解释下什么叫组合：一个结构体嵌到另一个结构体，称作组合。例如一个结构体包含了一个匿名结构体，就说这个结构体组合了该匿名结构体。多态通过接口来实现。


至于构造函数、析构函数、方法重载和 this 指针等，Go 为了保持语言的简洁性去掉了这些特性。Go 中面向对象编程方法，见下图：


![img](https://static001.geekbang.org/resource/image/27/b8/27c84757b1f4626e84535d994ca70eb8.png?wh=1872x606)

我们通过一个示例，来具体看下 Go 是如何实现面向对象编程中的类、抽象、封装、继承和多态的。代码如下：


```go
package main

import "fmt"

// 基类：Bird
type Bird struct {
  Type string
}

// 鸟的类别
func (bird *Bird) Class() string {
  return bird.Type
}

// 定义了一个鸟类
type Birds interface {
  Name() string
  Class() string
}

// 鸟类：金丝雀
type Canary struct {
  Bird
  name string
}

func (c *Canary) Name() string {
  return c.name
}

// 鸟类：乌鸦
type Crow struct {
  Bird
  name string
}

func (c *Crow) Name() string {
  return c.name
}

func NewCrow(name string) *Crow {
  return &Crow{
    Bird: Bird{
      Type: "Crow",
    },
    name: name,
  }
}

func NewCanary(name string) *Canary {
  return &Canary{
    Bird: Bird{
      Type: "Canary",
    },
    name: name,
  }
}

func BirdInfo(birds Birds) {
  fmt.Printf("I'm %s, I belong to %s bird class!\n", birds.Name(), birds.Class())
}

func main() {
    canary := NewCanary("CanaryA")
    crow := NewCrow("CrowA")
  BirdInfo(canary)
  BirdInfo(crow)
}
```
将上述代码保存在 oop.go 文件中，执行以下代码输出如下：

```go
$ go run oop.go
I'm CanaryA, I belong to Canary bird class!
I'm CrowA, I belong to Crow bird class!
```
在上面的例子中，分别通过 Canary 和 Crow 结构体定义了金丝雀和乌鸦两种类别的鸟，其中分别封装了 name 属性和 Name 方法。也就是说通过结构体实现了类，该类抽象了鸟类，并封装了该鸟类的属性和方法。

在 Canary 和 Crow 结构体中，都有一个 Bird 匿名字段，Bird 字段为 Canary 和 Crow 类的父类，Canary 和 Crow 继承了 Bird 类的 Class 属性和方法。也就是说通过匿名字段实现了继承。


在 main 函数中，通过 NewCanary 创建了 Canary 鸟类实例，并将其传给 BirdInfo 函数。也就是说通过结构体变量实现实例。


在 BirdInfo 函数中，将 Birds 接口类型作为参数传入，并在函数中调用了 birds.Name，birds.Class 方法，这两个方法会根据 birds 类别的不同而返回不同的名字和类别，也就是说通过接口实现了多态。


### 软件设计方法
接下来，我们继续学习编写高质量 Go 代码的第二项内功，也就是让编写的代码遵循一些业界沉淀下来的，优秀的软件设计方法。

优秀的软件设计方法有很多，其中有两类方法对我们代码质量的提升特别有帮助，分别是**设计模式（Design pattern）和 SOLID 原则**。在我看来，设计模式可以理解为业界针对一些特定的场景总结出来的最佳实现方式。它的特点是**解决的场景比较具体**，实施起来会比较简单；而 SOLID 原则**更侧重设计原则**，需要我们彻底理解，并在编写代码时多思考和落地。


关于设计模式和 SOLID 原则，我是这么安排的：在第 11 讲，我会带你学习 Go 项目常用的设计模式；至于 SOLID 原则，网上已经有很多高质量的文章了，所以我会简单告诉你这个原则是啥，然后给你**推荐**一篇介绍文章。


我们先了解下有哪些设计模式。在软件领域，沉淀了一些比较优秀的设计模式，其中最受欢迎的是 GOF 设计模式。GOF 设计模式中包含了 3 大类（创建型模式、结构型模式、行为型模式），共 25 种经典的、可以解决常见软件设计问题的设计方案。这 25 种设计方案同样也适用于 Go 语言开发的项目。


这里，我将这 25 种设计模式总结成了一张图，你可以先看看，有个大概的印象，对于一些在 Go 项目开发中常用的设计模式，我会在第 11 讲详细介绍。


![img](https://static001.geekbang.org/resource/image/14/9c/1440f4bbcda682c8f5e7a599c8c51f9c.png?wh=2963x1613)
如果说设计模式解决的是具体的场景，那么 SOLID 原则就是我们设计应用代码时的指导方针。SOLID 原则，是由罗伯特·C·马丁在 21 世纪早期引入的，包括了面向对象编程和面向对象设计的五个基本原则：


![img](https://static001.geekbang.org/resource/image/19/3b/19b697bbbe31450d6cc8f222491d3e3b.png?wh=1462x879)


遵循 SOLID 原则可以确保我们设计的代码是易维护、易扩展、易阅读的。SOLID 原则同样也适用于 Go 程序设计。如果你需要更详细地了解 SOLID 原则，可以参考下SOLID 原则介绍这篇文章。



到这里，我们就学完了“编写高质量的 Go 应用”这部分内容。接下来，我们再来学习下如何高效管理 Go 项目，以及如何编写高质量的项目文档。这里面的大部分内容，之前我们都有学习过，因为它们是“如何写出优雅的 Go 项目”的重要组成部分，所以，这里我仍然会简单介绍下它们。


### 高效管理项目
一个优雅的 Go 项目，还需要具备高效的项目管理特性。那么如何高效管理我们的项目呢？

不同团队、不同项目会采用不同的方法来管理项目，在我看来比较重要的有 3 点，分别是制定一个高效的开发流程、使用 Makefile 管理项目和将项目管理自动化。我们可以通过自动生成代码、借助工具、对接 CI/CD 系统等方法来将项目管理自动化。具体见下图：


![img](https://static001.geekbang.org/resource/image/61/6d/61e022c1b25dab2b0fefb407fc1c776d.png?wh=2356x766)

#### 高效的开发流程
高效管理项目的第一步，就是要有一个高效的开发流程，这可以提高开发效率、减少软件维护成本。你可以回想一下设计开发流程的知识，如果印象比较模糊了，一定要回去复习下 08 讲的内容，因为这部分很重要 。


#### 使用 Makefile 管理项目
为了更好地管理项目，除了一个高效的开发流程之外，使用 Makefile 也很重要。Makefile 可以将项目管理的工作通过 Makefile 依赖的方式实现自动化，除了可以提高管理效率之外，还能够减少人为操作带来的失误，并统一操作方式，使项目更加规范。


IAM 项目的所有操作均是通过 Makefile 来完成的，具体 Makefile 完成了如下操作：


```
 build              Build source code for host platform.
  build.multiarch    Build source code for multiple platforms. See option PLATFORMS.
  image              Build docker images for host arch.
  image.multiarch    Build docker images for multiple platforms. See option PLATFORMS.
  push               Build docker images for host arch and push images to registry.
  push.multiarch     Build docker images for multiple platforms and push images to registry.
  deploy             Deploy updated components to development env.
  clean              Remove all files that are created by building.
  lint               Check syntax and styling of go sources.
  test               Run unit test.
  cover              Run unit test and get test coverage.
  release            Release iam
  format             Gofmt (reformat) package sources (exclude vendor dir if existed).
  verify-copyright   Verify the boilerplate headers for all files.
  add-copyright      Ensures source code files have copyright license headers.
  gen                Generate all necessary files, such as error code files.
  ca                 Generate CA files for all iam components.
  install            Install iam system with all its components.
  swagger            Generate swagger document.
  serve-swagger      Serve swagger spec and docs.
  dependencies       Install necessary dependencies.
  tools              install dependent tools.
  check-updates      Check outdated dependencies of the go projects.
  help               Show this help info.
```
#### 自动生成代码
低代码的理念现在越来越流行。虽然低代码有很多缺点，但确实有很多优点，例如：自动化生成代码，减少工作量，提高工作效率。代码有既定的生成规则，相比人工编写代码，准确性更高、更规范。

目前来看，自动生成代码现在已经成为趋势，比如 Kubernetes 项目有很多代码都是自动生成的。我认为，想写出一个优雅的 Go 项目，你也应该认真思考哪些地方的代码可以自动生成。在这门课的 IAM 项目中，就有大量的代码是自动生成的，我放在这里供你参考：

错误码、错误码说明文档。自动生成缺失的 doc.go 文件。利用 gotests 工具，自动生成单元测试用例。使用 Swagger 工具，自动生成 Swagger 文档。使用 Mock 工具，自动生成接口的 Mock 实例。



#### 善于借助工具
在开发 Go 项目的过程中，我们也要善于借助工具，来帮助我们完成一部分工作。利用工具可以带来很多好处：


解放双手，提高工作效率。利用工具的确定性，可以确保执行结果的一致性。例如，使用 golangci-lint 对代码进行检查，可以确保不同开发者开发的代码至少都遵循 golangci-lint 的代码检查规范。有利于实现自动化，可以将工具集成到 CI/CD 流程中，触发流水线自动执行。



那么，Go 项目中，有哪些工具可以为我们所用呢？这里，我给你整理了一些有用的工具：


![img](https://static001.geekbang.org/resource/image/90/80/90ca527c2863fe642f9ab3d5b90fe980.png?wh=1645x1477)
所有这些工具都可以通过下面的方式安装。


```
$ cd $IAM_ROOT
$ make tools.install
```
IAM 项目使用了上面这些工具的绝大部分，用来尽可能提高整个项目的自动化程度，提高项目维护效率。


#### 对接 CI/CD
代码在合并入主干时，应该有一套 CI/CD 流程来自动化地对代码进行检查、编译、单元测试等，只有通过后的代码才可以并入主干。通过 CI/CD 流程来保证代码的质量。当前比较流行的 CI/CD 工具有 Jenkins、GitLab、Argo、Github Actions、JenkinsX 等。在第 51 讲 和 第 52 讲中，我会详细介绍 CI/CD 的原理和实战。



### 编写高质量的项目文档
最后，一个优雅的项目，还应该有完善的文档。例如 README.md、安装文档、开发文档、使用文档、API 接口文档、设计文档等等。这些内容在第 04 讲的文档规范部分有详细介绍，你可以去复习下。

### 总结
使用 Go 语言做项目开发，核心目的其实就是开发一个优雅的 Go 项目。那么如何开发一个优雅的 Go 项目呢？Go 项目包含三大内容，即 Go 应用、项目管理、项目文档，因此开发一个优雅的 Go 项目，其实就是编写高质量的 Go 应用、高效管理项目和编写高质量的项目文档。针对每一项，我都给出了一些实现方式，这些方式详见下图：

![img](https://static001.geekbang.org/resource/image/b0/cc/b051da025c897996473df44693ea4ecc.png?wh=3619x2006)


## 11 | 设计模式：Go常用设计模式概述
在软件开发中，经常会遇到各种各样的编码场景，这些场景往往重复发生，因此具有典型性。针对这些典型场景，我们可以自己编码解决，也可以采取更为省时省力的方式：直接采用设计模式。

设计模式是啥呢？简单来说，就是将软件开发中需要重复性解决的编码场景，按最佳实践的方式抽象成一个模型，模型描述的解决方法就是设计模式。使用设计模式，可以使代码更易于理解，保证代码的重用性和可靠性。


在软件领域，GoF（四人帮，全拼 Gang of Four）首次系统化提出了 3 大类、共 25 种可复用的经典设计方案，来解决常见的软件设计问题，为可复用软件设计奠定了一定的理论基础。从总体上说，这些设计模式可以分为创建型模式、结构型模式、行为型模式 3 大类，用来完成不同的场景。这一讲，我会介绍几个在 Go 项目开发中比较常用的设计模式，帮助你用更加简单快捷的方法应对不同的编码场景。其中，简单工厂模式、抽象工厂模式和工厂方法模式都属于工厂模式，我会把它们放在一起讲解。


![img](https://static001.geekbang.org/resource/image/98/20/98fb0ecb8ba65bc83f25bb2504e51d20.png?wh=3142x1613)

### 创建型模式
首先来看创建型模式（Creational Patterns），它提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这种类型的设计模式里，单例模式和工厂模式（具体包括简单工厂模式、抽象工厂模式和工厂方法模式三种）在 Go 项目开发中比较常用。我们先来看单例模式。


#### 单例模式
单例模式（Singleton Pattern），是最简单的一个模式。在 Go 中，单例模式指的是全局只有一个实例，并且它负责创建自己的对象。单例模式不仅有利于减少内存开支，还有减少系统性能开销、防止多个实例产生冲突等优点。因为单例模式保证了实例的全局唯一性，而且只被初始化一次，所以比较适合全局共享一个实例，且只需要被初始化一次的场景，例如数据库实例、全局配置、全局任务池等。单例模式又分为饿汉方式和懒汉方式。饿汉方式指全局的单例实例在包被加载时创建，而懒汉方式指全局的单例实例在第一次被使用时创建。你可以看到，这种命名方式非常形象地体现了它们不同的特点。


接下来，我就来分别介绍下这两种方式。先来看饿汉方式。下面是一个饿汉方式的单例模式代码：


```go
package singleton

type singleton struct {
}

var ins *singleton = &singleton{}

func GetInsOr() *singleton {
    return ins
}
```
你需要**注意**，**因为实例是在包被导入时初始化的，所以如果初始化耗时，会导致程序加载时间比较长。懒汉方式是开源项目中使用最多的，但它的缺点是非并发安全，在实际使用时需要加锁**。以下是懒汉方式不加锁的一个实现：


```go
package singleton

type singleton struct {
}

var ins *singleton

func GetInsOr() *singleton {
    if ins == nil {
        ins = &singleton{}
    }
    
    return ins
}
```
可以看到，在创建 ins 时，如果 ins==nil，就会再创建一个 ins 实例，这时候单例就会有多个实例。为了解决懒汉方式非并发安全的问题，需要对实例进行加锁，**下面是带检查锁的一个实现**：


```go
import "sync"

type singleton struct {
}

var ins *singleton
var mu sync.Mutex

func GetIns() *singleton {
  if ins == nil {
    mu.Lock()
    if ins == nil {
      ins = &singleton{}
    }
    mu.Unlock()
  }
  return ins
}
```
上述代码只有在创建时才会加锁，既提高了代码效率，又保证了并发安全。除了饿汉方式和懒汉方式，在 Go 开发中，还有一种更优雅的实现方式，我**建议**你采用这种方式，代码如下：



```go
package singleton

import (
    "sync"
)

type singleton struct {
}

var ins *singleton
var once sync.Once

func GetInsOr() *singleton {
    once.Do(func() {
        ins = &singleton{}
    })
    return ins
}
```
使用once.Do可以确保 ins 实例全局只被创建一次，once.Do 函数还可以确保当同时有多个创建动作时，只有一个创建动作在被执行。另外，IAM 应用中大量使用了单例模式，如果你想了解更多单例模式的使用方式，可以直接查看 IAM 项目代码。IAM 中单例模式有 GetStoreInsOr、GetEtcdFactoryOr、GetMySQLFactoryOr、GetCacheInsOr等。



#### 工厂模式
工厂模式（Factory Pattern）是面向对象编程中的常用模式。在 Go 项目开发中，你可以通过使用多种不同的工厂模式，来使代码更简洁明了。Go 中的结构体，可以理解为面向对象编程中的类，例如 Person 结构体（类）实现了 Greet 方法。


```go
type Person struct {
  Name string
  Age int
}

func (p Person) Greet() {
  fmt.Printf("Hi! My name is %s", p.Name)
}
```
有了 Person“类”，就可以创建 Person 实例。我们可以通过简单工厂模式、抽象工厂模式、工厂方法模式这三种方式，来创建一个 Person 实例。这三种工厂模式中，简单工厂模式是最常用、最简单的。它就是一个接受一些参数，然后返回 Person 实例的函数：


```go
type Person struct {
  Name string
  Age int
}

func (p Person) Greet() {
  fmt.Printf("Hi! My name is %s", p.Name)
}

func NewPerson(name string, age int) *Person {
  return &Person{
    Name: name,
    Age: age,
  }
}
```
**和p：=＆Person {}这种创建实例的方式相比，简单工厂模式可以确保我们创建的实例具有需要的参数，进而保证实例的方法可以按预期执行**。例如，通过NewPerson创建 Person 实例时，可以确保实例的 name 和 age 属性被设置。再来看**抽象工厂模式，它和简单工厂模式的唯一区别，就是它返回的是接口而不是结构体**。通过返回接口，**可以在你不公开内部实现的情况下，让调用者使用你提供的各种功能**，例如：


```go
type Person interface {
  Greet()
}

type person struct {
  name string
  age int
}

func (p person) Greet() {
  fmt.Printf("Hi! My name is %s", p.name)
}

// Here, NewPerson returns an interface, and not the person struct itself
func NewPerson(name string, age int) Person {
  return person{
    name: name,
    age: age,
  }
}
```
上面这个代码，定义了一个不可导出的结构体person，在通过 NewPerson 创建实例的时候返回的是接口，而不是结构体。通过返回接口，我们还可以实现多个工厂函数，来返回不同的接口实现，例如：


```go
// We define a Doer interface, that has the method signature
// of the `http.Client` structs `Do` method
type Doer interface {
  Do(req *http.Request) (*http.Response, error)
}

// This gives us a regular HTTP client from the `net/http` package
func NewHTTPClient() Doer {
  return &http.Client{}
}

type mockHTTPClient struct{}

func (*mockHTTPClient) Do(req *http.Request) (*http.Response, error) {
  // The `NewRecorder` method of the httptest package gives us
  // a new mock request generator
  res := httptest.NewRecorder()

  // calling the `Result` method gives us
  // the default empty *http.Response object
  return res.Result(), nil
}

// This gives us a mock HTTP client, which returns
// an empty response for any request sent to it
func NewMockHTTPClient() Doer {
  return &mockHTTPClient{}
}
```
NewHTTPClient和NewMockHTTPClient都返回了同一个接口类型 Doer，这使得二者可以互换使用。当你想测试一段调用了 Doer 接口 Do 方法的代码时，这一点特别有用。因为你可以使用一个 Mock 的 HTTP 客户端，从而避免了调用真实外部接口可能带来的失败。来看个例子，假设我们想测试下面这段代码：


```go
func QueryUser(doer Doer) error {
  req, err := http.NewRequest("Get", "http://iam.api.marmotedu.com:8080/v1/secrets", nil)
  if err != nil {
    return err
  }

  _, err := doer.Do(req)
  if err != nil {
    return err
  }

  return nil
}
```
其测试用例为：


```go
func TestQueryUser(t *testing.T) {
  doer := NewMockHTTPClient()
  if err := QueryUser(doer); err != nil {
    t.Errorf("QueryUser failed, err: %v", err)
  }
}
```
另外，在使用简单工厂模式和抽象工厂模式返回实例对象时，都可以返回指针。例如，简单工厂模式可以这样返回实例对象：


```go
return &Person{
  Name: name,
  Age: age
}
```
抽象工厂模式可以这样返回实例对象：



```go
return &person{
  name: name,
  age: age
}
```
在实际开发中，我**建议**返回非指针的实例，因为我们主要是想通过创建实例，调用其提供的方法，而不是对实例做更改。如果需要对实例做更改，可以实现SetXXX的方法。通过返回非指针的实例，可以确保实例的属性，避免属性被意外 / 任意修改。

**在简单工厂模式中，依赖于唯一的工厂对象，如果我们需要实例化一个产品，就要向工厂中传入一个参数，获取对应的对象；如果要增加一种产品，就要在工厂中修改创建产品的函数。这会导致耦合性过高，这时我们就可以使用工厂方法模式。**



在工厂方法模式中，依赖工厂函数，我们可以通过实现工厂函数来创建多种工厂，将对象创建从由一个对象负责所有具体类的实例化，变成由一群子类来负责对具体类的实例化，从而将过程解耦。下面是工厂方法模式的一个代码实现：



```go
type Person struct {
  name string
  age int
}

func NewPersonFactory(age int) func(name string) Person {
  return func(name string) Person {
    return Person{
      name: name,
      age: age,
    }
  }
}
```
然后，我们可以使用此功能来创建具有默认年龄的工厂：


```go
newBaby := NewPersonFactory(1)
baby := newBaby("john")

newTeenager := NewPersonFactory(16)
teen := newTeenager("jill")
```
### 结构型模式
我已经向你介绍了单例模式、工厂模式这两种创建型模式，接下来我们来看结构型模式（Structural Patterns），它的特点是**关注类和对象的组合**。这一类型里，我想详细讲讲策略模式和模板模式。


#### 策略模式
策略模式（Strategy Pattern）定义一组算法，将每个算法都封装起来，并且使它们之间可以互换。


在什么时候，我们需要用到策略模式呢？在项目开发中，我们经常要根据不同的场景，采取不同的措施，也就是不同的策略。比如，假设我们需要对 a、b 这两个整数进行计算，根据条件的不同，需要执行不同的计算方式。**我们可以把所有的操作都封装在同一个函数中，然后通过 if ... else ... 的形式来调用不同的计算方式**，这种方式称之为**硬编码**。


在实际应用中，随着功能和体验的不断增长，我们需要经常添加 / 修改策略，这样就需要不断修改已有代码，不仅会让这个函数越来越难维护，还可能因为修改带来一些 bug。所以为了解耦，需要使用策略模式，定义一些独立的类来封装不同的算法，每一个类封装一个具体的算法（即策略）。下面是一个实现策略模式的代码：


```go
package strategy

// 策略模式

// 定义一个策略类
type IStrategy interface {
  do(int, int) int
}

// 策略实现：加
type add struct{}

func (*add) do(a, b int) int {
  return a + b
}

// 策略实现：减
type reduce struct{}

func (*reduce) do(a, b int) int {
  return a - b
}

// 具体策略的执行者
type Operator struct {
  strategy IStrategy
}

// 设置策略
func (operator *Operator) setStrategy(strategy IStrategy) {
  operator.strategy = strategy
}

// 调用策略中的方法
func (operator *Operator) calculate(a, b int) int {
  return operator.strategy.do(a, b)
}
```
在上述代码中，我们定义了策略接口 IStrategy，还定义了 add 和 reduce 两种策略。最后定义了一个策略执行者，可以设置不同的策略，并执行，例如：



```go
func TestStrategy(t *testing.T) {
  operator := Operator{}

  operator.setStrategy(&add{})
  result := operator.calculate(1, 2)
  fmt.Println("add:", result)

  operator.setStrategy(&reduce{})
  result = operator.calculate(2, 1)
  fmt.Println("reduce:", result)
}
```
可以看到，我们可以随意更换策略，而不影响 Operator 的所有实现。



#### 模版模式
模版模式 (Template Pattern) 定义一个操作中算法的骨架，而将一些步骤延迟到子类中。这种方法让子类在不改变一个算法结构的情况下，就能重新定义该算法的某些特定步骤。


简单来说，模板模式就是将一个类中能够公共使用的方法放置在抽象类中实现，将不能公共使用的方法作为抽象方法，强制子类去实现，这样就做到了将一个类作为一个模板，让开发者去填充需要填充的地方。以下是模板模式的一个实现：



```go
package template

import "fmt"

type Cooker interface {
  fire()
  cooke()
  outfire()
}

// 类似于一个抽象类
type CookMenu struct {
}

func (CookMenu) fire() {
  fmt.Println("开火")
}

// 做菜，交给具体的子类实现
func (CookMenu) cooke() {
}

func (CookMenu) outfire() {
  fmt.Println("关火")
}

// 封装具体步骤
func doCook(cook Cooker) {
  cook.fire()
  cook.cooke()
  cook.outfire()
}

type XiHongShi struct {
  CookMenu
}

func (*XiHongShi) cooke() {
  fmt.Println("做西红柿")
}

type ChaoJiDan struct {
  CookMenu
}

func (ChaoJiDan) cooke() {
  fmt.Println("做炒鸡蛋")
}
```
这里来看下测试用例：


```go
func TestTemplate(t *testing.T) {
  // 做西红柿
  xihongshi := &XiHongShi{}
  doCook(xihongshi)

  fmt.Println("\n=====> 做另外一道菜")
  // 做炒鸡蛋
  chaojidan := &ChaoJiDan{}
  doCook(chaojidan)

}

```
### 行为型模式
然后，让我们来看最后一个类别，行为型模式（Behavioral Patterns），它的特点是关注对象之间的通信。这一类别的设计模式中，我们会讲到代理模式和选项模式。



#### 代理模式
代理模式 (Proxy Pattern)，可以为另一个对象提供一个替身或者占位符，以控制对这个对象的访问。以下代码是一个代理模式的实现：


```go
package proxy

import "fmt"

type Seller interface {
  sell(name string)
}

// 火车站
type Station struct {
  stock int //库存
}

func (station *Station) sell(name string) {
  if station.stock > 0 {
    station.stock--
    fmt.Printf("代理点中：%s买了一张票,剩余：%d \n", name, station.stock)
  } else {
    fmt.Println("票已售空")
  }

}

// 火车代理点
type StationProxy struct {
  station *Station // 持有一个火车站对象
}

func (proxy *StationProxy) sell(name string) {
  if proxy.station.stock > 0 {
    proxy.station.stock--
    fmt.Printf("代理点中：%s买了一张票,剩余：%d \n", name, proxy.station.stock)
  } else {
    fmt.Println("票已售空")
  }
}
```
上述代码中，StationProxy 代理了 Station，代理类中持有被代理类对象，并且和被代理类对象实现了同一接口。


#### 选项模式
选项模式（Options Pattern）也是 Go 项目开发中经常使用到的模式，例如，grpc/grpc-go 的NewServer函数，uber-go/zap 包的New函数都用到了选项模式。使用选项模式，我们可以创建一个带有默认值的 struct 变量，并选择性地修改其中一些参数的值。


在 Python 语言中，创建一个对象时，可以给参数设置默认值，这样在不传入任何参数时，可以返回携带默认值的对象，并在需要时修改对象的属性。这种特性可以大大简化开发者创建一个对象的成本，尤其是在对象拥有众多属性时。


而在 Go 语言中，因为不支持给参数设置默认值，为了既能够创建带默认值的实例，又能够创建自定义参数的实例，不少开发者会通过以下两种方法来实现：

第一种方法，我们要分别开发两个用来创建实例的函数，一个可以创建带默认值的实例，一个可以定制化创建实例。



```go
package options

import (
  "time"
)

const (
  defaultTimeout = 10
  defaultCaching = false
)

type Connection struct {
  addr    string
  cache   bool
  timeout time.Duration
}

// NewConnect creates a connection.
func NewConnect(addr string) (*Connection, error) {
  return &Connection{
    addr:    addr,
    cache:   defaultCaching,
    timeout: defaultTimeout,
  }, nil
}

// NewConnectWithOptions creates a connection with options.
func NewConnectWithOptions(addr string, cache bool, timeout time.Duration) (*Connection, error) {
  return &Connection{
    addr:    addr,
    cache:   cache,
    timeout: timeout,
  }, nil
}
```
使用这种方式，创建同一个 Connection 实例，却要实现两个不同的函数，实现方式很不优雅。另外一种方法相对优雅些。我们需要创建一个带默认值的选项，并用该选项创建实例：


```go
package options

import (
  "time"
)

const (
  defaultTimeout = 10
  defaultCaching = false
)

type Connection struct {
  addr    string
  cache   bool
  timeout time.Duration
}

type ConnectionOptions struct {
  Caching bool
  Timeout time.Duration
}

func NewDefaultOptions() *ConnectionOptions {
  return &ConnectionOptions{
    Caching: defaultCaching,
    Timeout: defaultTimeout,
  }
}

// NewConnect creates a connection with options.
func NewConnect(addr string, opts *ConnectionOptions) (*Connection, error) {
  return &Connection{
    addr:    addr,
    cache:   opts.Caching,
    timeout: opts.Timeout,
  }, nil
}

```
使用这种方式，虽然只需要实现一个函数来创建实例，但是也有缺点：为了创建 Connection 实例，每次我们都要创建 ConnectionOptions，操作起来比较麻烦。那么有没有更优雅的解决方法呢？答案当然是有的，就是使用选项模式来创建实例。以下代码通过选项模式实现上述功能：



```go
package options

import (
  "time"
)

type Connection struct {
  addr    string
  cache   bool
  timeout time.Duration
}

const (
  defaultTimeout = 10
  defaultCaching = false
)

type options struct {
  timeout time.Duration
  caching bool
}

// Option overrides behavior of Connect.
type Option interface {
  apply(*options)
}

type optionFunc func(*options)

func (f optionFunc) apply(o *options) {
  f(o)
}

func WithTimeout(t time.Duration) Option {
  return optionFunc(func(o *options) {
    o.timeout = t
  })
}

func WithCaching(cache bool) Option {
  return optionFunc(func(o *options) {
    o.caching = cache
  })
}

// Connect creates a connection.
func NewConnect(addr string, opts ...Option) (*Connection, error) {
  options := options{
    timeout: defaultTimeout,
    caching: defaultCaching,
  }

  for _, o := range opts {
    o.apply(&options)
  }

  return &Connection{
    addr:    addr,
    cache:   options.caching,
    timeout: options.timeout,
  }, nil
}
```
在上面的代码中，首先我们定义了options结构体，它携带了 timeout、caching 两个属性。接下来，我们通过NewConnect创建了一个连接，NewConnect函数中先创建了一个带有默认值的options结构体变量，并通过调用


```go
for _, o := range opts {
    o.apply(&options)
}
```
来修改所创建的options结构体变量。


需要修改的属性，是在NewConnect时，通过 Option 类型的选项参数传递进来的。可以通过WithXXX函数来创建 Option 类型的选项参数：WithTimeout、WithCaching。Option 类型的选项参数需要实现apply(*options)函数，结合 WithTimeout、WithCaching 函数的返回值和 optionFunc 的 apply 方法实现，可以知道o.apply(&options)其实就是把 WithTimeout、WithCaching 传入的参数赋值给 options 结构体变量，以此动态地设置 options 结构体变量的属性。


这里还有一个好处：我们可以在 apply 函数中自定义赋值逻辑，例如o.timeout = 100 * t。通过这种方式，我们会有更大的灵活性来设置结构体的属性。选项模式有很多优点，例如：支持传递多个参数，并且在参数发生变化时保持兼容性；支持任意顺序传递参数；支持默认值；方便扩展；通过 WithXXX 的函数命名，可以使参数意义更加明确，等等。


不过，为了实现选项模式，我们增加了很多代码，所以在开发中，要根据实际场景选择是否使用选项模式。选项模式通常适用于以下场景：


结构体参数很多，创建结构体时，我们期望创建一个携带默认值的结构体变量，并选择性修改其中一些参数的值。结构体参数经常变动，变动时我们又不想修改创建实例的函数。例如：结构体新增一个 retry 参数，但是又不想在 NewConnect 入参列表中添加retry int这样的参数声明。


如果结构体参数比较少，可以慎重考虑要不要采用选项模式。


### 总结
设计模式，是业界沉淀下来的针对特定场景的最佳解决方案。在软件领域，GoF 首次系统化提出了 3 大类设计模式：创建型模式、结构型模式、行为型模式。这一讲，我介绍了 Go 项目开发中 6 种常用的设计模式。每种设计模式解决某一类场景，我给你总结成了一张表格，你可以根据自己的需要进行选择。


![img](https://static001.geekbang.org/resource/image/1e/01/1e32f9d8318c8968b50e9ea7e89bbe01.png?wh=1455x1015)


## 基础功能

## 12 | API 风格（上）：如何设计RESTful API？

绝大部分的 Go 后端服务需要编写 API 接口，对外提供服务。所以在开发之前，我们需要确定一种 API 风格。API 风格也可以理解为 API 类型，目前业界常用的 API 风格有三种：REST、RPC 和 GraphQL。我们需要根据项目需求，并结合 API 风格的特点，确定使用哪种 API 风格，这对以后的编码实现、通信方式和通信效率都有很大的影响。

在 Go 项目开发中，用得最多的是 REST 和 RPC，我们在 IAM 实战项目中也使用了 REST 和 RPC 来构建示例项目。接下来的两讲，我会详细介绍下 REST 和 RPC 这两种风格，如果你对 GraphQL 感兴趣，GraphQL 中文官网有很多文档和代码示例，你可以自行学习。


### RESTful API 介绍


在回答“RESTful API 是什么”之前，我们先来看下 REST 是什么意思：REST 代表的是表现层状态转移（REpresentational State Transfer），由 Roy Fielding 在他的论文《Architectural Styles and the Design of Network-based Software Architectures》里提出。REST 本身并没有创造新的技术、组件或服务，它只是一种软件架构风格，是一组架构约束条件和原则，而不是技术框架。

REST 有一系列规范，满足这些规范的 API 均可称为 RESTful API。**REST 规范把所有内容都视为资源，也就是说网络上一切皆资源**。REST 架构对资源的操作包括获取、创建、修改和删除，这些操作正好对应 HTTP 协议提供的 GET、POST、PUT 和 DELETE 方法。HTTP 动词与 REST 风格 CRUD 的对应关系见下表：![img](https://static001.geekbang.org/resource/image/40/92/409164157ce4cde3131f0236d660e092.png?wh=1754x582)

REST 风格虽然适用于很多传输协议，但在实际开发中，由于 REST 天生和 HTTP 协议相辅相成，因此 HTTP 协议已经成了实现 RESTful API 事实上的标准。所以，REST 具有以下核心特点：
- 以资源 (resource) 为中心，所有的东西都抽象成资源，所有的行为都应该是在资源上的 CRUD 操作。
    - 资源对应着面向对象范式里的对象，面向对象范式以对象为中心。
    - 资源使用 URI 标识，每个资源实例都有一个唯一的 URI 标识。例如，如果我们有一个用户，用户名是 admin，那么它的 URI 标识就可以是 /users/admin。
- 资源是有状态的，使用 JSON/XML 等在 HTTP Body 里表征资源的状态。
- 客户端通过四个 HTTP 动词，对服务器端资源进行操作，实现“表现层状态转化”。
- 无状态，这里的无状态是指每个 RESTful API 请求都包含了所有足够完成本次操作的信息，服务器端无须保持 session。无状态对于服务端的弹性扩容是很重要的。

因为怕你弄混概念，这里强调下 REST 和 RESTful API 的区别：REST 是一种规范，而 RESTful API 则是满足这种规范的 API 接口。

### RESTful API 设计原则
上面我们说了，RESTful API 就是满足 REST 规范的 API，由此看来，RESTful API 的核心是规范，那么具体有哪些规范呢？

接下来，我就从 URI 设计、API 版本管理等七个方面，给你详细介绍下 RESTful API 的设计原则，然后再通过一个示例来帮助你快速启动一个 RESTful API 服务。希望你学完这一讲之后，对如何设计 RESTful API 有一个清楚的认知。

#### URI 设计
资源都是使用 URI 标识的，我们应该按照一定的规范来设计 URI，通过规范化可以使我们的 API 接口更加易读、易用。以下是 URI 设计时，应该遵循的一些规范：
- **资源名使用名词而不是动词，并且用名词复数表示。资源分为 Collection 和 Member 两种。**
    - Collection：一堆资源的集合。例如我们系统里有很多用户（User）, 这些用户的集合就是 Collection。Collection 的 URI 标识应该是 域名/资源名复数, 例如https:// iam.api.marmotedu.com/users。
    - Member：单个特定资源。例如系统中特定名字的用户，就是 Collection 里的一个 Member。Member 的 URI 标识应该是 域名/资源名复数/资源名称, 例如https:// iam.api.marmotedu/users/admin。
- URI 结尾不应包含/。
- URI 中不能出现下划线 _，必须用中杠线 -代替（有些人**推荐**用 _，有些人**推荐**用 -，统一使用一种格式即可，我比较**推荐**用 -）。
- URI 路径用小写，不要用大写。
- **避免层级过深的 URI。超过 2 层的资源嵌套会很乱，建议将其他资源转化为?参数，比如：**

```
/schools/tsinghua/classes/rooma/students/zhang # 不**推荐**
/students?school=qinghua&class=rooma # **推荐**
```
这里有个地方需要**注意**：在实际的 API 开发中，可能你会发现有些操作不能很好地映射为一个 REST 资源，这时候，你可以参考下面的做法。
- 将一个操作变成资源的一个属性，比如想在系统中暂时禁用某个用户，可以这么设计 URI：/users/zhangsan?active=false。
- 将操作当作是一个资源的嵌套资源，比如一个 GitHub 的加星操作：
```
PUT /gists/:id/star # github star action
DELETE /gists/:id/star # github unstar action
```
- 如果以上都不能解决问题，有时可以打破这类规范。比如登录操作，登录不属于任何一个资源，URI 可以设计为：/login。

在设计 URI 时，如果你遇到一些不确定的地方，**推荐**你参考 GitHub 标准 RESTful API。

#### REST 资源操作映射为 HTTP 方法
基本上 RESTful API 都是使用 HTTP 协议原生的 GET、PUT、POST、DELETE 来标识对资源的 CRUD 操作的，形成的规范如下表所示：![img](https://static001.geekbang.org/resource/image/d9/2d/d970bcd53d2827b7f2096e639d5fa82d.png?wh=1524x698)

对资源的操作应该满足安全性和幂等性：
- 安全性：不会改变资源状态，可以理解为只读的。
- 幂等性：执行 1 次和执行 N 次，对资源状态改变的效果是等价的。

使用不同 HTTP 方法时，资源操作的安全性和幂等性对照见下表：![img](https://static001.geekbang.org/resource/image/b7/e1/b746421291654e4d2e51509b885c4ee1.png?wh=1434x448)

在使用 HTTP 方法的时候，有以下两点需要你**注意**：
- GET 返回的结果，要尽量可用于 PUT、POST 操作中。例如，用 GET 方法获得了一个 user 的信息，调用者修改 user 的邮件，然后将此结果再用 PUT 方法更新。这要求 GET、PUT、POST 操作的资源属性是一致的。
- 如果对资源进行状态 / 属性变更，要用 PUT 方法，POST 方法仅用来创建或者批量删除这两种场景。

**在设计 API 时，经常会有批量删除的需求，需要在请求中携带多个需要删除的资源名，但是 HTTP 的 DELETE 方法不能携带多个资源名，这时候可以通过下面三种方式来解决：**

- 发起多个 DELETE 请求。
- 操作路径中带多个 id，id 之间用分隔符分隔, 例如：DELETE /users?ids=1,2,3 。
- 直接使用 POST 方式来批量删除，body 中传入需要删除的资源列表。

其中，**第二种是我最推荐的方式**，因为使用了匹配的 DELETE 动词，并且不需要发送多次 DELETE 请求。

你需要**注意**的是，这三种方式都有各自的使用场景，你可以根据需要自行选择。如果选择了某一种方式，那么整个项目都需要统一用这种方式。
#### 统一的返回格式
一般来说，一个系统的 RESTful API 会向外界开放多个资源的接口，每个接口的返回格式要保持一致。另外，每个接口都会返回成功和失败两种消息，这两种消息的格式也要保持一致。不然，客户端代码要适配不同接口的返回格式，每个返回格式又要适配成功和失败两种消息格式，会大大增加用户的学习和使用成本。

返回的格式没有强制的标准，你可以根据实际的业务需要返回不同的格式。本专栏 第 19 讲 中会**推荐**一种返回格式，它也是业界最常用和**推荐**的返回格式。

#### API 版本管理
随着时间的推移、需求的变更，一个 API 往往满足不了现有的需求，这时候就需要对 API 进行修改。对 API 进行修改时，不能影响其他调用系统的正常使用，这就要求 API 变更做到向下兼容，也就是新老版本共存。

**但在实际场景中，很可能会出现同一个 API 无法向下兼容的情况。这时候最好的解决办法是从一开始就引入 API 版本机制，当不能向下兼容时，就引入一个新的版本，老的版本则保留原样。**这样既能保证服务的可用性和安全性，同时也能满足新需求。

API 版本有不同的标识方法，在 RESTful API 开发中，通常将版本标识放在如下 3 个位置：
- URL 中，比如/v1/users。
- HTTP Header 中，比如Accept: vnd.example-com.foo+json; version=1.0。
- Form 参数中，比如/users?version=v1。

**我们这门课中的版本标识是放在 URL 中的，比如/v1/users，这样做的好处是很直观，GitHub、Kubernetes、Etcd 等很多优秀的 API 均采用这种方式。**

这里要**注意**，有些开发人员不**建议**将版本放在 URL 中，因为他们觉得不同的版本可以理解成同一种资源的不同表现形式，所以应该采用同一个 URI。对于这一点，没有严格的标准，根据项目实际需要选择一种方式即可。

#### API 命名
API 通常的命名方式有三种，分别是驼峰命名法 (serverAddress)、蛇形命名法 (server_address) 和脊柱命名法 (server-address)。

驼峰命名法和蛇形命名法都需要切换输入法，会增加操作的复杂性，也容易出错，所以这里**建议**用脊柱命名法。GitHub API 用的就是脊柱命名法，例如 selected-actions。

#### 统一分页 / 过滤 / 排序 / 搜索功能

**REST 资源的查询接口，通常情况下都需要实现分页、过滤、排序、搜索功能**，因为这些功能是每个 REST 资源都能用到的，所以可以实现为一个公共的 API 组件。下面来介绍下这些功能。

- 分页：在列出一个 Collection 下所有的 Member 时，应该提供分页功能，**例如/users?offset=0&limit=20（limit，指定返回记录的数量；offset，指定返回记录的开始位置**）。引入分页功能可以减少 API 响应的延时，同时可以避免返回太多条目，导致服务器 / 客户端响应特别慢，甚至导致服务器 / 客户端 crash 的情况。
- 过滤：如果用户不需要一个资源的全部状态属性，可以在 URI 参数里指定返回哪些属性，例如/users?fields=email,username,address。
- 排序：用户很多时候会根据创建时间或者其他因素，列出一个 Collection 中前 100 个 Member，这时可以在 URI 参数中指明排序参数，例如/users?sort=age,desc。
- 搜索：当一个资源的 Member 太多时，用户可能想通过搜索，快速找到所需要的 Member，或着想搜下有没有名字为 xxx 的某类资源，这时候就需要提供搜索功能。搜索**建议**按**模糊匹配**来搜索。



#### 域名
API 的域名设置主要有两种方式：
- https://marmotedu.com/api，这种方式适合 API 将来不会有进一步扩展的情况，比如刚开始 marmotedu.com 域名下只有一套 API 系统，未来也只有这一套 API 系统。
- https://iam.api.marmotedu.com，如果 marmotedu.com 域名下未来会新增另一个系统 API，这时候最好的方式是每个系统的 API 拥有专有的 API 域名，**比如：storage.api.marmotedu.com，network.api.marmotedu.com。腾讯云的域名就是采用这种方式**。

到这里，我们就将 REST 设计原则中的核心原则讲完了，这里有个需要**注意**的点：不同公司、不同团队、不同项目可能采取不同的 REST 设计原则，以上所列的基本上都是大家公认的原则。

REST 设计原则中，还有一些原则因为内容比较多，并且可以独立成模块，所以放在后面来讲。比如 RESTful API 安全性、状态返回码和认证等。
#### REST 示例
上面介绍了一些概念和原则，这里我们通过一个“Hello World”程序，来教你用 Go 快速启动一个 RESTful API 服务，示例代码存放在gopractise-demo/apistyle/ping/main.go。
```go
package main
import ( "log" "net/http")
func main() { 
    http.HandleFunc("/ping", pong) 
    log.Println("Starting http server ...") 
    log.Fatal(http.ListenAndServe(":50052", nil))
}
func pong(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte("pong"))
}

package main
import (
	"log"
    "net/http"
)
func main(){
    http.HandleFunc("/ping",pong)
    log.Println("Starting http server ...")
    log.Fatal(http.ListenAndServe(":50052",nil))
}
func pong(w http.ResponseWriter,r *http.Request){
    w.write([]byte("pong"))
}



```
在上面的代码中，我们通过 http.HandleFunc，向 HTTP 服务注册了一个 pong handler，在 pong handler 中，我们编写了真实的业务代码：返回 pong 字符串。

创建完 main.go 文件后，在当前目录下执行 go run main.go 启动 HTTP 服务，在一个新的 Linux 终端下发送 HTTP 请求，进行使用 curl 命令测试：
```
$ curl http://127.0.0.1:50052/ping
pong
```
### 总结
这一讲，我介绍了两种常用 API 风格中的一种，RESTful API。REST 是一种 API 规范，而 RESTful API 则是满足这种规范的 API 接口，RESTful API 的核心是规范。

在 REST 规范中，资源通过 URI 来标识，资源名使用名词而不是动词，并且用名词复数表示，资源都是分为 Collection 和 Member 两种。RESTful API 中，分别使用 POST、DELETE、PUT、GET 来表示 REST 资源的增删改查，HTTP 方法、Collection、Member 不同组合会产生不同的操作，具体的映射你可以看下 REST 资源操作映射为 HTTP 方法 部分的表格。

为了方便用户使用和理解，每个 RESTful API 的返回格式、错误和正确消息的返回格式，都应该保持一致。RESTful API 需要支持 API 版本，并且版本应该能够向前兼容，我们可以将版本号放在 URL 中、HTTP Header 中、Form 参数中，但这里我**建议**将版本号放在 URL 中，例如 /v1/users，这种形式比较直观。

另外，我们可以通过脊柱命名法来命名 API 接口名。对于一个 REST 资源，其查询接口还应该支持分页 / 过滤 / 排序 / 搜索功能，这些功能可以用同一套机制来实现。 API 的域名可以采用 https://marmotedu.com/api 和 https://iam.api.marmotedu.com 两种格式。

最后，在 Go 中我们可以使用 net/http 包来快速启动一个 RESTful API 服务。


## 13 | API 风格（下）：RPC API介绍

在 Go 项目开发中，如果业务对性能要求比较高，并且需要提供给多种编程语言调用，这时候就可以考虑使用 RPC API 接口。RPC 在 Go 项目开发中用得也非常多，需要我们认真掌握。

为什么要用rpc框架：
在采用微服务架构之前，我们需要思考为什么采用微服务架构，并不是所有的开发团队和发展阶段都适合采用微服务架构。通常，采用微服务架构可以解决以下问题：首先，开发团队具有一定的规模，所有成员共同开发一个单体应用的内耗太高，如果采用微服务架构，每个服务可以由单个或者少数成员独立负责。第二，业务系统的功能模块很多，耦合在一起会增加测试和部署的成本，任何一个模块故障也会导致整个系统故障。第三，功能模块之间的负载无法隔离，容易互相影响，没有办法针对热点模块的计算层或者存储层进行扩容。

如果我们采用微服务架构，单个服务是⾮常简单的，但是，分布式服务之间的功能调用远⽐单体应用内部更加复杂。在单体应用中，⼀个函数可以调⽤其他任何一个公共函数。在微服务架构中，一个函数只可以调⽤同⼀个微服务的函数。如何实现分布式服务之间的通信是微服务架构的首要问题，构建高性能、高可用的远程调用能力并不容易。值得庆幸的是，已经有 grpc、thrift、tars、go-zero、GoFrame、[cloudwego/kitex](https://github.com/cloudwego/kitex) 和 spring cloud 等大量开源的分布式服务开发框架，这些框架可以帮助终端用户快速地构建微服务。不幸的是，仅仅把服务开发出来并且跑通是不够的，保障大规模服务的稳定运营还需要考虑诸多问题，例如：在分布式架构中如何处理基础设施以及应用层的各种异常、如何实现大规模服务的无损发布和流量调度，如何定位和分析复杂调用链路中出现的问题等。对于中大型企业来说，还存在异构的开发技术栈和运行时环境，存在跨地域和混合云的架构要求，如何在更加复杂的应用场景中解决上述问题，面临更多的挑战。


### RPC 介绍
根据维基百科的定义，RPC（Remote Procedure Call），即远程过程调用，是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员不用额外地为这个交互作用编程。

**通俗来讲，就是服务端实现了一个函数，客户端使用 RPC 框架提供的接口，像调用本地函数一样调用这个函数，并获取返回值。**RPC 屏蔽了底层的网络通信细节，使得开发人员无需关注网络编程的细节，可以将更多的时间和精力放在业务逻辑本身的实现上，从而提高开发效率。

RPC 的调用过程如下图所示：![img](https://static001.geekbang.org/resource/image/98/1d/984yy094616b9b24193b22a1f2f2271d.png?wh=2521x1671)


RPC 调用具体流程如下：
1. Client 通过本地调用，调用 Client Stub。
2. Client Stub 将参数打包（也叫 Marshalling）成一个消息，然后发送这个消息。 
3. Client 所在的 OS 将消息发送给 Server。
4. Server 端接收到消息后，将消息传递给 Server Stub。
5. Server Stub 将消息解包（也叫 Unmarshalling）得到参数。
6. Server Stub 调用服务端的子程序（函数），处理完后，将最终结果按照相反的步骤返回给 Client。

这里需要**注意**，Stub 负责调用参数和返回值的流化（serialization）、参数的打包和解包，以及网络层的通信。Client 端一般叫 Stub，Server 端一般叫 Skeleton。

目前，业界有很多优秀的 RPC 协议，例如腾讯的 Tars、阿里的 Dubbo、微博的 Motan、Facebook 的 Thrift、RPCX，等等。但使用最多的还是gRPC，这也是本专栏所采用的 RPC 框架，所以接下来我会重点介绍 gRPC 框架。

### gRPC 介绍
gRPC 是由 Google 开发的高性能、开源、跨多种编程语言的通用 RPC 框架，基于 HTTP 2.0 协议开发，默认采用 Protocol Buffers 数据序列化协议。gRPC 具有如下特性：
- 支持多种语言，例如 Go、Java、C、C++、C#、Node.js、PHP、Python、Ruby 等。
- 基于 IDL（Interface Definition Language）文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。通过这种方式，也可以将服务端和客户端解耦，使客户端和服务端可以并行开发。
- 通信协议基于标准的 HTTP/2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性。
- 支持 Protobuf 和 JSON 序列化数据格式。Protobuf 是一种语言无关的高性能序列化框架，可以减少网络传输流量，提高通信效率。

这里要**注意**的是，gRPC 的全称不是 golang Remote Procedure Call，而是 google Remote Procedure Call。

gRPC 的调用如下图所示：![img](https://static001.geekbang.org/resource/image/01/09/01ac424c7c1d64f678e1218827bc0109.png?wh=2079x1025)

在 gRPC 中，客户端可以直接调用部署在不同机器上的 gRPC 服务所提供的方法，调用远端的 gRPC 方法就像调用本地的方法一样，非常简单方便，通过 gRPC 调用，我们可以非常容易地构建出一个分布式应用。

像很多其他的 RPC 服务一样，gRPC 也是通过 IDL 语言，预先定义好接口（接口的名字、传入参数和返回参数等）。在服务端，gRPC 服务实现我们所定义的接口。在客户端，gRPC 存根提供了跟服务端相同的方法。

gRPC 支持多种语言，比如我们可以用 Go 语言实现 gRPC 服务，并通过 Java 语言客户端调用 gRPC 服务所提供的方法。通过多语言支持，我们编写的 gRPC 服务能满足客户端多语言的需求。

gRPC API 接口通常使用的数据传输格式是 Protocol Buffers。接下来，我们就一起了解下 Protocol Buffers。


### Protocol Buffers 介绍
Protocol Buffers（ProtocolBuffer/ protobuf）是 Google 开发的一套对数据结构进行序列化的方法，可用作（数据）通信协议、数据存储格式等，也是一种更加灵活、高效的数据格式，与 XML、JSON 类似。它的传输性能非常好，所以常被用在一些对数据传输性能要求比较高的系统中，作为数据传输格式。Protocol Buffers 的主要特性有下面这几个。
- 更快的数据传输速度：protobuf 在传输时，会将数据序列化为二进制数据，和 XML、JSON 的文本传输格式相比，这可以节省大量的 IO 操作，从而提高数据传输速度。
- 跨平台多语言：protobuf 自带的编译工具 protoc 可以基于 protobuf 定义文件，编译出不同语言的客户端或者服务端，供程序直接调用，因此可以满足多语言需求的场景。
- 具有非常好的扩展性和兼容性，可以更新已有的数据结构，而不破坏和影响原有的程序。
- 基于 IDL 文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端和客户端接口。

在 gRPC 的框架中，Protocol Buffers 主要有三个作用。

第一，可以用来**定义数据结构**。举个例子，下面的代码定义了一个 SecretInfo 数据结构：
```go
// SecretInfo contains secret details.
message SecretInfo {
    string name = 1;
    string secret_id  = 2;
    string username   = 3;
    string secret_key = 4;
    int64 expires = 5;
    string description = 6;
    string created_at = 7;
    string updated_at = 8;
}
```
第二，可以用来**定义服务接口**。下面的代码定义了一个 Cache 服务，服务包含了 ListSecrets 和 ListPolicies 两个 API 接口。


```go
// Cache implements a cache rpc service.
service Cache{
  rpc ListSecrets(ListSecretsRequest) returns (ListSecretsResponse) {}
  rpc ListPolicies(ListPoliciesRequest) returns (ListPoliciesResponse) {}
}
```
第三，可以通过 **protobuf 序列化和反序列化**，提升传输效率。


### gRPC 示例
我们已经对 gRPC 这一通用 RPC 框架有了一定的了解，但是你可能还不清楚怎么使用 gRPC 编写 API 接口。接下来，我就通过 gRPC 官方的一个示例来快速给大家展示下。运行本示例需要在 Linux 服务器上安装 Go 编译器、Protocol buffer 编译器（protoc，v3）和 protoc 的 Go 语言插件，在 02 讲 中我们已经安装过，这里不再讲具体的安装方法。

这个示例分为下面几个步骤：定义 gRPC 服务。生成客户端和服务器代码。实现 gRPC 服务。实现 gRPC 客户端。

示例代码存放在gopractise-demo/apistyle/greeter目录下。代码结构如下：
```
$ tree
├── client
│   └── main.go
├── helloworld
│   ├── helloworld.pb.go
│   └── helloworld.proto
└── server
    └── main.go
```
client 目录存放 Client 端的代码，helloworld 目录用来存放服务的 IDL 定义，server 目录用来存放 Server 端的代码。

下面我具体介绍下这个示例的四个步骤。
1. 定义 gRPC 服务。

首先，需要定义我们的服务。进入 helloworld 目录，新建文件 helloworld.proto：
```go
$ cd helloworld
$ vi helloworld.proto
```
内容如下：
```go
syntax = "proto3";

option go_package = "github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld";

package helloworld;

// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}

// The request message containing the user's name.
message HelloRequest {
  string name = 1; 
}

// The response message containing the greetings
message HelloReply {
  string message = 1;
}
```
在 helloworld.proto 定义文件中，option 关键字用来对.proto 文件进行一些设置，其中 go_package 是必需的设置，而且 go_package 的值必须是包导入的路径。package 关键字指定生成的.pb.go 文件所在的包名。我们通过 service 关键字定义服务，然后再指定该服务拥有的 RPC 方法，并定义方法的请求和返回的结构体类型：

```go
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}
```
gRPC 支持定义 **4 种类型的服务方法**，分别是**简单模式、服务端数据流模式、客户端数据流模式和双向数据流模式。**
- 简单模式（Simple RPC）：是最简单的 gRPC 模式。客户端发起一次请求，服务端响应一个数据。定义格式为 rpc SayHello (HelloRequest) returns (HelloReply) {}。
- 服务端数据流模式（Server-side streaming RPC）：客户端发送一个请求，服务器返回数据流响应，客户端从流中读取数据直到为空。定义格式为 rpc SayHello (HelloRequest) returns (stream HelloReply) {}。
- 客户端数据流模式（Client-side streaming RPC）：客户端将消息以流的方式发送给服务器，服务器全部处理完成之后返回一次响应。定义格式为 rpc SayHello (stream HelloRequest) returns (HelloReply) {}。
- 双向数据流模式（Bidirectional streaming RPC）：客户端和服务端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，也就是可以实现实时交互 RPC 框架原理。定义格式为 rpc SayHello (stream HelloRequest) returns (stream HelloReply) {}。

本示例使用了简单模式。.proto 文件也包含了 Protocol Buffers 消息的定义，包括请求消息和返回消息。例如请求消息：
```go
// The request message containing the user's name.
message HelloRequest {
  string name = 1;
}
```
2. 生成客户端和服务器代码。

接下来，我们需要根据.proto 服务定义生成 gRPC 客户端和服务器接口。我们可以使用 protoc 编译工具，并指定使用其 Go 语言插件来生成：

```
$ protoc -I. --go_out=plugins=grpc:$GOPATH/src helloworld.proto
$ ls
helloworld.pb.go  helloworld.proto
```
你可以看到，新增了一个 helloworld.pb.go 文件。

3. 实现 gRPC 服务。
接着，我们就可以实现 gRPC 服务了。进入 server 目录，新建 main.go 文件：
```
$ cd ../server
$ vi main.go
```
main.go 内容如下：
```go
// Package main implements a server for Greeter service.
package main

import (
  "context"
  "log"
  "net"

  pb "github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld"
  "google.golang.org/grpc"
)

const (
  port = ":50051"
)

// server is used to implement helloworld.GreeterServer.
type server struct {
  pb.UnimplementedGreeterServer
}

// SayHello implements helloworld.GreeterServer
func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {
  log.Printf("Received: %v", in.GetName())
  return &pb.HelloReply{Message: "Hello " + in.GetName()}, nil
}

func main() {
  lis, err := net.Listen("tcp", port)
  if err != nil {
    log.Fatalf("failed to listen: %v", err)
  }
  s := grpc.NewServer()
  pb.RegisterGreeterServer(s, &server{})
  if err := s.Serve(lis); err != nil {
    log.Fatalf("failed to serve: %v", err)
  }
}
```
上面的代码实现了我们上一步根据服务定义生成的 Go 接口。

我们先定义了一个 Go 结构体 server，并为 server 结构体添加SayHello(context.Context, pb.HelloRequest) (pb.HelloReply, error)方法，也就是说 server 是 GreeterServer 接口（位于 helloworld.pb.go 文件中）的一个实现。

在我们实现了 gRPC 服务所定义的方法之后，就可以通过 net.Listen(...) 指定监听客户端请求的端口；接着，通过 grpc.NewServer() 创建一个 gRPC Server 实例，并通过 pb.RegisterGreeterServer(s, &server{}) 将该服务注册到 gRPC 框架中；最后，通过 s.Serve(lis) 启动 gRPC 服务。

创建完 main.go 文件后，在当前目录下执行 go run main.go ，启动 gRPC 服务。

4. 实现 gRPC 客户端。

打开一个新的 Linux 终端，进入 client 目录，新建 main.go 文件：
```
$ cd ../client
$ vi main.go
```
main.go 内容如下：
```go
// Package main implements a client for Greeter service.
package main

import (
  "context"
  "log"
  "os"
  "time"

  pb "github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld"
  "google.golang.org/grpc"
)

const (
  address     = "localhost:50051"
  defaultName = "world"
)

func main() {
  // Set up a connection to the server.
  conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock())
  if err != nil {
    log.Fatalf("did not connect: %v", err)
  }
  defer conn.Close()
  c := pb.NewGreeterClient(conn)

  // Contact the server and print out its response.
  name := defaultName
  if len(os.Args) > 1 {
    name = os.Args[1]
  }
  ctx, cancel := context.WithTimeout(context.Background(), time.Second)
  defer cancel()
  r, err := c.SayHello(ctx, &pb.HelloRequest{Name: name})
  if err != nil {
    log.Fatalf("could not greet: %v", err)
  }
  log.Printf("Greeting: %s", r.Message)
}
```
在上面的代码中，我们通过如下代码创建了一个 gRPC 连接，用来跟服务端进行通信：
```go
// Set up a connection to the server.
conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock())
if err != nil {
    log.Fatalf("did not connect: %v", err)
}
defer conn.Close()
```
在创建连接时，我们可以指定不同的选项，用来控制创建连接的方式，例如 grpc.WithInsecure()、grpc.WithBlock() 等。gRPC 支持很多选项，更多的选项可以参考 grpc 仓库下dialoptions.go文件中以 With 开头的函数。

连接建立起来之后，我们需要创建一个客户端 stub，用来执行 RPC 请求c := pb.NewGreeterClient(conn)。创建完成之后，我们就可以像调用本地函数一样，调用远程的方法了。例如，下面一段代码通过 c.SayHello 这种本地式调用方式调用了远端的 SayHello 接口：
```go
r, err := c.SayHello(ctx, &pb.HelloRequest{Name: name})
if err != nil {
    log.Fatalf("could not greet: %v", err)
}
log.Printf("Greeting: %s", r.Message)
```
从上面的调用格式中，我们可以看到 RPC 调用具有下面两个特点。
- 调用方便：RPC 屏蔽了底层的网络通信细节，使得调用 RPC 就像调用本地方法一样方便，调用方式跟大家所熟知的调用类的方法一致：ClassName.ClassFuc(params)。
- 不需要打包和解包：RPC 调用的入参和返回的结果都是 Go 的结构体，不需要对传入参数进行打包操作，也不需要对返回参数进行解包操作，简化了调用步骤。

最后，创建完 main.go 文件后，在当前目录下，执行 go run main.go 发起 RPC 调用：
```
$ go run main.go
2020/10/17 07:55:00 Greeting: Hello world
```
至此，我们用四个步骤，创建并调用了一个 gRPC 服务。接下来我再给大家讲解一个在具体场景中的**注意**事项。

在做服务开发时，我们经常会遇到一种场景：定义一个接口，接口会通过判断是否传入某个参数，决定接口行为。例如，我们想提供一个 GetUser 接口，期望 GetUser 接口在传入 username 参数时，根据 username 查询用户的信息，如果没有传入 username，则默认根据 userId 查询用户信息。

这时候，我们需要判断客户端有没有传入 username 参数。我们不能根据 username 是否为空值来判断，因为我们不能区分客户端传的是空值，还是没有传 username 参数。这是由 Go 语言的语法特性决定的：如果客户端没有传入 username 参数，Go 会默认赋值为所在类型的零值，而字符串类型的零值就是空字符串。

那我们怎么判断客户端有没有传入 username 参数呢？最好的方法是通过指针来判断，如果是 nil 指针就说明没有传入，非 nil 指针就说明传入，具体实现步骤如下：

1. 编写 protobuf 定义文件。新建 user.proto 文件，内容如下:
```
proto
syntax = "proto3";

package proto;
option go_package = "github.com/marmotedu/gopractise-demo/protobuf/user";

//go:generate protoc -I. --experimental_allow_proto3_optional --go_out=plugins=grpc:.

service User {
  rpc GetUser(GetUserRequest) returns (GetUserResponse) {}
}

message GetUserRequest {
  string class = 1;
  optional string username = 2;
  optional string user_id = 3;
}

message GetUserResponse {
  string class = 1;
  string user_id = 2;
  string username = 3;
  string address = 4;
  string sex = 5;
  string phone = 6;
}
```
你需要**注意**，这里我们在需要设置为可选字段的前面添加了 optional 标识。

2. 使用 protoc 工具编译 protobuf 文件。

在执行 protoc 命令时，需要传入--experimental_allow_proto3_optional参数以打开 optional 选项，编译命令如下：
```
$ protoc --experimental_allow_proto3_optional --go_out=plugins=grpc:. user.proto
```
上述编译命令会生成 user.pb.go 文件，其中的 GetUserRequest 结构体定义如下：
```go
type GetUserRequest struct {
    state         protoimpl.MessageState
    sizeCache     protoimpl.SizeCache
    unknownFields protoimpl.UnknownFields

    Class    string  `protobuf:"bytes,1,opt,name=class,proto3" json:"class,omitempty"`
    Username *string `protobuf:"bytes,2,opt,name=username,proto3,oneof" json:"username,omitempty"`
    UserId   *string `protobuf:"bytes,3,opt,name=user_id,json=userId,proto3,oneof" json:"user_id,omitempty"`
}
```
通过 optional + --experimental_allow_proto3_optional 组合，我们可以将一个字段编译为指针类型。
3. 编写 gRPC 接口实现。
新建一个 user.go 文件，内容如下：
```go
package user

import (
    "context"

    pb "github.com/marmotedu/api/proto/apiserver/v1"

    "github.com/marmotedu/iam/internal/apiserver/store"
)

type User struct {
}

func (c *User) GetUser(ctx context.Context, r *pb.GetUserRequest) (*pb.GetUserResponse, error) {
    if r.Username != nil {
        return store.Client().Users().GetUserByName(r.Class, r.Username)
    }

    return store.Client().Users().GetUserByID(r.Class, r.UserId)
}
```
总之，在 GetUser 方法中，我们可以通过判断 r.Username 是否为 nil，来判断客户端是否传入了 Username 参数。
### RESTful VS gRPC
到这里，今天我们已经介绍完了 gRPC API。回想一下我们昨天学习的 RESTful API，你可能想问：这两种 API 风格分别有什么优缺点，适用于什么场景呢？我把这个问题的答案放在了下面这张表中，你可以对照着它，根据自己的需求在实际应用时进行选择。![img](https://static001.geekbang.org/resource/image/e6/ab/e6ae61fc4b0fc821f94d257239f332ab.png?wh=1483x1026)

当然，更多的时候，RESTful API 和 gRPC API 是一种合作的关系，**对内业务使用 gRPC API，对外业务使用 RESTful API**，如下图所示：![img](https://static001.geekbang.org/resource/image/47/18/471ac923d2eaeca8fe13cb74731c1318.png?wh=1606x1144)


在 Go 项目开发中，我们可以选择使用 RESTful API 风格和 RPC API 风格，这两种服务都用得很多。其中，RESTful API 风格因为规范、易理解、易用，所以适合用在需要对外提供 API 接口的场景中。而 RPC API 因为性能比较高、调用方便，更适合用在内部业务中。

RESTful API 使用的是 HTTP 协议，而 RPC API 使用的是 RPC 协议。目前，有很多 RPC 协议可供你选择，而我**推荐**你使用 gRPC，因为它很轻量，同时性能很高、很稳定，是一个优秀的 RPC 框架。所以目前业界用的最多的还是 gRPC 协议，腾讯、阿里等大厂内部很多核心的线上服务用的就是 gRPC。

除了使用 gRPC 协议，在进行 Go 项目开发前，你也可以了解业界一些其他的优秀 Go RPC 框架，比如腾讯的 tars-go、阿里的 dubbo-go、Facebook 的 thrift、rpcx 等，你可以在项目开发之前一并调研，根据实际情况进行选择。

## 14 | 项目管理：如何编写高质量的Makefile？

要写出一个优雅的 Go 项目，不仅仅是要开发一个优秀的 Go 应用，而且还要能够高效地管理项目。有效手段之一，就是通过 Makefile 来管理我们的项目，这就要求我们要为项目编写 Makefile 文件。


在和其他开发同学交流时，我发现大家都认可 Makefile 强大的项目管理能力，也会自己编写 Makefile。但是其中的一些人项目管理做得并不好，我和他们进一步交流后发现，这些同学在用 Makefile 简单的语法重复编写一些低质量 Makefile 文件，根本没有把 Makefile 的功能充分发挥出来。

下面给你举个例子，你就会理解低质量的 Makefile 文件是什么样的了。


```
makefile
build: clean vet
  @mkdir -p ./Role
  @export GOOS=linux && go build -v .

vet:
  go vet ./...

fmt:
  go fmt ./...

clean:
  rm -rf dashboard
```
上面这个 Makefile 存在不少问题。例如：功能简单，只能完成最基本的编译、格式化等操作，像构建镜像、自动生成代码等一些高阶的功能都没有；扩展性差，没法编译出可在 Mac 下运行的二进制文件；没有 Help 功能，使用难度高；单 Makefile 文件，结构单一，不适合添加一些复杂的管理功能。所以，我们不光要编写 Makefile，还要编写高质量的 Makefile。那么如何编写一个高质量的 Makefile 呢？我觉得，可以通过以下 4 个方法来实现：


打好基础，也就是熟练掌握 Makefile 的语法。做好准备工作，也就是提前规划 Makefile 要实现的功能。进行规划，设计一个合理的 Makefile 结构。掌握方法，用好 Makefile 的编写技巧。


### 熟练掌握 Makefile 语法
工欲善其事，必先利其器。编写高质量 Makefile 的第一步，便是熟练掌握 Makefile 的核心语法。

因为 Makefile 的语法比较多，我把一些**建议**你重点掌握的语法放在了近期会更新的特别放送中，包括 Makefile 规则语法、伪目标、变量赋值、条件语句和 Makefile 常用函数等等。如果你想更深入、全面地学习 Makefile 的语法，我**推荐**你学习陈皓老师编写的[《跟我一起写 Makefile》 (PDF 重制版)](https://github.com/seisman/how-to-write-makefile)。


### 规划 Makefile 要实现的功能
接着，我们需要规划 Makefile 要实现的功能。提前规划好功能，有利于你设计 Makefile 的整体结构和实现方法。


不同项目拥有不同的 Makefile 功能，这些功能中一小部分是通过目标文件来实现的，但更多的功能是通过伪目标来实现的。对于 Go 项目来说，虽然不同项目集成的功能不一样，但绝大部分项目都需要实现一些通用的功能。接下来，我们就来看看，在一个大型 Go 项目中 Makefile 通常可以实现的功能。下面是 IAM 项目的 Makefile 所集成的功能，希望会对你日后设计 Makefile 有一些帮助。


```
makefile
$ make help

Usage: make <TARGETS> <OPTIONS> ...

Targets:
  # 代码生成类命令
  gen                Generate all necessary files, such as error code files.

  # 格式化类命令
  format             Gofmt (reformat) package sources (exclude vendor dir if existed).

  # 静态代码检查
  lint               Check syntax and styling of go sources.

  # 测试类命令
  test               Run unit test.
  cover              Run unit test and get test coverage.

  # 构建类命令
  build              Build source code for host platform.
  build.multiarch    Build source code for multiple platforms. See option PLATFORMS.

  # Docker镜像打包类命令
  image              Build docker images for host arch.
  image.multiarch    Build docker images for multiple platforms. See option PLATFORMS.
  push               Build docker images for host arch and push images to registry.
  push.multiarch     Build docker images for multiple platforms and push images to registry.

  # 部署类命令
  deploy             Deploy updated components to development env.

  # 清理类命令
  clean              Remove all files that are created by building.

  # 其他命令，不同项目会有区别
  release            Release iam
  verify-copyright   Verify the boilerplate headers for all files.
  ca                 Generate CA files for all iam components.
  install            Install iam system with all its components.
  swagger            Generate swagger document.
  tools              install dependent tools.

  # 帮助命令
  help               Show this help info.

# 选项
Options:
  DEBUG        Whether to generate debug symbols. Default is 0.
  BINS         The binaries to build. Default is all of cmd.
               This option is available when using: make build/build.multiarch
               Example: make build BINS="iam-apiserver iam-authz-server"
  ...
```
更详细的命令，你可以在 IAM 项目仓库根目录下执行make help查看。通常而言，Go 项目的 Makefile 应该实现以下功能：格式化代码、静态代码检查、单元测试、代码构建、文件清理、帮助等等。如果通过 docker 部署，还需要有 docker 镜像打包功能。因为 Go 是跨平台的语言，所以构建和 docker 打包命令，还要能够支持不同的 CPU 架构和平台。为了能够更好地控制 Makefile 命令的行为，还需要支持 Options。


为了方便查看 Makefile 集成了哪些功能，我们需要支持 help 命令。help 命令最好通过解析 Makefile 文件来输出集成的功能，例如：


```
makefile
## help: Show this help info.
.PHONY: help
help: Makefile
  @echo -e "\nUsage: make <TARGETS> <OPTIONS> ...\n\nTargets:"
  @sed -n 's/^##//p' $< | column -t -s ':' | sed -e 's/^/ /'
  @echo "$$USAGE_OPTIONS"
```
上面的 help 命令，通过解析 Makefile 文件中的##注释，获取支持的命令。通过这种方式，我们以后新加命令时，就不用再对 help 命令进行修改了。你可以参考上面的 Makefile 管理功能，结合自己项目的需求，整理出一个 Makefile 要实现的功能列表，并初步确定实现思路和方法。做完这些，你的编写前准备工作就基本完成了。


### 设计合理的 Makefile 结构
设计完 Makefile 需要实现的功能，接下来我们就进入 Makefile 编写阶段。编写阶段的第一步，就是设计一个合理的 Makefile 结构。


对于大型项目来说，需要管理的内容很多，所有管理功能都集成在一个 Makefile 中，可能会导致 Makefile 很大，难以阅读和维护，所以****建议**采用分层的设计方法，根目录下的 Makefile 聚合所有的 Makefile 命令，具体实现则按功能分类，放在另外的 Makefile 中。**


我们经常会在 Makefile 命令中集成 shell 脚本，但如果 shell 脚本过于复杂，也会导致 Makefile 内容过多，难以阅读和维护。并且在 Makefile 中集成复杂的 shell 脚本，编写体验也很差。对于这种情况，**可以将复杂的 shell 命令封装在 shell 脚本中，供 Makefile 直接调用，而一些简单的命令则可以直接集成在 Makefile 中**。所以，最终我**推荐**的 Makefile 结构如下：


![img](https://static001.geekbang.org/resource/image/5c/f7/5c524e0297b6d6e4e151643d2e1bbbf7.png?wh=2575x1017)

在上面的 Makefile 组织方式中，根目录下的 Makefile 聚合了项目所有的管理功能，这些管理功能通过 Makefile 伪目标的方式实现。同时，还将这些伪目标进行分类，把相同类别的伪目标放在同一个 Makefile 中，这样可以使得 Makefile 更容易维护。对于复杂的命令，则编写成独立的 shell 脚本，并在 Makefile 命令中调用这些 shell 脚本。举个例子，下面是 IAM 项目的 Makefile 组织结构：


```
├── Makefile
├── scripts
│   ├── gendoc.sh
│   ├── make-rules
│   │   ├── gen.mk
│   │   ├── golang.mk
│   │   ├── image.mk
│   │   └── ...
    └── ...
```
我们将相同类别的操作统一放在 scripts/make-rules 目录下的 Makefile 文件中。Makefile 的文件名参考分类命名，例如 golang.mk。最后，在 /Makefile 中 include 这些 Makefile。为了跟 Makefile 的层级相匹配，golang.mk 中的所有目标都按go.xxx这种方式命名。通过这种命名方式，我们可以很容易分辨出某个目标完成什么功能，放在什么文件里，这在复杂的 Makefile 中尤其有用。以下是 IAM 项目根目录下，Makefile 的内容摘录，你可以看一看，作为参考：


```
makefile
include scripts/make-rules/golang.mk
include scripts/make-rules/image.mk
include scripts/make-rules/gen.mk
include scripts/make-rules/...

## build: Build source code for host platform.
.PHONY: build
build:
  @$(MAKE) go.build

## build.multiarch: Build source code for multiple platforms. See option PLATFORMS.
.PHONY: build.multiarch
build.multiarch:
  @$(MAKE) go.build.multiarch

## image: Build docker images for host arch.
.PHONY: image
image:
  @$(MAKE) image.build

## push: Build docker images for host arch and push images to registry.
.PHONY: push
push:
  @$(MAKE) image.push

## ca: Generate CA files for all iam components.
.PHONY: ca
ca:
  @$(MAKE) gen.ca
```
另外，一个合理的 Makefile 结构应该具有前瞻性。也就是说，要在不改变现有结构的情况下，接纳后面的新功能。这就需要你整理好 Makefile 当前要实现的功能、即将要实现的功能和未来可能会实现的功能，然后基于这些功能，利用 Makefile 编程技巧，编写可扩展的 Makefile。


这里需要你**注意**：上面的 Makefile 通过 .PHONY 标识定义了大量的伪目标，定义伪目标一定要加 .PHONY 标识，否则当有同名的文件时，伪目标可能不会被执行。



### 掌握 Makefile 编写技巧
最后，在编写过程中，你还需要掌握一些 Makefile 的编写技巧，这些技巧可以使你编写的 Makefile 扩展性更强，功能更强大。接下来，我会把自己长期开发过程中积累的一些 Makefile 编写经验分享给你。这些技巧，你需要在实际编写中多加练习，并形成编写习惯。



#### 技巧 1：善用通配符和自动变量
Makefile 允许对目标进行类似正则运算的匹配，主要用到的通配符是%。通过使用通配符，可以使不同的目标使用相同的规则，从而使 Makefile 扩展性更强，也更简洁。我们的 IAM 实战项目中，就大量使用了通配符%，例如：go.build.%、ca.gen.%、deploy.run.%、tools.verify.%、tools.install.%等。这里，我们来看一个具体的例子，tools.verify.%（位于scripts/make-rules/tools.mk文件中）定义如下：

```
makefile
tools.verify.%:
  @if ! which $* &>/dev/null; then $(MAKE) tools.install.$*; fi
```
make tools.verify.swagger, make tools.verify.mockgen等均可以使用上面定义的规则，%分别代表了swagger和mockgen。如果不使用%，则我们需要分别为tools.verify.swagger和tools.verify.mockgen定义规则，很麻烦，后面修改也困难。


另外，这里也能看出tools.verify.%这种命名方式的好处：tools 说明依赖的定义位于scripts/make-rules/tools.mk Makefile 中；verify说明tools.verify.%伪目标属于 verify 分类，主要用来验证工具是否安装。通过这种命名方式，你可以很容易地知道目标位于哪个 Makefile 文件中，以及想要完成的功能。另外，上面的定义中还用到了自动变量$*，用来指代被匹配的值swagger、mockgen。


#### 技巧 2：善用函数
Makefile 自带的函数能够帮助我们实现很多强大的功能。所以，在我们编写 Makefile 的过程中，如果有功能需求，可以优先使用这些函数。我把常用的函数以及它们实现的功能整理在了 Makefile 常用函数列表 中，你可以参考下。


IAM 的 Makefile 文件中大量使用了上述函数，如果你想查看这些函数的具体使用方法和场景，可以参考 IAM 项目的 Makefile 文件 make-rules。



#### 技巧 3：依赖需要用到的工具
如果 Makefile 某个目标的命令中用到了某个工具，可以将该工具放在目标的依赖中。这样，当执行该目标时，就可以指定检查系统是否安装该工具，如果没有安装则自动安装，从而实现更高程度的自动化。例如，/Makefile 文件中，format 伪目标，定义如下：


```
makefile
.PHONY: format
format: tools.verify.golines tools.verify.goimports
  @echo "===========> Formating codes"
  @$(FIND) -type f -name '*.go' | $(XARGS) gofmt -s -w
  @$(FIND) -type f -name '*.go' | $(XARGS) goimports -w -local $(ROOT_PACKAGE)
  @$(FIND) -type f -name '*.go' | $(XARGS) golines -w --max-len=120 --reformat-tags --shorten-comments --ignore-generated .
```
你可以看到，format 依赖tools.verify.golines tools.verify.goimports。我们再来看下tools.verify.golines的定义：


```
makefile
tools.verify.%:
  @if ! which $* &>/dev/null; then $(MAKE) tools.install.$*; fi
```
再来看下tools.install.$*规则：



```
makefile
.PHONY: install.golines
install.golines:
  @$(GO) get -u github.com/segmentio/golines
```
通过tools.verify.%规则定义，我们可以知道，tools.verify.%会先检查工具是否安装，如果没有安装，就会执行tools.install.$*来安装。如此一来，当我们执行tools.verify.%目标时，如果系统没有安装 golines 命令，就会自动调用go get安装，提高了 Makefile 的自动化程度。



#### 技巧 4：把常用功能放在 /Makefile 中，不常用的放在分类 Makefile 中
一个项目，尤其是大型项目，有很多需要管理的地方，其中大部分都可以通过 Makefile 实现自动化操作。不过，为了保持 /Makefile 文件的整洁性，我们不能把所有的命令都添加在 /Makefile 文件中。



一个比较好的**建议**是，将常用功能放在 /Makefile 中，不常用的放在分类 Makefile 中，并在 /Makefile 中 include 这些分类 Makefile。例如，IAM 项目的 /Makefile 集成了format、lint、test、build等常用命令，而将gen.errcode.code、gen.errcode.doc这类不常用的功能放在 scripts/make-rules/gen.mk 文件中。当然，我们也可以直接执行 make gen.errcode.code来执行gen.errcode.code伪目标。通过这种方式，既可以保证 /Makefile 的简洁、易维护，又可以通过make命令来运行伪目标，更加灵活。



#### 技巧 5：编写可扩展的 Makefile
什么叫可扩展的 Makefile 呢？在我看来，可扩展的 Makefile 包含两层含义：


可以在不改变 Makefile 结构的情况下添加新功能。扩展项目时，新功能可以自动纳入到 Makefile 现有逻辑中。


其中的第一点，我们可以通过设计合理的 Makefile 结构来实现。要实现第二点，就需要我们在编写 Makefile 时采用一定的技巧，例如多用通配符、自动变量、函数等。这里我们来看一个例子，可以让你更好地理解。


在我们 IAM 实战项目的golang.mk中，执行 make go.build 时能够构建 cmd/ 目录下的所有组件，也就是说，当有新组件添加时， make go.build 仍然能够构建新增的组件，这就实现了上面说的第二点。具体实现方法如下：



```
makefile
COMMANDS ?= $(filter-out %.md, $(wildcard ${ROOT_DIR}/cmd/*))
BINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))

.PHONY: go.build
go.build: go.build.verify $(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS)))
.PHONY: go.build.%               

go.build.%:             
  $(eval COMMAND := $(word 2,$(subst ., ,$*)))
  $(eval PLATFORM := $(word 1,$(subst ., ,$*)))
  $(eval OS := $(word 1,$(subst _, ,$(PLATFORM))))           
  $(eval ARCH := $(word 2,$(subst _, ,$(PLATFORM))))                         
  @echo "===========> Building binary $(COMMAND) $(VERSION) for $(OS) $(ARCH)"
  @mkdir -p $(OUTPUT_DIR)/platforms/$(OS)/$(ARCH)
  @CGO_ENABLED=0 GOOS=$(OS) GOARCH=$(ARCH) $(GO) build $(GO_BUILD_FLAGS) -o $(OUTPUT_DIR)/platforms/$(OS)/$(ARCH)/$(COMMAND)$(GO_OUT_EXT) $(ROOT_PACKAGE)/cmd/$(COMMAND)
```
当执行make go.build 时，会执行 go.build 的依赖 $(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS))) ,addprefix函数最终返回字符串 go.build.linux_amd64.iamctl go.build.linux_amd64.iam-authz-server go.build.linux_amd64.iam-apiserver ... ，这时候就会执行 go.build.% 伪目标。

在 go.build.% 伪目标中，通过 eval、word、subst 函数组合，算出了 COMMAND 的值 iamctl/iam-apiserver/iam-authz-server/...，最终通过 $(ROOT_PACKAGE)/cmd/$(COMMAND) 定位到需要构建的组件的 main 函数所在目录。


上述实现中有两个技巧，你可以**注意**下。首先，通过


```
makefile
COMMANDS ?= $(filter-out %.md, $(wildcard ${ROOT_DIR}/cmd/*))
BINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))
```
获取到了 cmd/ 目录下的所有组件名。接着，通过使用通配符和自动变量，自动匹配到go.build.linux_amd64.iam-authz-server 这类伪目标并构建。可以看到，想要编写一个可扩展的 Makefile，熟练掌握 Makefile 的用法是基础，更多的是需要我们动脑思考如何去编写 Makefile。


#### 技巧 6：将所有输出存放在一个目录下，方便清理和查找
在执行 Makefile 的过程中，会输出各种各样的文件，例如 Go 编译后的二进制文件、测试覆盖率数据等，我**建议**你把这些文件统一放在一个目录下，方便后期的清理和查找。通常我们可以把它们放在_output这类目录下，这样清理时就很方便，只需要清理_output文件夹就可以，例如：


```
makefile
.PHONY: go.clean
go.clean:
  @echo "===========> Cleaning all build output"
  @-rm -vrf $(OUTPUT_DIR)
```
这里要**注意**，要用-rm，而不是rm，防止在没有_output目录时，执行make go.clean报错。


#### 技巧 7：使用带层级的命名方式
通过使用带层级的命名方式，例如tools.verify.swagger ，我们可以实现目标分组管理。这样做的好处有很多。首先，当 Makefile 有大量目标时，通过分组，我们可以更好地管理这些目标。其次，分组也能方便理解，可以通过组名一眼识别出该目标的功能类别。最后，这样做还可以大大减小目标重名的概率。



例如，IAM 项目的 Makefile 就大量采用了下面这种命名方式。


```
makefile
.PHONY: gen.run
gen.run: gen.clean gen.errcode gen.docgo

.PHONY: gen.errcode
gen.errcode: gen.errcode.code gen.errcode.doc

.PHONY: gen.errcode.code
gen.errcode.code: tools.verify.codegen
    ...
.PHONY: gen.errcode.doc
gen.errcode.doc: tools.verify.codegen
    ...
```
#### 技巧 8：做好目标拆分
还有一个比较实用的技巧：我们要合理地拆分目标。比如，我们可以将安装工具拆分成两个目标：验证工具是否已安装和安装工具。通过这种方式，可以给我们的 Makefile 带来更大的灵活性。例如：我们可以根据需要选择性地执行其中一个操作，也可以两个操作一起执行。

这里来看一个例子：


```
makefile
gen.errcode.code: tools.verify.codegen

tools.verify.%:    
  @if ! which $* &>/dev/null; then $(MAKE) tools.install.$*; fi  

.PHONY: install.codegen
install.codegen:              
  @$(GO) install ${ROOT_DIR}/tools/codegen/codegen.go
```
上面的 Makefile 中，gen.errcode.code 依赖了 tools.verify.codegen，tools.verify.codegen 会先检查 codegen 命令是否存在，如果不存在，再调用 install.codegen 来安装 codegen 工具。如果我们的 Makefile 设计是：

```
makefile
gen.errcode.code: install.codegen
```
那每次执行 gen.errcode.code 都要重新安装 codegen 命令，这种操作是不必要的，还会导致 make gen.errcode.code 执行很慢。



#### 技巧 9：设置 OPTIONS
编写 Makefile 时，我们还需要把一些可变的功能通过 OPTIONS 来控制。为了帮助你理解，这里还是拿 IAM 项目的 Makefile 来举例。



假设我们需要通过一个选项 V ，来控制是否需要在执行 Makefile 时打印详细的信息。这可以通过下面的步骤来实现。

首先，在 /Makefile 中定义 USAGE_OPTIONS 。定义 USAGE_OPTIONS 可以使开发者在执行 make help 后感知到此 OPTION，并根据需要进行设置。



```
makefile
define USAGE_OPTIONS    
                         
Options:
  ...
  BINS         The binaries to build. Default is all of cmd.
               ...
  ...
  V            Set to 1 enable verbose build. Default is 0.    
endef    
export USAGE_OPTIONS    
```
接着，在scripts/make-rules/common.mk文件中，我们通过判断有没有设置 V 选项，来选择不同的行为：


```
makefile
ifndef V    
MAKEFLAGS += --no-print-directory    
endif
```
当然，我们还可以通过下面的方法来使用 V ：


```
makefile
ifeq ($(origin V), undefined)                                
MAKEFLAGS += --no-print-directory              
endif
```
上面，我介绍了 V OPTION，我们在 Makefile 中通过判断有没有定义 V ，来执行不同的操作。其实还有一种 OPTION，这种 OPTION 的值我们在 Makefile 中是直接使用的，例如BINS。针对这种 OPTION，我们可以通过以下方式来使用：


```
makefile
BINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))
...
go.build: go.build.verify $(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS)))
```
也就是说，通过 ?= 来判断 BINS 变量有没有被赋值，如果没有，则赋予等号后的值。接下来，就可以在 Makefile 规则中使用它。


#### 技巧 10：定义环境变量
我们可以在 Makefile 中定义一些环境变量，例如：



```
makefile
GO := go                                          
GO_SUPPORTED_VERSIONS ?= 1.13|1.14|1.15|1.16|1.17    
GO_LDFLAGS += -X $(VERSION_PACKAGE).GitVersion=$(VERSION) \    
  -X $(VERSION_PACKAGE).GitCommit=$(GIT_COMMIT) \       
  -X $(VERSION_PACKAGE).GitTreeState=$(GIT_TREE_STATE) \                          
  -X $(VERSION_PACKAGE).BuildDate=$(shell date -u +'%Y-%m-%dT%H:%M:%SZ')    
ifneq ($(DLV),)                                                                                                                              
  GO_BUILD_FLAGS += -gcflags "all=-N -l"    
  LDFLAGS = ""      
endif                                                                                   
GO_BUILD_FLAGS += -tags=jsoniter -ldflags "$(GO_LDFLAGS)" 
...
FIND := find . ! -path './third_party/*' ! -path './vendor/*'    
XARGS := xargs --no-run-if-empty 
```
这些环境变量和编程中使用宏定义的作用是一样的：只要修改一处，就可以使很多地方同时生效，避免了重复的工作。通常，我们可以将 GO、GO_BUILD_FLAGS、FIND 这类变量定义为环境变量。


#### 技巧 11：自己调用自己
在编写 Makefile 的过程中，你可能会遇到这样一种情况：A-Target 目标命令中，需要完成操作 B-Action，而操作 B-Action 我们已经通过伪目标 B-Target 实现过。为了达到最大的代码复用度，这时候最好的方式是在 A-Target 的命令中执行 B-Target。方法如下：


```
makefile
tools.verify.%:
  @if ! which $* &>/dev/null; then $(MAKE) tools.install.$*; fi
```
这里，我们通过 $(MAKE) 调用了伪目标 tools.install.$* 。要**注意**的是，默认情况下，Makefile 在切换目录时会输出以下信息：


```
makefile
$ make tools.install.codegen
===========> Installing codegen
make[1]: Entering directory `/home/colin/workspace/golang/src/github.com/marmotedu/iam'
make[1]: Leaving directory `/home/colin/workspace/golang/src/github.com/marmotedu/iam'
```
如果觉得 Entering directory 这类信息很烦人，可以通过设置 MAKEFLAGS += --no-print-directory 来禁止 Makefile 打印这些信息。



### 总结
如果你想要高效管理项目，使用 Makefile 来管理是目前的最佳实践。我们可以通过下面的几个方法，来编写一个高质量的 Makefile。首先，你需要熟练掌握 Makefile 的语法。我**建议**你重点掌握以下语法：Makefile 规则语法、伪目标、变量赋值、特殊变量、自动化变量。接着，我们需要提前规划 Makefile 要实现的功能。一个大型 Go 项目通常需要实现以下功能：代码生成类命令、格式化类命令、静态代码检查、 测试类命令、构建类命令、Docker 镜像打包类命令、部署类命令、清理类命令，等等。然后，我们还需要通过 Makefile 功能分类、文件分层、复杂命令脚本化等方式，来设计一个合理的 Makefile 结构。最后，我们还需要掌握一些 Makefile 编写技巧，例如：善用通配符、自动变量和函数；编写可扩展的 Makefile；使用带层级的命名方式，等等。通过这些技巧，可以进一步保证我们编写出一个高质量的 Makefile。

## 15 | 研发流程实战：IAM项目是如何进行研发流程管理的？

在这一讲中，我会重点介绍这两个阶段中的 Makefile 项目管理功能，并且穿插一些我的 Makefile 的设计思路。

为了向你演示流程，这里先假设一个场景。我们有一个需求：给 IAM 客户端工具 iamctl 增加一个 helloworld 命令，该命令向终端打印 hello world。接下来，我们就来看下如何具体去执行研发流程中的每一步。首先，我们进入开发阶段。

### 开发阶段
开发阶段是开发者的主战场，完全由开发者来主导，它又可分为代码开发和代码提交两个子阶段。我们先来看下代码开发阶段。



#### 代码开发
拿到需求之后，首先需要开发代码。这时，我们就需要选择一个适合团队和项目的 Git 工作流。因为 **Git Flow 工作流比较适合大型的非开源项目**，所以这里我们选择 Git Flow 工作流。代码开发的具体步骤如下：


第一步，基于 develop 分支，新建一个功能分支 feature/helloworld。


```
$ git checkout -b feature/helloworld develop
```
这里需要**注意**：新建的 branch 名要符合 Git Flow 工作流中的分支命名规则。否则，在 git commit 阶段，会因为 branch 不规范导致 commit 失败。IAM 项目的分支命令规则具体如下图所示：

![img](https://static001.geekbang.org/resource/image/15/79/15bb43219269273baf70a27ea94e1279.png?wh=2775x1250)

IAM 项目通过 pre-commit githooks 来确保分支名是符合规范的。在 IAM 项目根目录下执行 git commit 命令，git 会自动执行pre-commit脚本，该脚本会检查当前 branch 的名字是否符合规范。


这里还有一个地方需要你**注意**：git 不会提交 .git/hooks 目录下的 githooks 脚本，所以我们需要通过以下手段，确保开发者 clone 仓库之后，仍然能安装我们指定的 githooks 脚本到 .git/hooks 目录：


```
# Copy githook scripts when execute makefile    
COPY_GITHOOK:=$(shell cp -f githooks/* .git/hooks/) 
```
上述代码放在scripts/make-rules/common.mk文件中，每次执行 make 命令时都会执行，可以确保 githooks 都安装到 .git/hooks 目录下。

第二步，在 feature/helloworld 分支中，完成 helloworld 命令的添加。首先，通过 iamctl new helloworld 命令创建 helloworld 命令模板：


```
$ iamctl new helloworld -d internal/iamctl/cmd/helloworld
Command file generated: internal/iamctl/cmd/helloworld/helloworld.go
```
接着，编辑internal/iamctl/cmd/cmd.go文件，在源码文件中添加helloworld.NewCmdHelloworld(f, ioStreams),，加载 helloworld 命令。这里将 helloworld 命令设置为Troubleshooting and Debugging Commands命令分组：



```
import (
    "github.com/marmotedu/iam/internal/iamctl/cmd/helloworld"
)
        ...
        {
            Message: "Troubleshooting and Debugging Commands:",
            Commands: []*cobra.Command{
                validate.NewCmdValidate(f, ioStreams),
                helloworld.NewCmdHelloworld(f, ioStreams),
            },
        },
```
这些操作中包含了 low code 的思想。在第 10 讲 中我就强调过，要尽可能使用代码自动生成这一技术。这样做有两个好处：一方面能够提高我们的代码开发效率；另一方面也能够保证规范，减少手动操作可能带来的错误。所以这里，我将 iamctl 的命令也模板化，并通过 iamctl new 自动生成。

第三步，生成代码。

```
$ make gen
```
如果改动不涉及代码生成，可以不执行make gen操作。 make gen 执行的其实是 gen.run 伪目标：



```
gen.run: gen.clean gen.errcode gen.docgo.doc
```
可以看到，当执行 make gen.run 时，其实会先清理之前生成的文件，再分别自动生成 error code 和 doc.go 文件。这里需要**注意**，通过make gen 生成的存量代码要具有幂等性。只有这样，才能确保每次生成的代码是一样的，避免不一致带来的问题。


我们可以将更多的与自动生成代码相关的功能放在 gen.mk Makefile 中。例如：gen.docgo.doc，代表自动生成 doc.go 文件。gen.ca.%，代表自动生成 iamctl、iam-apiserver、iam-authz-server 证书文件。


第四步，版权检查。如果有新文件添加，我们还需要执行 make verify-copyright ，来检查新文件有没有添加版权头信息。


```
$ make verify-copyright
```
如果版权检查失败，可以执行make add-copyright自动添加版权头。添加版权信息只针对开源软件，如果你的软件不需要添加，就可以略过这一步。这里还有个 Makefile 编写技巧：**如果 Makefile 的 command 需要某个命令，就可以使该目标依赖类似 tools.verify.addlicense 这种目标，tools.verify.addlicense 会检查该工具是否已安装，如果没有就先安装。**




```
.PHONY: copyright.verify    
copyright.verify: tools.verify.addlicense 
  ...
tools.verify.%:          
  @if ! which $* &>/dev/null; then $(MAKE) tools.install.$*; fi
.PHONY: install.addlicense                              
install.addlicense:        
  @$(GO) get -u github.com/marmotedu/addlicense

```
通过这种方式，可以使 make copyright.verify 尽可能自动化，减少手动介入的概率。第五步，代码格式化。


```
$ make format
```
执行make format会依次执行以下格式化操作：调用 gofmt 格式化你的代码。调用 goimports 工具，自动增删依赖的包，并将依赖包按字母序排序并分类。调用 golines 工具，把超过 120 行的代码按 golines 规则，格式化成 <120 行的代码。调用 go mod edit -fmt 格式化 go.mod 文件。



第六步，静态代码检查。

```
$ make lint
```
关于静态代码检查，在这里你可以先了解代码开发阶段有这个步骤，至于如何操作，我会在下一讲给你详细介绍。

第七步，单元测试。


```
$ make test
```
这里要**注意**，并不是所有的包都需要执行单元测试。你可以通过如下命令，排除掉不需要单元测试的包：


```
go test `go list ./...|egrep -v $(subst $(SPACE),'|',$(sort $(EXCLUDE_TESTS)))`
```
在 go.test 的 command 中，我们还运行了以下命令：



```
sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out
```
运行该命令的目的，是把 mock_.* .go 文件中的函数单元测试信息从 coverage.out 中删除。mock_.*.go 文件中的函数是不需要单元测试的，如果不删除，就会影响后面的单元测试覆盖率的计算。



如果想检查单元测试覆盖率，请执行：


```
$ make cover
```
默认测试覆盖率至少为 60%，也可以在命令行指定覆盖率阈值为其他值，例如：


```
$ make cover COVERAGE=90
```
如果测试覆盖率不满足要求，就会返回以下错误信息：


```
test coverage is 62.1%
test coverage does not meet expectations: 90%, please add test cases!
make[1]: *** [go.test.cover] Error 1
make: *** [cover] Error 2
```
这里 make 命令的退出码为1。如果单元测试覆盖率达不到设置的阈值，就需要补充测试用例，否则禁止合并到 develop 和 master 分支。IAM 项目配置了 GitHub Actions CI 自动化流水线，CI 流水线会自动运行，检查单元测试覆盖率是否达到要求。


第八步，构建。最后，我们执行make build命令，构建出cmd/目录下所有的二进制安装文件。


```
$ make build
```
make build 会自动构建 cmd/ 目录下的所有组件，如果只想构建其中的一个或多个组件，可以传入 BINS选项，组件之间用空格隔开，并用双引号引起来：


```
$ make build BINS="iam-apiserver iamctl"
```
到这里，我们就完成了代码开发阶段的全部操作。如果你觉得手动执行的 make 命令比较多，可以直接执行 make 命令：


```
$ make
===========> Generating iam error code go source files
===========> Generating error code markdown documentation
===========> Generating missing doc.go for go packages
===========> Verifying the boilerplate headers for all files
===========> Formating codes
===========> Run golangci to lint source codes
===========> Run unit test
...
===========> Building binary iam-pump v0.7.2-24-g5814e7b for linux amd64
===========> Building binary iamctl v0.7.2-24-g5814e7b for linux amd64
...
```
直接执行make会执行伪目标all所依赖的伪目标 all: tidy gen add-copyright format lint cover build，也即执行以下操作：依赖包添加 / 删除、生成代码、自动添加版权头、代码格式化、静态代码检查、覆盖率测试、构建。


这里你需要**注意**一点：all 中依赖 cover，cover 实际执行的是 go.test.cover ，而 go.test.cover 又依赖 go.test ，所以 cover 实际上是先执行单元测试，再检查单元测试覆盖率是否满足预设的阈值。

最后补充一点，在开发阶段我们可以根据需要随时执行 make gen 、 make format 、 make lint 、 make cover 等操作，为的是能够提前发现问题并改正。

#### 代码提交
代码开发完成之后，我们就需要将代码提交到远程仓库，整个流程分为以下几个步骤。

第一步，开发完后，将代码提交到 feature/helloworld 分支，并 push 到远端仓库。



```
$ git add internal/iamctl/cmd/helloworld internal/iamctl/cmd/cmd.go
$ git commit -m "feat: add new iamctl command 'helloworld'"
$ git push origin feature/helloworld
```
这里我**建议**你只添加跟feature/helloworld相关的改动，这样就知道一个 commit 做了哪些变更，方便以后追溯。所以，我不**建议**直接执行git add .这类方式提交改动。


在提交 commit 时，commit-msg githooks 会检查 commit message 是否符合 Angular Commit Message 规范，如果不符合会报错。commit-msage 调用了go-gitlint来检查 commit message。go-gitlint 会读取 .gitlint 中配置的 commit message 格式：



```
--subject-regex=^((Merge branch.*of.*)|((revert: )?(feat|fix|perf|style|refactor|test|ci|docs|chore)(\(.+\))?: [^A-Z].*[^.]$))
--subject-maxlen=72
--body-regex=^([^\r\n]{0,72}(\r?\n|$))*$
```
IAM 项目配置了 GitHub Actions，当有代码被 push 后，会触发 CI 流水线，流水线会执行make all目标。GitHub Actions CI 流程执行记录如下图：![img](https://static001.geekbang.org/resource/image/68/22/6819f96bda8dcb214c3b7eeba2f37022.png?wh=2061x435)


如果 CI 不通过，就需要修改代码，直到 CI 流水线通过为止。这里，我们来看下 GitHub Actions 的配置：



```
name: IamCI

on: 
  push:
    branchs:
    - '*'
  pull_request:
    types: [opened, reopened]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2

    - name: Set up Go
      uses: actions/setup-go@v2
      with:
        go-version: 1.16

    - name: all
      run: make
```
可以看到，GitHub Actions 实际上执行了 3 步：拉取代码、设置 Go 编译环境、执行 make 命令（也就是执行 make all 目标）。


GitHub Actions 也执行了 make all 目标，和手动操作执行的 make all 目标保持一致，这样做是为了让线上的 CI 流程和本地的 CI 流程完全保持一致。这样，当我们在本地执行 make 命令通过后，在线上也会通过。保持一个一致的执行流程和执行结果很重要。否则，本地执行 make 通过，但是线上却不通过，岂不很让人头疼？


第二步，提交 pull request。登陆 GitHub，基于 feature/helloworld 创建 pull request，并指定 Reviewers 进行 code review。具体操作如下图：


![img](https://static001.geekbang.org/resource/image/53/ab/53f4103f5c8cabb76ef2fddaec3a54ab.png?wh=1694x733)


当有新的 pull request 被创建后，也会触发 CI 流水线。


第三步，创建完 pull request 后，就可以通知 reviewers 来 review 代码，GitHub 也会发站内信。第四步，Reviewers 对代码进行 review。


Reviewer 通过 review github diff 后的内容，并结合 CI 流程是否通过添加评论，并选择 Comment（仅评论）、Approve（通过）、Request Changes（不通过，需要修改），如下图所示：


![img](https://static001.geekbang.org/resource/image/39/ce/39d992c7bdb35848706bce792877e8ce.png?wh=2473x1001)


如果 review 不通过，feature 开发者可以直接在 feature/helloworld 分支修正代码，并 push 到远端的 feature/helloworld 分支，然后通知 reviewers 再次 review。因为有 push 事件发生，所以会触发 GitHub Actions CI 流水线。



第五步，code review 通过后，maintainer 就可以将新的代码合并到 develop 分支。使用 Create a merge commit 的方式，将 pull request 合并到 develop 分支，如下图所示：


![img](https://static001.geekbang.org/resource/image/30/7d/30de6bb6c8ff431ec56debbc0f5b667d.png?wh=1247x366)

Create a merge commit 的实际操作是 git merge --no-ff，feature/helloworld 分支上所有的 commit 都会加到 develop 分支上，并且会生成一个 merge commit。使用这种方式，可以清晰地知道是谁做了哪些提交，回溯历史的时候也会更加方便。


第六步，合并到 develop 分支后，触发 CI 流程。到这里，开发阶段的操作就全部完成了，整体流程如下：


![img](https://static001.geekbang.org/resource/image/44/73/444b0701f8866b50a49bd0138488c873.png?wh=1697x1028)

合并到 develop 分支之后，我们就可以进入开发阶段的下一阶段，也就是测试阶段了。


### 测试阶段
在测试阶段，开发人员主要负责提供测试包和修复测试期间发现的 bug，这个过程中也可能会发现一些新的需求或变动点，所以需要合理评估这些新的需求或变动点是否要放在当前迭代修改。

测试阶段的操作流程如下。第一步，基于 develop 分支，创建 release 分支，测试代码。


```
$ git checkout -b release/1.0.0 develop
$ make
```
第二步，提交测试。将 release/1.0.0 分支的代码提交给测试同学进行测试。这里假设一个测试失败的场景：我们要求打印“hello world”，但打印的是“Hello World”，需要修复。那具体应该怎么操作呢？


你可以直接在 release/1.0.0 分支修改代码，修改完成后，本地构建并提交代码：


```
$ make
$ git add internal/iamctl/cmd/helloworld/
$ git commit -m "fix: fix helloworld print bug"
$ git push origin release/1.0.0
```
push 到 release/1.0.0 后，GitHub Actions 会执行 CI 流水线。如果流水线执行成功，就将代码提供给测试；如果测试不成功，再重新修改，直到流水线执行成功。


测试同学会对 release/1.0.0 分支的代码进行充分的测试，例如功能测试、性能测试、集成测试、系统测试等。


第三步，测试通过后，将功能分支合并到 master 分支和 develop 分支。



```
$ git checkout develop
$ git merge --no-ff release/1.0.0
$ git checkout master
$ git merge --no-ff release/1.0.0
$ git tag -a v1.0.0 -m "add print hello world" # master分支打tag
```
到这里，测试阶段的操作就基本完成了。测试阶段的产物是 master/develop 分支的代码。



第四步，删除 feature/helloworld 分支，也可以选择性删除 release/1.0.0 分支。我们的代码都合并入 master/develop 分支后，feature 开发者可以选择是否要保留 feature。不过，如果没有特别的原因，我**建议**删掉，因为 feature 分支太多的话，不仅看起来很乱，还会影响性能，删除操作如下：


```
$ git branch -d feature/helloworld
```
### IAM 项目的 Makefile 项目管理技巧
在上面的内容中，我们以研发流程为主线，亲身体验了 IAM 项目的 Makefile 项目管理功能。这些是你最应该掌握的核心功能，但 IAM 项目的 Makefile 还有很多功能和设计技巧。接下来，我会给你分享一些很有价值的 Makefile 项目管理技巧。


#### help 自动解析
因为随着项目的扩展，Makefile 大概率会不断加入新的管理功能，这些管理功能也需要加入到 make help 输出中。但如果每添加一个目标，都要修改 make help 命令，就比较麻烦，还容易出错。所以这里，我通过自动解析的方式，来生成make help输出：



```
## help: Show this help info.    
.PHONY: help           
help: Makefile               
  @echo -e "\nUsage: make <TARGETS> <OPTIONS> ...\n\nTargets:"                         
  @sed -n 's/^##//p' $< | column -t -s ':' | sed -e 's/^/ /'    
  @echo "$$USAGE_OPTIONS"    
```
目标 help 的命令中，通过 sed -n 's/^##//p' $< | column -t -s ':' | sed -e 's/^/ /' 命令，自动解析 Makefile 中 ## 开头的注释行，从而自动生成 make help 输出。


#### Options 中指定变量值
通过以下赋值方式，变量可以在 Makefile options 中被指定：


```
ifeq ($(origin COVERAGE),undefined)    
COVERAGE := 60    
endif   
```
例如，如果我们执行make ，则 COVERAGE 设置为默认值 60；如果我们执行make COVERAGE=90 ，则 COVERAGE 值为 90。通过这种方式，我们可以更灵活地控制 Makefile 的行为。


#### 自动生成 CHANGELOG
一个项目最好有 CHANGELOG 用来展示每个版本之间的变更内容，作为 Release Note 的一部分。但是，如果每次都要手动编写 CHANGELOG，会很麻烦，也不容易坚持，所以这里我们可以借助git-chglog工具来自动生成。

IAM 项目的 git-chglog 工具的配置文件放在.chglog目录下，在学习 git-chglog 工具时，你可以参考下。


#### 自动生成版本号
一个项目也需要有一个版本号，当前用得比较多的是语义化版本号规范。但如果靠开发者手动打版本号，工作效率低不说，经常还会出现漏打、打的版本号不规范等问题。所以最好的办法是，版本号也通过工具自动生成。在 IAM 项目中，采用了gsemver工具来自动生成版本号。


整个 IAM 项目的版本号，都是通过scripts/ensure_tag.sh脚本来生成的：


```
version=v`gsemver bump`
if [ -z "`git tag -l $version`" ];then
  git tag -a -m "release version $version" $version
fi
```
在 scripts/ensure_tag.sh 脚本中，通过 gsemver bump 命令来自动化生成语义化的版本号，并执行 git tag -a 给仓库打上版本号标签，gsemver 命令会根据 Commit Message 自动生成版本号。

之后，Makefile 和 Shell 脚本用到的所有版本号均统一使用scripts/make-rules/common.mk文件中的 VERSION 变量：



```
VERSION := $(shell git describe --tags --always --match='v*')
```
上述的 Shell 命令通过 git describe 来获取离当前提交最近的 tag（版本号）。


在执行 git describe 时，如果符合条件的 tag 指向最新提交，则只显示 tag 的名字，否则会有相关的后缀，来描述该 tag 之后有多少次提交，以及最新的提交 commit id。例如：


```
$ git describe --tags --always --match='v*'
v1.0.0-3-g1909e47
```
这里解释下版本号中各字符的含义：3：表示自打 tag v1.0.0 以来有 3 次提交。g1909e47：g 为 git 的缩写，在多种管理工具并存的环境中很有用处。1909e47：7 位字符表示为最新提交的 commit id 前 7 位。


最后解释下参数：–tags，使用所有的标签，而不是只使用带注释的标签（annotated tag）。git tag 生成一个 unannotated tag，git tag -a -m '' 生成一个 annotated tag。–always，如果仓库没有可用的标签，那么使用 commit 缩写来替代标签。–match，只考虑与给定模式相匹配的标签。



#### 保持行为一致
上面我们介绍了一些管理功能，例如检查 Commit Message 是否符合规范、自动生成 CHANGELOG、自动生成版本号。这些可以通过 Makefile 来操作，我们也可以手动执行。例如，通过以下命令，检查 IAM 的所有 Commit 是否符合 Angular Commit Message 规范：



```
$ go-gitlint
b62db1f: subject does not match regex [^(revert: )?(feat|fix|perf|style|refactor|test|ci|docs|chore)(\(.+\))?: [^A-Z].*[^.]$]
```
也可以通过以下命令，手动来生成 CHANGELOG：


```
$ git-chglog v1.0.0 CHANGELOG/CHANGELOG-1.0.0.md
```
还可以执行 gsemver 来生成版本号：


```
$ gsemver bump
1.0.1
```
这里要强调的是，我们要保证不管使用手动操作，还是通过 Makefile 操作，都要确保 git commit message 规范检查结果、生成的 CHANGELOG、生成的版本号是一致的。这需要我们采用同一种操作方式。


### 总结
在整个研发流程中，需要开发人员深度参与的阶段有两个，分别是开发阶段和测试阶段。在开发阶段，开发者完成代码开发之后，通常需要执行生成代码、版权检查、代码格式化、静态代码检查、单元测试、构建等操作。我们可以将这些操作集成在 Makefile 中，来提高效率，并借此统一操作。


另外，IAM 项目在编写 Makefile 时也采用了一些技巧，例如make help 命令中，help 信息是通过解析 Makefile 文件的注释来完成的；可以通过 git-chglog 自动生成 CHANGELOG；通过 gsemver 自动生成语义化的版本号等。

## 16 | 代码检查：如何进行静态代码检查？
在做 Go 项目开发的过程中，我们肯定需要对 Go 代码做静态代码检查。虽然 Go 命令提供了 go vet 和 go tool vet，但是它们检查的内容还不够全面，我们需要一种更加强大的静态代码检查工具。


其实，Go 生态中有很多这样的工具，也不乏一些比较优秀的。今天我想给你介绍的 golangci-lint，是目前使用最多，也最受欢迎的静态代码检查工具，我们的 IAM 实战项目也用到了它。


接下来，我就从 golangci-lint 的优点、golangci-lint 提供的命令和选项、golangci-lint 的配置这三个方面来向你介绍下它。在你了解这些基础知识后，我会带着你使用 golangci-lint 进行静态代码检查，让你熟悉操作，在这个基础上，再把我使用 golangci-lint 时总结的一些经验技巧分享给你。


### 为什么选择 golangci-lint 做静态代码检查？
选择 golangci-lint，是因为它具有其他静态代码检查工具不具备的一些优点。在我看来，它的核心优点至少有这些：


- 速度非常快：golangci-lint 是基于 gometalinter 开发的，但是平均速度要比 gometalinter 快 5 倍。golangci-lint 速度快的原因有三个：可以并行检查代码；可以复用 go build 缓存；会缓存分析结果。
- 可配置：支持 YAML 格式的配置文件，让检查更灵活，更可控。
- IDE 集成：可以集成进多个主流的 IDE，例如 VS Code、GNU Emacs、Sublime Text、Goland 等。
- linter 聚合器：1.41.1 版本的 golangci-lint 集成了 76 个 linter，不需要再单独安装这 76 个 linter。并且 golangci-lint 还支持自定义 linter。
- 最小的误报数：golangci-lint 调整了所集成 linter 的默认设置，大幅度减少了误报。
- 良好的输出：输出的结果带有颜色、代码行号和 linter 标识，易于查看和定位。


下图是一个 golangci-lint 的检查结果：


![img](https://static001.geekbang.org/resource/image/ed/d4/ed9c1d775e31a8a5b60a5a6882d0bed4.png?wh=2527x563)

你可以看到，输出的检查结果中包括如下信息：检查出问题的源码文件、行号和错误行内容。出问题的原因，也就是打印出不符合检查规则的原因。报错的 linter。


通过查看 golangci-lint 的输出结果，可以准确地定位到报错的位置，快速弄明白报错的原因，方便开发者修复。


除了上述优点之外，在我看来 golangci-lint 还有一个非常大的优点：当前更新迭代速度很快，不断有新的 linter 被集成到 golangci-lint 中。有这么全的 linter 为你的代码保驾护航，你在交付代码时肯定会更有自信。


目前，有很多公司 / 项目使用了 golangci-lint 工具作为静态代码检查工具，例如 Google、Facebook、Istio、Red Hat OpenShift 等。


### golangci-lint 提供了哪些命令和选项？
在使用之前，首先需要安装 golangci-lint。golangci-lint 的安装方法也很简单，你只需要执行以下命令，就可以安装了。



```
$ go get github.com/golangci/golangci-lint/cmd/golangci-lint@v1.41.1
$ golangci-lint version # 输出 golangci-lint 版本号，说明安装成功
golangci-lint has version v1.39.0 built from (unknown, mod sum: "h1:aAUjdBxARwkGLd5PU0vKuym281f2rFOyqh3GB4nXcq8=") on (unknown)
```
这里**注意**，为了避免安装失败，强烈**建议**你安装 golangci-lint releases page 中的指定版本，例如 v1.41.1。另外，还**建议**你定期更新 golangci-lint 的版本，因为该项目正在被积极开发并不断改进。安装之后，就可以使用了。我们可以通过执行 golangci-lint -h 查看其用法，golangci-lint 支持的子命令见下表：


![img](https://static001.geekbang.org/resource/image/34/42/34617a68604b7b5613948f89230c7a42.png?wh=1376x1015)

此外，golangci-lint 还支持一些全局选项。全局选项是指适用于所有子命令的选项，golangci-lint 支持的全局选项如下：


![img](https://static001.geekbang.org/resource/image/79/88/79e517e6a7fd3882ce30320f28aa7088.png?wh=1339x1063)

接下来，我就详细介绍下 golangci-lint 支持的核心子命令：run、cache、completion、config、linters。


#### run 命令
run 命令执行 golangci-lint，对代码进行检查，是 golangci-lint 最为核心的一个命令。run 没有子命令，但有很多选项。run 命令的具体使用方法，我会在讲解如何执行静态代码检查的时候详细介绍。


#### cache 命令
cache 命令用来进行缓存控制，并打印缓存的信息。它包含两个子命令：clean 用来清除 cache，当我们觉得 cache 的内容异常，或者 cache 占用空间过大时，可以通过golangci-lint cache clean清除 cache。status 用来打印 cache 的状态，比如 cache 的存放目录和 cache 的大小，例如：


```
$ golangci-lint cache status
Dir: /home/colin/.cache/golangci-lint
Size: 773.4KiB
```
#### completion 命令
completion 命令包含 4 个子命令 bash、fish、powershell 和 zsh，分别用来输出 bash、fish、powershell 和 zsh 的自动补全脚本。


下面是一个配置 bash 自动补全的示例：



```
$ golangci-lint completion bash > ~/.golangci-lint.bash
$ echo "source '$HOME/.golangci-lint.bash'" >> ~/.bashrc
$ source ~/.bashrc
```
执行完上面的命令，键入如下命令，即可自动补全子命令：


```
$ golangci-lint comp<TAB>
```
上面的命令行会自动补全为golangci-lint completion 。


#### config 命令
config 命令可以打印 golangci-lint 当前使用的配置文件路径，例如：


```
$ golangci-lint config path
.golangci.yaml
```
#### linters 命令
linters 命令可以打印出 golangci-lint 所支持的 linter，并将这些 linter 分成两类，分别是配置为启用的 linter 和配置为禁用的 linter，例如：


```
$ golangci-lint linters
Enabled by your configuration linters:
...
deadcode: Finds unused code [fast: true, auto-fix: false]
...
Disabled by your configuration linters:
exportloopref: checks for pointers to enclosing loop variables [fast: true, auto-fix: false]
...
```
上面我介绍了 golangci-lint 提供的命令，接下来，我们再来看下 golangci-lint 的配置。


#### golangci-lint 配置
和其他 linter 相比，golangci-lint 一个非常大的优点是使用起来非常灵活，这要得益于它对自定义配置的支持。


golangci-lint 支持两种配置方式，分别是命令行选项和配置文件。如果 bool/string/int 的选项同时在命令行选项和配置文件中被指定，命令行的选项就会覆盖配置文件中的选项。如果是 slice 类型的选项，则命令行和配置中的配置会进行合并。golangci-lint run 支持很多命令行选项，可通过golangci-lint run -h查看，这里选择一些比较重要的选项进行介绍，见下表：


![img](https://static001.geekbang.org/resource/image/ac/fa/ac6098cf64cde7b8326cfd3508b04dfa.jpg?wh=2284x3988)

此外，我们还可以通过 golangci-lint配置文件进行配置，默认的配置文件名为.golangci.yaml、.golangci.toml、.golangci.json，可以通过-c选项指定配置文件名。通过配置文件，可以实现下面几类功能：


- golangci-lint 本身的一些选项，比如超时、并发，是否检查*_test.go文件等。
- 配置需要忽略的文件和文件夹。
- 配置启用哪些 linter，禁用哪些 linter。
- 配置输出格式。
- golangci-lint 支持很多 linter，其中有些 linter 支持一些配置项，这些配置项可以在配置文件中配置。
- 配置符合指定正则规则的文件可以忽略的 linter。
- 设置错误严重级别，像日志一样，检查错误也是有严重级别的。


更详细的配置内容，你可以参考Configuration。另外，你也可以参考 IAM 项目的 golangci-lint 配置.golangci.yaml。.golangci.yaml 里面的一些配置，我**建议**你一定要设置，具体如下：


```
yaml
run:
  skip-dirs: # 设置要忽略的目录
    - util
    - .*~
    - api/swagger/docs
  skip-files: # 设置不需要检查的go源码文件，支持正则匹配，这里**建议**包括：_test.go
    - ".*\\.my\\.go$"
    - _test.go
linters-settings:
  errcheck:
    check-type-assertions: true # 这里**建议**设置为true，如果确实不需要检查，可以写成`num, _ := strconv.Atoi(numStr)`
    check-blank: false
  gci:
    # 将以`github.com/marmotedu/iam`开头的包放在第三方包后面
    local-prefixes: github.com/marmotedu/iam
  godox:
    keywords: # **建议**设置为BUG、FIXME、OPTIMIZE、HACK
      - BUG
      - FIXME
      - OPTIMIZE
      - HACK
  goimports:
    # 设置哪些包放在第三方包后面，可以设置多个包，逗号隔开
    local-prefixes: github.com/marmotedu/iam
  gomoddirectives: # 设置允许在go.mod中replace的包
    replace-local: true
    replace-allow-list:
      - github.com/coreos/etcd
      - google.golang.org/grpc
      - github.com/marmotedu/api
      - github.com/marmotedu/component-base
      - github.com/marmotedu/marmotedu-sdk-go
  gomodguard: # 下面是根据需要选择可以使用的包和版本，**建议**设置
    allowed:
      modules:
        - gorm.io/gorm
        - gorm.io/driver/mysql
        - k8s.io/klog
      domains: # List of allowed module domains
        - google.golang.org
        - gopkg.in
        - golang.org
        - github.com
        - go.uber.org
    blocked:
      modules:
        - github.com/pkg/errors:
            recommendations:
              - github.com/marmotedu/errors
            reason: "`github.com/marmotedu/errors` is the log package used by marmotedu projects."
      versions:
        - github.com/MakeNowJust/heredoc:
            version: "> 2.0.9"
            reason: "use the latest version"
      local_replace_directives: false
  lll:
    line-length: 240 # 这里可以设置为240，240一般是够用的
  importas: # 设置包的alias，根据需要设置
    jwt: github.com/appleboy/gin-jwt/v2         
    metav1: github.com/marmotedu/component-base/pkg/meta/v1
```
需要**注意**的是，golangci-lint 不**建议**使用 enable-all: true 选项，为了尽可能使用最全的 linters，我们可以使用以下配置：



```
yaml
linters: 
  disable-all: true  
  enable: # enable下列出 <期望的所有linters>
    - typecheck
    - ... 

```
<期望的所有linters> = - <不期望执行的linters>，我们可以通过执行以下命令来获取：



```
$ ./scripts/print_enable_linters.sh
    - asciicheck
    - bodyclose
    - cyclop
    - deadcode
    - ...
```
将以上输出结果替换掉.golangci.yaml 配置文件中的 linters.enable 部分即可。


上面我们介绍了与 golangci-lint 相关的一些基础知识，接下来我就给你详细展示下，如何使用 golangci-lint 进行静态代码检查。


### 如何使用 golangci-lint 进行静态代码检查？
要对代码进行静态检查，只需要执行 golangci-lint run 命令即可。接下来，我会先给你介绍 5 种常见的 golangci-lint 使用方法。


对当前目录及子目录下的所有 Go 文件进行静态代码检查：


```
$ golangci-lint run
```
命令等效于golangci-lint run ./...。


对指定的 Go 文件或者指定目录下的 Go 文件进行静态代码检查：

```
$ golangci-lint run dir1 dir2/... dir3/file1.go
```
这里需要你**注意**：上述命令不会检查 dir1 下子目录的 Go 文件，如果想递归地检查一个目录，需要在目录后面追加/...，例如：dir2/...。

根据指定配置文件，进行静态代码检查：


```
$ golangci-lint run -c .golangci.yaml ./...
```
运行指定的 linter：
golangci-lint 可以在不指定任何配置文件的情况下运行，这会运行默认启用的 linter，你可以通过golangci-lint help linters查看它。


你可以传入参数-E/--enable来使某个 linter 可用，也可以使用-D/--disable参数来使某个 linter 不可用。下面的示例仅仅启用了 errcheck linter：


```
$ golangci-lint run --no-config --disable-all -E errcheck ./...
```
这里你需要**注意**，默认情况下，golangci-lint 会从当前目录一层层往上寻找配置文件名.golangci.yaml、.golangci.toml、.golangci.json直到根（/）目录。如果找到，就以找到的配置文件作为本次运行的配置文件，所以为了防止读取到未知的配置文件，可以用 --no-config 参数使 golangci-lint 不读取任何配置文件。


禁止运行指定的 liner：如果我们想禁用某些 linter，可以使用-D选项。


```
$ golangci-lint run --no-config -D godot,errcheck
```
在使用 golangci-lint 进行代码检查时，可能会有很多误报。所谓的误报，其实是我们希望 golangci-lint 的一些 linter 能够容忍某些 issue。那么如何尽可能减少误报呢？golangci-lint 也提供了一些途径，我**建议**你使用下面这三种：

在命令行中添加-e参数，或者在配置文件的issues.exclude部分设置要排除的检查错误。你也可以使用issues.exclude-rules来配置哪些文件忽略哪些 linter。通过run.skip-dirs、run.skip-files或者issues.exclude-rules配置项，来忽略指定目录下的所有 Go 文件，或者指定的 Go 文件。通过在 Go 源码文件中添加//nolint注释，来忽略指定的代码行。

因为 golangci-lint 设置了很多 linters，对于一个大型项目，启用所有的 linter 会检查出很多问题，并且每个项目对 linter 检查的粒度要求也不一样，所以 glangci-lint使用 nolint 标记来开关某些检查项，不同位置的 nolint 标记效果也会不一样。接下来我想向你介绍 nolint 的几种用法。

忽略某一行所有 linter 的检查


```
var bad_name int //nolint
```
忽略某一行指定 linter 的检查，可以指定多个 linter，用逗号 , 隔开。


```
var bad_name int //nolint:golint,unused
```
忽略某个代码块的检查。


```
//nolint
func allIssuesInThisFunctionAreExcluded() *string {
  // ...
}

//nolint:govet
var (
  a int
  b int
)
```
忽略某个文件的指定 linter 检查。在 package xx 上面一行添加//nolint注释。


```
//nolint:unparam
package pkg
...
```
在使用 nolint 的过程中，有 3 个地方需要你**注意**。首先，如果启用了 nolintlint，你就需要在//nolint后面添加 nolint 的原因// xxxx。其次，你使用的应该是//nolint而不是// nolint。因为根据 Go 的规范，需要程序读取的注释 // 后面不应该有空格。最后，如果要忽略所有 linter，可以用//nolint；如果要忽略某个指定的 linter，可以用//nolint:,。



#### golangci-lint 使用技巧
我在使用 golangci-lint 时，总结了一些经验技巧，放在这里供你参考，希望能够帮助你更好地使用 golangci-lint。


技巧 1：第一次修改，可以按目录修改。如果你第一次使用 golangci-lint 检查你的代码，一定会有很多错误。为了减轻修改的压力，可以按目录检查代码并修改。这样可以有效减少失败条数，减轻修改压力。当然，如果错误太多，一时半会儿改不完，想以后慢慢修改或者干脆不修复存量的 issues，那么你可以使用 golangci-lint 的 --new-from-rev 选项，只检查新增的 code，例如：


```
$ golangci-lint run --new-from-rev=HEAD~1
```
技巧 2：按文件修改，减少文件切换次数，提高修改效率。如果有很多检查错误，涉及很多文件，**建议**先修改一个文件，这样就不用来回切换文件。可以通过 grep 过滤出某个文件的检查失败项，例如：


```
$ golangci-lint run ./...|grep pkg/storage/redis_cluster.go
pkg/storage/redis_cluster.go:16:2: "github.com/go-redis/redis/v7" imported but not used (typecheck)
pkg/storage/redis_cluster.go:82:28: undeclared name: `redis` (typecheck)
pkg/storage/redis_cluster.go:86:14: undeclared name: `redis` (typecheck)
...
```
技巧 3：把 linters-setting.lll.line-length 设置得大一些。在 Go 项目开发中，为了易于阅读代码，通常会将变量名 / 函数 / 常量等命名得有意义，这样很可能导致每行的代码长度过长，很容易超过lll linter 设置的默认最大长度 80。这里**建议**将linters-setting.lll.line-length设置为 120/240。



技巧 4：尽可能多地使用 golangci-lint 提供的 linter。golangci-lint 集成了很多 linters，可以通过如下命令查看：


```
$ golangci-lint linters
Enabled by your configuration linters:
deadcode: Finds unused code [fast: true, auto-fix: false]
...
varcheck: Finds unused global variables and constants [fast: true, auto-fix: false]

Disabled by your configuration linters:
asciicheck: Simple linter to check that your code does not contain non-ASCII identifiers [fast: true, auto-fix: false]
...
wsl: Whitespace Linter - Forces you to use empty lines! [fast: true, auto-fix: false]
```
这些 linter 分为两类，一类是默认启用的，另一类是默认禁用的。每个 linter 都有两个属性：
- fast：true/false，如果为 true，说明该 linter 可以缓存类型信息，支持快速检查。因为第一次缓存了这些信息，所以后续的运行会非常快。
- auto-fix：true/false，如果为 true 说明该 linter 支持自动修复发现的错误；如果为 false 说明不支持自动修复。


如果配置了 golangci-lint 配置文件，则可以通过命令golangci-lint help linters查看在当前配置下启用和禁用了哪些 linter。golangci-lint 也支持自定义 linter 插件，具体你可以参考：New linters。


在使用 golangci-lint 的时候，我们要尽可能多的使用 linter。使用的 linter 越多，说明检查越严格，意味着代码越规范，质量越高。如果时间和精力允许，**建议**打开 golangci-lint 提供的所有 linter。


技巧 5：每次修改代码后，都要执行 golangci-lint。每次修改完代码后都要执行 golangci-lint，一方面可以及时修改不规范的地方，另一方面可以减少错误堆积，减轻后面的修改压力。

技巧 6：**建议**在根目录下放一个通用的 golangci-lint 配置文件。在/目录下存放通用的 golangci-lint 配置文件，可以让你不用为每一个项目都配置 golangci-lint。当你需要为某个项目单独配置 golangci-lint 时，只需在该项目根目录下增加一个项目级别的 golangci-lint 配置文件即可。



### 总结
Go 项目开发中，对代码进行静态代码检查是必要的操作。当前有很多优秀的静态代码检查工具，但 golangci-lint 因为具有检查速度快、可配置、少误报、内置了大量 linter 等优点，成为了目前最受欢迎的静态代码检查工具。


golangci-lint 功能非常强大，支持诸如 run、cache、completion、linters 等命令。其中最常用的是 run 命令，run 命令可以通过以下方式来进行静态代码检查：


```
$ golangci-lint run #  对当前目录及子目录下的所有Go文件进行静态代码检查
$ golangci-lint run dir1 dir2/... dir3/file1.go # 对指定的Go文件或者指定目录下的Go文件进行静态代码检查
$ golangci-lint run -c .golangci.yaml ./... # 根据指定配置文件，进行静态代码检查
$ golangci-lint run --no-config --disable-all -E errcheck ./... # 运行指定的 errcheck linter
$ golangci-lint run --no-config -D godot,errcheck # 禁止运行指定的godot,errcheck liner
```
此外，golangci-lint 还支持 //nolint 、//nolint:golint,unused 等方式来减少误报。最后，我分享了一些自己使用 golangci-lint 时总结的经验。例如：第一次修改，可以按目录修改；按文件修改，减少文件切换次数，提高修改效率；尽可能多地使用 golangci-lint 提供的 linter。希望这些**建议**对你使用 golangci-lint 有一定帮助。

## 17 | API 文档：如何生成 Swagger API 文档 ？
作为一名开发者，我们通常讨厌编写文档，因为这是一件重复和缺乏乐趣的事情。但是在开发过程中，又有一些文档是我们必须要编写的，比如 API 文档。

一个企业级的 Go 后端项目，通常也会有个配套的前端。为了加快研发进度，通常是后端和前端并行开发，这就需要后端开发者在开发后端代码之前，先设计好 API 接口，提供给前端。所以在设计阶段，我们就需要生成 API 接口文档。



一个好的 API 文档，可以减少用户上手的复杂度，也意味着更容易留住用户。好的 API 文档也可以减少沟通成本，帮助开发者更好地理解 API 的调用方式，从而节省时间，提高开发效率。这时候，我们一定希望有一个工具能够帮我们自动生成 API 文档，解放我们的双手。Swagger 就是这么一个工具，可以帮助我们生成易于共享且具有足够描述性的 API 文档。


接下来，我们就来看下，如何使用 Swagger 生成 API 文档。


### Swagger 介绍
Swagger 是一套围绕 OpenAPI 规范构建的开源工具，可以设计、构建、编写和使用 REST API。Swagger 包含很多工具，其中主要的 Swagger 工具包括：

- Swagger 编辑器：基于浏览器的编辑器，可以在其中编写 OpenAPI 规范，并实时预览 API 文档。https://editor.swagger.io 就是一个 Swagger 编辑器，你可以尝试在其中编辑和预览 API 文档。
- Swagger UI：将 OpenAPI 规范呈现为交互式 API 文档，并可以在浏览器中尝试 API 调用。
- Swagger Codegen：根据 OpenAPI 规范，生成服务器存根和客户端代码库，目前已涵盖了 40 多种语言。


### Swagger 和 OpenAPI 的区别
我们在谈到 Swagger 时，也经常会谈到 OpenAPI。那么二者有什么区别呢？


OpenAPI 是一个 API 规范，它的前身叫 Swagger 规范，通过定义一种用来描述 API 格式或 API 定义的语言，来规范 RESTful 服务开发过程，目前最新的 OpenAPI 规范是OpenAPI 3.0（也就是 Swagger 2.0 规范）。

OpenAPI 规范规定了一个 API 必须包含的基本信息，这些信息包括：对 API 的描述，介绍 API 可以实现的功能。每个 API 上可用的路径（/users）和操作（GET /users，POST /users）。每个 API 的输入 / 返回的参数。验证方法。联系信息、许可证、使用条款和其他信息。


所以，你可以简单地这么理解：OpenAPI 是一个 API 规范，Swagger 则是实现规范的工具。另外，要编写 Swagger 文档，首先要会使用 Swagger 文档编写语法，因为语法比较多，这里就不多介绍了，你可以参考 Swagger 官方提供的[OpenAPI Specification](https://swagger.io/specification/)来学习。


### 用 go-swagger 来生成 Swagger API 文档
在 Go 项目开发中，我们可以通过下面两种方法来生成 Swagger API 文档：


第一，如果你熟悉 Swagger 语法的话，可以直接编写 JSON/YAML 格式的 Swagger 文档。**建议**选择 YAML 格式，因为它比 JSON 格式更简洁直观。第二，通过工具生成 Swagger 文档，目前可以通过swag和go-swagger两个工具来生成。


对比这两种方法，直接编写 Swagger 文档，不比编写 Markdown 格式的 API 文档工作量小，我觉得不符合程序员“偷懒”的习惯。所以，本专栏我们就使用 go-swagger 工具，基于代码注释来自动生成 Swagger 文档。为什么选 go-swagger 呢？有这么几个原因：


go-swagger 比 swag 功能更强大：go-swagger 提供了更灵活、更多的功能来描述我们的 API。使我们的代码更易读：如果使用 swag，我们每一个 API 都需要有一个冗长的注释，有时候代码注释比代码还要长，但是通过 go-swagger 我们可以将代码和注释分开编写，一方面可以使我们的代码保持简洁，清晰易读，另一方面我们可以在另外一个包中，统一管理这些 Swagger API 文档定义。更好的社区支持：go-swagger 目前有非常多的 Github star 数，出现 Bug 的概率很小，并且处在一个频繁更新的活跃状态。


你已经知道了，go-swagger 是一个功能强大的、高性能的、可以根据代码注释生成 Swagger API 文档的工具。除此之外，go-swagger 还有很多其他特性：


根据 Swagger 定义文件生成服务端代码。根据 Swagger 定义文件生成客户端代码。校验 Swagger 定义文件是否正确。启动一个 HTTP 服务器，使我们可以通过浏览器访问 API 文档。根据 Swagger 文档定义的参数生成 Go model 结构体定义。

可以看到，使用 go-swagger 生成 Swagger 文档，可以帮助我们减少编写文档的时间，提高开发效率，并能保证文档的及时性和准确性。这里需要**注意**，如果我们要对外提供 API 的 Go SDK，可以考虑使用 go-swagger 来生成客户端代码。但是我觉得 go-swagger 生成的服务端代码不够优雅，所以**建议**你自行编写服务端代码。

目前，有很多知名公司和组织的项目都使用了 go-swagger，例如 Moby、CoreOS、Kubernetes、Cilium 等。


#### 安装 Swagger 工具
go-swagger 通过 swagger 命令行工具来完成其功能，swagger 安装方法如下：


```
$ go get -u github.com/go-swagger/go-swagger/cmd/swagger
$ swagger version
dev
```
#### swagger 命令行工具介绍
swagger 命令格式为swagger [OPTIONS] 。可以通过swagger -h查看 swagger 使用帮助。swagger 提供的子命令及功能见下表：


![img](https://static001.geekbang.org/resource/image/yy/78/yy3428aa968c7029cb4f6b11f2596678.png?wh=1176x1180)

#### 如何使用 swagger 命令生成 Swagger 文档？
go-swagger 通过解析源码中的注释来生成 Swagger 文档，go-swagger 的详细注释语法可参考官方文档。常用的有如下几类注释语法：


![img](https://static001.geekbang.org/resource/image/94/b3/947262c5175f6f518ff677063af293b3.png?wh=1087x1134)


#### 解析注释生成 Swagger 文档
swagger generate 命令会找到 main 函数，然后遍历所有源码文件，解析源码中与 Swagger 相关的注释，然后自动生成 swagger.json/swagger.yaml 文件。这一过程的示例代码为gopractise-demo/swagger。目录下有一个 main.go 文件，定义了如下 API 接口：


```go
package main

import (
    "fmt"
    "log"
    "net/http"

    "github.com/gin-gonic/gin"

    "github.com/marmotedu/gopractise-demo/swagger/api"
    // This line is necessary for go-swagger to find your docs!
    _ "github.com/marmotedu/gopractise-demo/swagger/docs"
)

var users []*api.User

func main() {
    r := gin.Default()
    r.POST("/users", Create)
    r.GET("/users/:name", Get)

    log.Fatal(r.Run(":5555"))
}

// Create create a user in memory.
func Create(c *gin.Context) {
    var user api.User
    if err := c.ShouldBindJSON(&user); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"message": err.Error(), "code": 10001})
        return
    }

    for _, u := range users {
        if u.Name == user.Name {
            c.JSON(http.StatusBadRequest, gin.H{"message": fmt.Sprintf("user %s already exist", user.Name), "code": 10001})
            return
        }
    }

    users = append(users, &user)
    c.JSON(http.StatusOK, user)
}

// Get return the detail information for a user.
func Get(c *gin.Context) {
    username := c.Param("name")
    for _, u := range users {
        if u.Name == username {
            c.JSON(http.StatusOK, u)
            return
        }
    }

    c.JSON(http.StatusBadRequest, gin.H{"message": fmt.Sprintf("user %s not exist", username), "code": 10002})
}
```
main 包中引入的 User struct 位于 gopractise-demo/swagger/api 目录下的user.go文件：


```go
// Package api defines the user model.
package api

// User represents body of User request and response.
type User struct {
    // User's name.
    // Required: true
    Name string `json:"name"`

    // User's nickname.
    // Required: true
    Nickname string `json:"nickname"`

    // User's address.
    Address string `json:"address"`

    // User's email.
    Email string `json:"email"`
}
```
// Required: true说明字段是必须的，生成 Swagger 文档时，也会在文档中声明该字段是必须字段。为了使代码保持简洁，我们在另外一个 Go 包中编写带 go-swagger 注释的 API 文档。假设该 Go 包名字为 docs，在开始编写 Go API 注释之前，需要在 main.go 文件中导入 docs 包：


```
_ "github.com/marmotedu/gopractise-demo/swagger/docs"

```
通过导入 docs 包，可以使 go-swagger 在递归解析 main 包的依赖包时，找到 docs 包，并解析包中的注释。在 gopractise-demo/swagger 目录下，创建 docs 文件夹：


```
$ mkdir docs
$ cd docs
```
在 docs 目录下，创建一个 doc.go 文件，在该文件中提供 API 接口的基本信息：


```go
// Package docs awesome.
//
// Documentation of our awesome API.
//
//     Schemes: http, https
//     BasePath: /
//     Version: 0.1.0
//     Host: some-url.com
//
//     Consumes:
//     - application/json
//
//     Produces:
//     - application/json
//
//     Security:
//     - basic
//
//    SecurityDefinitions:
//    basic:
//      type: basic
//
// swagger:meta
package docs
```
Package docs 后面的字符串 awesome 代表我们的 HTTP 服务名。Documentation of our awesome API是我们 API 的描述。其他都是 go-swagger 可识别的注释，代表一定的意义。最后以swagger:meta注释结束。


编写完 doc.go 文件后，进入 gopractise-demo/swagger 目录，执行如下命令，生成 Swagger API 文档，并启动 HTTP 服务，在浏览器查看 Swagger：



```
$ swagger generate spec -o swagger.yaml
$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml

2020/10/20 23:16:47 serving docs at http://localhost:36666/docs
```
- -o：指定要输出的文件名。swagger 会根据文件名后缀.yaml 或者.json，决定生成的文件格式为 YAML 或 JSON。
- –no-open：因为是在 Linux 服务器下执行命令，没有安装浏览器，所以使–no-open 禁止调用浏览器打开 URL。
- -F：指定文档的风格，可选 swagger 和 redoc。我选用了 redoc，因为觉得 redoc 格式更加易读和清晰。
- –port：指定启动的 HTTP 服务监听端口。


打开浏览器，访问http://localhost:36666/docs ，如下图所示：


![img](https://static001.geekbang.org/resource/image/9a/2c/9a9fb7a31d418d8e4dc13b19cefa832c.png?wh=2524x699)

如果我们想要 JSON 格式的 Swagger 文档，可执行如下命令，将生成的 swagger.yaml 转换为 swagger.json：

```
$ swagger generate spec -i ./swagger.yaml -o ./swagger.json
```
接下来，我们就可以编写 API 接口的定义文件（位于[gopractise-demo/swagger/docs/user.go](https://github.com/marmotedu/gopractise-demo/blob/main/swagger/docs/user.go)文件中）：


```go
package docs

import (
    "github.com/marmotedu/gopractise-demo/swagger/api"
)

// swagger:route POST /users user createUserRequest
// Create a user in memory.
// responses:
//   200: createUserResponse
//   default: errResponse

// swagger:route GET /users/{name} user getUserRequest
// Get a user from memory.
// responses:
//   200: getUserResponse
//   default: errResponse

// swagger:parameters createUserRequest
type userParamsWrapper struct {
    // This text will appear as description of your request body.
    // in:body
    Body api.User
}

// This text will appear as description of your request url path.
// swagger:parameters getUserRequest
type getUserParamsWrapper struct {
    // in:path
    Name string `json:"name"`
}

// This text will appear as description of your response body.
// swagger:response createUserResponse
type createUserResponseWrapper struct {
    // in:body
    Body api.User
}

// This text will appear as description of your response body.
// swagger:response getUserResponse
type getUserResponseWrapper struct {
    // in:body
    Body api.User
}

// This text will appear as description of your error response body.
// swagger:response errResponse
type errResponseWrapper struct {
    // Error code.
    Code int `json:"code"`

    // Error message.
    Message string `json:"message"`
}
```
user.go 文件说明：

- swagger:route：swagger:route代表 API 接口描述的开始，后面的字符串格式为HTTP方法 URL Tag ID。可以填写多个 tag，相同 tag 的 API 接口在 Swagger 文档中会被分为一组。ID 是一个标识符，swagger:parameters是具有相同 ID 的swagger:route的请求参数。swagger:route下面的一行是该 API 接口的描述，需要以英文点号为结尾。responses:定义了 API 接口的返回参数，例如当 HTTP 状态码是 200 时，返回 createUserResponse，createUserResponse 会跟swagger:response进行匹配，匹配成功的swagger:response就是该 API 接口返回 200 状态码时的返回。
- swagger:response：swagger:response定义了 API 接口的返回，例如 getUserResponseWrapper，关于名字，我们可以根据需要自由命名，并不会带来任何不同。getUserResponseWrapper 中有一个 Body 字段，其注释为// in:body，说明该参数是在 HTTP Body 中返回。swagger:response之上的注释会被解析为返回参数的描述。api.User 自动被 go-swagger 解析为Example Value和Model。我们不用再去编写重复的返回字段，只需要引用已有的 Go 结构体即可，这也是通过工具生成 Swagger 文档的魅力所在。
- swagger:parameters：swagger:parameters定义了 API 接口的请求参数，例如 userParamsWrapper。userParamsWrapper 之上的注释会被解析为请求参数的描述，// in:body代表该参数是位于 HTTP Body 中。同样，userParamsWrapper 结构体名我们也可以随意命名，不会带来任何不同。swagger:parameters之后的 createUserRequest 会跟swagger:route的 ID 进行匹配，匹配成功则说明是该 ID 所在 API 接口的请求参数。


进入 gopractise-demo/swagger 目录，执行如下命令，生成 Swagger API 文档，并启动 HTTP 服务，在浏览器查看 Swagger：


```
$ swagger generate spec -o swagger.yaml
$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml
2020/10/20 23:28:30 serving docs at http://localhost:36666/docs

```
打开浏览器，访问 http://localhost:36666/docs ，如下图所示：


![img](https://static001.geekbang.org/resource/image/e6/e0/e6d6d138fb890ef219d71671d146d5e0.png?wh=2450x1213)
上面我们生成了 swagger 风格的 UI 界面，我们也可以使用 redoc 风格的 UI 界面，如下图所示：


![img](https://static001.geekbang.org/resource/image/dd/48/dd568a44290283861ba5c37f28307d48.png?wh=2527x1426)

#### go-swagger 其他常用功能介绍
上面，我介绍了 swagger 最常用的 generate、serve 命令，关于 swagger 其他有用的命令，这里也简单介绍一下。


对比 Swagger 文档


```
$ swagger diff -d change.log swagger.new.yaml swagger.old.yaml
$ cat change.log

BREAKING CHANGES:
=================
/users:post Request - Body.Body.nickname.address.email.name.Body : User - Deleted property
compatibility test FAILED: 1 breaking changes detected
```
生成服务端代码
我们也可以先定义 Swagger 接口文档，再用 swagger 命令，基于 Swagger 接口文档生成服务端代码。假设我们的应用名为 go-user，进入 gopractise-demo/swagger 目录，创建 go-user 目录，并生成服务端代码：


```
$ mkdir go-user
$ cd go-user
$ swagger generate server -f ../swagger.yaml -A go-user
```
上述命令会在当前目录生成 cmd、restapi、models 文件夹，可执行如下命令查看 server 组件启动方式：

```
$ go run cmd/go-user-server/main.go -h
```
生成客户端代码
在 go-user 目录下执行如下命令：


```
$ swagger generate client -f ../swagger.yaml -A go-user
```
上述命令会在当前目录生成 client，包含了 API 接口的调用函数，也就是 API 接口的 Go SDK。

验证 Swagger 文档是否合法


```
$ swagger validate swagger.yaml
2020/10/21 09:53:18
The swagger spec at "swagger.yaml" is valid against swagger specification 2.0
```
合并 Swagger 文档


```
$ swagger mixin swagger_part1.yaml swagger_part2.yaml
```
### IAM Swagger 文档
IAM 的 Swagger 文档定义在iam/api/swagger/docs目录下，遵循 go-swagger 规范进行定义。

iam/api/swagger/docs/doc.go文件定义了更多 Swagger 文档的基本信息，比如开源协议、联系方式、安全认证等。



更详细的定义，你可以直接查看 iam/api/swagger/docs 目录下的 Go 源码文件。为了便于生成文档和启动 HTTP 服务查看 Swagger 文档，该操作被放在 Makefile 中执行（位于iam/scripts/make-rules/swagger.mk文件中）：


```
makefile
.PHONY: swagger.run    
swagger.run: tools.verify.swagger    
  @echo "===========> Generating swagger API docs"    
  @swagger generate spec --scan-models -w $(ROOT_DIR)/cmd/genswaggertypedocs -o $(ROOT_DIR)/api/swagger/swagger.yaml    
    
.PHONY: swagger.serve    
swagger.serve: tools.verify.swagger    
  @swagger serve -F=redoc --no-open --port 36666 $(ROOT_DIR)/api/swagger/swagger.yaml  
```
Makefile 文件说明：
- tools.verify.swagger：检查 Linux 系统是否安装了 go-swagger 的命令行工具 swagger，如果没有安装则运行 go get 安装。
- swagger.run：运行 swagger generate spec 命令生成 Swagger 文档 swagger.yaml，运行前会检查 swagger 是否安装。 --scan-models 指定生成的文档中包含带有 swagger:model 注释的 Go Models。-w 指定 swagger 命令运行的目录。
- swagger.serve：运行 swagger serve 命令打开 Swagger 文档 swagger.yaml，运行前会检查 swagger 是否安装。


在 iam 源码根目录下执行如下命令，即可生成并启动 HTTP 服务查看 Swagger 文档：



```
$ make swagger
$ make serve-swagger
2020/10/21 06:45:03 serving docs at http://localhost:36666/docs
```
打开浏览器，打开http://x.x.x.x:36666/docs查看 Swagger 文档，x.x.x.x 是服务器的 IP 地址，如下图所示：


![img](https://static001.geekbang.org/resource/image/6a/3b/6ac3529ed98aa94573862da99434683b.png?wh=2524x1440)

IAM 的 Swagger 文档，还可以通过在 iam 源码根目录下执行go generate ./...命令生成，为此，我们需要在 iam/cmd/genswaggertypedocs/swagger_type_docs.go 文件中，添加//go:generate注释。如下图所示：


![img](https://static001.geekbang.org/resource/image/cc/d7/cc03b896e5403cc55d7e11fe2078d9d7.png?wh=1657x397)


### 总结
在做 Go 服务开发时，我们要向前端或用户提供 API 文档，手动编写 API 文档工作量大，也难以维护。所以，现在很多项目都是自动生成 Swagger 格式的 API 文档。提到 Swagger，很多开发者不清楚其和 OpenAPI 的区别，所以我也给你总结了：OpenAPI 是一个 API 规范，Swagger 则是实现规范的工具。


在 Go 中，用得最多的是利用 go-swagger 来生成 Swagger 格式的 API 文档。go-swagger 包含了很多语法，我们可以访问Swagger 2.0进行学习。学习完 Swagger 2.0 的语法之后，就可以编写 swagger 注释了，之后可以通过


```
$ swagger generate spec -o swagger.yaml
```
来生成 swagger 文档 swagger.yaml。通过


```
$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml
```
来提供一个前端界面，供我们访问 swagger 文档。为了方便管理，我们可以将 swagger generate spec 和 swagger serve 命令加入到 Makefile 文件中，通过 Makefile 来生成 Swagger 文档，并提供给前端界面。

## 18 | 错误处理（上）：如何设计一套科学的错误码？

现代的软件架构，很多都是对外暴露 RESTful API 接口，内部系统通信采用 RPC 协议。因为 RESTful API 接口有一些天生的优势，比如规范、调试友好、易懂，所以通常作为直接面向用户的通信规范。


既然是直接面向用户，那么首先就要求消息返回格式是规范的；其次，如果接口报错，还要能给用户提供一些有用的报错信息，通常需要包含 Code 码（用来唯一定位一次错误）和 Message（用来展示出错的信息）。这就需要我们设计一套规范的、科学的错误码。


这一讲，我就来详细介绍下，如何设计一套规范的、科学的错误码。下一讲，我还会介绍如何提供一个 errors 包来支持我们设计的错误码。


### 期望错误码实现的功能
要想设计一套错误码，首先就得弄清我们的需求。

RESTful API 是基于 HTTP 协议的一系列 API 开发规范，HTTP 请求结束后，无论 API 请求成功或失败，都需要让客户端感知到，以便客户端决定下一步该如何处理。为了让用户拥有最好的体验，需要有一个比较好的错误码实现方式。这里我介绍下在设计错误码时，期望能够实现的功能。


第一个功能是有业务 Code 码标识。因为 HTTP Code 码有限，并且都是跟 HTTP Transport 层相关的 Code 码，所以我们希望能有自己的错误 Code 码。一方面，可以根据需要自行扩展，另一方面也能够精准地定位到具体是哪个错误。同时，因为 Code 码通常是对计算机友好的 10 进制整数，基于 Code 码，计算机也可以很方便地进行一些分支处理。当然了，业务码也要有一定规则，可以通过业务码迅速定位出是哪类错误。


第二个功能，考虑到安全，希望能够对外对内分别展示不同的错误信息。当开发一个对外的系统，业务出错时，需要一些机制告诉用户出了什么错误，如果能够提供一些帮助文档会更好。但是，我们不可能把所有的错误都暴露给外部用户，这不仅没必要，也不安全。所以也需要能让我们获取到更详细的内部错误信息的机制，这些内部错误信息可能包含一些敏感的数据，不宜对外展示，但可以协助我们进行问题定位。


所以，我们需要设计的错误码应该是规范的，能方便客户端感知到 HTTP 是否请求成功，并带有业务码和出错信息。



### 常见的错误码设计方式
在业务中，大致有三种错误码实现方式。我用一次因为用户账号没有找到而请求失败的例子，分别给你解释一下：

第一种方式，不论请求成功或失败，始终返回200 http status code，在 HTTP Body 中包含用户账号没有找到的错误信息。例如 Facebook API 的错误 Code 设计，始终返回 200 http status code：


```
{
  "error": {
    "message": "Syntax error \"Field picture specified more than once. This is only possible before version 2.1\" at character 23: id,name,picture,picture",
    "type": "OAuthException",
    "code": 2500,
    "fbtrace_id": "xxxxxxxxxxx"
  }
}
```
采用固定返回200 http status code的方式，有其合理性。比如，HTTP Code 通常代表 HTTP Transport 层的状态信息。当我们收到 HTTP 请求，并返回时，HTTP Transport 层是成功的，所以从这个层面上来看，HTTP Status 固定为 200 也是合理的。


但是这个方式的缺点也很明显：对于每一次请求，我们都要去解析 HTTP Body，从中解析出错误码和错误信息。实际上，大部分情况下，我们对于成功的请求，要么直接转发，要么直接解析到某个结构体中；对于失败的请求，我们也希望能够更直接地感知到请求失败。这种方式对性能会有一定的影响，对客户端不友好。所以我不**建议**你使用这种方式。

第二种方式，返回http 404 Not Found错误码，并在 Body 中返回简单的错误信息。例如：Twitter API 的错误设计，会根据错误类型，返回合适的 HTTP Code，并在 Body 中返回错误信息和自定义业务 Code。


```
HTTP/1.1 400 Bad Request
x-connection-hash: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
set-cookie: guest_id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Date: Thu, 01 Jun 2017 03:04:23 GMT
Content-Length: 62
x-response-time: 5
strict-transport-security: max-age=631138519
Connection: keep-alive
Content-Type: application/json; charset=utf-8
Server: tsa_b

{"errors":[{"code":215,"message":"Bad Authentication data."}]}
```
这种方式比第一种要好一些，通过http status code可以使客户端非常直接地感知到请求失败，并且提供给客户端一些错误信息供参考。但是仅仅靠这些信息，还不能准确地定位和解决问题。


第三种方式，返回http 404 Not Found错误码，并在 Body 中返回详细的错误信息。例如：微软 Bing API 的错误设计，会根据错误类型，返回合适的 HTTP Code，并在 Body 中返回详尽的错误信息。


```
HTTP/1.1 400
Date: Thu, 01 Jun 2017 03:40:55 GMT
Content-Length: 276
Connection: keep-alive
Content-Type: application/json; charset=utf-8
Server: Microsoft-IIS/10.0
X-Content-Type-Options: nosniff

{"SearchResponse":{"Version":"2.2","Query":{"SearchTerms":"api error codes"},"Errors":[{"Code":1001,"Message":"Required parameter is missing.","Parameter":"SearchRequest.AppId","HelpUrl":"http\u003a\u002f\u002fmsdn.microsoft.com\u002fen-us\u002flibrary\u002fdd251042.aspx"}]}}
```
这是我比较**推荐**的一种方式，既能通过http status code使客户端方便地知道请求出错，又可以使用户根据返回的信息知道哪里出错，以及如何解决问题。同时，返回了机器友好的业务 Code 码，可以在有需要时让程序进一步判断处理。


### 错误码设计**建议**
综合刚才讲到的，我们可以总结出一套优秀的错误码设计思路：


- 有区别于http status code的业务码，业务码需要有一定规则，可以通过业务码判断出是哪类错误。
- 请求出错时，可以通过http status code直接感知到请求出错。
- 需要在请求出错时，返回详细的信息，通常包括 3 类信息：业务 Code 码、错误信息和参考文档（可选）。
- 返回的错误信息，需要是可以直接展示给用户的安全信息，也就是说不能包含敏感信息；同时也要有内部更详细的错误信息，方便 debug。
- 返回的数据格式应该是固定的、规范的。
- 错误信息要保持简洁，并且提供有用的信息。


这里其实还有两个功能点需要我们实现：业务 Code 码设计，以及请求出错时，如何设置http status code。接下来，我会详细介绍下如何实现这两个功能点。


### 业务 Code 码设计
要解决业务 Code 码如何设计这个问题，我们先来看下为什么要引入业务 Code 码。


在实际开发中，引入业务 Code 码有下面几个好处：
- 可以非常方便地定位问题和定位代码行（看到错误码知道什么意思、grep 错误码可以定位到错误码所在行、某个错误类型的唯一标识）。
- 错误码包含一定的信息，通过错误码可以判断出错误级别、错误模块和具体错误信息。
- Go 中的 HTTP 服务器开发都是引用 net/http 包，该包中只有 60 个错误码，基本都是跟 HTTP 请求相关的错误码，在一个大型系统中，这些错误码完全不够用，而且这些错误码跟业务没有任何关联，满足不了业务的需求。引入业务的 Code 码，则可以解决这些问题。
- 业务开发过程中，可能需要判断错误是哪种类型，以便做相应的逻辑处理，通过定制的错误可以很容易做到这点，例如：



```go
if err == code.ErrBind {
    ...
}
```
这里要**注意**，业务 Code 码可以是一个整数，也可以是一个整型字符串，还可以是一个字符型字符串，它是错误的唯一标识。



**通过研究腾讯云、阿里云、新浪的开放 API，我发现新浪的 API Code 码设计更合理些。所以，我参考新浪的 Code 码设计，总结出了我**推荐**的 Code 码设计规范：纯数字表示，不同部位代表不同的服务，不同的模块。**


错误代码说明：10010110: 服务。01: 某个服务下的某个模块。01: 模块下的错误码序号，每个模块可以注册 100 个错误。


通过100101可以知道这个错误是服务 A，数据库模块下的记录没有找到错误。


你可能会问：按这种设计，每个模块下最多能注册 100 个错误，是不是有点少？其实在我看来，如果每个模块的错误码超过 100 个，要么说明这个模块太大了，**建议**拆分；要么说明错误码设计得不合理，共享性差，需要重新设计。


### 如何设置 HTTP Status Code
Go net/http 包提供了 60 个错误码，大致分为如下 5 类：


- 1XX - （指示信息）表示请求已接收，继续处理。
- 2XX - （请求成功）表示成功处理了请求的状态代码。
- 3XX - （请求被重定向）表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。
- 4XX - （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理，通常是客户端出错，需要客户端做进一步的处理。
- 5XX - （服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是客户端的问题。


可以看到 HTTP Code 有很多种，如果每个 Code 都做错误映射，会面临很多问题。比如，研发同学不太好判断错误属于哪种http status code，到最后很可能会导致错误或者http status code不匹配，变成一种形式。而且，客户端也难以应对这么多的 HTTP 错误码。

所以，这里**建议**http status code不要太多，基本上只需要这 3 个 HTTP Code:200 - 表示请求成功执行。400 - 表示客户端出问题。500 - 表示服务端出问题。


如果觉得这 3 个错误码不够用，最多可以加如下 3 个错误码：401 - 表示认证失败。403 - 表示授权失败。404 - 表示资源找不到，这里的资源可以是 URL 或者 RESTful 资源。


将错误码控制在适当的数目内，客户端比较容易处理和判断，开发也比较容易进行错误码映射。



### IAM 项目错误码设计规范
接下来，我们来看下 IAM 项目的错误码是如何设计的。


#### Code 设计规范
先来看下 IAM 项目业务的 Code 码设计规范，具体实现可参考internal/pkg/code 目录。IAM 项目的错误码设计规范符合上面介绍的错误码设计思路和规范，具体规范见下。

Code 代码从 100001 开始，1000 以下为 github.com/marmotedu/errors 保留 code。
错误代码说明：100001


![img](https://static001.geekbang.org/resource/image/9c/6e/9c088dcb4c7b2509c2eaa81ed3be3b6e.jpg?wh=1385x699)

服务和模块说明


![img](https://static001.geekbang.org/resource/image/91/f5/91296aab54da035580e80b6637dd4df5.png?wh=1457x1188)

通用：说明所有服务都适用的错误，提高复用性，避免重复造轮子。


错误信息规范说明
对外暴露的错误，统一大写开头，结尾不要加.。对外暴露的错误要简洁，并能准确说明问题。对外暴露的错误说明，应该是 该怎么做 而不是 哪里错了。


这里你需要**注意**，错误信息是直接暴露给用户的，不能包含敏感信息。


#### IAM API 接口返回值说明
如果返回结果中存在 code 字段，则表示调用 API 接口失败。例如：


```
{
  "code": 100101,
  "message": "Database error",
  "reference": "https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/faq/iam-apiserver"
}
```
上述返回中 code 表示错误码，message 表示该错误的具体信息。每个错误同时也对应一个 HTTP 状态码。比如上述错误码对应了 HTTP 状态码 500(Internal Server Error)。另外，在出错时，也返回了reference字段，该字段包含了可以解决这个错误的文档链接地址。关于 IAM 系统支持的错误码，我给你列了一个表格，你可以看看：


![img](https://static001.geekbang.org/resource/image/b5/95/b58ff5b9455d13fc397fdf5228ea7195.png?wh=1441x1518)

![img](https://static001.geekbang.org/resource/image/c6/d2/c6d356a3f5f2bfc3d6001yy3c05a90d2.png?wh=1321x1570)

### 总结
对外暴露的 API 接口需要有一套规范的、科学的错误码。目前业界的错误码大概有 3 种设计方式，我用一次因为用户账号没有找到而请求失败的例子，给你做了解释：


不论请求成功失败，始终返回200 http status code，在 HTTP Body 中包含用户账号没有找到的错误信息。返回http 404 Not Found错误码，并在 Body 中返回简单的错误信息。返回http 404 Not Found错误码，并在 Body 中返回详细的错误信息。


这一讲，我参考这 3 个错误码设计，给出了自己的错误码设计**建议**：错误码包含 HTTP Code 和业务 Code，并且业务 Code 会映射为一个 HTTP Code。错误码也会对外暴露两种错误信息，一种是直接暴露给用户的，不包含敏感信息的信息；另一种是供内部开发查看，定位问题的错误信息。该错误码还支持返回参考文档，用于在出错时展示给用户，供用户查看解决问题。

****建议**你重点关注我总结的 Code 码设计规范：纯数字表示，不同部位代表不同的服务，不同的模块。**

比如错误代码100101，其中 10 代表服务；中间的 01 代表某个服务下的某个模块；最后的 01 代表模块下的错误码序号，每个模块可以注册 100 个错误。

## 19 | 错误处理（下）：如何设计错误包？

在 Go 项目开发中，错误是我们必须要处理的一个事项。除了我们上一讲学习过的错误码，处理错误也离不开错误包。业界有很多优秀的、开源的错误包可供选择，例如 Go 标准库自带的errors包、github.com/pkg/errors包。但是这些包目前还不支持业务错误码，很难满足生产级应用的需求。所以，在实际开发中，我们有必要开发出适合自己错误码设计的错误包。当然，我们也没必要自己从 0 开发，可以基于一些优秀的包来进行二次封装。这一讲里，我们就来一起看看，如何设计一个错误包来适配上一讲我们设计的错误码，以及一个错误码的具体实现。


### 错误包需要具有哪些功能？
要想设计一个优秀的错误包，我们首先得知道一个优秀的错误包需要具备哪些功能。在我看来，至少需要有下面这六个功能：


首先，应该能支持错误堆栈。我们来看下面一段代码，假设保存在bad.go文件中：


```go
package main

import (
  "fmt"
  "log"
)

func main() {
  if err := funcA(); err != nil {
    log.Fatalf("call func got failed: %v", err)
    return
  }

  log.Println("call func success")
}

func funcA() error {
  if err := funcB(); err != nil {
    return err
  }

  return fmt.Errorf("func called error")
}

func funcB() error {
  return fmt.Errorf("func called error")
}
```
执行上面的代码：


```
$ go run bad.go
2021/07/02 08:06:55 call func got failed: func called error
exit status 1
```
这时我们想定位问题，但不知道具体是哪行代码报的错误，只能靠猜，还不一定能猜到。为了解决这个问题，我们可以加一些 Debug 信息，来协助我们定位问题。这样做在测试环境是没问题的，但是在线上环境，一方面修改、发布都比较麻烦，另一方面问题可能比较难重现。这时候我们会想，要是能打印错误的堆栈就好了。例如：


```
2021/07/02 14:17:03 call func got failed: func called error
main.funcB
  /home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:27
main.funcA
  /home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:19
main.main
  /home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:10
runtime.main
  /home/colin/go/go1.16.2/src/runtime/proc.go:225
runtime.goexit
  /home/colin/go/go1.16.2/src/runtime/asm_amd64.s:1371
exit status 1
```
通过上面的错误输出，我们可以很容易地知道是哪行代码报的错，从而极大提高问题定位的效率，降低定位的难度。所以，在我看来，一个优秀的 errors 包，首先需要支持错误堆栈。

其次，能够支持不同的打印格式。例如%+v、%v、%s等格式，可以根据需要打印不同丰富度的错误信息。


再次，能支持 Wrap/Unwrap 功能，也就是在已有的错误上，追加一些新的信息。例如errors.Wrap(err, "open file failed") 。Wrap 通常用在调用函数中，调用函数可以基于被调函数报错时的错误 Wrap 一些自己的信息，丰富报错信息，方便后期的错误定位，例如：



```go
func funcA() error {
    if err := funcB(); err != nil {
        return errors.Wrap(err, "call funcB failed")
    }

    return errors.New("func called error")
}

func funcB() error {
    return errors.New("func called error")
}
```
这里要**注意**，不同的错误类型，Wrap 函数的逻辑也可以不同。另外，在调用 Wrap 时，也会生成一个错误堆栈节点。我们既然能够嵌套 error，那有时候还可能需要获取被嵌套的 error，这时就需要错误包提供Unwrap函数。


还有，错误包应该有Is方法。在实际开发中，我们经常需要判断某个 error 是否是指定的 error。在 Go 1.13 之前，也就是没有 wrapping error 的时候，我们要判断 error 是不是同一个，可以使用如下方法：


```go
if err == os.ErrNotExist {
  // normal code
}
```
但是现在，因为有了 wrapping error，这样判断就会有问题。因为你根本不知道返回的 err 是不是一个嵌套的 error，嵌套了几层。这种情况下，我们的错误包就需要提供Is函数：


```go
func Is(err, target error) bool
```
当 err 和 target 是同一个，或者 err 是一个 wrapping error 的时候，如果 target 也包含在这个嵌套 error 链中，返回 true，否则返回 fasle。

**另外，错误包应该支持 As 函数。**在 Go 1.13 之前，没有 wrapping error 的时候，我们要把 error 转为另外一个 error，一般都是使用 type assertion 或者 type switch，也就是类型断言。例如：


```go
if perr, ok := err.(*os.PathError); ok {
  fmt.Println(perr.Path)
}
```
但是现在，返回的 err 可能是嵌套的 error，甚至好几层嵌套，这种方式就不能用了。所以，我们可以通过实现 As 函数来完成这种功能。现在我们把上面的例子，用 As 函数实现一下：



```go
var perr *os.PathError
if errors.As(err, &perr) {
  fmt.Println(perr.Path)
}
```
这样就可以完全实现类型断言的功能，而且还更强大，因为它可以处理 wrapping error。最后，能够支持两种错误创建方式：非格式化创建和格式化创建。例如：


```go
errors.New("file not found")
errors.Errorf("file %s not found", "iam-apiserver")
```
上面，我们介绍了一个优秀的错误包应该具备的功能。一个好消息是，Github 上有不少实现了这些功能的错误包，其中github.com/pkg/errors包最受欢迎。所以，我基于github.com/pkg/errors包进行了二次封装，用来支持上一讲所介绍的错误码。

### 错误包实现
明确优秀的错误包应该具备的功能后，我们来看下错误包的实现。实现的源码存放在github.com/marmotedu/errors。


我通过在文件github.com/pkg/errors/errors.go中增加新的withCode结构体，来引入一种新的错误类型，该错误类型可以记录错误码、stack、cause 和具体的错误信息。


```go
type withCode struct {
    err   error // error 错误
    code  int // 业务错误码
    cause error // cause error
    *stack // 错误堆栈
}
```
下面，我们通过一个示例，来了解下github.com/marmotedu/errors所提供的功能。假设下述代码保存在errors.go文件中：


```go
package main

import (
  "fmt"

  "github.com/marmotedu/errors"
  code "github.com/marmotedu/sample-code"
)

func main() {
  if err := bindUser(); err != nil {
    // %s: Returns the user-safe error string mapped to the error code or the error message if none is specified.
    fmt.Println("====================> %s <====================")
    fmt.Printf("%s\n\n", err)

    // %v: Alias for %s.
    fmt.Println("====================> %v <====================")
    fmt.Printf("%v\n\n", err)

    // %-v: Output caller details, useful for troubleshooting.
    fmt.Println("====================> %-v <====================")
    fmt.Printf("%-v\n\n", err)

    // %+v: Output full error stack details, useful for debugging.
    fmt.Println("====================> %+v <====================")
    fmt.Printf("%+v\n\n", err)

    // %#-v: Output caller details, useful for troubleshooting with JSON formatted output.
    fmt.Println("====================> %#-v <====================")
    fmt.Printf("%#-v\n\n", err)

    // %#+v: Output full error stack details, useful for debugging with JSON formatted output.
    fmt.Println("====================> %#+v <====================")
    fmt.Printf("%#+v\n\n", err)

    // do some business process based on the error type
    if errors.IsCode(err, code.ErrEncodingFailed) {
      fmt.Println("this is a ErrEncodingFailed error")
    }

    if errors.IsCode(err, code.ErrDatabase) {
      fmt.Println("this is a ErrDatabase error")
    }

    // we can also find the cause error
    fmt.Println(errors.Cause(err))
  }
}

func bindUser() error {
  if err := getUser(); err != nil {
    // Step3: Wrap the error with a new error message and a new error code if needed.
    return errors.WrapC(err, code.ErrEncodingFailed, "encoding user 'Lingfei Kong' failed.")
  }

  return nil
}

func getUser() error {
  if err := queryDatabase(); err != nil {
    // Step2: Wrap the error with a new error message.
    return errors.Wrap(err, "get user failed.")
  }

  return nil
}

func queryDatabase() error {
  // Step1. Create error with specified error code.
  return errors.WithCode(code.ErrDatabase, "user 'Lingfei Kong' not found.")
}
```
上述代码中，通过WithCode函数来创建新的 withCode 类型的错误；通过WrapC来将一个 error 封装成一个 withCode 类型的错误；通过IsCode来判断一个 error 链中是否包含指定的 code。

withCode 错误实现了一个func (w *withCode) Format(state fmt.State, verb rune)方法，该方法用来打印不同格式的错误信息，见下表：


![img](https://static001.geekbang.org/resource/image/18/5c/18a93313e017d4f3b21370099d011c5c.png?wh=1755x1198)
例如，%+v会打印以下错误信息：


```
get user failed. - #1 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:19 (main.getUser)] (100101) Database error; user 'Lingfei Kong' not found. - #0 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:26 (main.queryDatabase)] (100101) Database error
```
那么你可能会问，这些错误信息中的100101错误码，还有Database error这种对外展示的报错信息等等，是从哪里获取的？这里我简单解释一下。


首先， withCode 中包含了 int 类型的错误码，例如100101。其次，当使用github.com/marmotedu/errors包的时候，需要调用Register或者MustRegister，将一个 Coder 注册到github.com/marmotedu/errors开辟的内存中，数据结构为：


```go
var codes = map[int]Coder{}
```
Coder 是一个接口，定义为：


```go
type Coder interface {
    // HTTP status that should be used for the associated error code.
    HTTPStatus() int

    // External (user) facing error text.
    String() string

    // Reference returns the detail documents for user.
    Reference() string

    // Code returns the code of the coder
    Code() int
}
```
这样 withCode 的Format方法，就能够通过 withCode 中的 code 字段获取到对应的 Coder，并通过 Coder 提供的 HTTPStatus、String、Reference、Code 函数，来获取 withCode 中 code 的详细信息，最后格式化打印。


这里要**注意**，我们实现了两个注册函数：Register和MustRegister，二者唯一区别是：当重复定义同一个错误 Code 时，MustRegister会 panic，这样可以防止后面注册的错误覆盖掉之前注册的错误。在实际开发中，**建议**使用MustRegister。


XXX()和MustXXX()的函数命名方式，是一种 Go 代码设计技巧，在 Go 代码中经常使用，例如 Go 标准库中regexp包提供的Compile和MustCompile函数。和XXX相比，MustXXX 会在某种情况不满足时 panic。因此使用MustXXX的开发者看到函数名就会有一个心理预期：使用不当，会造成程序 panic。



最后，我还有一个**建议**：在实际的生产环境中，我们可以使用 JSON 格式打印日志，JSON 格式的日志可以非常方便的供日志系统解析。我们可以根据需要，选择%#-v或%#+v两种格式。



错误包在代码中，经常被调用，所以我们要保证错误包一定要是高性能的，否则很可能会影响接口的性能。这里，我们再来看下github.com/marmotedu/errors包的性能。


在这里，我们把这个错误包跟 go 标准库的 errors 包，以及 github.com/pkg/errors 包进行对比，来看看它们的性能：


```
$  go test -test.bench=BenchmarkErrors -benchtime="3s"
goos: linux
goarch: amd64
pkg: github.com/marmotedu/errors
BenchmarkErrors/errors-stack-10-8           57658672          61.8 ns/op        16 B/op         1 allocs/op
BenchmarkErrors/pkg/errors-stack-10-8        2265558        1547 ns/op       320 B/op         3 allocs/op
BenchmarkErrors/marmot/errors-stack-10-8     1903532        1772 ns/op       360 B/op         5 allocs/op
BenchmarkErrors/errors-stack-100-8           4883659         734 ns/op        16 B/op         1 allocs/op
BenchmarkErrors/pkg/errors-stack-100-8       1202797        2881 ns/op       320 B/op         3 allocs/op
BenchmarkErrors/marmot/errors-stack-100-8    1000000        3116 ns/op       360 B/op         5 allocs/op
BenchmarkErrors/errors-stack-1000-8           505636        7159 ns/op        16 B/op         1 allocs/op
BenchmarkErrors/pkg/errors-stack-1000-8       327681       10646 ns/op       320 B/op         3 allocs/op
BenchmarkErrors/marmot/errors-stack-1000-8             304160       11896 ns/op       360 B/op         5 allocs/op
PASS
ok    github.com/marmotedu/errors  39.200s
```
可以看到github.com/marmotedu/errors和github.com/pkg/errors包的性能基本持平。在对比性能时，重点关注 ns/op，也即每次 error 操作耗费的纳秒数。另外，我们还需要测试不同 error 嵌套深度下的 error 操作性能，嵌套越深，性能越差。例如：在嵌套深度为 10 的时候， github.com/pkg/errors 包 ns/op 值为 1547， github.com/marmotedu/errors 包 ns/op 值为 1772。可以看到，二者性能基本保持一致。


具体性能数据对比见下表：


![img](https://static001.geekbang.org/resource/image/a6/5e/a6a794d7523bc1edfa459d3a49f9685e.png?wh=1737x1145)
我们是通过BenchmarkErrors测试函数来测试 error 包性能的，你感兴趣可以打开链接看看。


### 如何记录错误？
上面，我们一起看了怎么设计一个优秀的错误包，那如何用我们设计的错误包来记录错误呢？根据我的开发经验，我**推荐**两种记录错误的方式，可以帮你快速定位问题。

方式一：通过github.com/marmotedu/errors包提供的错误堆栈能力，来跟踪错误。具体你可以看看下面的代码示例。以下代码保存在errortrack_errors.go中。



```go
package main

import (
  "fmt"

  "github.com/marmotedu/errors"

  code "github.com/marmotedu/sample-code"
)

func main() {
  if err := getUser(); err != nil {
    fmt.Printf("%+v\n", err)
  }
}

func getUser() error {
  if err := queryDatabase(); err != nil {
    return errors.Wrap(err, "get user failed.")
  }

  return nil
}

func queryDatabase() error {
  return errors.WithCode(code.ErrDatabase, "user 'Lingfei Kong' not found.")
}
```
执行上述的代码：


```
$ go run errortrack_errors.go
get user failed. - #1 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:19 (main.getUser)] (100101) Database error; user 'Lingfei Kong' not found. - #0 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:26 (main.queryDatabase)] (100101) Database error
```
可以看到，打印的日志中打印出了详细的错误堆栈，包括错误发生的函数、文件名、行号和错误信息，通过这些错误堆栈，我们可以很方便地定位问题。

你使用这种方法时，我**推荐**的用法是，在错误最开始处使用 errors.WithCode() 创建一个 withCode 类型的错误。上层在处理底层返回的错误时，可以根据需要，使用 Wrap 函数基于该错误封装新的错误信息。如果要包装的 error 不是用github.com/marmotedu/errors包创建的，**建议**用 errors.WithCode() 新建一个 error。


方式二：在错误产生的最原始位置调用日志包记录函数，打印错误信息，其他位置直接返回（当然，也可以选择性的追加一些错误信息，方便故障定位）。示例代码（保存在errortrack_log.go）如下：



```go
package main

import (
  "fmt"

  "github.com/marmotedu/errors"
  "github.com/marmotedu/log"

  code "github.com/marmotedu/sample-code"
)

func main() {
  if err := getUser(); err != nil {
    fmt.Printf("%v\n", err)
  }
}

func getUser() error {
  if err := queryDatabase(); err != nil {
    return err
  }

  return nil
}

func queryDatabase() error {
  opts := &log.Options{
    Level:            "info",
    Format:           "console",
    EnableColor:      true,
    EnableCaller:     true,
    OutputPaths:      []string{"test.log", "stdout"},
    ErrorOutputPaths: []string{},
  }

  log.Init(opts)
  defer log.Flush()

  err := errors.WithCode(code.ErrDatabase, "user 'Lingfei Kong' not found.")
  if err != nil {
    log.Errorf("%v", err)
  }
  return err
}
```
执行以上代码：


```
$ go run errortrack_log.go
2021-07-03 14:37:31.597  ERROR  errors/errortrack_log.go:41  Database error
Database error

```
当错误发生时，调用 log 包打印错误。通过 log 包的 caller 功能，可以定位到 log 语句的位置，也就是定位到错误发生的位置。你使用这种方式来打印日志时，我有两个**建议**。


只在错误产生的最初位置打印日志，其他地方直接返回错误，一般不需要再对错误进行封装。当代码调用第三方包的函数时，第三方包函数出错时打印错误信息。比如：


```go
if err := os.Chdir("/root"); err != nil {
    log.Errorf("change dir failed: %v", err)
}
```
### 一个错误码的具体实现
接下来，我们看一个依据上一讲介绍的错误码规范的具体错误码实现github.com/marmotedu/sample-code。


sample-code实现了两类错误码，分别是通用错误码（sample-code/base.go）和业务模块相关的错误码（sample-code/apiserver.go）。首先，我们来看通用错误码的定义：



```go
// 通用: 基本错误
// Code must start with 1xxxxx
const (
    // ErrSuccess - 200: OK.
    ErrSuccess int = iota + 100001

    // ErrUnknown - 500: Internal server error.
    ErrUnknown

    // ErrBind - 400: Error occurred while binding the request body to the struct.
    ErrBind

    // ErrValidation - 400: Validation failed.
    ErrValidation

    // ErrTokenInvalid - 401: Token invalid.
    ErrTokenInvalid
)
```
在代码中，我们通常使用整型常量（ErrSuccess）来代替整型错误码（100001），因为使用 ErrSuccess 时，一看就知道它代表的错误类型，可以方便开发者使用。

错误码用来指代一个错误类型，该错误类型需要包含一些有用的信息，例如对应的 HTTP Status Code、对外展示的 Message，以及跟该错误匹配的帮助文档。所以，我们还需要实现一个 Coder 来承载这些信息。这里，我们定义了一个实现了github.com/marmotedu/errors.Coder接口的ErrCode结构体：


```go
// ErrCode implements `github.com/marmotedu/errors`.Coder interface.
type ErrCode struct {
    // C refers to the code of the ErrCode.
    C int

    // HTTP status that should be used for the associated error code.
    HTTP int

    // External (user) facing error text.
    Ext string

    // Ref specify the reference document.
    Ref string
}
```
可以看到ErrCode结构体包含了以下信息：int 类型的业务码。对应的 HTTP Status Code。暴露给外部用户的消息。错误的参考文档。


下面是一个具体的 Coder 示例：


```go
coder := &ErrCode{
    C:    100001,
    HTTP: 200,
    Ext:  "OK",
    Ref:  "https://github.com/marmotedu/sample-code/blob/master/README.md",
}
```
接下来，我们就可以调用github.com/marmotedu/errors包提供的Register或者MustRegister函数，将 Coder 注册到github.com/marmotedu/errors包维护的内存中。一个项目有很多个错误码，如果每个错误码都手动调用MustRegister函数会很麻烦，这里我们通过代码自动生成的方法，来生成 register 函数调用：



```go
//go:generate codegen -type=int
//go:generate codegen -type=int -doc -output ./error_code_generated.md
```
//go:generate codegen -type=int 会调用codegen工具，生成sample_code_generated.go源码文件：


```go
func init() {
  register(ErrSuccess, 200, "OK")
  register(ErrUnknown, 500, "Internal server error")
  register(ErrBind, 400, "Error occurred while binding the request body to the struct")
  register(ErrValidation, 400, "Validation failed")
    // other register function call
}
```
这些register调用放在 init 函数中，在加载程序的时候被初始化。这里要**注意**，在注册的时候，我们会检查 HTTP Status Code，只允许定义 200、400、401、403、404、500 这 6 个 HTTP 错误码。这里通过程序保证了错误码是符合 HTTP Status Code 使用要求的。


//go:generate codegen -type=int -doc -output ./error_code_generated.md会生成错误码描述文档 error_code_generated.md。当我们提供 API 文档时，也需要记着提供一份错误码描述文档，这样客户端才可以根据错误码，知道请求是否成功，以及具体发生哪类错误，好针对性地做一些逻辑处理。


codegen工具会根据错误码注释生成sample_code_generated.go和error_code_generated.md文件：


```go
// ErrSuccess - 200: OK.
 ErrSuccess int = iota + 100001
```
codegen 工具之所以能够生成sample_code_generated.go和error_code_generated.md，是因为我们的错误码注释是有规定格式的：// <错误码整型常量> - <对应的HTTP Status Code>: .。codegen 工具可以在 IAM 项目根目录下，执行以下命令来安装：


```
$ make tools.install.codegen
```
安装完 codegen 工具后，可以在 github.com/marmotedu/sample-code 包根目录下执行 go generate 命令，来生成sample_code_generated.go和error_code_generated.md。这里有个技巧需要你**注意**：生成的文件**建议**统一用 xxxx_generated.xx 来命名，这样通过 generated ，我们就知道这个文件是代码自动生成的，有助于我们理解和使用。

在实际的开发中，我们可以将错误码独立成一个包，放在 internal/pkg/code/目录下，这样可以方便整个应用调用。例如 IAM 的错误码就放在 IAM 项目根目录下的internal/pkg/code/目录下。我们的错误码是分服务和模块的，所以这里**建议**你把相同的服务放在同一个 Go 源文件中，例如 IAM 的错误码存放文件：


```
$ ls base.go apiserver.go authzserver.go 
apiserver.go  authzserver.go  base.go
```
一个应用中会有多个服务，例如 IAM 应用中，就包含了 iam-apiserver、iam-authz-server、iam-pump 三个服务。这些服务有一些通用的错误码，为了便于维护，可以将这些通用的错误码统一放在 base.go 源码文件中。其他的错误码，我们可以按服务分别放在不同的文件中：iam-apiserver 服务的错误码统一放在 apiserver.go 文件中；iam-authz-server 的错误码统一存放在 authzserver.go 文件中。其他服务以此类推。

另外，同一个服务中不同模块的错误码，可以按以下格式来组织：相同模块的错误码放在同一个 const 代码块中，不同模块的错误码放在不同的 const 代码块中。每个 const 代码块的开头注释就是该模块的错误码定义。例如：


```go
// iam-apiserver: user errors.
const (
    // ErrUserNotFound - 404: User not found.
    ErrUserNotFound int = iota + 110001

    // ErrUserAlreadyExist - 400: User already exist.
    ErrUserAlreadyExist
)

// iam-apiserver: secret errors.
const (
    // ErrEncrypt - 400: Secret reach the max count.
    ErrReachMaxCount int = iota + 110101

    //  ErrSecretNotFound - 404: Secret not found.
    ErrSecretNotFound
)
```
最后，我们还需要将错误码定义记录在项目的文件中，供开发者查阅、遵守和使用，例如 IAM 项目的错误码定义记录文档为code_specification.md。这个文档中记录了错误码说明、错误描述规范和错误记录规范等。

### 错误码实际使用方法示例
上面，我讲解了错误包和错误码的实现方式，那你一定想知道在实际开发中我们是如何使用的。这里，我就举一个在 gin web 框架中使用该错误码的例子：


```go
// Response defines project response format which in marmotedu organization.
type Response struct {
    Code      errors.Code `json:"code,omitempty"`
    Message   string      `json:"message,omitempty"`
    Reference string      `json:"reference,omitempty"`
    Data      interface{} `json:"data,omitempty"`
}

// WriteResponse used to write an error and JSON data into response.
func WriteResponse(c *gin.Context, err error, data interface{}) {
    if err != nil {
        coder := errors.ParseCoder(err)

        c.JSON(coder.HTTPStatus(), Response{
            Code:      coder.Code(),
            Message:   coder.String(),
            Reference: coder.Reference(),
            Data:      data,
        })
    }

    c.JSON(http.StatusOK, Response{Data: data})
}

func GetUser(c *gin.Context) {
    log.Info("get user function called.", "X-Request-Id", requestid.Get(c))
    // Get the user by the `username` from the database.
    user, err := store.Client().Users().Get(c.Param("username"), metav1.GetOptions{})
    if err != nil {
        core.WriteResponse(c, errors.WithCode(code.ErrUserNotFound, err.Error()), nil)
        return
    }

    core.WriteResponse(c, nil, user)
}
```
上述代码中，通过WriteResponse统一处理错误。在 WriteResponse 函数中，如果err != nil，则从 error 中解析出 Coder，并调用 Coder 提供的方法，获取错误相关的 Http Status Code、int 类型的业务码、暴露给用户的信息、错误的参考文档链接，并返回 JSON 格式的信息。如果 err == nil 则返回 200 和数据。


### 总结
记录错误是应用程序必须要做的一件事情，在实际开发中，我们通常会封装自己的错误包。一个优秀的错误包，应该能够支持错误堆栈、不同的打印格式、Wrap/Unwrap/Is/As 等函数，并能够支持格式化创建 error。


根据这些错误包设计要点，我基于 github.com/pkg/errors 包设计了 IAM 项目的错误包 github.com/marmotedu/errors ，该包符合我们上一讲设计的错误码规范。另外，本讲也给出了一个具体的错误码实现 sample-code ， sample-code 支持业务 Code 码、HTTP Status Code、错误参考文档、可以对内对外展示不同的错误信息。


最后，因为错误码注释是有固定格式的，所以我们可以通过 codegen 工具解析错误码的注释，生成 register 函数调用和错误码文档。这种做法也体现了我一直强调的 low code 思想，可以提高开发效率，减少人为失误。


## 20 | 日志处理（上）：如何设计日志包并记录日志？
在做 Go 项目开发时，除了处理错误之外，我们必须要做的另外一件事是记录日志。通过记录日志，可以完成一些基本功能，比如开发、测试期间的 Debug，故障排除，数据分析，监控告警，以及记录发生的事件等。

要实现这些功能，首先我们需要一个优秀的日志包。另外，我还发现不少 Go 项目开发者记录日志很随意，输出的日志并不能有效定位到问题。所以，我们还需要知道怎么更好地记录日志，这就需要一个日志记录规范。

有了优秀的日志包和日志记录规范，我们就能很快地定位到问题，获取足够的信息，并完成后期的数据分析和监控告警，也可以很方便地进行调试了。这一讲，我就来详细介绍下，如何设计日志包和日志记录规范。首先，我们来看下如何设计日志包。


### 如何设计日志包
目前，虽然有很多优秀的开源日志包可供我们选择，但在一个大型系统中，这些开源日志包很可能无法满足我们定制化的需求，这时候我们就需要自己开发日志包。


这些日志包可能是基于某个，或某几个开源的日志包改造而来，也可能是全新开发的日志包。那么在开发日志包时，我们需要实现哪些功能，又如何实现呢？接下来，我们就来详细聊聊。先来看下日志包需要具备哪些功能。根据功能的重要性，我将日志包需要实现的功能分为**基础功能、高级功能和可选功能**。基础功能是一个日志包必须要具备的功能；高级功能、可选功能都是在特定场景下可增加的功能。我们先来说基础功能。



### 基础功能
基础功能，是优秀日志包必备的功能，能够满足绝大部分的使用场景，适合一些中小型的项目。一个日志包应该具备以下 4 个基础功能。


支持基本的日志信息
日志包需要支持基本的日志信息，包括时间戳、文件名、行号、日志级别和日志信息。时间戳可以记录日志发生的时间。在定位问题时，我们往往需要根据时间戳，来复原请求过程，核对相同时间戳下的上下文，从而定位出问题。


文件名和行号，可以使我们更快速定位到打印日志的位置，找到问题代码。一个日志库如果不支持文件名和行号，排查故障就会变得非常困难，基本只能靠 grep 和记忆来定位代码。对于企业级的服务，需要保证服务在故障后能够快速恢复，恢复的时间越久，造成的损失就越大，影响就越大。这就要求研发人员能够快速定位并解决问题。通过文件名和行号，我们可以精准定位到问题代码，尽快地修复问题并恢复服务。


通过日志级别，可以知道日志的错误类型，最通常的用法是：直接过滤出 Error 级别的日志，这样就可以直接定位出问题出错点，然后再结合其他日志定位出出错的原因。如果不支持日志级别，在定位问题时，可能要查看一大堆无用的日志。在大型系统中，一次请求的日志量很多，这会大大延长我们定位问题的时间。而通过日志信息，我们可以知道错误发生的具体原因。


支持不同的日志级别
不同的日志级别代表不同的日志类型，例如：Error 级别的日志，说明日志是错误类型，在排障时，会首先查看错误级别的日志。Warn 级别日志说明出现异常，但还不至于影响程序运行，如果程序执行的结果不符合预期，则可以参考 Warn 级别的日志，定位出异常所在。Info 级别的日志，可以协助我们 Debug，并记录一些有用的信息，供后期进行分析。


通常一个日志包至少要实现 6 个级别，我给你提供了一张表格，按优先级从低到高排列如下：


![img](https://static001.geekbang.org/resource/image/bb/2b/bb1356bd3cf332ddeb30d3aef8fc8d2b.png?wh=1794x1120)

有些日志包，例如 logrus，还支持 Trace 日志级别。Trace 级别比 Debug 级别还低，能够打印更细粒度的日志信息。在我看来，Trace 级别不是必须的，你可以根据需要自行选择。


打印日志时，一个日志调用其实具有两个属性：
- 输出级别：打印日志时，我们期望日志的输出级别。例如，我们调用 glog.Info("This is info message") 打印一条日志，则输出日志级别为 Info。
- 开关级别：启动应用程序时，期望哪些输出级别的日志被打印。例如，使用 glog 时 -v=4 ，说明了只有日志级别高于 4 的日志才会被打印。


如果开关级别设置为 L ，只有输出级别 >=L 时，日志才会被打印。例如，开关级别为 Warn，则只会记录 Warn、Error 、Panic 和 Fatal 级别的日志。具体的输出关系如下图所示：


![img](https://static001.geekbang.org/resource/image/dd/ed/dd4e9c3ed26b254cb5b65ff1fddd40ed.png?wh=1654x526)


支持自定义配置
不同的运行环境，需要不同的日志输出配置，例如：开发测试环境为了能够方便地 Debug，需要设置日志级别为 Debug 级别；现网环境为了提高应用程序的性能，则需要设置日志级别为 Info 级别。又比如，现网环境为了方便日志采集，通常会输出 JSON 格式的日志；开发测试环境为了方便查看日志，会输出 TEXT 格式的日志。

所以，我们的日志包需要能够被配置，还要不同环境采用不同的配置。通过配置，可以在不重新编译代码的情况下，改变记录日志的行为。


支持输出到标准输出和文件
日志总是要被读的，要么输出到标准输出，供开发者实时读取，要么保存到文件，供开发者日后查看。输出到标准输出和保存到文件是一个日志包最基本的功能。


### 高级功能
除了上面提到的这些基本功能外，在一些大型系统中，通常还会要求日志包具备一些高级功能。这些高级功能可以帮我们更好地记录日志，并实现更丰富的功能，例如日志告警。那么一个日志包可以具备哪些高级功能呢？


支持多种日志格式
日志格式也是我们要考虑的一个点，一个好的日志格式，不仅方便查看日志，还能方便一些日志采集组件采集日志，并对接类似 Elasticsearch 这样的日志搜索引擎。


一个日志包至少需要提供以下两种格式：

TEXT 格式：TEXT 格式的日志具有良好的可读性，可以方便我们在开发联调阶段查看日志，例如：


```
2020-12-02T01:16:18+08:00 INFO example.go:11 std log
2020-12-02T01:16:18+08:00 DEBUG example.go:13 change std log to debug level
```
JSON 格式：JSON 格式的日志可以记录更详细的信息，日志中包含一些通用的或自定义的字段，可供日后的查询、分析使用，而且可以很方便地供 filebeat、logstash 这类日志采集工具采集并上报。下面是 JSON 格式的日志：



```
{"level":"DEBUG","time":"2020-12-02T01:16:18+08:00","file":"example.go:15","func":"main.main","message":"log in json format"}
{"level":"INFO","time":"2020-12-02T01:16:18+08:00","file":"example.go:16","func":"main.main","message":"another log in json format"}
```
我**建议**在开发联调阶段使用 TEXT 格式的日志，在现网环境使用 JSON 格式的日志。一个优秀的日志库，例如 logrus，除了提供基本的输出格式外，还应该允许开发者自定义日志输出格式。


能够按级别分类输出
为了能够快速定位到需要的日志，一个比较好的做法是将日志按级别分类输出，至少错误级别的日志可以输出到独立的文件中。这样，出现问题时，可以直接查找错误文件定位问题。例如，glog 就支持分类输出，如下图所示：


![img](https://static001.geekbang.org/resource/image/10/4b/100af3121e8d4e84428979f9d0yydf4b.png?wh=2091x326)

支持结构化日志
结构化日志（Structured Logging），就是使用 JSON 或者其他编码方式使日志结构化，这样可以方便后续使用 Filebeat、Logstash Shipper 等各种工具，对日志进行采集、过滤、分析和查找。就像下面这个案例，使用 zap 进行日志打印：


```go
package main

import (
    "time"

    "go.uber.org/zap"
)

func main() {
    logger, _ := zap.NewProduction()
    defer logger.Sync() // flushes buffer, if any
    url := "http://marmotedu.com"
    // 结构化日志打印
    logger.Sugar().Infow("failed to fetch URL", "url", url, "attempt", 3, "backoff", time.Second)

    // 非结构化日志打印
    logger.Sugar().Infof("failed to fetch URL: %s", url)
}
```
上述代码输出为：


```
{"level":"info","ts":1607303966.9903321,"caller":"zap/structured_log.go:14","msg":"failed to fetch URL","url":"http://marmotedu.com","attempt":3,"backoff":1}
{"level":"info","ts":1607303966.9904354,"caller":"zap/structured_log.go:17","msg":"failed to fetch URL: http://marmotedu.com"}
```
支持日志轮转
在一个大型项目中，一天可能会产生几十个 G 的日志。为了防止日志把磁盘空间占满，导致服务器或者程序异常，就需要确保日志大小达到一定量级时，对日志进行切割、压缩，并转存。

如何切割呢？你可以按照日志大小进行切割，也可以按日期切割。日志的切割、压缩和转存功能可以基于 GitHub 上一些优秀的开源包来封装，例如：lumberjack可以支持按大小和日期归档日志，file-rotatelogs支持按小时数进行日志切割。

对于日志轮转功能，其实我不**建议**在日志包中添加，因为这会增加日志包的复杂度，我更**建议**的做法是借助其他的工具来实现日志轮转。例如，在 Linux 系统中可以使用 Logrotate 来轮转日志。Logrotate 功能强大，是一个专业的日志轮转工具。


具备 Hook 能力
Hook 能力可以使我们对日志内容进行自定义处理。例如，当某个级别的日志产生时，发送邮件或者调用告警接口进行告警。很多优秀的开源日志包提供了 Hook 能力，例如 logrus 和 zap。


在一个大型系统中，日志告警是非常重要的功能，但更好的实现方式是将告警能力做成旁路功能。通过旁路功能，可以保证日志包功能聚焦、简洁。例如：可以将日志收集到 Elasticsearch，并通过 ElastAlert 进行日志告警。


### 可选功能
除了基础功能和高级功能外，还有一些功能。这些功能不会影响到日志包的核心功能，但是如果具有这些功能，会使日志包更加易用。比如下面的这三个功能。


支持颜色输出
在开发、测试时开启颜色输出，不同级别的日志会被不同颜色标识，这样我们可以很轻松地发现一些 Error、Warn 级别的日志，方便开发调试。发布到生产环境时，可以关闭颜色输出，以提高性能。


兼容标准库 log 包
一些早期的 Go 项目大量使用了标准库 log 包，如果我们的日志库能够兼容标准库 log 包，我们就可以很容易地替换掉标准库 log 包。例如，logrus 就兼容标准库 log 包。这里，我们来看一个使用了标准库 log 包的代码：


```go
package main

import (
    "log"
)

func main() {
    log.Print("call Print: line1")
    log.Println("call Println: line2")
}
```
只需要使用log "github.com/sirupsen/logrus"替换"log"就可以完成标准库 log 包的切换：


```go
package main

import (
    log "github.com/sirupsen/logrus"
)

func main() {
    log.Print("call Print: line1")
    log.Println("call Println: line2")
}
```
支持输出到不同的位置
在分布式系统中，一个服务会被部署在多台机器上，这时候如果我们要查看日志，就需要分别登录不同的机器查看，非常麻烦。我们更希望将日志统一投递到 Elasticsearch 上，在 Elasticsearch 上查看日志。

我们还可能需要从日志中分析某个接口的调用次数、某个用户的请求次数等信息，这就需要我们能够对日志进行处理。一般的做法是将日志投递到 Kafka，数据处理服务消费 Kafka 中保存的日志，从而分析出调用次数等信息。


以上两种场景，分别需要把日志投递到 Elasticsearch、Kafka 等组件，如果我们的日志包支持将日志投递到不同的目的端，那会是一项非常让人期待的功能：


![img](https://static001.geekbang.org/resource/image/bd/4b/bda7177a7a627b0117bfffdbd129914b.png?wh=1904x842)
如果日志不支持投递到不同的下游组件，例如 Elasticsearch、Kafka、Fluentd、Logstash 等位置，也可以通过 Filebeat 采集磁盘上的日志文件，进而投递到下游组件。



### 设计日志包时需要关注的点
上面，我们介绍了日志包具备的功能，这些功能可以指导我们完成日志包设计。这里，我们再来看下设计日志包时，我们还需要关注的几个层面：

- 高性能：因为我们要在代码中频繁调用日志包，记录日志，所以日志包的性能是首先要考虑的点，一个性能很差的日志包必然会导致整个应用性能很差。
- 并发安全：Go 应用程序会大量使用 Go 语言的并发特性，也就意味着需要并发地记录日志，这就需要日志包是并发安全的。
- 插件化能力：日志包应该能提供一些插件化的能力，比如允许开发者自定义输出格式，自定义存储位置，自定义错误发生时的行为（例如 告警、发邮件等）。插件化的能力不是必需的，因为日志自身的特性就能满足绝大部分的使用需求，例如：输出格式支持 JSON 和 TEXT，存储位置支持标准输出和文件，日志监控可以通过一些旁路系统来实现。
- 日志参数控制：日志包应该能够灵活地进行配置，初始化时配置或者程序运行时配置。例如：初始化配置可以通过 Init 函数完成，运行时配置可以通过 SetOptions / SetLevel 等函数来完成。


### 如何记录日志？
前面我们介绍了在设计日志包时，要包含的一些功能、实现方法和**注意**事项。但在这个过程中，还有一项重要工作需要**注意**，那就是日志记录问题。



日志并不是越多越好，在实际开发中，经常会遇到一大堆无用的日志，却没有我们需要的日志；或者有效的日志被大量无用的日志淹没，查找起来非常困难。一个优秀的日志包可以协助我们更好地记录、查看和分析日志，但是如何记录日志决定了我们能否获取到有用的信息。日志包是工具，日志记录才是灵魂。这里，我就来详细讲讲如何记录日志。

想要更好地记录日志，我们需要解决以下几个问题：**在何处打印日志？在哪个日志级别打印日志？如何记录日志内容？**


#### 在何处打印日志？
日志主要是用来定位问题的，所以整体来说，我们要在有需要的地方打印日志。那么具体是哪些地方呢？我给你几个**建议**。


- 在分支语句处打印日志。在分支语句处打印日志，可以判断出代码走了哪个分支，有助于判断请求的下一跳，继而继续排查问题。
- 写操作必须打印日志。写操作最可能会引起比较严重的业务故障，写操作打印日志，可以在出问题时找到关键信息。
- 在循环中打印日志要慎重。如果循环次数过多，会导致打印大量的日志，严重拖累代码的性能，**建议**的办法是在循环中记录要点，在循环外面总结打印出来。
- 在错误产生的最原始位置打印日志。对于嵌套的 Error，可在 Error 产生的最初位置打印 Error 日志，上层如果不需要添加必要的信息，可以直接返回下层的 Error。我给你举个例子：


```go
package main

import (
    "flag"
    "fmt"

    "github.com/golang/glog"
)

func main() {
    flag.Parse()
    defer glog.Flush()

    if err := loadConfig(); err != nil {
        glog.Error(err)
    }
}

func loadConfig() error {
    return decodeConfig() // 直接返回
}

func decodeConfig() error {
    if err := readConfig(); err != nil {
        return fmt.Errorf("could not decode configuration data for user %s: %v", "colin", err) // 添加必要的信息，用户名称
    }

    return nil
}

func readConfig() error {
    glog.Errorf("read: end of input.")
    return fmt.Errorf("read: end of input")
}
```
通过在最初产生错误的位置打印日志，我们可以很方便地追踪到日志的根源，进而在上层追加一些必要的信息。这可以让我们了解到该错误产生的影响，有助于排障。另外，直接返回下层日志，还可以减少重复的日志打印。当代码调用第三方包的函数，且第三方包函数出错时，会打印错误信息。比如：


```go
if err := os.Chdir("/root"); err != nil {
    log.Errorf("change dir failed: %v", err)
}
```
#### 在哪个日志级别打印日志？
不同级别的日志，具有不同的意义，能实现不同的功能，在开发中，我们应该根据目的，在合适的级别记录日志，这里我同样给你一些**建议**。


Debug 级别
为了获取足够的信息进行 Debug，通常会在 Debug 级别打印很多日志。例如，可以打印整个 HTTP 请求的请求 Body 或者响应 Body。


Debug 级别需要打印大量的日志，这会严重拖累程序的性能。并且，Debug 级别的日志，主要是为了能在开发测试阶段更好地 Debug，多是一些不影响现网业务的日志信息。所以，对于 Debug 级别的日志，在服务上线时我们一定要禁止掉。否则，就可能会因为大量的日志导致硬盘空间快速用完，从而造成服务宕机，也可能会影响服务的性能和产品体验。

Debug 这个级别的日志可以随意输出，任何你觉得有助于开发、测试阶段调试的日志，都可以在这个级别打印。


Info 级别
Info 级别的日志可以记录一些有用的信息，供以后的运营分析，所以 Info 级别的日志不是越多越好，也不是越少越好，应以满足需求为主要目标。一些关键日志，可以在 Info 级别记录，但如果日志量大、输出频度过高，则要考虑在 Debug 级别记录。



现网的日志级别一般是 Info 级别，为了不使日志文件占满整个磁盘空间，在记录日志时，要**注意**避免产生过多的 Info 级别的日志。例如，在 for 循环中，就要慎用 Info 级别的日志。


Warn 级别
一些警告类的日志可以记录在 Warn 级别，Warn 级别的日志往往说明程序运行异常，不符合预期，但又不影响程序的继续运行，或者是暂时影响，但后续会恢复。像这些日志，就需要你关注起来。Warn 更多的是业务级别的警告日志。


Error 级别
Error 级别的日志告诉我们程序执行出错，这些错误肯定会影响到程序的执行结果，例如请求失败、创建资源失败等。要记录每一个发生错误的日志，避免日后排障过程中这些错误被忽略掉。大部分的错误可以归在 Error 级别。


Panic 级别
Panic 级别的日志在实际开发中很少用，通常只在需要错误堆栈，或者不想因为发生严重错误导致程序退出，而采用 defer 处理错误时使用。


Fatal 级别
Fatal 是最高级别的日志，这个级别的日志说明问题已经相当严重，严重到程序无法继续运行，通常是系统级的错误。在开发中也很少使用，除非我们觉得某个错误发生时，整个程序无法继续运行。


这里用一张图来总结下，如何选择 Debug、Info、Warn、Error、Panic、Fatal 这几种日志级别。


![img](https://static001.geekbang.org/resource/image/75/35/75e8c71a791f279a68c35734f2451035.png?wh=3646x1542)


#### 如何记录日志内容？
关于如何记录日志内容，我有几条**建议**：


- 在记录日志时，不要输出一些敏感信息，例如密码、密钥等。
- 为了方便调试，通常会在 Debug 级别记录一些临时日志，这些日志内容可以用一些特殊的字符开头，例如 log.Debugf("XXXXXXXXXXXX-1:Input key was: %s", setKeyName) 。这样，在完成调试后，可以通过查找 XXXXXXXXXXXX 字符串，找到这些临时日志，在 commit 前删除。
- 日志内容应该小写字母开头，以英文点号 . 结尾，例如 log.Info("update user function called.") 。
- 为了提高性能，尽可能使用明确的类型，例如使用 log.Warnf("init datastore: %s", err.Error()) 而非 log.Warnf("init datastore: %v", err) 。
- 根据需要，日志最好包含两个信息。一个是请求 ID（RequestID），是每次请求的唯一 ID，便于从海量日志中过滤出某次请求的日志，可以将请求 ID 放在请求的通用日志字段中。另一个是用户和行为，用于标识谁做了什么。
- 不要将日志记录在错误的日志级别上。例如，我在项目开发中，经常会发现有同事将正常的日志信息打印在 Error 级别，将错误的日志信息打印在 Info 级别。



### 记录日志的“最佳”实践总结
关于日志记录问题，我从以上三个层面给你讲解了。综合来说，对于日志记录的最佳实践，你在平时都可以**注意**或进行尝试，我把这些重点放在这里，方便你后续查阅。


- 开发调试、现网故障排障时，不要遗忘一件事情：根据排障的过程优化日志打印。好的日志，可能不是一次就可以写好的，可以在实际开发测试，还有现网定位问题时，不断优化。但这需要你重视日志，而不是把日志仅仅当成记录信息的一种方式，甚至不知道为什么打印一条 Info 日志。
- 打印日志要“不多不少”，避免打印没有作用的日志，也不要遗漏关键的日志信息。最好的信息是，仅凭借这些关键的日志就能定位到问题。
- 支持动态日志输出，方便线上问题定位。
- 总是将日志记录在本地文件：通过将日志记录在本地文件，可以和日志中心化平台进行解耦，这样当网络不可用，或者日志中心化平台故障时，仍然能够正常的记录日志。
- 集中化日志存储处理：因为应用可能包含多个服务，一个服务包含多个实例，为了查看日志方便，最好将这些日志统一存储在同一个日志平台上，例如 Elasticsearch，方便集中管理和查看日志。
- 结构化日志记录：添加一些默认通用的字段到每行日志，方便日志查询和分析。
- 支持 RequestID：使用 RequestID 串联一次请求的所有日志，这些日志可能分布在不同的组件，不同的机器上。支持 RequestID 可以大大提高排障的效率，降低排障难度。在一些大型分布式系统中，没有 RequestID 排障简直就是灾难。
- 支持动态开关 Debug 日志：对于定位一些隐藏得比较深的问题，可能需要更多的信息，这时候可能需要打印 Debug 日志。但现网的日志级别会设置为 Info 级别，为了获取 Debug 日志，我们可能会修改日志级别为 Debug 级别并重启服务，定位完问题后，再修改日志级别为 Info 级别，然后再重启服务，这种方式不仅麻烦而且还可能会对现网业务造成影响，最好的办法是能够在请求中通过 debug=true 这类参数动态控制某次请求是否开启 Debug 日志。



### 拓展内容：分布式日志解决方案（EFK/ELK）
前面我们介绍了设计日志包和记录日志的规范，除此之外，还有一个问题你应该了解，那就是：我们记录的日志如何收集、处理和展示。

在实际 Go 项目开发中，**为了实现高可用，同一个服务至少需要部署两个实例**，通过轮询的负载均衡策略转发请求。另外，一个应用又可能包含多个服务。假设我们的应用包含两个服务，每个服务部署两个实例，如果应用出故障，我们可能需要登陆 4（2 x 2）台服务器查看本地的日志文件，定位问题，非常麻烦，会增加故障恢复时间。所以在真实的企业场景中，我们会将这些日志统一收集并展示。


在业界，日志的收集、处理和展示，早已经有了一套十分流行的日志解决方案：EFK（Elasticsearch + Filebeat + Kibana）或者 ELK（Elasticsearch + Logstash + Kibana），EFK 可以理解为 ELK 的演进版，把日志收集组件从 Logstash 替换成了 Filebeat。用 Filebeat 替换 Logstash，主要原因是 Filebeat 更轻量级，占用的资源更少。关于日志处理架构，你可以参考这张图。


![img](https://static001.geekbang.org/resource/image/5d/c8/5daabdfea213c05fc0387aa735e54ec8.png?wh=4194x778)

通过 log 包将日志记录在本地文件中（*.log 文件），再通过 Shipper 收集到 Kafka 中。Shipper 可以根据需要灵活选择，常见的 Shipper 有 Logstash Shipper、Flume、Fluentd、Filebeat。其中 Filebeat 和 Logstash Shipper 用得最多。Shipper 没有直接将日志投递到 Logstash indexer，或者 Elasticsearch，是因为 Kafka 能够支持更大的吞吐量，起到削峰填谷的作用。

Kafka 中的日志消息会被 Logstash indexer 消费，处理后投递到 Elasticsearch 中存储起来。Elasticsearch 是实时全文搜索和分析引擎，提供搜集、分析、存储数据三大功能。Elasticsearch 中存储的日志，可以通过 Kibana 提供的图形界面来展示。Kibana 是一个基于 Web 的图形界面，用于搜索、分析和可视化存储在 Elasticsearch 中的日志数据。

Logstash 负责采集、转换和过滤日志。它支持几乎任何类型的日志，包括系统日志、错误日志和自定义应用程序日志。Logstash 又分为 Logstash Shipper 和 Logstash indexer。其中，Logstash Shipper 监控并收集日志，并将日志内容发送到 Logstash indexer，然后 Logstash indexer 过滤日志，并将日志提交给 Elasticsearch。


### 总结
记录日志，是应用程序必备的功能。记录日志最大的作用是排障，如果想更好地排障，我们需要一个优秀的工具，日志包。那么如何设计日志包呢？首先我们需要知道日志包的功能，在我看来日志包需要具备以下功能：


- 基础功能：支持基本的日志信息、支持不同的日志级别、支持自定义配置、支持输出到标准输出和文件。
- 高级功能：支持多种日志格式、能够按级别分类输出、支持结构化日志、支持日志轮转、具备 Hook 能力。
- 可选功能：支持颜色输出、兼容标准库 log 包、支持输出到不同的位置。


另外，一个日志包还需要支持不同级别的日志，按日志级别优先级从低到高分别是：Trace < Debug < Info < Warn/Warning < Error < Panic < Fatal。其中 Debug、Info、Warn、Error、Fatal 是比较基础的级别，**建议**在开发一个日志包时包含这些级别。Trace、Panic 是可选的级别。


在我们掌握了日志包的功能之后，就可以设计、开发日志包了。但我们在开发过程中，还需要确保我们的日志包具有比较高的性能、并发安全、支持插件化的能力，并支持日志参数控制。有了日志包，我们还需要知道如何更好地使用日志包，也就是如何记录日志。在文中，我给出了一些记录**建议**，内容比较多，你可以返回文中查看。

最后，我还给出了分布式日志解决方案：EFK/ELK。EFK 是 ELK 的升级版，在实际项目开发中，我们可以直接选择 EFK。在 EFK 方案中，通过 Filebeat 将日志上传到 Kafka，Logstash indexer 消费 Kafka 中的日志，并投递到 Elasticsearch 中存储起来，最后通过 Kibana 图形界面来查看日志。

## 21 | 日志处理（下）：手把手教你从 0 编写一个日志包

在实际开发中，我们可以选择一些优秀的开源日志包，不加修改直接拿来使用。但更多时候，是基于一个或某几个优秀的开源日志包进行二次开发。想要开发或者二次开发一个日志包，就要掌握日志包的实现方式。那么这一讲中，我来带你从 0 到 1，实现一个具备基本功能的日志包，让你从中一窥日志包的实现原理和实现方法。在开始实战之前，我们先来看下目前业界有哪些优秀的开源日志包。


### 有哪些优秀的开源日志包？
在 Go 项目开发中，我们可以通过修改一些优秀的开源日志包，来实现项目的日志包。Go 生态中有很多优秀的开源日志包，例如标准库 log 包、glog、logrus、zap、seelog、zerolog、log15、apex/log、go-logging 等。其中，用得比较多的是标准库 log 包、glog、logrus 和 zap。


为了使你了解开源日志包的现状，接下来我会简单介绍下这几个常用的日志包。至于它们的具体使用方法，你可以参考我整理的一篇文章：[优秀开源日志包使用教程](https://github.com/marmotedu/geekbang-go/blob/master/%E4%BC%98%E7%A7%80%E5%BC%80%E6%BA%90%E6%97%A5%E5%BF%97%E5%8C%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.md)。


#### 标准库 log 包
标准库 log 包的功能非常简单，只提供了 Print、Panic 和 Fatal 三类函数用于日志输出。因为是标准库自带的，所以不需要我们下载安装，使用起来非常方便。标准库 log 包只有不到 400 行的代码量，如果你想研究如何实现一个日志包，阅读标准库 log 包是一个不错的开始。Go 的标准库大量使用了 log 包，例如net/http 、 net/rpc 等。


#### glog
glog是 Google 推出的日志包，跟标准库 log 包一样，它是一个轻量级的日志包，使用起来简单方便。但 glog 比标准库 log 包提供了更多的功能，它具有如下特性：

- 支持 4 种日志级别：Info、Warning、Error、Fatal。
- 支持命令行选项，例如-alsologtostderr、-log_backtrace_at、-log_dir、-logtostderr、-v等，每个参数实现某种功能。
- 支持根据文件大小切割日志文件。
- 支持日志按级别分类输出。
- 支持 V level。V level 特性可以使开发者自定义日志级别。
- 支持 vmodule。vmodule 可以使开发者对不同的文件使用不同的日志级别。
- 支持 traceLocation。traceLocation 可以打印出指定位置的栈信息。

Kubernetes 项目就使用了基于 glog 封装的 klog，作为其日志库。


#### logrus
logrus是目前 GitHub 上 star 数量最多的日志包，它的优点是功能强大、性能高效、高度灵活，还提供了自定义插件的功能。很多优秀的开源项目，例如 Docker、Prometheus 等，都使用了 logrus。除了具有日志的基本功能外，logrus 还具有如下特性：


- 支持常用的日志级别。logrus 支持 Debug、Info、Warn、Error、Fatal 和 Panic 这些日志级别。
- 可扩展。logrus 的 Hook 机制允许使用者通过 Hook 的方式，将日志分发到任意地方，例如本地文件、标准输出、Elasticsearch、Logstash、Kafka 等。
- 支持自定义日志格式。logrus 内置了 JSONFormatter 和 TextFormatter 两种格式。除此之外，logrus 还允许使用者通过实现 Formatter 接口，来自定义日志格式。
- 结构化日志记录。logrus 的 Field 机制允许使用者自定义日志字段，而不是通过冗长的消息来记录日志。
- 预设日志字段。logrus 的 Default Fields 机制，可以给一部分或者全部日志统一添加共同的日志字段，例如给某次 HTTP 请求的所有日志添加 X-Request-ID 字段。
- Fatal handlers。logrus 允许注册一个或多个 handler，当产生 Fatal 级别的日志时调用。当我们的程序需要优雅关闭时，这个特性会非常有用。


#### zap
zap是 uber 开源的日志包，以高性能著称，很多公司的日志包都是基于 zap 改造而来。除了具有日志基本的功能之外，zap 还具有很多强大的特性：


- 支持常用的日志级别，例如：Debug、Info、Warn、Error、DPanic、Panic、Fatal。
- 性能非常高。zap 具有非常高的性能，适合对性能要求比较高的场景。
- 支持针对特定的日志级别，输出调用堆栈。
- 像 logrus 一样，zap 也支持结构化的目录日志、预设日志字段，也因为支持 Hook 而具有可扩展性。


### 开源日志包选择
上面我介绍了很多日志包，每种日志包使用的场景不同，你可以根据自己的需求，结合日志包的特性进行选择：


- 标准库 log 包： 标准库 log 包不支持日志级别、日志分割、日志格式等功能，所以在大型项目中很少直接使用，通常用于一些短小的程序，比如用于生成 JWT Token 的 main.go 文件中。标准库日志包也很适合一些简短的代码，用于快速调试和验证。
- glog： glog 实现了日志包的基本功能，非常适合一些对日志功能要求不多的小型项目。
- logrus： logrus 功能强大，不仅实现了日志包的基本功能，还有很多高级特性，适合一些大型项目，尤其是需要结构化日志记录的项目。
- zap： zap 提供了很强大的日志功能，性能高，内存分配次数少，适合对日志性能要求很高的项目。另外，zap 包中的子包 zapcore，提供了很多底层的日志接口，适合用来做二次封装。


举个我自己选择日志包来进行二次开发的例子：我在做容器云平台开发时，发现 Kubernetes 源码中大量使用了 glog，这时就需要日志包能够兼容 glog。于是，我基于 zap 和 zapcore 封装了github.com/marmotedu/iam/pkg/log日志包，这个日志包可以很好地兼容 glog。


在实际项目开发中，你可以根据项目需要，从上面几个日志包中进行选择，直接使用，但更多时候，你还需要基于这些包来进行定制开发。为了使你更深入地掌握日志包的设计和开发，接下来，我会从 0 到 1 带你开发一个日志包。


### 从 0 编写一个日志包
接下来，我会向你展示如何快速编写一个具备基本功能的日志包，让你通过这个简短的日志包实现掌握日志包的核心设计思路。该日志包主要实现以下几个功能：


- 支持自定义配置。
- 支持文件名和行号。
- 支持日志级别 Debug、Info、Warn、Error、Panic、Fatal。
- 支持输出到本地文件和标准输出。
- 支持 JSON 和 TEXT 格式的日志输出，支持自定义日志格式。
- 支持选项模式。


日志包名称为cuslog，示例项目完整代码存放在 cuslog。具体实现分为以下四个步骤：

- 定义：定义日志级别和日志选项。
- 创建：创建 Logger 及各级别日志打印方法。
- 写入：将日志输出到支持的输出中。
- 自定义：自定义日志输出格式。


#### 定义日志级别和日志选项
一个基本的日志包，首先需要定义好日志级别和日志选项。本示例将定义代码保存在options.go文件中。


```go
type Level uint8

const (
    DebugLevel Level = iota
    InfoLevel
    WarnLevel
    ErrorLevel
    PanicLevel
    FatalLevel
)

var LevelNameMapping = map[Level]string{
    DebugLevel: "DEBUG",
    InfoLevel:  "INFO",
    WarnLevel:  "WARN",
    ErrorLevel: "ERROR",
    PanicLevel: "PANIC",
    FatalLevel: "FATAL",
}
```
在日志输出时，要通过对比开关级别和输出级别的大小，来决定是否输出，所以日志级别 Level 要定义成方便比较的数值类型。几乎所有的日志包都是用常量计数器 iota 来定义日志级别。另外，因为要在日志输出中，输出可读的日志级别（例如输出 INFO 而不是 1），所以需要有 Level 到 Level Name 的映射 LevelNameMapping，LevelNameMapping 会在格式化时用到。



接下来看定义日志选项。日志需要是可配置的，方便开发者根据不同的环境设置不同的日志行为，比较常见的配置选项为：日志级别。输出位置，例如标准输出或者文件。输出格式，例如 JSON 或者 Text。是否开启文件名和行号。


本示例的日志选项定义如下：


```go
type options struct {
    output        io.Writer
    level         Level
    stdLevel      Level
    formatter     Formatter
    disableCaller bool
}
```
为了灵活地设置日志的选项，你可以通过选项模式，来对日志选项进行设置：


```go
type Option func(*options)

func initOptions(opts ...Option) (o *options) {
    o = &options{}
    for _, opt := range opts {
        opt(o)
    }

    if o.output == nil {
        o.output = os.Stderr
    }

    if o.formatter == nil {
        o.formatter = &TextFormatter{}
    }

    return
}

func WithLevel(level Level) Option {
    return func(o *options) {
        o.level = level
    }
}
...
func SetOptions(opts ...Option) {
    std.SetOptions(opts...)
}

func (l *logger) SetOptions(opts ...Option) {
    l.mu.Lock()
    defer l.mu.Unlock()

    for _, opt := range opts {
        opt(l.opt)
    }
}
```
具有选项模式的日志包，可通过以下方式，来动态地修改日志的选项：


```
cuslog.SetOptions(cuslog.WithLevel(cuslog.DebugLevel))
```
你可以根据需要，对每一个日志选项创建设置函数 WithXXXX 。这个示例日志包支持如下选项设置函数：
- WithOutput（output io.Writer）：设置输出位置。
- WithLevel（level Level）：设置输出级别。
- WithFormatter（formatter Formatter）：设置输出格式。
- WithDisableCaller（caller bool）：设置是否打印文件名和行号。


#### 创建 Logger 及各级别日志打印方法
为了打印日志，我们需要根据日志配置，创建一个 Logger，然后通过调用 Logger 的日志打印方法，完成各级别日志的输出。本示例将创建代码保存在logger.go文件中。


可以通过如下方式创建 Logger：



```go
var std = New()

type logger struct {
    opt       *options
    mu        sync.Mutex
    entryPool *sync.Pool
}

func New(opts ...Option) *logger {
    logger := &logger{opt: initOptions(opts...)}
    logger.entryPool = &sync.Pool{New: func() interface{} { return entry(logger) }}
    return logger
}
```
上述代码中，定义了一个 Logger，并实现了创建 Logger 的 New 函数。日志包都会有一个默认的全局 Logger，本示例通过 var std = New() 创建了一个全局的默认 Logger。cuslog.Debug、cuslog.Info 和 cuslog.Warnf 等函数，则是通过调用 std Logger 所提供的方法来打印日志的。


定义了一个 Logger 之后，还需要给该 Logger 添加最核心的日志打印方法，要提供所有支持级别的日志打印方法。如果日志级别是 Xyz，则通常需要提供两类方法，分别是非格式化方法Xyz(args ...interface{})和格式化方法Xyzf(format string, args ...interface{})，例如：



```go
func (l *logger) Debug(args ...interface{}) {
    l.entry().write(DebugLevel, FmtEmptySeparate, args...)
}
func (l *logger) Debugf(format string, args ...interface{}) {
    l.entry().write(DebugLevel, format, args...)
}

```
本示例实现了如下方法：Debug、Debugf、Info、Infof、Warn、Warnf、Error、Errorf、Panic、Panicf、Fatal、Fatalf。更详细的实现，你可以参考 cuslog/logger.go。这里要**注意**，Panic、Panicf 要调用 panic() 函数，Fatal、Fatalf 函数要调用 os.Exit(1) 函数。


#### 将日志输出到支持的输出中
调用日志打印函数之后，还需要将这些日志输出到支持的输出中，所以需要实现 write 函数，它的写入逻辑保存在entry.go文件中。实现方式如下：


```go
type Entry struct {
    logger *logger
    Buffer *bytes.Buffer
    Map    map[string]interface{}
    Level  Level
    Time   time.Time
    File   string
    Line   int
    Func   string
    Format string
    Args   []interface{}
}

func (e *Entry) write(level Level, format string, args ...interface{}) {
    if e.logger.opt.level > level {
        return
    }
    e.Time = time.Now()
    e.Level = level
    e.Format = format
    e.Args = args
    if !e.logger.opt.disableCaller {
        if pc, file, line, ok := runtime.Caller(2); !ok {
            e.File = "???"
            e.Func = "???"
        } else {
            e.File, e.Line, e.Func = file, line, runtime.FuncForPC(pc).Name()
            e.Func = e.Func[strings.LastIndex(e.Func, "/")+1:]
        }
    }
    e.format()
    e.writer()
    e.release()
}

func (e *Entry) format() {
    _ = e.logger.opt.formatter.Format(e)
}

func (e *Entry) writer() {
    e.logger.mu.Lock()
    _, _ = e.logger.opt.output.Write(e.Buffer.Bytes())
    e.logger.mu.Unlock()
}

func (e *Entry) release() {
    e.Args, e.Line, e.File, e.Format, e.Func = nil, 0, "", "", ""
    e.Buffer.Reset()
    e.logger.entryPool.Put(e)
}
```
上述代码，首先定义了一个 Entry 结构体类型，该类型用来保存所有的日志信息，即日志配置和日志内容。写入逻辑都是围绕 Entry 类型的实例来完成的。用 Entry 的 write 方法来完成日志的写入，在 write 方法中，会首先判断日志的输出级别和开关级别，如果输出级别小于开关级别，则直接返回，不做任何记录。

在 write 中，还会判断是否需要记录文件名和行号，如果需要则调用 runtime.Caller() 来获取文件名和行号，调用 runtime.Caller() 时，要**注意**传入正确的栈深度。write 函数中调用 e.format 来格式化日志，调用 e.writer 来写入日志，在创建 Logger 传入的日志配置中，指定了输出位置 output io.Writer ，output 类型为 io.Writer ，示例如下：


```go
type Writer interface {
    Write(p []byte) (n int, err error)
}
```
io.Writer 实现了 Write 方法可供写入，所以只需要调用e.logger.opt.output.Write(e.Buffer.Bytes())即可将日志写入到指定的位置中。最后，会调用 release() 方法来清空缓存和对象池。至此，我们就完成了日志的记录和写入。


#### 自定义日志输出格式
cuslog 包支持自定义输出格式，并且内置了 JSON 和 Text 格式的 Formatter。Formatter 接口定义为：


```go
type Formatter interface {
    Format(entry *Entry) error
}
```
cuslog 内置的 Formatter 有两个：JSON和TEXT。


#### 测试日志包
cuslog 日志包开发完成之后，可以编写测试代码，调用 cuslog 包来测试 cuslog 包，代码如下：


```go
package main

import (
    "log"
    "os"

    "github.com/marmotedu/gopractise-demo/log/cuslog"
)

func main() {
    cuslog.Info("std log")
    cuslog.SetOptions(cuslog.WithLevel(cuslog.DebugLevel))
    cuslog.Debug("change std log to debug level")
    cuslog.SetOptions(cuslog.WithFormatter(&cuslog.JsonFormatter{IgnoreBasicFields: false}))
    cuslog.Debug("log in json format")
    cuslog.Info("another log in json format")

    // 输出到文件
    fd, err := os.OpenFile("test.log", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        log.Fatalln("create file test.log failed")
    }
    defer fd.Close()

    l := cuslog.New(cuslog.WithLevel(cuslog.InfoLevel),
        cuslog.WithOutput(fd),
        cuslog.WithFormatter(&cuslog.JsonFormatter{IgnoreBasicFields: false}),
    )
    l.Info("custom log with json formatter")
}
```
将上述代码保存在 main.go 文件中，运行：


```
$ go run example.go
2020-12-04T10:32:12+08:00 INFO example.go:11 std log
2020-12-04T10:32:12+08:00 DEBUG example.go:13 change std log to debug level
{"file":"/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/log/cuslog/example/example.go:15","func":"main.main","message":"log in json format","level":"DEBUG","time":"2020-12-04T10:32:12+08:00"}
{"level":"INFO","time":"2020-12-04T10:32:12+08:00","file":"/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/log/cuslog/example/example.go:16","func":"main.main","message":"another log in json format"}
```
到这里日志包就开发完成了，完整包见 log/cuslog。


### IAM 项目日志包设计
这一讲的最后，我们再来看下我们的 IAM 项目中，日志包是怎么设计的。

先来看一下 IAM 项目 log 包的存放位置：pkg/log。放在这个位置，主要有两个原因：第一个，log 包属于 IAM 项目，有定制开发的内容；第二个，log 包功能完备、成熟，外部项目也可以使用。


该 log 包是基于 go.uber.org/zap 包封装而来的，根据需要添加了更丰富的功能。接下来，我们通过 log 包的Options，来看下 log 包所实现的功能：



```go
type Options struct {
    OutputPaths       []string `json:"output-paths"       mapstructure:"output-paths"`
    ErrorOutputPaths  []string `json:"error-output-paths" mapstructure:"error-output-paths"`
    Level             string   `json:"level"              mapstructure:"level"`
    Format            string   `json:"format"             mapstructure:"format"`
    DisableCaller     bool     `json:"disable-caller"     mapstructure:"disable-caller"`
    DisableStacktrace bool     `json:"disable-stacktrace" mapstructure:"disable-stacktrace"`
    EnableColor       bool     `json:"enable-color"       mapstructure:"enable-color"`
    Development       bool     `json:"development"        mapstructure:"development"`
    Name              string   `json:"name"               mapstructure:"name"`
}
```
Options 各配置项含义如下：
- development：是否是开发模式。如果是开发模式，会对 DPanicLevel 进行堆栈跟踪。
- name：Logger 的名字。
- disable-caller：是否开启 caller，如果开启会在日志中显示调用日志所在的文件、函数和行号。
- disable-stacktrace：是否在 Panic 及以上级别禁止打印堆栈信息。
- enable-color：是否开启颜色输出，true，是；false，否。
- level：日志级别，优先级从低到高依次为：Debug, Info, Warn, Error, Dpanic, Panic, Fatal。
- format：支持的日志输出格式，目前支持 Console 和 JSON 两种。Console 其实就是 Text 格式。
- output-paths：支持输出到多个输出，用逗号分开。支持输出到标准输出（stdout）和文件。
- error-output-paths：zap 内部 (非业务) 错误日志输出路径，多个输出，用逗号分开。


log 包的 Options 结构体支持以下 3 个方法：
- Build 方法。Build 方法可以根据 Options 构建一个全局的 Logger。AddFlags 方法。
- AddFlags 方法可以将 Options 的各个字段追加到传入的 pflag.FlagSet 变量中。
- String 方法。String 方法可以将 Options 的值以 JSON 格式字符串返回。


log 包实现了以下 3 种日志记录方法：


```
log.Info("This is a info message", log.Int32("int_key", 10))
log.Infof("This is a formatted %s message", "info")
log.Infow("Message printed with Infow", "X-Request-ID", "fbf54504-64da-4088-9b86-67824a7fb508")
```
Info 使用指定的 key/value 记录日志。Infof 格式化记录日志。 Infow 也是使用指定的 key/value 记录日志，跟 Info 的区别是：使用 Info 需要指定值的类型，通过指定值的日志类型，日志库底层不需要进行反射操作，所以使用 Info 记录日志性能最高。


log 包支持非常丰富的类型，具体你可以参考 types.go。上述日志输出为：


```
2021-07-06 14:02:07.070 INFO This is a info message {"int_key": 10}
2021-07-06 14:02:07.071 INFO This is a formatted info message
2021-07-06 14:02:07.071 INFO Message printed with Infow {"X-Request-ID": "fbf54504-64da-4088-9b86-67824a7fb508"}
```
log 包为每种级别的日志都提供了 3 种日志记录方式，举个例子：假设日志格式为 Xyz ，则分别提供了 Xyz(msg string, fields ...Field) ，Xyzf(format string, v ...interface{}) ，Xyzw(msg string, keysAndValues ...interface{}) 3 种日志记录方法。


另外，log 包相较于一般的日志包，还提供了众多记录日志的方法。

第一个方法， log 包支持 V Level，可以通过整型数值来灵活指定日志级别，数值越大，优先级越低。例如：


```go
// V level使用
log.V(1).Info("This is a V level message")
log.V(1).Infof("This is a %s V level message", "formatted")
log.V(1).Infow("This is a V level message with fields", "X-Request-ID", "7a7b9f24-4cae-4b2a-9464-69088b45b904")
```
这里要**注意**，Log.V 只支持 Info 、Infof 、Infow三种日志记录方法。
第二个方法， log 包支持 WithValues 函数，例如：


```go
// WithValues使用
lv := log.WithValues("X-Request-ID", "7a7b9f24-4cae-4b2a-9464-69088b45b904")
lv.Infow("Info message printed with [WithValues] logger")
lv.Infow("Debug message printed with [WithValues] logger")
```
上述日志输出如下：


```
2021-07-06 14:15:28.555 INFO Info message printed with [WithValues] logger {"X-Request-ID": "7a7b9f24-4cae-4b2a-9464-69088b45b904"}
2021-07-06 14:15:28.556 INFO Debug message printed with [WithValues] logger {"X-Request-ID": "7a7b9f24-4cae-4b2a-9464-69088b45b904"}
```
WithValues 可以返回一个携带指定 key-value 的 Logger，供后面使用。

第三个方法， log 包提供 WithContext 和 FromContext 用来将指定的 Logger 添加到某个 Context 中，以及从某个 Context 中获取 Logger，例如：


```go
// Context使用
ctx := lv.WithContext(context.Background())
lc := log.FromContext(ctx)
lc.Info("Message printed with [WithContext] logger")
```
WithContext和FromContext非常适合用在以context.Context传递的函数中，例如：


```go
func main() {
 
    ...
 
    // WithValues使用
    lv := log.WithValues("X-Request-ID", "7a7b9f24-4cae-4b2a-9464-69088b45b904")
     
    // Context使用
    lv.Infof("Start to call pirntString")
    ctx := lv.WithContext(context.Background())
    pirntString(ctx, "World")  
}
 
func pirntString(ctx context.Context, str string) {
    lc := log.FromContext(ctx)
    lc.Infof("Hello %s", str)
}
```
上述代码输出如下：


```
2021-07-06 14:38:02.050 INFO Start to call pirntString {"X-Request-ID": "7a7b9f24-4cae-4b2a-9464-69088b45b904"}
2021-07-06 14:38:02.050 INFO Hello World {"X-Request-ID": "7a7b9f24-4cae-4b2a-9464-69088b45b904"}
```
将 Logger 添加到 Context 中，并通过 Context 在不同函数间传递，可以使 key-value 在不同函数间传递。例如上述代码中， X-Request-ID 在 main 函数、printString 函数中的日志输出中均有记录，从而实现了一种调用链的效果。



第四个方法， 可以很方便地从 Context 中提取出指定的 key-value，作为上下文添加到日志输出中，例如 internal/apiserver/api/v1/user/create.go文件中的日志调用：




```go
log.L(c).Info("user create function called.")
```
通过调用 Log.L() 函数，实现如下：


```go
// L method output with specified context value.
func L(ctx context.Context) *zapLogger {
    return std.L(ctx)
}
 
func (l *zapLogger) L(ctx context.Context) *zapLogger {
    lg := l.clone()
 
    requestID, _ := ctx.Value(KeyRequestID).(string)
    username, _ := ctx.Value(KeyUsername).(string)
    lg.zapLogger = lg.zapLogger.With(zap.String(KeyRequestID, requestID), zap.String(KeyUsername, username))
 
    return lg
}
```
L() 方法会从传入的 Context 中提取出 requestID 和 username ，追加到 Logger 中，并返回 Logger。这时候调用该 Logger 的 Info、Infof、Infow 等方法记录日志，输出的日志中均包含 requestID 和 username 字段，例如：


```
2021-07-06 14:46:00.743 INFO    apiserver       secret/create.go:23     create secret function called.  {"requestID": "73144bed-534d-4f68-8e8d-dc8a8ed48507", "username": "admin"}
```
通过将 Context 在函数间传递，很容易就能实现调用链效果，例如：


```go
// Create add new secret key pairs to the storage.
func (s *SecretHandler) Create(c *gin.Context) {
    log.L(c).Info("create secret function called.")
     
    ...
     
    secrets, err := s.srv.Secrets().List(c, username, metav1.ListOptions{    
        Offset: pointer.ToInt64(0),
        Limit:  pointer.ToInt64(-1),
    })
     
    ...
     
     if err := s.srv.Secrets().Create(c, &r, metav1.CreateOptions{}); err != nil {
        core.WriteResponse(c, err, nil)

        return
    }
 
    core.WriteResponse(c, nil, r)
}
```
上述代码输出为：


```
2021-07-06 14:46:00.743 INFO    apiserver       secret/create.go:23     create secret function called.  {"requestID": "73144bed-534d-4f68-8e8d-dc8a8ed48507", "username": "admin"}
2021-07-06 14:46:00.744 INFO    apiserver       secret/create.go:23     list secret from storage.  {"requestID": "73144bed-534d-4f68-8e8d-dc8a8ed48507", "username": "admin"}
2021-07-06 14:46:00.745 INFO    apiserver       secret/create.go:23     insert secret to storage.  {"requestID": "73144bed-534d-4f68-8e8d-dc8a8ed48507", "username": "admin"}
```
这里要**注意**， log.L 函数默认会从 Context 中取 requestID 和 username 键，这跟 IAM 项目有耦合度，但这不影响 log 包供第三方项目使用。这也是我**建议**你自己封装日志包的原因。


### 总结
开发一个日志包，我们很多时候需要基于一些业界优秀的开源日志包进行二次开发。当前很多项目的日志包都是基于 zap 日志包来封装的，如果你有封装的需要，我**建议**你优先选择 zap 日志包。


这一讲中，我先给你介绍了标准库 log 包、glog、logrus 和 zap 这四种常用的日志包，然后向你展现了开发一个日志包的四个步骤，步骤如下：定义日志级别和日志选项。创建 Logger 及各级别日志打印方法。将日志输出到支持的输出中。自定义日志输出格式。


最后，我介绍了 IAM 项目封装的 log 包的设计和使用方式。log 包基于 go.uber.org/zap封装，并提供了以下强大特性：
- log 包支持 V Level，可以灵活的通过整型数值来指定日志级别。
- log 包支持 WithValues 函数， WithValues 可以返回一个携带指定 key-value 对的 Logger，供后面使用。
- log 包提供 WithContext 和 FromContext 用来将指定的 Logger 添加到某个 Context 中和从某个 Context 中获取 Logger。
- log 包提供了 Log.L() 函数，可以很方便的从 Context 中提取出指定的 key-value 对，作为上下文添加到日志输出中。

## 22 | 应用构建三剑客：Pflag、Viper、Cobra 核心功能介绍

因为 IAM 项目使用了 Pflag、Viper 和 Cobra 包来构建 IAM 的应用框架，为了让你后面学习更加容易，这里简单介绍下这 3 个包的核心功能和使用方式。其实如果单独讲每个包的话，还是有很多功能可讲的，但我们这一讲的目的是减小你后面学习 IAM 源码的难度，所以我会主要介绍跟 IAM 相关的功能。在正式介绍这三个包之前，我们先来看下如何构建应用的框架。


### 如何构建应用框架
想知道如何构建应用框架，首先你要明白，一个应用框架包含哪些部分。在我看来，一个应用框架需要包含以下 3 个部分：

- 命令行参数解析：主要用来解析命令行参数，这些命令行参数可以影响命令的运行效果。
- 配置文件解析：一个大型应用，通常具有很多参数，为了便于管理和配置这些参数，通常会将这些参数放在一个配置文件中，供程序读取并解析。
- 应用的命令行框架：应用最终是通过命令来启动的。这里有 3 个需求点，一是命令需要具备 Help 功能，这样才能告诉使用者如何去使用；二是命令需要能够解析命令行参数和配置文件；三是命令需要能够初始化业务代码，并最终启动业务进程。也就是说，我们的命令需要具备框架的能力，来纳管这 3 个部分。

这 3 个部分的功能，你可以自己开发，也可以借助业界已有的成熟实现。跟之前的想法一样，我不**建议**你自己开发，更**建议**你采用业界已有的成熟实现。命令行参数可以通过Pflag来解析，配置文件可以通过Viper来解析，应用的命令行框架则可以通过Cobra来实现。这 3 个包目前也是最受欢迎的包，并且这 3 个包不是割裂的，而是有联系的，我们可以有机地组合这 3 个包，从而实现一个非常强大、优秀的应用命令行框架。


接下来，我们就来详细看下，这 3 个包在 Go 项目开发中是如何使用的。


### 命令行参数解析工具：Pflag 使用介绍
Go 服务开发中，经常需要给开发的组件加上各种启动参数来配置服务进程，影响服务的行为。像 kube-apiserver 就有多达 200 多个启动参数，而且这些参数的类型各不相同（例如：string、int、ip 类型等），使用方式也不相同（例如：需要支持--长选项，-短选项等），所以我们需要一个强大的命令行参数解析工具。

虽然 Go 源码中提供了一个标准库 Flag 包，用来对命令行参数进行解析，但在大型项目中应用更广泛的是另外一个包：Pflag。Pflag 提供了很多强大的特性，非常适合用来构建大型项目，一些耳熟能详的开源项目都是用 Pflag 来进行命令行参数解析的，例如：Kubernetes、Istio、Helm、Docker、Etcd 等。

接下来，我们就来介绍下如何使用 Pflag。Pflag 主要是通过创建 Flag 和 FlagSet 来使用的。我们先来看下 Flag。


#### Pflag 包 Flag 定义
Pflag 可以对命令行参数进行处理，一个命令行参数在 Pflag 包中会解析为一个 Flag 类型的变量。Flag 是一个结构体，定义如下：



```go
type Flag struct {
    Name                string // flag长选项的名称
    Shorthand           string // flag短选项的名称，一个缩写的字符
    Usage               string // flag的使用文本
    Value               Value  // flag的值
    DefValue            string // flag的默认值
    Changed             bool // 记录flag的值是否有被设置过
    NoOptDefVal         string // 当flag出现在命令行，但是没有指定选项值时的默认值
    Deprecated          string // 记录该flag是否被放弃
    Hidden              bool // 如果值为true，则从help/usage输出信息中隐藏该flag
    ShorthandDeprecated string // 如果flag的短选项被废弃，当使用flag的短选项时打印该信息
    Annotations         map[string][]string // 给flag设置注解
}
```
Flag 的值是一个 Value 类型的接口，Value 定义如下：


```go
type Value interface {
    String() string // 将flag类型的值转换为string类型的值，并返回string的内容
    Set(string) error // 将string类型的值转换为flag类型的值，转换失败报错
    Type() string // 返回flag的类型，例如：string、int、ip等
}

```
通过将 Flag 的值抽象成一个 interface 接口，我们就可以自定义 Flag 的类型了。只要实现了 Value 接口的结构体，就是一个新类型。


#### Pflag 包 FlagSet 定义
Pflag 除了支持单个的 Flag 之外，还支持 FlagSet。FlagSet 是一些预先定义好的 Flag 的集合，几乎所有的 Pflag 操作，都需要借助 FlagSet 提供的方法来完成。在实际开发中，我们可以使用两种方法来获取并使用 FlagSet：


方法一，调用 NewFlagSet 创建一个 FlagSet。方法二，使用 Pflag 包定义的全局 FlagSet：CommandLine。实际上 CommandLine 也是由 NewFlagSet 函数创建的。


先来看下第一种方法，自定义 FlagSet。下面是一个自定义 FlagSet 的示例：


```go
var version bool
flagSet := pflag.NewFlagSet("test", pflag.ContinueOnError)
flagSet.BoolVar(&version, "version", true, "Print version information and quit.")
```
我们可以通过定义一个新的 FlagSet 来定义命令及其子命令的 Flag。再来看下第二种方法，使用全局 FlagSet。下面是一个使用全局 FlagSet 的示例：


```go
import (
    "github.com/spf13/pflag"
)

pflag.BoolVarP(&version, "version", "v", true, "Print version information and quit.")

```
这其中，pflag.BoolVarP 函数定义如下：



```go
func BoolVarP(p *bool, name, shorthand string, value bool, usage string) {
    flag := CommandLine.VarPF(newBoolValue(value, p), name, shorthand, usage)
    flag.NoOptDefVal = "true"
}
```
可以看到 pflag.BoolVarP 最终调用了 CommandLine，CommandLine 是一个包级别的变量，定义为：


```go
// CommandLine is the default set of command-line flags, parsed from os.Args.
var CommandLine = NewFlagSet(os.Args[0], ExitOnError)

```
在一些不需要定义子命令的命令行工具中，我们可以直接使用全局的 FlagSet，更加简单方便。


#### Pflag 使用方法
上面，我们介绍了使用 Pflag 包的两个核心结构体。接下来，我来详细介绍下 Pflag 的常见使用方法。Pflag 有很多强大的功能，我这里介绍 7 个常见的使用方法。


支持多种命令行参数定义方式。
Pflag 支持以下 4 种命令行参数定义方式：

支持长选项、默认值和使用文本，并将标志的值存储在指针中。


```go
var name = pflag.String("name", "colin", "Input Your Name")
```
支持长选项、短选项、默认值和使用文本，并将标志的值存储在指针中。


```go
var name = pflag.StringP("name", "n", "colin", "Input Your Name")
```
支持长选项、默认值和使用文本，并将标志的值绑定到变量。


```go
var name string
pflag.StringVar(&name, "name", "colin", "Input Your Name")
```
支持长选项、短选项、默认值和使用文本，并将标志的值绑定到变量。



```go
var name string
pflag.StringVarP(&name, "name", "n","colin", "Input Your Name")
```
上面的函数命名是有规则的：函数名带Var说明是将标志的值绑定到变量，否则是将标志的值存储在指针中。函数名带P说明支持短选项，否则不支持短选项。


使用Get获取参数的值。
可以使用Get来获取标志的值，代表 Pflag 所支持的类型。例如：有一个 pflag.FlagSet，带有一个名为 flagname 的 int 类型的标志，可以使用GetInt()来获取 int 值。需要**注意** flagname 必须存在且必须是 int，例如：



```go
i, err := flagset.GetInt("flagname")
```
获取非选项参数。
代码示例如下：


```go
package main

import (
    "fmt"

    "github.com/spf13/pflag"
)

var (
    flagvar = pflag.Int("flagname", 1234, "help message for flagname")
)

func main() {
    pflag.Parse()

    fmt.Printf("argument number is: %v\n", pflag.NArg())
    fmt.Printf("argument list is: %v\n", pflag.Args())
    fmt.Printf("the first argument is: %v\n", pflag.Arg(0))
}

```
执行上述代码，输出如下：


```
$ go run example1.go arg1 arg2
argument number is: 2
argument list is: [arg1 arg2]
the first argument is: arg1
```
在定义完标志之后，可以调用pflag.Parse()来解析定义的标志。解析后，可通过pflag.Args()返回所有的非选项参数，通过pflag.Arg(i)返回第 i 个非选项参数。参数下标 0 到 pflag.NArg() - 1。


指定了选项但是没有指定选项值时的默认值。
创建一个 Flag 后，可以为这个 Flag 设置pflag.NoOptDefVal。如果一个 Flag 具有 NoOptDefVal，并且该 Flag 在命令行上没有设置这个 Flag 的值，则该标志将设置为 NoOptDefVal 指定的值。例如：


```go
var ip = pflag.IntP("flagname", "f", 1234, "help message")
pflag.Lookup("flagname").NoOptDefVal = "4321"
```
上面的代码会产生结果，具体你可以参照下表：


![img](https://static001.geekbang.org/resource/image/fe/3f/fe76a52906c35b49b890225d1f5fc93f.png?wh=1428x336)


弃用标志或者标志的简写。
Pflag 可以弃用标志或者标志的简写。弃用的标志或标志简写在帮助文本中会被隐藏，并在使用不**推荐**的标志或简写时打印正确的用法提示。例如，弃用名为 logmode 的标志，并告知用户应该使用哪个标志代替：


```go
// deprecate a flag by specifying its name and a usage message
pflag.CommandLine.MarkDeprecated("logmode", "please use --log-mode instead")
```
这样隐藏了帮助文本中的 logmode，并且当使用 logmode 时，打印了Flag --logmode has been deprecated, please use --log-mode instead。


保留名为 port 的标志，但是弃用它的简写形式。


```go
pflag.IntVarP(&port, "port", "P", 3306, "MySQL service host port.")

// deprecate a flag shorthand by specifying its flag name and a usage message
pflag.CommandLine.MarkShorthandDeprecated("port", "please use --port only")
```
这样隐藏了帮助文本中的简写 P，并且当使用简写 P 时，打印了Flag shorthand -P has been deprecated, please use --port only。usage message 在此处必不可少，并且不应为空。

隐藏标志。
可以将 Flag 标记为隐藏的，这意味着它仍将正常运行，但不会显示在 usage/help 文本中。例如：隐藏名为 secretFlag 的标志，只在内部使用，并且不希望它显示在帮助文本或者使用文本中。代码如下：


```go
// hide a flag by specifying its name
pflag.CommandLine.MarkHidden("secretFlag")
```
至此，我们介绍了 Pflag 包的重要用法。接下来，我们再来看下如何解析配置文件。


### 配置解析神器：Viper 使用介绍
几乎所有的后端服务，都需要一些配置项来配置我们的服务，一些小型的项目，配置不是很多，可以选择只通过命令行参数来传递配置。但是大型项目配置很多，通过命令行参数传递就变得很麻烦，不好维护。标准的解决方案是将这些配置信息保存在配置文件中，由程序启动时加载和解析。Go 生态中有很多包可以加载并解析配置文件，目前最受欢迎的是 Viper 包。

Viper 是 Go 应用程序现代化的、完整的解决方案，能够处理不同格式的配置文件，让我们在构建现代应用程序时，不必担心配置文件格式。Viper 也能够满足我们对应用配置的各种需求。


Viper 可以从不同的位置读取配置，不同位置的配置具有不同的优先级，高优先级的配置会覆盖低优先级相同的配置，按优先级从高到低排列如下：

1. 通过 viper.Set 函数显示设置的配置
2. 命令行参数
3. 环境变量
4. 配置文件
5. Key/Value 存储
6. 默认值

这里需要**注意**，Viper 配置键不区分大小写。Viper 有很多功能，最重要的两类功能是读入配置和读取配置，Viper 提供不同的方式来实现这两类功能。接下来，我们就来详细介绍下 Viper 如何读入配置和读取配置。


#### 读入配置
读入配置，就是将配置读入到 Viper 中，有如下读入方式：

- 设置默认的配置文件名。
- 读取配置文件。
- 监听和重新读取配置文件。
- 从 io.Reader 读取配置。
- 从环境变量读取。
- 从命令行标志读取。
- 从远程 Key/Value 存储读取。


这几个方法的具体读入方式，你可以看下面的展示。



设置默认值。一个好的配置系统应该支持默认值。Viper 支持对 key 设置默认值，当没有通过配置文件、环境变量、远程配置或命令行标志设置 key 时，设置默认值通常是很有用的，可以让程序在没有明确指定配置时也能够正常运行。例如：


```go
viper.SetDefault("ContentDir", "content")
viper.SetDefault("LayoutDir", "layouts")
viper.SetDefault("Taxonomies", map[string]string{"tag": "tags", "category": "categories"})
```
读取配置文件。Viper 可以读取配置文件来解析配置，支持 JSON、TOML、YAML、YML、Properties、Props、Prop、HCL、Dotenv、Env 格式的配置文件。Viper 支持搜索多个路径，并且默认不配置任何搜索路径，将默认决策留给应用程序。


以下是如何使用 Viper 搜索和读取配置文件的示例：


```go
package main

import (
  "fmt"

  "github.com/spf13/pflag"
  "github.com/spf13/viper"
)

var (
  cfg  = pflag.StringP("config", "c", "", "Configuration file.")
  help = pflag.BoolP("help", "h", false, "Show this help message.")
)

func main() {
  pflag.Parse()
  if *help {
    pflag.Usage()
    return
  }

  // 从配置文件中读取配置
  if *cfg != "" {
    viper.SetConfigFile(*cfg)   // 指定配置文件名
    viper.SetConfigType("yaml") // 如果配置文件名中没有文件扩展名，则需要指定配置文件的格式，告诉viper以何种格式解析文件
  } else {
    viper.AddConfigPath(".")          // 把当前目录加入到配置文件的搜索路径中
    viper.AddConfigPath("$HOME/.iam") // 配置文件搜索路径，可以设置多个配置文件搜索路径
    viper.SetConfigName("config")     // 配置文件名称（没有文件扩展名）
  }

  if err := viper.ReadInConfig(); err != nil { // 读取配置文件。如果指定了配置文件名，则使用指定的配置文件，否则在注册的搜索路径中搜索
    panic(fmt.Errorf("Fatal error config file: %s \n", err))
  }

  fmt.Printf("Used configuration file is: %s\n", viper.ConfigFileUsed())
}
```
Viper 支持设置多个配置文件搜索路径，需要**注意**添加搜索路径的顺序，Viper 会根据添加的路径顺序搜索配置文件，如果找到则停止搜索。如果调用 SetConfigFile 直接指定了配置文件名，并且配置文件名没有文件扩展名时，需要显式指定配置文件的格式，以使 Viper 能够正确解析配置文件。


如果通过搜索的方式查找配置文件，则需要**注意**，SetConfigName 设置的配置文件名是不带扩展名的，在搜索时 Viper 会在文件名之后追加文件扩展名，并尝试搜索所有支持的扩展类型。


监听和重新读取配置文件。Viper 支持在运行时让应用程序实时读取配置文件，也就是热加载配置。可以通过 WatchConfig 函数热加载配置。在调用 WatchConfig 函数之前，需要确保已经添加了配置文件的搜索路径。另外，还可以为 Viper 提供一个回调函数，以便在每次发生更改时运行。这里我也给你个示例：


```go
viper.WatchConfig()
viper.OnConfigChange(func(e fsnotify.Event) {
   // 配置文件发生变更之后会调用的回调函数
  fmt.Println("Config file changed:", e.Name)
})
```
我不**建议**在实际开发中使用热加载功能，因为即使配置热加载了，程序中的代码也不一定会热加载。例如：修改了服务监听端口，但是服务没有重启，这时候服务还是监听在老的端口上，会造成不一致。


设置配置值。我们可以通过 viper.Set() 函数来显式设置配置：


```
viper.Set("user.username", "colin")
```
使用环境变量。Viper 还支持环境变量，通过如下 5 个函数来支持环境变量：


- AutomaticEnv()
- BindEnv(input …string) error
- SetEnvPrefix(in string)
- SetEnvKeyReplacer(r *strings.Replacer)
- AllowEmptyEnv(allowEmptyEnv bool)


这里要**注意**：Viper 读取环境变量是区分大小写的。Viper 提供了一种机制来确保 Env 变量是唯一的。通过使用 SetEnvPrefix，可以告诉 Viper 在读取环境变量时使用前缀。BindEnv 和 AutomaticEnv 都将使用此前缀。比如，我们设置了 viper.SetEnvPrefix(“VIPER”)，当使用 viper.Get(“apiversion”) 时，实际读取的环境变量是VIPER_APIVERSION。


BindEnv 需要一个或两个参数。第一个参数是键名，第二个是环境变量的名称，环境变量的名称区分大小写。如果未提供 Env 变量名，则 Viper 将假定 Env 变量名为：环境变量前缀_键名全大写。例如：前缀为 VIPER，key 为 username，则 Env 变量名为VIPER_USERNAME。当显示提供 Env 变量名（第二个参数）时，它不会自动添加前缀。例如，如果第二个参数是 ID，Viper 将查找环境变量 ID。


在使用 Env 变量时，需要**注意**的一件重要事情是：每次访问该值时都将读取它。Viper 在调用 BindEnv 时不固定该值。


还有一个魔法函数 SetEnvKeyReplacer，SetEnvKeyReplacer 允许你使用 strings.Replacer 对象来重写 Env 键。如果你想在 Get() 调用中使用-或者.，但希望你的环境变量使用_分隔符，可以通过 SetEnvKeyReplacer 来实现。比如，我们设置了环境变量USER_SECRET_KEY=bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb，但我们想用viper.Get("user.secret-key")，那我们就调用函数：


```go
viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_"))
```
上面的代码，在调用 viper.Get() 函数时，会用 _ 替换.和-。默认情况下，空环境变量被认为是未设置的，并将返回到下一个配置源。若要将空环境变量视为已设置，可以使用 AllowEmptyEnv 方法。使用环境变量示例如下：



```go
// 使用环境变量
os.Setenv("VIPER_USER_SECRET_ID", "QLdywI2MrmDVjSSv6e95weNRvmteRjfKAuNV")
os.Setenv("VIPER_USER_SECRET_KEY", "bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb")

viper.AutomaticEnv()                                             // 读取环境变量
viper.SetEnvPrefix("VIPER")                                      // 设置环境变量前缀：VIPER_，如果是viper，将自动转变为大写。
viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_")) // 将viper.Get(key) key字符串中'.'和'-'替换为'_'
viper.BindEnv("user.secret-key")
viper.BindEnv("user.secret-id", "USER_SECRET_ID") // 绑定环境变量名到key
```
使用标志。Viper 支持 Pflag 包，能够绑定 key 到 Flag。与 BindEnv 类似，在调用绑定方法时，不会设置该值，但在访问它时会设置。对于单个标志，可以调用 BindPFlag() 进行绑定：


```go
viper.BindPFlag("token", pflag.Lookup("token")) // 绑定单个标志
```
还可以绑定一组现有的 pflags（pflag.FlagSet）：


```go
viper.BindPFlags(pflag.CommandLine)             //绑定标志集
```
#### 读取配置
Viper 提供了如下方法来读取配置：
- Get(key string) interface{}
- Get(key string) 
- AllSettings() map[string]interface{}
- IsSet(key string) : bool


每一个 Get 方法在找不到值的时候都会返回零值。为了检查给定的键是否存在，可以使用 IsSet() 方法。可以是 Viper 支持的类型，首字母大写：Bool、Float64、Int、IntSlice、String、StringMap、StringMapString、StringSlice、Time、Duration。例如：GetInt()。


常见的读取配置方法有以下几种。


访问嵌套的键。例如，加载下面的 JSON 文件：


```
json
{
    "host": {
        "address": "localhost",
        "port": 5799
    },
    "datastore": {
        "metric": {
            "host": "127.0.0.1",
            "port": 3099
        },
        "warehouse": {
            "host": "198.0.0.1",
            "port": 2112
        }
    }
}
```
Viper 可以通过传入.分隔的路径来访问嵌套字段：


```go
viper.GetString("datastore.metric.host") // (返回 "127.0.0.1")
```
如果datastore.metric被直接赋值覆盖（被 Flag、环境变量、set() 方法等等），那么datastore.metric的所有子键都将变为未定义状态，它们被高优先级配置级别覆盖了。如果存在与分隔的键路径匹配的键，则直接返回其值。例如：


```
json
{
    "datastore.metric.host": "0.0.0.0",
    "host": {
        "address": "localhost",
        "port": 5799
    },
    "datastore": {
        "metric": {
            "host": "127.0.0.1",
            "port": 3099
        },
        "warehouse": {
            "host": "198.0.0.1",
            "port": 2112
        }
    }
}
```
通过 viper.GetString 获取值：


```go
viper.GetString("datastore.metric.host") // 返回 "0.0.0.0"
```
反序列化。Viper 可以支持将所有或特定的值解析到结构体、map 等。可以通过两个函数来实现：

- Unmarshal(rawVal interface{}) error
- UnmarshalKey(key string, rawVal interface{}) error

一个示例：


```go
type config struct {
  Port int
  Name string
  PathMap string `mapstructure:"path_map"`
}

var C config

err := viper.Unmarshal(&C)
if err != nil {
  t.Fatalf("unable to decode into struct, %v", err)
}
```
如果想要解析那些键本身就包含.(默认的键分隔符）的配置，则需要修改分隔符：


```go
v := viper.NewWithOptions(viper.KeyDelimiter("::"))

v.SetDefault("chart::values", map[string]interface{}{
    "ingress": map[string]interface{}{
        "annotations": map[string]interface{}{
            "traefik.frontend.rule.type":                 "PathPrefix",
            "traefik.ingress.kubernetes.io/ssl-redirect": "true",
        },
    },
})

type config struct {
  Chart struct{
        Values map[string]interface{}
    }
}

var C config

v.Unmarshal(&C)
```
Viper 在后台使用github.com/mitchellh/mapstructure来解析值，其默认情况下使用mapstructure tags。当我们需要将 Viper 读取的配置反序列到我们定义的结构体变量中时，一定要使用 mapstructure tags。


序列化成字符串。有时候我们需要将 Viper 中保存的所有设置序列化到一个字符串中，而不是将它们写入到一个文件中，示例如下：


```go
import (
    yaml "gopkg.in/yaml.v2"
    // ...
)

func yamlStringSettings() string {
    c := viper.AllSettings()
    bs, err := yaml.Marshal(c)
    if err != nil {
        log.Fatalf("unable to marshal config to YAML: %v", err)
    }
    return string(bs)
}
```
### 现代化的命令行框架：Cobra 全解
Cobra 既是一个可以创建强大的现代 CLI 应用程序的库，也是一个可以生成应用和命令文件的程序。有许多大型项目都是用 Cobra 来构建应用程序的，例如 Kubernetes、Docker、etcd、Rkt、Hugo 等。


Cobra 建立在 commands、arguments 和 flags 结构之上。commands 代表命令，arguments 代表非选项参数，flags 代表选项参数（也叫标志）。一个好的应用程序应该是易懂的，用户可以清晰地知道如何去使用这个应用程序。应用程序通常遵循如下模式：APPNAME VERB NOUN --ADJECTIVE或者APPNAME COMMAND ARG --FLAG，例如：


```
git clone URL --bare # clone 是一个命令，URL是一个非选项参数，bare是一个选项参数
```
这里，VERB 代表动词，NOUN 代表名词，ADJECTIVE 代表形容词。


Cobra 提供了两种方式来创建命令：Cobra 命令和 Cobra 库。Cobra 命令可以生成一个 Cobra 命令模板，而命令模板也是通过引用 Cobra 库来构建命令的。所以，这里我直接介绍如何使用 Cobra 库来创建命令。



#### 使用 Cobra 库创建命令
如果要用 Cobra 库编码实现一个应用程序，需要首先创建一个空的 main.go 文件和一个 rootCmd 文件，之后可以根据需要添加其他命令。具体步骤如下：


创建 rootCmd。


```
$ mkdir -p newApp2 && cd newApp2
```
通常情况下，我们会将 rootCmd 放在文件 cmd/root.go 中。



```go
var rootCmd = &cobra.Command{
  Use:   "hugo",
  Short: "Hugo is a very fast static site generator",
  Long: `A Fast and Flexible Static Site Generator built with
                love by spf13 and friends in Go.
                Complete documentation is available at http://hugo.spf13.com`,
  Run: func(cmd *cobra.Command, args []string) {
    // Do Stuff Here
  },
}

func Execute() {
  if err := rootCmd.Execute(); err != nil {
    fmt.Println(err)
    os.Exit(1)
  }
}
```
还可以在 init() 函数中定义标志和处理配置，例如 cmd/root.go。


```go
import (
  "fmt"
  "os"

  homedir "github.com/mitchellh/go-homedir"
  "github.com/spf13/cobra"
  "github.com/spf13/viper"
)

var (
    cfgFile     string
    projectBase string
    userLicense string
)

func init() {
  cobra.OnInitialize(initConfig)
  rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $HOME/.cobra.yaml)")
  rootCmd.PersistentFlags().StringVarP(&projectBase, "projectbase", "b", "", "base project directory eg. github.com/spf13/")
  rootCmd.PersistentFlags().StringP("author", "a", "YOUR NAME", "Author name for copyright attribution")
  rootCmd.PersistentFlags().StringVarP(&userLicense, "license", "l", "", "Name of license for the project (can provide `licensetext` in config)")
  rootCmd.PersistentFlags().Bool("viper", true, "Use Viper for configuration")
  viper.BindPFlag("author", rootCmd.PersistentFlags().Lookup("author"))
  viper.BindPFlag("projectbase", rootCmd.PersistentFlags().Lookup("projectbase"))
  viper.BindPFlag("useViper", rootCmd.PersistentFlags().Lookup("viper"))
  viper.SetDefault("author", "NAME HERE <EMAIL ADDRESS>")
  viper.SetDefault("license", "apache")
}

func initConfig() {
  // Don't forget to read config either from cfgFile or from home directory!
  if cfgFile != "" {
    // Use config file from the flag.
    viper.SetConfigFile(cfgFile)
  } else {
    // Find home directory.
    home, err := homedir.Dir()
    if err != nil {
      fmt.Println(err)
      os.Exit(1)
    }

    // Search config in home directory with name ".cobra" (without extension).
    viper.AddConfigPath(home)
    viper.SetConfigName(".cobra")
  }

  if err := viper.ReadInConfig(); err != nil {
    fmt.Println("Can't read config:", err)
    os.Exit(1)
  }
}
```
创建 main.go。我们还需要一个 main 函数来调用 rootCmd，通常我们会创建一个 main.go 文件，在 main.go 中调用 rootCmd.Execute() 来执行命令：


```go
package main

import (
  "{pathToYourApp}/cmd"
)

func main() {
  cmd.Execute()
}
```
需要**注意**，main.go 中不**建议**放很多代码，通常只需要调用 cmd.Execute() 即可。



添加命令。除了 rootCmd，我们还可以调用 AddCommand 添加其他命令，通常情况下，我们会把其他命令的源码文件放在 cmd/ 目录下，例如，我们添加一个 version 命令，可以创建 cmd/version.go 文件，内容为：



```go
package cmd

import (
  "fmt"

  "github.com/spf13/cobra"
)

func init() {
  rootCmd.AddCommand(versionCmd)
}

var versionCmd = &cobra.Command{
  Use:   "version",
  Short: "Print the version number of Hugo",
  Long:  `All software has versions. This is Hugo's`,
  Run: func(cmd *cobra.Command, args []string) {
    fmt.Println("Hugo Static Site Generator v0.9 -- HEAD")
  },
}

```
本示例中，我们通过调用rootCmd.AddCommand(versionCmd)给 rootCmd 命令添加了一个 versionCmd 命令。


编译并运行。将 main.go 中{pathToYourApp}替换为对应的路径，例如本示例中 pathToYourApp 为github.com/marmotedu/gopractise-demo/cobra/newApp2。


```
$ go mod init github.com/marmotedu/gopractise-demo/cobra/newApp2
$ go build -v .
$ ./newApp2 -h
A Fast and Flexible Static Site Generator built with
love by spf13 and friends in Go.
Complete documentation is available at http://hugo.spf13.com
 
Usage:
hugo [flags]
hugo [command]
 
Available Commands:
help Help about any command
version Print the version number of Hugo
 
Flags:
-a, --author string Author name for copyright attribution (default "YOUR NAME")
--config string config file (default is $HOME/.cobra.yaml)
-h, --help help for hugo
-l, --license licensetext Name of license for the project (can provide licensetext in config)
-b, --projectbase string base project directory eg. github.com/spf13/
--viper Use Viper for configuration (default true)
 
Use "hugo [command] --help" for more information about a command.
```
通过步骤一、步骤二、步骤三，我们就成功创建和添加了 Cobra 应用程序及其命令。接下来，我再来详细介绍下 Cobra 的核心特性。



#### 使用标志
Cobra 可以跟 Pflag 结合使用，实现强大的标志功能。使用步骤如下：


使用持久化的标志。标志可以是“持久的”，这意味着该标志可用于它所分配的命令以及该命令下的每个子命令。可以在 rootCmd 上定义持久标志：


```go
rootCmd.PersistentFlags().BoolVarP(&Verbose, "verbose", "v", false, "verbose output")
```
使用本地标志。也可以分配一个本地标志，本地标志只能在它所绑定的命令上使用：


```go
rootCmd.Flags().StringVarP(&Source, "source", "s", "", "Source directory to read from")
```
--source标志只能在 rootCmd 上引用，而不能在 rootCmd 的子命令上引用。


将标志绑定到 Viper。我们可以将标志绑定到 Viper，这样就可以使用 viper.Get() 获取标志的值。


```go
var author string

func init() {
  rootCmd.PersistentFlags().StringVar(&author, "author", "YOUR NAME", "Author name for copyright attribution")
  viper.BindPFlag("author", rootCmd.PersistentFlags().Lookup("author"))
}
```
设置标志为必选。默认情况下，标志是可选的，我们也可以设置标志为必选，当设置标志为必选，但是没有提供标志时，Cobra 会报错。


```go
rootCmd.Flags().StringVarP(&Region, "region", "r", "", "AWS region (required)")
rootCmd.MarkFlagRequired("region")
```
#### 非选项参数验证
在命令的过程中，经常会传入非选项参数，并且需要对这些非选项参数进行验证，Cobra 提供了机制来对非选项参数进行验证。可以使用 Command 的 Args 字段来验证非选项参数。Cobra 也内置了一些验证函数：


- NoArgs：如果存在任何非选项参数，该命令将报错。
- ArbitraryArgs：该命令将接受任何非选项参数。
- OnlyValidArgs：如果有任何非选项参数不在 Command 的 ValidArgs 字段中，该命令将报错。
- MinimumNArgs(int)：如果没有至少 N 个非选项参数，该命令将报错。
- MaximumNArgs(int)：如果有多于 N 个非选项参数，该命令将报错。
- ExactArgs(int)：如果非选项参数个数不为 N，该命令将报错。
- ExactValidArgs(int)：如果非选项参数的个数不为 N，或者非选项参数不在 Command 的 ValidArgs 字段中，该命令将报错。
- RangeArgs(min, max)：如果非选项参数的个数不在 min 和 max 之间，该命令将报错。


使用预定义验证函数，示例如下：


```go
var cmd = &cobra.Command{
  Short: "hello",
  Args: cobra.MinimumNArgs(1), // 使用内置的验证函数
  Run: func(cmd *cobra.Command, args []string) {
    fmt.Println("Hello, World!")
  },
}
```
当然你也可以自定义验证函数，示例如下：


```go
var cmd = &cobra.Command{
  Short: "hello",
  // Args: cobra.MinimumNArgs(10), // 使用内置的验证函数
  Args: func(cmd *cobra.Command, args []string) error { // 自定义验证函数
    if len(args) < 1 {
      return errors.New("requires at least one arg")
    }
    if myapp.IsValidColor(args[0]) {
      return nil
    }
    return fmt.Errorf("invalid color specified: %s", args[0])
  },
  Run: func(cmd *cobra.Command, args []string) {
    fmt.Println("Hello, World!")
  },
}
```
#### PreRun and PostRun Hooks
在运行 Run 函数时，我们可以运行一些钩子函数，比如 PersistentPreRun 和 PreRun 函数在 Run 函数之前执行，PersistentPostRun 和 PostRun 在 Run 函数之后执行。如果子命令没有指定Persistent*Run函数，则子命令将会继承父命令的Persistent*Run函数。这些函数的运行顺序如下：


1. PersistentPreRun
2. PreRun
3. Run
4. PostRun
5. PersistentPostRun


**注意**，父级的 PreRun 只会在父级命令运行时调用，子命令是不会调用的。Cobra 还支持很多其他有用的特性，比如：自定义 Help 命令；可以自动添加--version标志，输出程序版本信息；当用户提供无效标志或无效命令时，Cobra 可以打印出 usage 信息；当我们输入的命令有误时，Cobra 会根据注册的命令，推算出可能的命令，等等。


### 总结
在开发 Go 项目时，我们可以通过 Pflag 来解析命令行参数，通过 Viper 来解析配置文件，用 Cobra 来实现命令行框架。你可以通过 pflag.String()、 pflag.StringP()、pflag.StringVar()、pflag.StringVarP() 方法来设置命令行参数，并使用 Get来获取参数的值。


同时，你也可以使用 Viper 从命令行参数、环境变量、配置文件等位置读取配置项。最常用的是从配置文件中读取，可以通过 viper.AddConfigPath 来设置配置文件搜索路径，通过 viper.SetConfigFile 和 viper.SetConfigType 来设置配置文件名，通过 viper.ReadInConfig 来读取配置文件。读取完配置文件，然后在程序中使用 Get/Get来读取配置项的值。最后，你可以使用 Cobra 来构建一个命令行框架，Cobra 可以很好地集成 Pflag 和 Viper。

## 23 | 应用构建实战：如何构建一个优秀的企业应用框架？

应用开发是软件开发工程师最核心的工作。在我这 7 年的 Go 开发生涯中，我构建了大大小小不下 50 个后端应用，深谙其中的痛点，比如：**重复造轮子**。同样的功能却每次都要重新开发，浪费非常多的时间和精力不说，每次实现的代码质量更是参差不齐。**理解成本高**。相同的功能，有 N 个服务对应着 N 种不同的实现方式，如果功能升级，或者有新成员加入，都可能得重新理解 N 次。**功能升级的开发工作量大**。一个应用由 N 个服务组成，如果要升级其中的某个功能，你需要同时更新 N 个服务的代码。


**想要解决上面这些问题，一个比较好的思路是：找出相同的功能，然后用一种优雅的方式去实现它，并通过 Go 包的形式，供所有的服务使用。**

我会带你找出服务的通用功能，并给出优雅的构建方式，帮助你一劳永逸地解决这些问题。在提高开发效率的同时，也能提高你的代码质量。

接下来，我们先来分析并找出 Go 服务通用的功能。



### 构建应用的基础：应用的三大基本功能
我们目前见到的 Go 后端服务，基本上可以分为 API 服务和非 API 服务两类。


- API 服务：通过对外提供 HTTP/RPC 接口来完成指定的功能。比如订单服务，通过调用创建订单的 API 接口，来创建商品订单。
- 非 API 服务：通过监听、定时运行等方式，而不是通过 API 调用来完成某些任务。比如数据处理服务，定时从 Redis 中获取数据，处理后存入后端存储中。再比如消息处理服务，监听消息队列（如 NSQ/Kafka/RabbitMQ），收到消息后进行处理。


对于 API 服务和非 API 服务来说，它们的启动流程基本一致，都可以分为三步：**应用框架的构建，这是最基础的一步。应用初始化。服务启动。**

如下图所示：


![img](https://static001.geekbang.org/resource/image/2a/9e/2a4ef770df3df2439ae595ef301e4d9e.png?wh=3075x1819)

图中，命令行程序、命令行参数解析和配置文件解析，是所有服务都需要具备的功能，这些功能有机结合到一起，共同构成了应用框架。所以，我们要构建的任何一个应用程序，至少要具备**命令行程序、命令行参数解析和配置文件解析**这 3 种功能。

命令行程序：用来启动一个应用。命令行程序需要实现诸如应用描述、help、参数校验等功能。根据需要，还可以实现命令自动补全、打印命令行参数等高级功能。命令行参数解析：用来在启动时指定应用程序的命令行参数，以控制应用的行为。配置文件解析：用来解析不同格式的配置文件。

另外，上述 3 类功能跟业务关系不大，可以抽象成一个统一的框架。应用初始化、创建 API/ 非 API 服务、启动服务，跟业务联系比较紧密，难以抽象成一个统一的框架。



### iam-apiserver 是如何构建应用框架的？
这里，我通过讲解 iam-apiserver 的应用构建方式，来给你讲解下如何构建应用。iam-apiserver 程序的 main 函数位于 apiserver.go 文件中，其构建代码可以简化为：


```go
import (
    ...
    "github.com/marmotedu/iam/internal/apiserver"
    "github.com/marmotedu/iam/pkg/app"
)

func main() {
    ...
    apiserver.NewApp("iam-apiserver").Run()
}

const commandDesc = `The IAM API server validates and configures data ...`

// NewApp creates a App object with default parameters.
func NewApp(basename string) *app.App {
    opts := options.NewOptions()
    application := app.NewApp("IAM API Server",
        basename,
        app.WithOptions(opts),
        app.WithDescription(commandDesc),
        app.WithDefaultValidArgs(),
        app.WithRunFunc(run(opts)),
    )

    return application
}

func run(opts *options.Options) app.RunFunc {
    return func(basename string) error {
        log.Init(opts.Log)
        defer log.Flush()

        cfg, err := config.CreateConfigFromOptions(opts)
        if err != nil {
            return err
        }

        return Run(cfg)
    }
}
```
可以看到，我们是通过调用包 github.com/marmotedu/iam/pkg/app 来构建应用的。也就是说，**我们将构建应用的功能抽象成了一个 Go 包，通过 Go 包可以提高代码的封装性和复用性**。iam-authz-server 和 iam-pump 组件也都是通过 github.com/marmotedu/iam/pkg/app 来构建应用的。



构建应用的流程也很简单，只需要创建一个 application 实例即可：



```go
opts := options.NewOptions()
application := app.NewApp("IAM API Server",
    basename,
    app.WithOptions(opts),
    app.WithDescription(commandDesc),
    app.WithDefaultValidArgs(),
    app.WithRunFunc(run(opts)),
)
```
在创建应用实例时，我传入了下面这些参数。IAM API Server：应用的简短描述。basename：应用的二进制文件名。opts：应用的命令行选项。commandDesc：应用的详细描述。run(opts)：应用的启动函数，初始化应用，并最终启动 HTTP 和 GRPC Web 服务。


创建应用时，你还可以根据需要来配置应用实例，比如 iam-apiserver 组件在创建应用时，指定了 WithDefaultValidArgs 来校验命令行非选项参数的默认校验逻辑。


可以看到，iam-apiserver 通过简单的几行代码，就创建出了一个应用。**之所以这么方便，是因为应用框架的构建代码都封装在了 github.com/marmotedu/iam/pkg/app 包中。**接下来，我们来重点看下 github.com/marmotedu/iam/pkg/app 包是如何实现的。为了方便描述，我在下文中统称为 App 包。


#### App 包设计和实现
我们先来看下 App 包目录下的文件：


```
[colin@dev iam]$ ls pkg/app/
app.go  cmd.go  config.go  doc.go  flag.go  help.go  options.go
```
pkg/app 目录下的 5 个主要文件是 app.go、cmd.go、config.go、flag.go、options.go，分别实现了应用程序框架中的应用、命令行程序、命令行参数解析、配置文件解析和命令行选项 5 个部分，具体关系如下图所示：


![img](https://static001.geekbang.org/resource/image/ea/12/ea3a0e20854b23fce7a654ce5f207512.png?wh=2378x828)

我再来解释下这张图。应用由命令行程序、命令行参数解析、配置文件解析三部分组成，命令行参数解析功能通过命令行选项来构建，二者通过接口解耦合：


```go
type CliOptions interface {    
    // AddFlags adds flags to the specified FlagSet object.    
    // AddFlags(fs *pflag.FlagSet)    
    Flags() (fss cliflag.NamedFlagSets)    
    Validate() []error    
}    
```
通过接口，应用可以定制自己独有的命令行参数。接下来，我们再来看下如何具体构建应用的每一部分。


#### 第 1 步：构建应用
APP 包提供了 NewApp 函数来创建一个应用：



```go
func NewApp(name string, basename string, opts ...Option) *App {
    a := &App{
        name:     name,
        basename: basename,
    }
 
    for _, o := range opts {
        o(a)
    }
 
    a.buildCommand()
 
    return a
}
```
NewApp 中使用了设计模式中的选项模式，来动态地配置 APP，支持 WithRunFunc、WithDescription、WithValidArgs 等选项。


#### 第 2 步：命令行程序构建
这一步，我们会使用 Cobra 包来构建应用的命令行程序。

NewApp 最终会调用 buildCommand 方法来创建 Cobra Command 类型的命令，命令的功能通过指定 Cobra Command 类型的各个字段来实现。通常可以指定：Use、Short、Long、SilenceUsage、SilenceErrors、RunE、Args 等字段。



在 buildCommand 函数中，也会根据应用的设置添加不同的命令行参数，例如：



```go
if !a.noConfig {
    addConfigFlag(a.basename, namedFlagSets.FlagSet("global"))
} 
```
上述代码的意思是：如果我们设置了 noConfig=false，那么就会在命令行参数 global 分组中添加以下命令行选项：


```
-c, --config FILE                                                        Read configuration from specified FILE, support JSON, TOML, YAML, HCL, or Java properties formats.
```
为了更加易用和人性化，命令还具有如下 3 个功能。
- 帮助信息：执行 -h/--help 时，输出的帮助信息。通过 cmd.SetHelpFunc 函数可以指定帮助信息。
- 使用信息（可选）：当用户提供无效的标志或命令时，向用户显示“使用信息”。通过 cmd.SetUsageFunc 函数，可以指定使用信息。如果不想每次输错命令打印一大堆 usage 信息，你可以通过设置 SilenceUsage: true 来关闭掉 usage。
- 版本信息：打印应用的版本。知道应用的版本号，对故障排查非常有帮助。通过 verflag.AddFlags 可以指定版本信息。例如，App 包通过 github.com/marmotedu/component-base/pkg/version 指定了以下版本信息：



```
$ ./iam-apiserver --version
  gitVersion: v0.3.0
   gitCommit: ccc31e292f66e6bad94efb1406b5ced84e64675c
gitTreeState: dirty
   buildDate: 2020-12-17T12:24:37Z
   goVersion: go1.15.1
    compiler: gc
    platform: linux/amd64
$ ./iam-apiserver --version=raw
version.Info{GitVersion:"v0.3.0", GitCommit:"ccc31e292f66e6bad94efb1406b5ced84e64675c", GitTreeState:"dirty", BuildDate:"2020-12-17T12:24:37Z", GoVersion:"go1.15.1", Compiler:"gc", Platform:"linux/amd64"}
```
接下来，再来看下应用需要实现的另外一个重要功能，也就是命令行参数解析。


#### 第 3 步：命令行参数解析
App 包在构建应用和执行应用两个阶段来实现命令行参数解析。


我们先看构建应用这个阶段。App 包在 buildCommand 方法中通过以下代码段，给应用添加了命令行参数：




```go
var namedFlagSets cliflag.NamedFlagSets
if a.options != nil {
    namedFlagSets = a.options.Flags()
    fs := cmd.Flags()
    for _, f := range namedFlagSets.FlagSets {
        fs.AddFlagSet(f)
    }
 
    ...
}
 
if !a.noVersion {
    verflag.AddFlags(namedFlagSets.FlagSet("global"))
}
if !a.noConfig {
    addConfigFlag(a.basename, namedFlagSets.FlagSet("global"))
}
globalflag.AddGlobalFlags(namedFlagSets.FlagSet("global"), cmd.Name())
```
namedFlagSets 中引用了 Pflag 包，上述代码先通过 a.options.Flags() 创建并返回了一批 FlagSet，a.options.Flags() 函数会将 FlagSet 进行分组。通过一个 for 循环，将 namedFlagSets 中保存的 FlagSet 添加到 Cobra 应用框架中的 FlagSet 中。buildCommand 还会根据应用的配置，选择性添加一些 flag。例如，在 global 分组下添加 --version 和 --config 选项。


执行 -h 打印命令行参数如下：


```
..
 
Usage:
  iam-apiserver [flags]
 
Generic flags:
 
      --server.healthz               Add self readiness check and install /healthz router. (default true)
      --server.max-ping-count int    The max number of ping attempts when server failed to startup. (default 3)
 
...
 
Global flags:
 
  -h, --help                     help for iam-apiserver
      --version version[=true]   Print version information and quit.
```
这里有两个技巧，你可以借鉴。**第一个技巧，将 flag 分组。**


一个大型系统，可能会有很多个 flag，例如 kube-apiserver 就有 200 多个 flag，这时对 flag 分组就很有必要了。通过分组，我们可以很快地定位到需要的分组及该分组具有的标志。例如，我们想了解 MySQL 有哪些标志，可以找到 MySQL 分组：


```
Mysql flags:
 
      --mysql.database string
                Database name for the server to use.
      --mysql.host string
                MySQL service host address. If left blank, the following related mysql options will be ignored. (default "127.0.0.1:3306")
      --mysql.log-mode int
                Specify gorm log level. (default 1)
      ...

```
**第二个技巧，flag 的名字带有层级关系**。这样不仅可以知道该 flag 属于哪个分组，而且能够避免重名。例如：


```
$ ./iam-apiserver -h |grep host
      --mysql.host string                         MySQL service host address. If left blank, the following related mysql options will be ignored. (default "127.0.0.1:3306")
      --redis.host string                   Hostname of your Redis server. (default "127.0.0.1")
```
对于 MySQL 和 Redis， 都可以指定相同的 host 标志，通过 --mysql.host 也可以知道该 flag 隶属于 mysql 分组，代表的是 MySQL 的 host。


我们再看应用执行阶段。这时会通过 viper.Unmarshal，将配置 Unmarshal 到 Options 变量中。这样我们就可以使用 Options 变量中的值，来执行后面的业务逻辑。我们传入的 Options 是一个实现了 CliOptions 接口的结构体变量，CliOptions 接口定义为：


```go
type CliOptions interface {
    Flags() (fss cliflag.NamedFlagSets)
    Validate() []error
}
```
因为 Options 实现了 Validate 方法，所以我们就可以在应用框架中调用 Validate 方法来校验参数是否合法。另外，我们还可以通过以下代码，来判断选项是否可补全和打印：如果可以补全，则补全选项；如果可以打印，则打印选项的内容。实现代码如下：



```go
func (a *App) applyOptionRules() error {
    if completeableOptions, ok := a.options.(CompleteableOptions); ok {  
        if err := completeableOptions.Complete(); err != nil {
            return err                     
        }                                                    
    }                    
                                                                               
    if errs := a.options.Validate(); len(errs) != 0 {                           
        return errors.NewAggregate(errs)                                            
    }                                                            
                                        
    if printableOptions, ok := a.options.(PrintableOptions); ok && !a.silence {
        log.Infof("%v Config: `%s`", progressMessage, printableOptions.String())
    }                                                     
                                                                                                                                    
    return nil                                                                                                                      
}       
```
通过配置补全，可以确保一些重要的配置项具有默认值，当这些配置项没有被配置时，程序也仍然能够正常启动。一个大型项目，有很多配置项，我们不可能对每一个配置项都进行配置。所以，给重要配置项设置默认值，就显得很重要了。这里，我们来看下 iam-apiserver 提供的 Validate 方法：




```go
func (s *ServerRunOptions) Validate() []error {
    var errs []error

    errs = append(errs, s.GenericServerRunOptions.Validate()...)
    errs = append(errs, s.GrpcOptions.Validate()...)
    errs = append(errs, s.InsecureServing.Validate()...)
    errs = append(errs, s.SecureServing.Validate()...)
    errs = append(errs, s.MySQLOptions.Validate()...)
    errs = append(errs, s.RedisOptions.Validate()...)
    errs = append(errs, s.JwtOptions.Validate()...)
    errs = append(errs, s.Log.Validate()...)
    errs = append(errs, s.FeatureOptions.Validate()...)

    return errs
}
```
可以看到，每个配置分组，都实现了 Validate() 函数，对自己负责的配置进行校验。通过这种方式，程序会更加清晰。因为只有配置提供者才更清楚如何校验自己的配置项，所以最好的做法是将配置的校验放权给配置提供者（分组）。




#### 第 4 步：配置文件解析
在 buildCommand 函数中，通过 addConfigFlag 调用，添加了 -c, --config FILE 命令行参数，用来指定配置文件：


```go
addConfigFlag(a.basename, namedFlagSets.FlagSet("global"))
```
addConfigFlag 函数代码如下：




```go
func addConfigFlag(basename string, fs *pflag.FlagSet) {
    fs.AddFlag(pflag.Lookup(configFlagName))

    viper.AutomaticEnv()
    viper.SetEnvPrefix(strings.Replace(strings.ToUpper(basename), "-", "_", -1))
    viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_"))

    cobra.OnInitialize(func() {
        if cfgFile != "" {
            viper.SetConfigFile(cfgFile)
        } else {
            viper.AddConfigPath(".")

            if names := strings.Split(basename, "-"); len(names) > 1 {
                viper.AddConfigPath(filepath.Join(homedir.HomeDir(), "."+names[0]))
            }

            viper.SetConfigName(basename)
        }

        if err := viper.ReadInConfig(); err != nil {
            _, _ = fmt.Fprintf(os.Stderr, "Error: failed to read configuration file(%s): %v\n", cfgFile, err)
            os.Exit(1)
        }
    })
}
```
addConfigFlag 函数中，指定了 Cobra Command 在执行命令之前，需要做的初始化工作：


```go
func() {
  if cfgFile != "" {
    viper.SetConfigFile(cfgFile)
  } else {
    viper.AddConfigPath(".")

    if names := strings.Split(basename, "-"); len(names) > 1 {
      viper.AddConfigPath(filepath.Join(homedir.HomeDir(), "."+names[0]))
    }

    viper.SetConfigName(basename)
  }

  if err := viper.ReadInConfig(); err != nil {
    _, _ = fmt.Fprintf(os.Stderr, "Error: failed to read configuration file(%s): %v\n", cfgFile, err)
    os.Exit(1)
  }
}
```
上述代码实现了以下功能：
- 如果命令行参数中没有指定配置文件的路径，则加载默认路径下的配置文件，通过 viper.AddConfigPath、viper.SetConfigName 来设置配置文件搜索路径和配置文件名。通过设置默认的配置文件，可以使我们不用携带任何命令行参数，即可运行程序。
- 支持环境变量，通过 viper.SetEnvPrefix 来设置环境变量前缀，避免跟系统中的环境变量重名。通过 viper.SetEnvKeyReplacer 重写了 Env 键。


上面，我们给应用添加了配置文件的命令行参数，并设置在命令执行前，读取配置文件。在命令执行时，会将配置文件中的配置项和命令行参数绑定，并将 Viper 的配置 Unmarshal 到传入的 Options 中：


```go
if !a.noConfig {    
    if err := viper.BindPFlags(cmd.Flags()); err != nil {    
        return err    
    }    
    
    if err := viper.Unmarshal(a.options); err != nil {    
        return err    
    }  
}  
```
Viper 的配置是命令行参数和配置文件配置 merge 后的配置。如果在配置文件中指定了 MySQL 的 host 配置，并且也同时指定了 --mysql.host 参数，则会优先取命令行参数设置的值。这里需要**注意**的是，不同于 YAML 格式的分级方式，配置项是通过点号 . 来分级的。


至此，我们已经成功构建了一个优秀的应用框架，接下来我们看下这个应用框架具有哪些优点吧。

### 这样构建的应用程序，有哪些优秀特性？
借助 Cobra 自带的能力，构建出的应用天然具备帮助信息、使用信息、子命令、子命令自动补全、非选项参数校验、命令别名、PreRun、PostRun 等功能，这些功能对于一个应用来说是非常有用的。

Cobra 可以集成 Pflag，通过将创建的 Pflag FlagSet 绑定到 Cobra 命令的 FlagSet 中，使得 Pflag 支持的标志能直接集成到 Cobra 命令中。集成到命令中有很多好处，例如：cobra -h 可以打印出所有设置的 flag，Cobra Command 命令提供的 GenBashCompletion 方法，可以实现命令行选项的自动补全。



通过 viper.BindPFlags 和 viper.ReadInConfig 函数，可以统一配置文件、命令行参数的配置项，使得应用的配置项更加清晰好记。面对不同场景可以选择不同的配置方式，使配置更加灵活。例如：配置 HTTPS 的绑定端口，可以通过 --secure.bind-port 配置，也可以通过配置文件配置（命令行参数优先于配置文件）：



```
secure:    
    bind-port: 8080
```
可以通过 viper.GetString("secure.bind-port") 这类方式获取应用的配置，获取方式更加灵活，而且全局可用。将应用框架的构建方法实现成了一个 Go 包，通过 Go 包可以提高应用构建代码的封装性和复用性。


### 如果你想自己构建应用，需要**注意**些什么？
当然，你也可以使用其他方式构建你的应用程序。比如，我就见过很多开发者使用如下方式来构建应用：直接在 main.go 文件中通过 gopkg.in/yaml.v3 包解析配置，通过 Go 标准库的 flag 包简单地添加一些命令行参数，例如--help、--config、--version。


但是，在你自己独立构建应用程序时，很可能会踩这么 3 个坑：
- 构建的应用功能简单，扩展性差，导致后期扩展复杂。
- 构建的应用没有帮助信息和使用信息，或者信息格式杂乱，增加应用的使用难度。
- 命令行选项和配置文件支持的配置项相互独立，导致配合应用程序的时候，不知道该使用哪种方式来配置。

**在我看来，对于小的应用，自己根据需要构建没什么问题，但是对于一个大型项目的话，还是在应用开发之初，就采用一些功能多、扩展性强的优秀包。这样，以后随着应用的迭代，可以零成本地进行功能添加和扩展，同时也能体现我们的专业性和技术深度，提高代码质量。**

如果你有特殊需求，一定要自己构建应用框架，那么我有以下几个**建议**：
- 应用框架应该清晰易读、扩展性强。
- 应用程序应该至少支持如下命令行选项：-h 打印帮助信息；-v 打印应用程序的版本；-c 支持指定配置文件的路径。
- 如果你的应用有很多命令行选项，那么**建议**支持 --secure.bind-port 这样的长选项，通过选项名字，就可以知道选项的作用。
- 配置文件使用 yaml 格式，yaml 格式的配置文件，能支持复杂的配置，还清晰易读。
- 如果你有多个服务，那么要保持所有服务的应用构建方式是一致的。


### 总结
一个应用框架由命令、命令行参数解析、配置文件解析 3 部分功能组成，我们可以通过 Cobra 来构建命令，通过 Pflag 来解析命令行参数，通过 Viper 来解析配置文件。一个项目，可能包含多个应用，这些应用都需要通过 Cobra、Viper、Pflag 来构建。为了不重复造轮子，简化应用的构建，我们可以将这些功能实现为一个 Go 包，方便直接调用构建应用。


IAM 项目的应用都是通过 github.com/marmotedu/iam/pkg/app 包来构建的，在构建时，调用 App 包提供的 NewApp 函数，来构建一个应用：


```go
func NewApp(basename string) *app.App {
    opts := options.NewOptions()
    application := app.NewApp("IAM API Server",
        basename,
        app.WithOptions(opts),
        app.WithDescription(commandDesc),
        app.WithDefaultValidArgs(),
        app.WithRunFunc(run(opts)),
    )

    return application
}
```
在构建应用时，只需要提供应用简短 / 详细描述、应用二进制文件名称和命令行选项即可。App 包会根据 Options 提供的 Flags() 方法，来给应用添加命令行选项。命令行选项中提供了 -c, --config 选项来指定配置文件，App 包也会加载并解析这个配置文件，并将配置文件和命令行选项相同配置项进行 Merge，最终将配置项的值保存在传入的 Options 变量中，供业务代码使用。

最后，如果你想自己构建应用，我给出了一些我的**建议**：设计一个清晰易读、易扩展的应用框架；支持一些常见的选项，例如 -h， -v， -c 等；如果应用的命令行选项比较多，**建议**使用 --secure.bind-port 这样的长选项。



## 服务开发


## 24 | Web 服务：Web 服务核心功能有哪些，如何实现？
在 Go 项目开发中，绝大部分情况下，我们是在写能提供某种功能的后端服务，这些功能以 RPC API 接口或者 RESTful API 接口的形式对外提供，能提供这两种 API 接口的服务也统称为 Web 服务。今天这一讲，我就通过介绍 RESTful API 风格的 Web 服务，来给你介绍下如何实现 Web 服务的核心功能。



### Web 服务的核心功能
Web 服务有很多功能，为了便于你理解，我将这些功能分成了基础功能和高级功能两大类，并总结在了下面这张图中：


![img](https://static001.geekbang.org/resource/image/1a/2e/1a6d38450cdd0e115e505ab30113602e.jpg?wh=2248x1835)

下面，我就按图中的顺序，来串讲下这些功能。


要实现一个 Web 服务，首先我们要选择通信协议和通信格式。在 Go 项目开发中，有 HTTP+JSON 和 gRPC+Protobuf 两种组合可选。因为 iam-apiserver 主要提供的是 REST 风格的 API 接口，所以选择的是 HTTP+JSON 组合。



Web 服务最核心的功能是路由匹配。路由匹配其实就是根据(HTTP方法, 请求路径)匹配到处理这个请求的函数，最终由该函数处理这次请求，并返回结果，过程如下图所示：


![img](https://static001.geekbang.org/resource/image/1f/9d/1f5yydeffb32732e7d0e23a0a9cd369d.jpg?wh=2248x975)

一次 HTTP 请求经过路由匹配，最终将请求交由Delete(c *gin.Context)函数来处理。变量c中存放了这次请求的参数，在 Delete 函数中，我们可以进行参数解析、参数校验、逻辑处理，最终返回结果。对于大型系统，可能会有很多个 API 接口，API 接口随着需求的更新迭代，可能会有多个版本，为了便于管理，我们需要**对路由进行分组**。有时候，我们需要在一个服务进程中，同时开启 HTTP 服务的 80 端口和 HTTPS 的 443 端口，这样我们就可以做到：对内的服务，访问 80 端口，简化服务访问复杂度；对外的服务，访问更为安全的 HTTPS 服务。显然，我们没必要为相同功能启动多个服务进程，所以这时候就需要 Web 服务能够支持**一进程多服务**的功能。


我们开发 Web 服务最核心的诉求是：输入一些参数，校验通过后，进行业务逻辑处理，然后返回结果。所以 Web 服务还应该能够进行参数解析、参数校验、逻辑处理、返回结果。这些都是 Web 服务的业务处理功能。


上面这些是 Web 服务的基本功能，此外，我们还需要支持一些高级功能。在进行 HTTP 请求时，经常需要针对每一次请求都设置一些通用的操作，比如添加 Header、添加 RequestID、统计请求次数等，这就要求我们的 Web 服务能够支持中间件特性。为了保证系统安全，对于每一个请求，我们都需要进行认证。Web 服务中，通常有两种认证方式，一种是基于用户名和密码，一种是基于 Token。认证通过之后，就可以继续处理请求了。为了方便定位和跟踪某一次请求，需要支持 RequestID，定位和跟踪 RequestID 主要是为了排障。


最后，当前的软件架构中，很多采用了前后端分离的架构。在前后端分离的架构中，前端访问地址和后端访问地址往往是不同的，浏览器为了安全，会针对这种情况设置跨域请求，所以 Web 服务需要能够处理浏览器的跨域请求。


到这里，我就把 Web 服务的基础功能和高级功能串讲了一遍。当然，上面只介绍了 Web 服务的核心功能，还有很多其他的功能，你可以通过学习[Gin 的官方文档](https://github.com/gin-gonic/gin)来了解。


你可以看到，Web 服务有很多核心功能，这些功能我们可以基于 net/http 包自己封装。但在实际的项目开发中， 我们更多会选择使用基于 net/http 包进行封装的优秀开源 Web 框架。本实战项目选择了 Gin 框架。接下来，我们主要看下 Gin 框架是如何实现以上核心功能的，这些功能我们在实际的开发中可以直接拿来使用。


### 为什么选择 Gin 框架？
优秀的 Web 框架有很多，我们为什么要选择 Gin 呢？在回答这个问题之前，我们先来看下选择 Web 框架时的关注点。


在选择 Web 框架时，我们可以关注如下几点：路由功能；是否具备 middleware/filter 能力；HTTP 参数（path、query、form、header、body）解析和返回；性能和稳定性；使用复杂度；社区活跃度。


按 GitHub Star 数来排名，当前比较火的 Go Web 框架有 Gin、Beego、Echo、Revel 、Martini。经过调研，我从中选择了 Gin 框架，原因是 Gin 具有如下特性：


轻量级，代码质量高，性能比较高；项目目前很活跃，并有很多可用的 Middleware；作为一个 Web 框架，功能齐全，使用起来简单。


那接下来，我就先详细介绍下 Gin 框架。Gin是用 Go 语言编写的 Web 框架，功能完善，使用简单，性能很高。Gin 核心的路由功能是通过一个定制版的HttpRouter来实现的，具有很高的路由性能。



Gin 有很多功能，这里我给你列出了它的一些核心功能：
- 支持 HTTP 方法：GET、POST、PUT、PATCH、DELETE、OPTIONS。
- 支持不同位置的 HTTP 参数：路径参数（path）、查询字符串参数（query）、表单参数（form）、HTTP 头参数（header）、消息体参数（body）。
- 支持 HTTP 路由和路由分组。
- 支持 middleware 和自定义 middleware。
- 支持自定义 Log。
- 支持 binding 和 validation，
- 支持自定义 validator。可以 bind 如下参数：query、path、body、header、form。
- 支持重定向。
- 支持 basic auth middleware。
- 支持自定义 HTTP 配置。
- 支持优雅关闭。
- 支持 HTTP2。
- 支持设置和获取 cookie。


### Gin 是如何支持 Web 服务基础功能的？
接下来，我们先通过一个具体的例子，看下 Gin 是如何支持 Web 服务基础功能的，后面再详细介绍这些功能的用法。我们创建一个 webfeature 目录，用来存放示例代码。因为要演示 HTTPS 的用法，所以需要创建证书文件。具体可以分为两步。

第一步，执行以下命令创建证书：


```
cat << 'EOF' > ca.pem
-----BEGIN CERTIFICATE-----
MIICSjCCAbOgAwIBAgIJAJHGGR4dGioHMA0GCSqGSIb3DQEBCwUAMFYxCzAJBgNV
BAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0YXRlMSEwHwYDVQQKExhJbnRlcm5ldCBX
aWRnaXRzIFB0eSBMdGQxDzANBgNVBAMTBnRlc3RjYTAeFw0xNDExMTEyMjMxMjla
Fw0yNDExMDgyMjMxMjlaMFYxCzAJBgNVBAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0
YXRlMSEwHwYDVQQKExhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQxDzANBgNVBAMT
BnRlc3RjYTCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAwEDfBV5MYdlHVHJ7
+L4nxrZy7mBfAVXpOc5vMYztssUI7mL2/iYujiIXM+weZYNTEpLdjyJdu7R5gGUu
g1jSVK/EPHfc74O7AyZU34PNIP4Sh33N+/A5YexrNgJlPY+E3GdVYi4ldWJjgkAd
Qah2PH5ACLrIIC6tRka9hcaBlIECAwEAAaMgMB4wDAYDVR0TBAUwAwEB/zAOBgNV
HQ8BAf8EBAMCAgQwDQYJKoZIhvcNAQELBQADgYEAHzC7jdYlzAVmddi/gdAeKPau
sPBG/C2HCWqHzpCUHcKuvMzDVkY/MP2o6JIW2DBbY64bO/FceExhjcykgaYtCH/m
oIU63+CFOTtR7otyQAWHqXa7q4SbCDlG7DyRFxqG0txPtGvy12lgldA2+RgcigQG
Dfcog5wrJytaQ6UA0wE=
-----END CERTIFICATE-----
EOF

cat << 'EOF' > server.key
-----BEGIN PRIVATE KEY-----
MIICdQIBADANBgkqhkiG9w0BAQEFAASCAl8wggJbAgEAAoGBAOHDFScoLCVJpYDD
M4HYtIdV6Ake/sMNaaKdODjDMsux/4tDydlumN+fm+AjPEK5GHhGn1BgzkWF+slf
3BxhrA/8dNsnunstVA7ZBgA/5qQxMfGAq4wHNVX77fBZOgp9VlSMVfyd9N8YwbBY
AckOeUQadTi2X1S6OgJXgQ0m3MWhAgMBAAECgYAn7qGnM2vbjJNBm0VZCkOkTIWm
V10okw7EPJrdL2mkre9NasghNXbE1y5zDshx5Nt3KsazKOxTT8d0Jwh/3KbaN+YY
tTCbKGW0pXDRBhwUHRcuRzScjli8Rih5UOCiZkhefUTcRb6xIhZJuQy71tjaSy0p
dHZRmYyBYO2YEQ8xoQJBAPrJPhMBkzmEYFtyIEqAxQ/o/A6E+E4w8i+KM7nQCK7q
K4JXzyXVAjLfyBZWHGM2uro/fjqPggGD6QH1qXCkI4MCQQDmdKeb2TrKRh5BY1LR
81aJGKcJ2XbcDu6wMZK4oqWbTX2KiYn9GB0woM6nSr/Y6iy1u145YzYxEV/iMwff
DJULAkB8B2MnyzOg0pNFJqBJuH29bKCcHa8gHJzqXhNO5lAlEbMK95p/P2Wi+4Hd
aiEIAF1BF326QJcvYKmwSmrORp85AkAlSNxRJ50OWrfMZnBgzVjDx3xG6KsFQVk2
ol6VhqL6dFgKUORFUWBvnKSyhjJxurlPEahV6oo6+A+mPhFY8eUvAkAZQyTdupP3
XEFQKctGz+9+gKkemDp7LBBMEMBXrGTLPhpEfcjv/7KPdnFHYmhYeBTBnuVmTVWe
F98XJ7tIFfJq
-----END PRIVATE KEY-----
EOF

cat << 'EOF' > server.pem
-----BEGIN CERTIFICATE-----
MIICnDCCAgWgAwIBAgIBBzANBgkqhkiG9w0BAQsFADBWMQswCQYDVQQGEwJBVTET
MBEGA1UECBMKU29tZS1TdGF0ZTEhMB8GA1UEChMYSW50ZXJuZXQgV2lkZ2l0cyBQ
dHkgTHRkMQ8wDQYDVQQDEwZ0ZXN0Y2EwHhcNMTUxMTA0MDIyMDI0WhcNMjUxMTAx
MDIyMDI0WjBlMQswCQYDVQQGEwJVUzERMA8GA1UECBMISWxsaW5vaXMxEDAOBgNV
BAcTB0NoaWNhZ28xFTATBgNVBAoTDEV4YW1wbGUsIENvLjEaMBgGA1UEAxQRKi50
ZXN0Lmdvb2dsZS5jb20wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAOHDFSco
LCVJpYDDM4HYtIdV6Ake/sMNaaKdODjDMsux/4tDydlumN+fm+AjPEK5GHhGn1Bg
zkWF+slf3BxhrA/8dNsnunstVA7ZBgA/5qQxMfGAq4wHNVX77fBZOgp9VlSMVfyd
9N8YwbBYAckOeUQadTi2X1S6OgJXgQ0m3MWhAgMBAAGjazBpMAkGA1UdEwQCMAAw
CwYDVR0PBAQDAgXgME8GA1UdEQRIMEaCECoudGVzdC5nb29nbGUuZnKCGHdhdGVy
em9vaS50ZXN0Lmdvb2dsZS5iZYISKi50ZXN0LnlvdXR1YmUuY29thwTAqAEDMA0G
CSqGSIb3DQEBCwUAA4GBAJFXVifQNub1LUP4JlnX5lXNlo8FxZ2a12AFQs+bzoJ6
hM044EDjqyxUqSbVePK0ni3w1fHQB5rY9yYC5f8G7aqqTY1QOhoUk8ZTSTRpnkTh
y4jjdvTZeLDVBlueZUTDRmy2feY5aZIU18vFDK08dTG0A87pppuv1LNIR3loveU8
-----END CERTIFICATE-----
EOF
```
第二步，创建 main.go 文件：


```go
package main

import (
  "fmt"
  "log"
  "net/http"
  "sync"
  "time"

  "github.com/gin-gonic/gin"
  "golang.org/x/sync/errgroup"
)

type Product struct {
  Username    string    `json:"username" binding:"required"`
  Name        string    `json:"name" binding:"required"`
  Category    string    `json:"category" binding:"required"`
  Price       int       `json:"price" binding:"gte=0"`
  Description string    `json:"description"`
  CreatedAt   time.Time `json:"createdAt"`
}

type productHandler struct {
  sync.RWMutex
  products map[string]Product
}

func newProductHandler() *productHandler {
  return &productHandler{
    products: make(map[string]Product),
  }
}

func (u *productHandler) Create(c *gin.Context) {
  u.Lock()
  defer u.Unlock()

  // 1. 参数解析
  var product Product
  if err := c.ShouldBindJSON(&product); err != nil {
    c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
    return
  }

  // 2. 参数校验
  if _, ok := u.products[product.Name]; ok {
    c.JSON(http.StatusBadRequest, gin.H{"error": fmt.Sprintf("product %s already exist", product.Name)})
    return
  }
  product.CreatedAt = time.Now()

  // 3. 逻辑处理
  u.products[product.Name] = product
  log.Printf("Register product %s success", product.Name)

  // 4. 返回结果
  c.JSON(http.StatusOK, product)
}

func (u *productHandler) Get(c *gin.Context) {
  u.Lock()
  defer u.Unlock()

  product, ok := u.products[c.Param("name")]
  if !ok {
    c.JSON(http.StatusNotFound, gin.H{"error": fmt.Errorf("can not found product %s", c.Param("name"))})
    return
  }

  c.JSON(http.StatusOK, product)
}

func router() http.Handler {
  router := gin.Default()
  productHandler := newProductHandler()
  // 路由分组、中间件、认证
  v1 := router.Group("/v1")
  {
    productv1 := v1.Group("/products")
    {
      // 路由匹配
      productv1.POST("", productHandler.Create)
      productv1.GET(":name", productHandler.Get)
    }
  }

  return router
}

func main() {
  var eg errgroup.Group

  // 一进程多端口
  insecureServer := &http.Server{
    Addr:         ":8080",
    Handler:      router(),
    ReadTimeout:  5 * time.Second,
    WriteTimeout: 10 * time.Second,
  }

  secureServer := &http.Server{
    Addr:         ":8443",
    Handler:      router(),
    ReadTimeout:  5 * time.Second,
    WriteTimeout: 10 * time.Second,
  }

  eg.Go(func() error {
    err := insecureServer.ListenAndServe()
    if err != nil && err != http.ErrServerClosed {
      log.Fatal(err)
    }
    return err
  })

  eg.Go(func() error {
    err := secureServer.ListenAndServeTLS("server.pem", "server.key")
    if err != nil && err != http.ErrServerClosed {
      log.Fatal(err)
    }
    return err
  })

  if err := eg.Wait(); err != nil {
    log.Fatal(err)
  }
}

```
运行以上代码：


```
$ go run main.go
```
打开另外一个终端，请求 HTTP 接口：



```
# 创建产品
$ curl -XPOST -H"Content-Type: application/json" -d'{"username":"colin","name":"iphone12","category":"phone","price":8000,"description":"cannot afford"}' http://127.0.0.1:8080/v1/products
{"username":"colin","name":"iphone12","category":"phone","price":8000,"description":"cannot afford","createdAt":"2021-06-20T11:17:03.818065988+08:00"}

# 获取产品信息
$ curl -XGET http://127.0.0.1:8080/v1/products/iphone12
{"username":"colin","name":"iphone12","category":"phone","price":8000,"description":"cannot afford","createdAt":"2021-06-20T11:17:03.818065988+08:00"}
```
示例代码存放地址为[webfeature](https://github.com/marmotedu/gopractise-demo/tree/master/gin/webfeature)。另外，Gin 项目仓库中也包含了很多使用示例，如果你想详细了解，可以参考 [gin examples](https://github.com/gin-gonic/examples)。下面，我来详细介绍下 Gin 是如何支持 Web 服务基础功能的。



#### HTTP/HTTPS 支持
因为 Gin 是基于 net/http 包封装的一个 Web 框架，所以它天然就支持 HTTP/HTTPS。在上述代码中，通过以下方式开启一个 HTTP 服务：


```go
insecureServer := &http.Server{
  Addr:         ":8080",
  Handler:      router(),
  ReadTimeout:  5 * time.Second,
  WriteTimeout: 10 * time.Second,
}
...
err := insecureServer.ListenAndServe()
```
通过以下方式开启一个 HTTPS 服务：



```go
secureServer := &http.Server{
  Addr:         ":8443",
  Handler:      router(),
  ReadTimeout:  5 * time.Second,
  WriteTimeout: 10 * time.Second,
}
...
err := secureServer.ListenAndServeTLS("server.pem", "server.key")
```
#### JSON 数据格式支持
Gin 支持多种数据通信格式，例如 application/json、application/xml。可以通过c.ShouldBindJSON函数，将 Body 中的 JSON 格式数据解析到指定的 Struct 中，通过c.JSON函数返回 JSON 格式的数据。


#### 路由匹配
Gin 支持两种路由匹配规则。第一种匹配规则是精确匹配。例如，路由为 /products/:name，匹配情况如下表所示：


![img](https://static001.geekbang.org/resource/image/11/df/11be05d7fe7f935e01725e2635f315df.jpg?wh=2248x1418)
第二种匹配规则是模糊匹配。例如，路由为 /products/*name，匹配情况如下表所示：


![img](https://static001.geekbang.org/resource/image/b5/7b/b5ccd9924e53dd90a64af6002967b67b.jpg?wh=2248x1636)

#### 路由分组
Gin 通过 Group 函数实现了路由分组的功能。路由分组是一个非常常用的功能，可以将相同版本的路由分为一组，也可以将相同 RESTful 资源的路由分为一组。例如：


```go
v1 := router.Group("/v1", gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"}))
{
    productv1 := v1.Group("/products")
    {
        // 路由匹配
        productv1.POST("", productHandler.Create)
        productv1.GET(":name", productHandler.Get)
    }

    orderv1 := v1.Group("/orders")
    {
        // 路由匹配
        orderv1.POST("", orderHandler.Create)
        orderv1.GET(":name", orderHandler.Get)
    }
}

v2 := router.Group("/v2", gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"}))
{
    productv2 := v2.Group("/products")
    {
        // 路由匹配
        productv2.POST("", productHandler.Create)
        productv2.GET(":name", productHandler.Get)
    }
}
```
通过将路由分组，可以对相同分组的路由做统一处理。比如上面那个例子，我们可以通过代码


```go
v1 := router.Group("/v1", gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"}))
```
给所有属于 v1 分组的路由都添加 gin.BasicAuth 中间件，以实现认证功能。中间件和认证，这里你先不用深究，下面讲高级功能的时候会介绍到。


#### 一进程多服务
我们可以通过以下方式实现一进程多服务：


```go
var eg errgroup.Group
insecureServer := &http.Server{...}
secureServer := &http.Server{...}

eg.Go(func() error {
  err := insecureServer.ListenAndServe()
  if err != nil && err != http.ErrServerClosed {
    log.Fatal(err)
  }
  return err
})
eg.Go(func() error {
  err := secureServer.ListenAndServeTLS("server.pem", "server.key")
  if err != nil && err != http.ErrServerClosed {
    log.Fatal(err)
  }
  return err
}

if err := eg.Wait(); err != nil {
  log.Fatal(err)
})
```
上述代码实现了两个相同的服务，分别监听在不同的端口。这里需要**注意**的是，为了不阻塞启动第二个服务，我们需要把 ListenAndServe 函数放在 goroutine 中执行，并且调用 eg.Wait() 来阻塞程序进程，从而让两个 HTTP 服务在 goroutine 中持续监听端口，并提供服务。


#### 参数解析、参数校验、逻辑处理、返回结果
此外，Web 服务还应该具有参数解析、参数校验、逻辑处理、返回结果 4 类功能，因为这些功能联系紧密，我们放在一起来说。

在 productHandler 的 Create 方法中，我们通过c.ShouldBindJSON来解析参数，接下来自己编写校验代码，然后将 product 信息保存在内存中（也就是业务逻辑处理），最后通过c.JSON返回创建的 product 信息。代码如下：


```go
func (u *productHandler) Create(c *gin.Context) {
  u.Lock()
  defer u.Unlock()

  // 1. 参数解析
  var product Product
  if err := c.ShouldBindJSON(&product); err != nil {
    c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
    return
  }

  // 2. 参数校验
  if _, ok := u.products[product.Name]; ok {
    c.JSON(http.StatusBadRequest, gin.H{"error": fmt.Sprintf("product %s already exist", product.Name)})
    return
  }
  product.CreatedAt = time.Now()

  // 3. 逻辑处理
  u.products[product.Name] = product
  log.Printf("Register product %s success", product.Name)

  // 4. 返回结果
  c.JSON(http.StatusOK, product)
}
```
那这个时候，你可能会问：HTTP 的请求参数可以存在不同的位置，Gin 是如何解析的呢？这里，我们先来看下 HTTP 有哪些参数类型。HTTP 具有以下 5 种参数类型：

- 路径参数（path）。例如gin.Default().GET("/user/:name", nil)， name 就是路径参数。
- 查询字符串参数（query）。例如/welcome?firstname=Lingfei&lastname=Kong，firstname 和 lastname 就是查询字符串参数。
- 表单参数（form）。例如curl -X POST -F 'username=colin' -F 'password=colin1234' http://mydomain.com/login，username 和 password 就是表单参数。
- HTTP 头参数（header）。例如curl -X POST -H 'Content-Type: application/json' -d '{"username":"colin","password":"colin1234"}' http://mydomain.com/login，Content-Type 就是 HTTP 头参数。
- 消息体参数（body）。例如curl -X POST -H 'Content-Type: application/json' -d '{"username":"colin","password":"colin1234"}' http://mydomain.com/login，username 和 password 就是消息体参数。


Gin 提供了一些函数，来分别读取这些 HTTP 参数，每种类别会提供两种函数，一种函数可以直接读取某个参数的值，另外一种函数会把同类 HTTP 参数绑定到一个 Go 结构体中。比如，有如下路径参数：


```go
gin.Default().GET("/:name/:id", nil)
```
我们可以直接读取每个参数：


```go
name := c.Param("name")
action := c.Param("action")
```
也可以将所有的路径参数，绑定到结构体中：


```go
type Person struct {
    ID string `uri:"id" binding:"required,uuid"`
    Name string `uri:"name" binding:"required"`
}

if err := c.ShouldBindUri(&person); err != nil {
    // normal code
    return
}
```
Gin 在绑定参数时，是通过结构体的 tag 来判断要绑定哪类参数到结构体中的。这里要**注意**，不同的 HTTP 参数有不同的结构体 tag。
- 路径参数：uri。
- 查询字符串参数：form。
- 表单参数：form。
- HTTP 头参数：header。
- 消息体参数：会根据 Content-Type，自动选择使用 json 或者 xml，也可以调用 ShouldBindJSON 或者 ShouldBindXML 直接指定使用哪个 tag。


针对每种参数类型，Gin 都有对应的函数来获取和绑定这些参数。这些函数都是基于如下两个函数进行封装的：



ShouldBindWith(obj interface{}, b binding.Binding) error非常重要的一个函数，很多 ShouldBindXXX 函数底层都是调用 ShouldBindWith 函数来完成参数绑定的。该函数会根据传入的绑定引擎，将参数绑定到传入的结构体指针中，**如果绑定失败，只返回错误内容，但不终止 HTTP 请求**。ShouldBindWith 支持多种绑定引擎，例如 binding.JSON、binding.Query、binding.Uri、binding.Header 等，更详细的信息你可以参考 [binding.go](https://github.com/gin-gonic/gin/blob/v1.7.2/binding/binding.go#L72)。


MustBindWith(obj interface{}, b binding.Binding) error这是另一个非常重要的函数，很多 BindXXX 函数底层都是调用 MustBindWith 函数来完成参数绑定的。该函数会根据传入的绑定引擎，将参数绑定到传入的结构体指针中，**如果绑定失败，返回错误并终止请求，返回 HTTP 400 错误**。MustBindWith 所支持的绑定引擎跟 ShouldBindWith 函数一样。


Gin 基于 ShouldBindWith 和 MustBindWith 这两个函数，又衍生出很多新的 Bind 函数。这些函数可以满足不同场景下获取 HTTP 参数的需求。Gin 提供的函数可以获取 5 个类别的 HTTP 参数。
- 路径参数：ShouldBindUri、BindUri；
- 查询字符串参数：ShouldBindQuery、BindQuery；
- 表单参数：ShouldBind；
- HTTP 头参数：ShouldBindHeader、BindHeader；
- 消息体参数：ShouldBindJSON、BindJSON 等。


每个类别的 Bind 函数，详细信息你可以参考[Gin 提供的 Bind 函数](https://github.com/marmotedu/geekbang-go/blob/master/Gin%E6%8F%90%E4%BE%9B%E7%9A%84Bind%E5%87%BD%E6%95%B0.md)。这里要**注意**，Gin 并没有提供类似 ShouldBindForm、BindForm 这类函数来绑定表单参数，但我们可以通过 ShouldBind 来绑定表单参数。当 HTTP 方法为 GET 时，ShouldBind 只绑定 Query 类型的参数；当 HTTP 方法为 POST 时，会先检查 content-type 是否是 json 或者 xml，如果不是，则绑定 Form 类型的参数。


所以，ShouldBind 可以绑定 Form 类型的参数，但前提是 HTTP 方法是 POST，并且 content-type 不是 application/json、application/xml。在 Go 项目开发中，我建议使用 ShouldBindXXX，这样可以确保我们设置的 HTTP Chain（Chain 可以理解为一个 HTTP 请求的一系列处理插件）能够继续被执行。


### Gin 是如何支持 Web 服务高级功能的？
上面介绍了 Web 服务的基础功能，这里我再来介绍下高级功能。Web 服务可以具备多个高级功能，但比较核心的高级功能是中间件、认证、RequestID、跨域和优雅关停。


#### 中间件
Gin 支持中间件，HTTP 请求在转发到实际的处理函数之前，会被一系列加载的中间件进行处理。在中间件中，可以解析 HTTP 请求做一些逻辑处理，例如：跨域处理或者生成 X-Request-ID 并保存在 context 中，以便追踪某个请求。处理完之后，可以选择中断并返回这次请求，也可以选择将请求继续转交给下一个中间件处理。当所有的中间件都处理完之后，请求才会转给路由函数进行处理。具体流程如下图：


![img](https://static001.geekbang.org/resource/image/f0/80/f0783cb9ee8cffa969f846ebe8eae880.jpg?wh=2248x1655)


通过中间件，可以实现对所有请求都做统一的处理，提高开发效率，并使我们的代码更简洁。但是，因为所有的请求都需要经过中间件的处理，可能会增加请求延时。对于中间件特性，我有如下建议：
- 中间件做成可加载的，通过配置文件指定程序启动时加载哪些中间件。
- 只将一些通用的、必要的功能做成中间件。
- 在编写中间件时，一定要保证中间件的代码质量和性能。


在 Gin 中，可以通过 gin.Engine 的 Use 方法来加载中间件。中间件可以加载到不同的位置上，而且不同的位置作用范围也不同，例如：


```go
router := gin.New()
router.Use(gin.Logger(), gin.Recovery()) // 中间件作用于所有的HTTP请求
v1 := router.Group("/v1").Use(gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"})) // 中间件作用于v1 group
v1.POST("/login", Login).Use(gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"})) //中间件只作用于/v1/login API接口
```
Gin 框架本身支持了一些中间件。
- gin.Logger()：Logger 中间件会将日志写到 gin.DefaultWriter，gin.DefaultWriter 默认为 os.Stdout。
- gin.Recovery()：Recovery 中间件可以从任何 panic 恢复，并且写入一个 500 状态码。
- gin.CustomRecovery(handle gin.RecoveryFunc)：类似 Recovery 中间件，但是在恢复时还会调用传入的 handle 方法进行处理。
- gin.BasicAuth()：HTTP 请求基本认证（使用用户名和密码进行认证）。


另外，Gin 还支持自定义中间件。中间件其实是一个函数，函数类型为 gin.HandlerFunc，HandlerFunc 底层类型为 func(*Context)。如下是一个 Logger 中间件的实现：



```go
package main

import (
  "log"
  "time"

  "github.com/gin-gonic/gin"
)

func Logger() gin.HandlerFunc {
  return func(c *gin.Context) {
    t := time.Now()

    // 设置变量example
    c.Set("example", "12345")

    // 请求之前

    c.Next()

    // 请求之后
    latency := time.Since(t)
    log.Print(latency)

    // 访问我们发送的状态
    status := c.Writer.Status()
    log.Println(status)
  }
}

func main() {
  r := gin.New()
  r.Use(Logger())

  r.GET("/test", func(c *gin.Context) {
    example := c.MustGet("example").(string)

    // it would print: "12345"
    log.Println(example)
  })

  // Listen and serve on 0.0.0.0:8080
  r.Run(":8080")
}
```
另外，还有很多开源的中间件可供我们选择，我把一些常用的总结在了表格里：


![img](https://static001.geekbang.org/resource/image/67/10/67137697a09d9f37bd87a81bf322f510.jpg?wh=1832x1521)

#### 认证、RequestID、跨域
认证、RequestID、跨域这三个高级功能，都可以通过 Gin 的中间件来实现，例如：


```go
router := gin.New()

// 认证
router.Use(gin.BasicAuth(gin.Accounts{"foo": "bar", "colin": "colin404"}))

// RequestID
router.Use(requestid.New(requestid.Config{
    Generator: func() string {
        return "test"
    },
}))

// 跨域
// CORS for https://foo.com and https://github.com origins, allowing:
// - PUT and PATCH methods
// - Origin header
// - Credentials share
// - Preflight requests cached for 12 hours
router.Use(cors.New(cors.Config{
    AllowOrigins:     []string{"https://foo.com"},
    AllowMethods:     []string{"PUT", "PATCH"},
    AllowHeaders:     []string{"Origin"},
    ExposeHeaders:    []string{"Content-Length"},
    AllowCredentials: true,
    AllowOriginFunc: func(origin string) bool {
        return origin == "https://github.com"
    },
    MaxAge: 12 * time.Hour,
}))
```
#### 优雅关停
Go 项目上线后，我们还需要不断迭代来丰富项目功能、修复 Bug 等，这也就意味着，我们要不断地重启 Go 服务。对于 HTTP 服务来说，如果访问量大，重启服务的时候可能还有很多连接没有断开，请求没有完成。如果这时候直接关闭服务，这些连接会直接断掉，请求异常终止，这就会对用户体验和产品口碑造成很大影响。因此，这种关闭方式不是一种优雅的关闭方式。

这时候，我们期望 HTTP 服务可以在处理完所有请求后，正常地关闭这些连接，也就是优雅地关闭服务。我们有两种方法来优雅关闭 HTTP 服务，分别是借助第三方的 Go 包和自己编码实现。

方法一：借助第三方的 Go 包如果使用第三方的 Go 包来实现优雅关闭，目前用得比较多的包是fvbock/endless。我们可以使用 [fvbock/endless](https://github.com/fvbock/endless) 来替换掉 net/http 的 ListenAndServe 方法，例如：


```go
router := gin.Default()
router.GET("/", handler)
// [...]
endless.ListenAndServe(":4242", router)
```
方法二：编码实现借助第三方包的好处是可以稍微减少一些编码工作量，但缺点是引入了一个新的依赖包，因此**我更倾向于自己编码实现**。Go 1.8 版本或者更新的版本，http.Server 内置的 Shutdown 方法，已经实现了优雅关闭。下面是一个示例：


```go
// +build go1.8

package main

import (
  "context"
  "log"
  "net/http"
  "os"
  "os/signal"
  "syscall"
  "time"

  "github.com/gin-gonic/gin"
)

func main() {
  router := gin.Default()
  router.GET("/", func(c *gin.Context) {
    time.Sleep(5 * time.Second)
    c.String(http.StatusOK, "Welcome Gin Server")
  })

  srv := &http.Server{
    Addr:    ":8080",
    Handler: router,
  }

  // Initializing the server in a goroutine so that
  // it won't block the graceful shutdown handling below
  go func() {
    if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
      log.Fatalf("listen: %s\n", err)
    }
  }()

  // Wait for interrupt signal to gracefully shutdown the server with
  // a timeout of 5 seconds.
  quit := make(chan os.Signal, 1)
  // kill (no param) default send syscall.SIGTERM
  // kill -2 is syscall.SIGINT
  // kill -9 is syscall.SIGKILL but can't be catch, so don't need add it
  signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
  <-quit
  log.Println("Shutting down server...")

  // The context is used to inform the server it has 5 seconds to finish
  // the request it is currently handling
  ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
  defer cancel()
  if err := srv.Shutdown(ctx); err != nil {
    log.Fatal("Server forced to shutdown:", err)
  }

  log.Println("Server exiting")
}
```
上面的示例中，需要把 srv.ListenAndServe 放在 goroutine 中执行，这样才不会阻塞到 srv.Shutdown 函数。因为我们把 srv.ListenAndServe 放在了 goroutine 中，所以需要一种可以让整个进程常驻的机制。


这里，我们借助了有缓冲 channel，并且调用 signal.Notify 函数将该 channel 绑定到 SIGINT、SIGTERM 信号上。这样，收到 SIGINT、SIGTERM 信号后，quilt 通道会被写入值，从而结束阻塞状态，程序继续运行，执行 srv.Shutdown(ctx)，优雅关停 HTTP 服务。



### 总结
今天我们主要学习了 Web 服务的核心功能，以及如何开发这些功能。在实际的项目开发中， 我们一般会使用基于 net/http 包进行封装的优秀开源 Web 框架。当前比较火的 Go Web 框架有 Gin、Beego、Echo、Revel、Martini。你可以根据需要进行选择。我比较推荐 Gin，Gin 也是目前比较受欢迎的 Web 框架。Gin Web 框架支持 Web 服务的很多基础功能，例如 HTTP/HTTPS、JSON 格式的数据、路由分组和匹配、一进程多服务等。另外，Gin 还支持 Web 服务的一些高级功能，例如 中间件、认证、RequestID、跨域和优雅关停等。


## 25 | 认证机制：应用程序如何进行访问认证？

保证应用的安全是软件开发的最基本要求，我们有多种途径来保障应用的安全，例如网络隔离、设置防火墙、设置 IP 黑白名单等。不过在我看来，这些更多是从运维角度来解决应用的安全问题。作为开发者，我们也可以从软件层面来保证应用的安全，这可以通过认证来实现。

这一讲，我以 HTTP 服务为例，来给你介绍下当前常见的四种认证方法：Basic、Digest、OAuth、Bearer。还有很多基于这四种方法的变种，这里就不再介绍了。IAM 项目使用了 Basic、Bearer 两种认证方法。这一讲，我先来介绍下这四种认证方法，下一讲，我会给你介绍下 IAM 项目是如何设计和实现访问认证功能的。


### 认证和授权有什么区别？
在介绍四种基本的认证方法之前，我想先带你区分下认证和授权，这是很多开发者都容易搞混的两个概念。


认证（Authentication，英文缩写 authn）：用来验证某个用户是否具有访问系统的权限。如果认证通过，该用户就可以访问系统，从而创建、修改、删除、查询平台支持的资源。

授权（Authorization，英文缩写 authz）：用来验证某个用户是否具有访问某个资源的权限，如果授权通过，该用户就能对资源做增删改查等操作。

这里，我通过下面的图片，来让你明白二者的区别：


![img](https://static001.geekbang.org/resource/image/8b/96/8b63cc7a624dbdb32b37898180a37596.jpg?wh=2248x1747)

图中，我们有一个仓库系统，用户 james、colin、aaron 分别创建了 Product-A、Product-B、Product-C。现在用户 colin 通过用户名和密码（认证）成功登陆到仓库系统中，但他尝试访问 Product-A、Product-C 失败，因为这两个产品不属于他（授权失败），但他可以成功访问自己创建的资源 Product-B（授权成功）。由此可见：**认证证明了你是谁，授权决定了你能做什么。**


上面，我们介绍了认证和授权的区别。那么接下来，我们就回到这一讲的重心：应用程序如何进行访问认证。


### 四种基本的认证方式
常见的认证方式有四种，分别是 Basic、Digest、OAuth 和 Bearer。先来看下 Basic 认证。


#### Basic
Basic 认证（基础认证），是最简单的认证方式。它简单地将用户名:密码进行 base64 编码后，放到 HTTP Authorization Header 中。HTTP 请求到达后端服务后，后端服务会解析出 Authorization Header 中的 base64 字符串，解码获取用户名和密码，并将用户名和密码跟数据库中记录的值进行比较，如果匹配则认证通过。例如：

```
$ basic=`echo -n 'admin:Admin@2021'|base64`
$ curl -XPOST -H"Authorization: Basic ${basic}" http://127.0.0.1:8080/login
```
通过 base64 编码，可以将密码以非明文的方式传输，增加一定的安全性。但是，base64 不是加密技术，入侵者仍然可以截获 base64 字符串，并反编码获取用户名和密码。另外，即使 Basic 认证中密码被加密，入侵者仍可通过加密后的用户名和密码进行重放攻击。


所以，Basic 认证虽然简单，但极不安全。使用 Basic 认证的唯一方式就是将它和 SSL 配合使用，来确保整个认证过程是安全的。


IAM 项目中，为了支持前端通过用户名和密码登录，仍然使用了 Basic 认证，但前后端使用 HTTPS 来通信，保证了认证的安全性。


这里需要注意，在设计系统时，要遵循一个通用的原则：**不要在请求参数中使用明文密码，也不要在任何存储中保存明文密码。**


#### Digest
Digest 认证（摘要认证），是另一种 HTTP 认证协议，它与基本认证兼容，但修复了基本认证的严重缺陷。Digest 具有如下特点：


- 绝不会用明文方式在网络上发送密码。
- 可以有效防止恶意用户进行重放攻击。
- 可以有选择地防止对报文内容的篡改。


摘要认证的过程见下图：


![img](https://static001.geekbang.org/resource/image/c6/b5/c693394977b4f91ae14b8c06f69056b5.jpg?wh=2248x1872)


在上图中，完成摘要认证需要下面这四步：
1. 客户端请求服务端的资源。
2. 在客户端能够证明它知道密码从而确认其身份之前，服务端认证失败，返回401 Unauthorized，并返回WWW-Authenticate头，里面包含认证需要的信息。
3. 客户端根据WWW-Authenticate头中的信息，选择加密算法，并使用密码随机数 nonce，计算出密码摘要 response，并再次请求服务端。
4. 服务器将客户端提供的密码摘要与服务器内部计算出的摘要进行对比。如果匹配，就说明客户端知道密码，认证通过，并返回一些与授权会话相关的附加信息，放在 Authorization-Info 中。


WWW-Authenticate头中包含的信息见下表：


![img](https://static001.geekbang.org/resource/image/59/9e/593e48602465b84165678bdc98467d9e.jpg?wh=2248x1755)

虽然使用摘要可以避免密码以明文方式发送，一定程度上保护了密码的安全性，但是仅仅隐藏密码并不能保证请求是安全的。因为请求（包括密码摘要）仍然可以被截获，这样就可以重放给服务器，带来安全问题。


为了防止重放攻击，服务器向客户端发送了密码随机数 nonce，nonce 每次请求都会变化。客户端会根据 nonce 生成密码摘要，这种方式，可以使摘要随着随机数的变化而变化。服务端收到的密码摘要只对特定的随机数有效，而没有密码的话，攻击者就无法计算出正确的摘要，这样我们就可以防止重放攻击。


**摘要认证可以保护密码，比基本认证安全很多。但摘要认证并不能保护内容，所以仍然要与 HTTPS 配合使用，来确保通信的安全。**


##### OAuth
OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一 Web 服务上存储的私密资源（例如照片、视频、音频等），而无需将用户名和密码提供给第三方应用。OAuth 目前的版本是 2.0 版。


OAuth2.0 一共分为四种授权方式，分别为密码式、隐藏式、凭借式和授权码模式。接下来，我们就具体介绍下每一种授权方式。


第一种，密码式。密码式的授权方式，就是用户把用户名和密码直接告诉给第三方应用，然后第三方应用使用用户名和密码换取令牌。所以，使用此授权方式的前提是无法采用其他授权方式，并且用户高度信任某应用。


认证流程如下：
1. 网站 A 向用户发出获取用户名和密码的请求；
2. 用户同意后，网站 A 凭借用户名和密码向网站 B 换取令牌；
3. 网站 B 验证用户身份后，给出网站 A 令牌，网站 A 凭借令牌可以访问网站 B 对应权限的资源。


第二种，隐藏式。这种方式适用于前端应用。认证流程如下：
1. A 网站提供一个跳转到 B 网站的链接，用户点击后跳转至 B 网站，并向用户请求授权；
2. 用户登录 B 网站，同意授权后，跳转回 A 网站指定的重定向 redirect_url 地址，并携带 B 网站返回的令牌，用户在 B 网站的数据给 A 网站使用。


这个授权方式存在着“中间人攻击”的风险，因此只能用于一些安全性要求不高的场景，并且令牌的有效时间要非常短。



第三种，凭借式。这种方式是在命令行中请求授权，适用于没有前端的命令行应用。认证流程如下：
1. 应用 A 在命令行向应用 B 请求授权，此时应用 A 需要携带应用 B 提前颁发的 secretID 和 secretKey，其中 secretKey 出于安全性考虑，需在后端发送；
2. 应用 B 接收到 secretID 和 secretKey，并进行身份验证，验证通过后返回给应用 A 令牌。

第四种，授权码模式。这种方式就是第三方应用先提前申请一个授权码，然后再使用授权码来获取令牌。相对来说，这种方式安全性更高，前端传送授权码，后端存储令牌，与资源的通信都是在后端，可以避免令牌的泄露导致的安全问题。认证流程如下：


![img](https://static001.geekbang.org/resource/image/54/a6/547b6362aba9e9ce8b72b511afee94a6.jpg?wh=2248x1127)

1. A 网站提供一个跳转到 B 网站的链接 +redirect_url，用户点击后跳转至 B 网站；
2. 用户携带向 B 网站提前申请的 client_id，向 B 网站发起身份验证请求；
3. 用户登录 B 网站，通过验证，授予 A 网站权限，此时网站跳转回 redirect_url，其中会有 B 网站通过验证后的授权码附在该 url 后；
4. 网站 A 携带授权码向网站 B 请求令牌，网站 B 验证授权码后，返回令牌即 access_token。


#### Bearer
Bearer 认证，也称为令牌认证，是一种 HTTP 身份验证方法。Bearer 认证的核心是 bearer token。bearer token 是一个加密字符串，通常由服务端根据密钥生成。客户端在请求服务端时，必须在请求头中包含Authorization: Bearer 。服务端收到请求后，解析出 ，并校验 的合法性，如果校验通过，则认证通过。跟基本认证一样，Bearer 认证需要配合 HTTPS 一起使用，来保证认证安全性。


当前最流行的 token 编码方式是 JSON Web Token（JWT，音同 jot，详见 JWT RFC 7519）。接下来，我通过讲解 JWT 认证来帮助你了解 Bearer 认证的原理。


### 基于 JWT 的 Token 认证机制实现
在典型业务场景中，为了区分用户和保证安全，必须对 API 请求进行鉴权，但是不能要求每一个请求都进行登录操作。合理做法是，在第一次登录之后产生一个有一定有效期的 token，并将它存储在浏览器的 Cookie 或 LocalStorage 之中。之后的请求都携带这个 token ，请求到达服务器端后，服务器端用这个 token 对请求进行认证。在第一次登录之后，服务器会将这个 token 用文件、数据库或缓存服务器等方法存下来，用于之后请求中的比对。


或者也可以采用更简单的方法：直接用密钥来签发 Token。这样，就可以省下额外的存储，也可以减少每一次请求时对数据库的查询压力。这种方法在业界已经有一种标准的实现方式，就是 JWT。接下来，我就来具体介绍下 JWT。


#### JWT 简介
JWT 是 Bearer Token 的一个具体实现，由 JSON 数据格式组成，通过 HASH 散列算法生成一个字符串。该字符串可以用来进行授权和信息交换。使用 JWT Token 进行认证有很多优点，比如说无需在服务端存储用户数据，可以减轻服务端压力；而且采用 JSON 数据格式，比较易读。除此之外，使用 JWT Token 还有跨语言、轻量级等优点。


#### JWT 认证流程
使用 JWT Token 进行认证的流程如下图：


![img](https://static001.geekbang.org/resource/image/48/01/480397e0a0e1503a350a082f44ec5901.jpg?wh=2248x1471)

具体可以分为四步：
1. 客户端使用用户名和密码请求登录。
2. 服务端收到请求后，会去验证用户名和密码。如果用户名和密码跟数据库记录不一致，则验证失败；如果一致则验证通过，服务端会签发一个 Token 返回给客户端。
3. 客户端收到请求后会将 Token 缓存起来，比如放在浏览器 Cookie 中或者 LocalStorage 中，之后每次请求都会携带该 Token。
4. 服务端收到请求后，会验证请求中的 Token，验证通过则进行业务逻辑处理，处理完后返回处理后的结果。


#### JWT 格式
JWT 由三部分组成，分别是 Header、Payload 和 Signature，它们之间用圆点.连接，例如：


```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2NDI4NTY2MzcsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MzUwODA2MzcsInN1YiI6ImFkbWluIn0.Shw27RKENE_2MVBq7-c8OmgYdF92UmdwS8xE-Fts2FM
```
JWT 中，每部分包含的信息见下图：


![img](https://static001.geekbang.org/resource/image/0c/08/0c6657bc2d0fd2a98737660c7c373e08.jpg?wh=2248x1732)

下面我来具体介绍下这三部分，以及它们包含的信息。


Header
JWT Token 的 Header 中，包含两部分信息：一是 Token 的类型，二是 Token 所使用的加密算法。例如：

```
{
  "typ": "JWT",
  "alg": "HS256"
}
```
参数说明：typ：说明 Token 类型是 JWT。alg：说明 Token 的加密算法，这里是 HS256（alg 算法可以有多种）。


这里，我们将 Header 进行 base64 编码：


```
$ echo -n '{"typ":"JWT","alg":"HS256"}'|base64
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9
```
在某些场景下，可能还会有 kid 选项，用来标识一个密钥 ID，例如：


```
{
    "alg": "HS256",
    "kid": "XhbY3aCrfjdYcP1OFJRu9xcno8JzSbUIvGE2",
    "typ": "JWT"
}
```
Payload（载荷）
Payload 中携带 Token 的具体内容由三部分组成：JWT 标准中注册的声明（可选）、公共的声明、私有的声明。下面来分别看下。


JWT 标准中注册的声明部分，有以下标准字段：


![img](https://static001.geekbang.org/resource/image/c2/e3/c271d01d41dc7f4a45a9f2e8892057e3.png?wh=2248x2077)

本例中的 payload 内容为：


```
{
  "aud": "iam.authz.marmotedu.com",
  "exp": 1604158987,
  "iat": 1604151787,
  "iss": "iamctl",
  "nbf": 1604151787
}
```
这里，我们将 Payload 进行 base64 编码：



```
$ echo -n '{"aud":"iam.authz.marmotedu.com","exp":1604158987,"iat":1604151787,"iss":"iamctl","nbf":1604151787}'|base64
eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYwNDE1ODk4NywiaWF0Ijox
NjA0MTUxNzg3LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MDQxNTE3ODd9
```
除此之外，还有公共的声明和私有的声明。公共的声明可以添加任何的需要的信息，一般添加用户的相关信息或其他业务需要的信息，注意不要添加敏感信息；私有声明是客户端和服务端所共同定义的声明，因为 base64 是对称解密的，所以一般不建议存放敏感信息。



Signature（签名）
Signature 是 Token 的签名部分，通过如下方式生成：将 Header 和 Payload 分别 base64 编码后，用 . 连接。然后再使用 Header 中声明的加密方式，利用 secretKey 对连接后的字符串进行加密，加密后的字符串即为最终的 Signature。

secretKey 是密钥，保存在服务器中，一般通过配置文件来保存，例如：


![img](https://static001.geekbang.org/resource/image/b1/d3/b183d2695c01cd863f782edf0a6d12d3.png?wh=1024x256)

这里要注意，密钥一定不能泄露。**密钥泄露后，入侵者可以使用该密钥来签发 JWT Token，从而入侵系统**。最后生成的 Token 如下：



```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYwNDE1ODk4NywiaWF0IjoxNjA0MTUxNzg3LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MDQxNTE3ODd9.LjxrK9DuAwAzUD8-9v43NzWBN7HXsSLfebw92DKd1JQ
```
签名后服务端会返回生成的 Token，客户端下次请求会携带该 Token。服务端收到 Token 后会解析出 header.payload，然后用相同的加密算法和密钥对 header.payload 再进行一次加密，得到 Signature。并且，对比加密后的 Signature 和收到的 Signature 是否相同，如果相同则验证通过，不相同则返回 HTTP 401 Unauthorized 的错误。


最后，关于 JWT 的使用，我还有两点建议：
1. 不要存放敏感信息在 Token 里；
2. Payload 中的 exp 值不要设置得太大，一般开发版本 7 天，线上版本 2 小时。当然，你也可以根据需要自行设置。


### 总结
在开发 Go 应用时，我们需要通过认证来保障应用的安全。认证，用来验证某个用户是否具有访问系统的权限，如果认证通过，该用户就可以访问系统，从而创建、修改、删除、查询平台支持的资源。业界目前有四种常用的认证方式：Basic、Digest、OAuth、Bearer。其中 Basic 和 Bearer 用得最多。

Basic 认证通过用户名和密码来进行认证，主要用在用户登录场景；Bearer 认证通过 Token 来进行认证，通常用在 API 调用场景。不管是 Basic 认证还是 Bearer 认证，都需要结合 HTTPS 来使用，来最大程度地保证请求的安全性。

Basic 认证简单易懂，但是 Bearer 认证有一定的复杂度，所以这一讲的后半部分通过 JWT Token，讲解了 Bearer Token 认证的原理。


JWT Token 是 Bearer 认证的一种比较好的实现，主要包含了 3 个部分：
- Header：包含了 Token 的类型、Token 使用的加密算法。在某些场景下，你还可以添加 kid 字段，用来标识一个密钥 ID。
- Payload：Payload 中携带 Token 的具体内容，由 JWT 标准中注册的声明、公共的声明和私有的声明三部分组成。
- Signature：Signature 是 Token 的签名部分，程序通过验证 Signature 是否合法，来决定认证是否通过。

## 26 | IAM项目是如何设计和实现访问认证功能的？

上一讲，我们学习了应用认证常用的四种方式：Basic、Digest、OAuth、Bearer。这一讲，我们再来看下 IAM 项目是如何设计和实现认证功能的。IAM 项目用到了 Basic 认证和 Bearer 认证。其中，Basic 认证用在前端登陆的场景，Bearer 认证用在调用后端 API 服务的场景下。接下来，我们先来看下 IAM 项目认证功能的整体设计思路。


### 如何设计 IAM 项目的认证功能？
在认证功能开发之前，我们要根据需求，认真考虑下如何设计认证功能，并在设计阶段通过技术评审。那么我们先来看下，如何设计 IAM 项目的认证功能。


首先，我们要梳理清楚认证功能的使用场景和需求。
- IAM 项目的 iam-apiserver 服务，提供了 IAM 系统的管理流功能接口，它的客户端可以是前端（这里也叫控制台），也可以是 App 端。
- 为了方便用户在 Linux 系统下调用，IAM 项目还提供了 iamctl 命令行工具。
- 为了支持在第三方代码中调用 iam-apiserver 提供的 API 接口，还支持了 API 调用。
- 为了提高用户在代码中调用 API 接口的效率，IAM 项目提供了 Go SDK。


可以看到，iam-apiserver 有很多客户端，每种客户端适用的认证方式是有区别的。

控制台、App 端需要登录系统，所以需要使用用户名：密码这种认证方式，也即 Basic 认证。iamctl、API 调用、Go SDK 因为可以不用登录系统，所以可以采用更安全的认证方式：Bearer 认证。同时，Basic 认证作为 iam-apiserver 已经集成的认证方式，仍然可以供 iamctl、API 调用、Go SDK 使用。

这里有个地方需要注意：如果 iam-apiserver 采用 Bearer Token 的认证方式，目前最受欢迎的 Token 格式是 JWT Token。而 JWT Token 需要密钥（后面统一用 secretKey 来指代），因此需要在 iam-apiserver 服务中为每个用户维护一个密钥，这样会增加开发和维护成本。


业界有一个更好的实现方式：将 iam-apiserver 提供的 API 接口注册到 API 网关中，通过 API 网关中的 Token 认证功能，来实现对 iam-apiserver API 接口的认证。有很多 API 网关可供选择，例如腾讯云 API 网关、Tyk、Kong 等。这里需要你注意：通过 iam-apiserver 创建的密钥对是提供给 iam-authz-server 使用的。


另外，我们还需要调用 iam-authz-server 提供的 RESTful API 接口：/v1/authz，来进行资源授权。API 调用比较适合采用的认证方式是 Bearer 认证。当然，/v1/authz也可以直接注册到 API 网关中。在实际的 Go 项目开发中，也是我推荐的一种方式。但在这里，为了展示实现 Bearer 认证的过程，iam-authz-server 自己实现了 Bearer 认证。讲到 iam-authz-server Bearer 认证实现的时候，我会详细介绍这一点。

Basic 认证需要用户名和密码，Bearer 认证则需要密钥，所以 iam-apiserver 需要将用户名 / 密码、密钥等信息保存在后端的 MySQL 中，持久存储起来。


在进行认证的时候，需要获取密码或密钥进行反加密，这就需要查询密码或密钥。查询密码或密钥有两种方式。一种是在请求到达时查询数据库。因为数据库的查询操作延时高，会导致 API 接口延时较高，所以不太适合用在数据流组件中。另外一种是将密码或密钥缓存在内存中，这样请求到来时，就可以直接从内存中查询，从而提升查询速度，提高接口性能。但是，将密码或密钥缓存在内存中时，就要考虑内存和数据库的数据一致性，这会增加代码实现的复杂度。因为管控流组件对性能延时要求不那么敏感，而数据流组件则一定要实现非常高的接口性能，所以 iam-apiserver 在请求到来时查询数据库，而 iam-authz-server 则将密钥信息缓存在内存中。


那在这里，可以总结出一张 IAM 项目的认证设计图：


![img](https://static001.geekbang.org/resource/image/7e/b6/7eed8e2364d358a8483c671d972fd2b6.jpg?wh=2248x1094)

另外，为了将控制流和数据流区分开来，密钥的 CURD 操作也放在了 iam-apiserver 中，但是 iam-authz-server 需要用到这些密钥信息。为了解决这个问题，目前的做法是：
- iam-authz-server 通过 gRPC API 请求 iam-apiserver，获取所有的密钥信息；
- 当 iam-apiserver 有密钥更新时，会 Pub 一条消息到 Redis Channel 中。因为 iam-authz-server 订阅了同一个 Redis Channel，iam-authz-searver 监听到 channel 有新消息时，会获取、解析消息，并更新它缓存的密钥信息。这样，我们就能确保 iam-authz-server 内存中缓存的密钥和 iam-apiserver 中的密钥保持一致。


学到这里，你可能会问：将所有密钥都缓存在 iam-authz-server 中，那岂不是要占用很大的内存？别担心，这个问题我也想过，并且替你计算好了：8G 的内存大概能保存约 8 千万个密钥信息，完全够用。后期不够用的话，可以加大内存。不过这里还是有个小缺陷：如果 Redis down 掉，或者出现网络抖动，可能会造成 iam-apiserver 中和 iam-authz-server 内存中保存的密钥数据不一致，但这不妨碍我们学习认证功能的设计和实现。至于如何保证缓存系统的数据一致性，我会在新一期的特别放送里专门介绍下。


最后注意一点：Basic 认证请求和 Bearer 认证请求都可能被截获并重放。**所以，为了确保 Basic 认证和 Bearer 认证的安全性，和服务端通信时都需要配合使用 HTTPS 协议。**



### IAM 项目是如何实现 Basic 认证的？
我们已经知道，IAM 项目中主要用了 Basic 和 Bearer 这两种认证方式。我们要支持 Basic 认证和 Bearer 认证，并根据需要选择不同的认证方式，这很容易让我们想到使用设计模式中的策略模式来实现。所以，在 IAM 项目中，我将每一种认证方式都视作一个策略，通过选择不同的策略，来使用不同的认证方法。


IAM 项目实现了如下策略：
- auto 策略：该策略会根据 HTTP 头Authorization: Basic XX.YY.ZZ和Authorization: Bearer XX.YY.ZZ自动选择使用 Basic 认证还是 Bearer 认证。
- basic 策略：该策略实现了 Basic 认证。
- jwt 策略：该策略实现了 Bearer 认证，JWT 是 Bearer 认证的具体实现。
- cache 策略：该策略其实是一个 Bearer 认证的实现，Token 采用了 JWT 格式，因为 Token 中的密钥 ID 是从内存中获取的，所以叫 Cache 认证。这一点后面会详细介绍。


iam-apiserver 通过创建需要的认证策略，并加载到需要认证的 API 路由上，来实现 API 认证。具体代码如下：

```go
jwtStrategy, _ := newJWTAuth().(auth.JWTStrategy)
g.POST("/login", jwtStrategy.LoginHandler)
g.POST("/logout", jwtStrategy.LogoutHandler)
// Refresh time can be longer than token timeout
g.POST("/refresh", jwtStrategy.RefreshHandler)

```
上述代码中，我们通过newJWTAuth函数创建了auth.JWTStrategy类型的变量，该变量包含了一些认证相关函数。


- LoginHandler：实现了 Basic 认证，完成登陆认证。
- RefreshHandler：重新刷新 Token 的过期时间。
- LogoutHandler：用户注销时调用。登陆成功后，如果在 Cookie 中设置了认证相关的信息，执行 LogoutHandler 则会清空这些信息。


下面，我来分别介绍下 LoginHandler、RefreshHandler 和 LogoutHandler。



LoginHandler这里，我们来看下 LoginHandler Gin 中间件，该函数定义位于github.com/appleboy/gin-jwt包的auth_jwt.go文件中。

```go
func (mw *GinJWTMiddleware) LoginHandler(c *gin.Context) {
  if mw.Authenticator == nil {
    mw.unauthorized(c, http.StatusInternalServerError, mw.HTTPStatusMessageFunc(ErrMissingAuthenticatorFunc, c))
    return
  }

  data, err := mw.Authenticator(c)

  if err != nil {
    mw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(err, c))
    return
  }

  // Create the token
  token := jwt.New(jwt.GetSigningMethod(mw.SigningAlgorithm))
  claims := token.Claims.(jwt.MapClaims)

  if mw.PayloadFunc != nil {
    for key, value := range mw.PayloadFunc(data) {
      claims[key] = value
    }
  }

  expire := mw.TimeFunc().Add(mw.Timeout)
  claims["exp"] = expire.Unix()
  claims["orig_iat"] = mw.TimeFunc().Unix()
  tokenString, err := mw.signedString(token)

  if err != nil {
    mw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(ErrFailedTokenCreation, c))
    return
  }

  // set cookie
  if mw.SendCookie {
    expireCookie := mw.TimeFunc().Add(mw.CookieMaxAge)
    maxage := int(expireCookie.Unix() - mw.TimeFunc().Unix())

    if mw.CookieSameSite != 0 {
      c.SetSameSite(mw.CookieSameSite)
    }

    c.SetCookie(
      mw.CookieName,
      tokenString,
      maxage,
      "/",
      mw.CookieDomain,
      mw.SecureCookie,
      mw.CookieHTTPOnly,
    )
  }

  mw.LoginResponse(c, http.StatusOK, tokenString, expire)
}
```
从 LoginHandler 函数的代码实现中，我们可以知道，LoginHandler 函数会执行Authenticator函数，来完成 Basic 认证。如果认证通过，则会签发 JWT Token，并执行 PayloadFunc函数设置 Token Payload。如果我们设置了 SendCookie=true ，还会在 Cookie 中添加认证相关的信息，例如 Token、Token 的生命周期等，最后执行 LoginResponse 方法返回 Token 和 Token 的过期时间。



Authenticator、PayloadFunc、LoginResponse这三个函数，是我们在创建 JWT 认证策略时指定的。下面我来分别介绍下。先来看下Authenticator函数。Authenticator 函数从 HTTP Authorization Header 中获取用户名和密码，并校验密码是否合法。


```go
func authenticator() func(c *gin.Context) (interface{}, error) {
  return func(c *gin.Context) (interface{}, error) {
    var login loginInfo
    var err error

    // support header and body both
    if c.Request.Header.Get("Authorization") != "" {
      login, err = parseWithHeader(c)
    } else {
      login, err = parseWithBody(c)
    }
    if err != nil {
      return "", jwt.ErrFailedAuthentication
    }

    // Get the user information by the login username.
    user, err := store.Client().Users().Get(c, login.Username, metav1.GetOptions{})
    if err != nil {
      log.Errorf("get user information failed: %s", err.Error())

      return "", jwt.ErrFailedAuthentication
    }

    // Compare the login password with the user password.
    if err := user.Compare(login.Password); err != nil {
      return "", jwt.ErrFailedAuthentication
    }

    return user, nil
  }
}
```
Authenticator函数需要获取用户名和密码。它首先会判断是否有Authorization请求头，如果有，则调用parseWithHeader函数获取用户名和密码，否则调用parseWithBody从 Body 中获取用户名和密码。如果都获取失败，则返回认证失败错误。所以，IAM 项目的 Basic 支持以下两种请求方式：


```
$ curl -XPOST -H"Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==" http://127.0.0.1:8080/login # 用户名:密码通过base64加码后，通过HTTP Authorization Header进行传递，因为密码非明文，建议使用这种方式。
$ curl -s -XPOST -H'Content-Type: application/json' -d'{"username":"admin","password":"Admin@2021"}' http://127.0.0.1:8080/login # 用户名和密码在HTTP Body中传递，因为密码是明文，所以这里不建议实际开发中，使用这种方式。
```
这里，我们来看下 parseWithHeader 是如何获取用户名和密码的。假设我们的请求为：


```
$ curl -XPOST -H"Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==" http://127.0.0.1:8080/login
```
其中，YWRtaW46QWRtaW5AMjAyMQ==值由以下命令生成：



```
$ echo -n 'admin:Admin@2021'|base64
YWRtaW46QWRtaW5AMjAyMQ==
```
parseWithHeader实际上执行的是上述命令的逆向步骤：
1. 获取Authorization头的值，并调用 strings.SplitN 函数，获取一个切片变量 auth，其值为 ["Basic","YWRtaW46QWRtaW5AMjAyMQ=="] 。
2. 将YWRtaW46QWRtaW5AMjAyMQ==进行 base64 解码，得到admin:Admin@2021。
3. 调用strings.SplitN函数获取 admin:Admin@2021 ，得到用户名为admin，密码为Admin@2021。


parseWithBody则是调用了 Gin 的ShouldBindJSON函数，来从 Body 中解析出用户名和密码。


获取到用户名和密码之后，程序会从数据库中查询出该用户对应的加密后的密码，这里我们假设是xxxx。最后authenticator函数调用user.Compare来判断 xxxx 是否和通过user.Compare加密后的字符串相匹配，如果匹配则认证成功，否则返回认证失败。


再来看下PayloadFunc函数：


```go
func payloadFunc() func(data interface{}) jwt.MapClaims {
    return func(data interface{}) jwt.MapClaims {
        claims := jwt.MapClaims{
            "iss": APIServerIssuer,
            "aud": APIServerAudience,
        }
        if u, ok := data.(*v1.User); ok {
            claims[jwt.IdentityKey] = u.Name
            claims["sub"] = u.Name
        }

        return claims
    }
}
```
PayloadFunc 函数会设置 JWT Token 中 Payload 部分的 iss、aud、sub、identity 字段，供后面使用。再来看下我们刚才说的第三个函数，LoginResponse 函数：


```go
func loginResponse() func(c *gin.Context, code int, token string, expire time.Time) {
    return func(c *gin.Context, code int, token string, expire time.Time) {
        c.JSON(http.StatusOK, gin.H{
            "token":  token,
            "expire": expire.Format(time.RFC3339),
        })
    }
}
```
该函数用来在 Basic 认证成功之后，返回 Token 和 Token 的过期时间给调用者：


```
$ curl -XPOST -H"Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==" http://127.0.0.1:8080/login
{"expire":"2021-09-29T01:38:49+08:00","token":"XX.YY.ZZ"}
```
登陆成功后，iam-apiserver 会返回 Token 和 Token 的过期时间，前端可以将这些信息缓存在 Cookie 中或 LocalStorage 中，之后的请求都可以使用 Token 来进行认证。使用 Token 进行认证，不仅能够提高认证的安全性，还能够避免查询数据库，从而提高认证效率。


RefreshHandler
RefreshHandler函数会先执行 Bearer 认证，如果认证通过，则会重新签发 Token。


LogoutHandler
最后，来看下LogoutHandler函数：


```go
func (mw *GinJWTMiddleware) LogoutHandler(c *gin.Context) {
    // delete auth cookie
    if mw.SendCookie {
        if mw.CookieSameSite != 0 {
            c.SetSameSite(mw.CookieSameSite)
        }

        c.SetCookie(
            mw.CookieName,
            "",
            -1,
            "/",
            mw.CookieDomain,
            mw.SecureCookie,
            mw.CookieHTTPOnly,
        )
    }

    mw.LogoutResponse(c, http.StatusOK)
}
```
可以看到，LogoutHandler 其实是用来清空 Cookie 中 Bearer 认证相关信息的。最后，我们来做个总结：Basic 认证通过用户名和密码来进行认证，通常用在登陆接口 /login 中。用户登陆成功后，会返回 JWT Token，前端会保存该 JWT Token 在浏览器的 Cookie 或 LocalStorage 中，供后续请求使用。



后续请求时，均会携带该 Token，以完成 Bearer 认证。另外，有了登陆接口，一般还会配套 /logout 接口和 /refresh 接口，分别用来进行注销和刷新 Token。这里你可能会问，为什么要刷新 Token？因为通过登陆接口签发的 Token 有过期时间，有了刷新接口，前端就可以根据需要，自行刷新 Token 的过期时间。过期时间可以通过 iam-apiserver 配置文件的jwt.timeout配置项来指定。登陆后签发 Token 时，使用的密钥（secretKey）由jwt.key配置项来指定。



### IAM 项目是如何实现 Bearer 认证的？
上面我们介绍了 Basic 认证。这里，我再来介绍下 IAM 项目中 Bearer 认证的实现方式。


IAM 项目中有两个地方实现了 Bearer 认证，分别是 iam-apiserver 和 iam-authz-server。下面我来分别介绍下它们是如何实现 Bearer 认证的。


#### iam-authz-server Bearer 认证实现
先来看下 iam-authz-server 是如何实现 Bearer 认证的。


iam-authz-server 通过在 /v1 路由分组中加载 cache 认证中间件来使用 cache 认证策略：


```go
auth := newCacheAuth()
apiv1 := g.Group("/v1", auth.AuthFunc())
```
来看下newCacheAuth函数：


```go
func newCacheAuth() middleware.AuthStrategy {
    return auth.NewCacheStrategy(getSecretFunc())
}

func getSecretFunc() func(string) (auth.Secret, error) {
    return func(kid string) (auth.Secret, error) {
        cli, err := store.GetStoreInsOr(nil)
        if err != nil {
            return auth.Secret{}, errors.Wrap(err, "get store instance failed")
        }

        secret, err := cli.GetSecret(kid)
        if err != nil {
            return auth.Secret{}, err
        }

        return auth.Secret{
            Username: secret.Username,
            ID:       secret.SecretId,
            Key:      secret.SecretKey,
            Expires:  secret.Expires,
        }, nil
    }
}
```
newCacheAuth 函数调用auth.NewCacheStrategy创建了一个 cache 认证策略，创建时传入了getSecretFunc函数，该函数会返回密钥的信息。密钥信息包含了以下字段：



```go
type Secret struct {
    Username string
    ID       string
    Key      string
    Expires  int64
}
```
再来看下 cache 认证策略实现的AuthFunc方法：



```go
func (cache CacheStrategy) AuthFunc() gin.HandlerFunc {
  return func(c *gin.Context) {
    header := c.Request.Header.Get("Authorization")
    if len(header) == 0 {
      core.WriteResponse(c, errors.WithCode(code.ErrMissingHeader, "Authorization header cannot be empty."), nil)
      c.Abort()

      return
    }

    var rawJWT string
    // Parse the header to get the token part.
    fmt.Sscanf(header, "Bearer %s", &rawJWT)

    // Use own validation logic, see below
    var secret Secret

    claims := &jwt.MapClaims{}
    // Verify the token
    parsedT, err := jwt.ParseWithClaims(rawJWT, claims, func(token *jwt.Token) (interface{}, error) {
      // Validate the alg is HMAC signature
      if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
        return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
      }

      kid, ok := token.Header["kid"].(string)
      if !ok {
        return nil, ErrMissingKID
      }

      var err error
      secret, err = cache.get(kid)
      if err != nil {
        return nil, ErrMissingSecret
      }

      return []byte(secret.Key), nil
    }, jwt.WithAudience(AuthzAudience))
    if err != nil || !parsedT.Valid {
      core.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, err.Error()), nil)
      c.Abort()

      return
    }

    if KeyExpired(secret.Expires) {
      tm := time.Unix(secret.Expires, 0).Format("2006-01-02 15:04:05")
      core.WriteResponse(c, errors.WithCode(code.ErrExpired, "expired at: %s", tm), nil)
      c.Abort()

      return
    }

    c.Set(CtxUsername, secret.Username)
    c.Next()
  }
}

// KeyExpired checks if a key has expired, if the value of user.SessionState.Expires is 0, it will be ignored.
func KeyExpired(expires int64) bool {
  if expires >= 1 {
    return time.Now().After(time.Unix(expires, 0))
  }

  return false
}
```
AuthFunc 函数依次执行了以下四大步来完成 JWT 认证，每一步中又有一些小步骤，下面我们来一起看看。


第一步，从 Authorization: Bearer XX.YY.ZZ 请求头中获取 XX.YY.ZZ，XX.YY.ZZ 即为 JWT Token。第二步，调用 github.com/dgrijalva/jwt-go 包提供的 ParseWithClaims 函数，该函数会依次执行下面四步操作。


调用 ParseUnverified 函数，依次执行以下操作：



从 Token 中获取第一段 XX，base64 解码后得到 JWT Token 的 Header{“alg”:“HS256”,“kid”:“a45yPqUnQ8gljH43jAGQdRo0bXzNLjlU0hxa”,“typ”:“JWT”}。从 Token 中获取第二段 YY，base64 解码后得到 JWT Token 的 Payload{“aud”:“iam.authz.marmotedu.com”,“exp”:1625104314,“iat”:1625097114,“iss”:“iamctl”,“nbf”:1625097114}。根据 Token Header 中的 alg 字段，获取 Token 加密函数。最终 ParseUnverified 函数会返回 Token 类型的变量，Token 类型包含 Method、Header、Claims、Valid 这些重要字段，这些字段会用于后续的认证步骤中。调用传入的 keyFunc 获取密钥，这里来看下 keyFunc 的实现：


```go
func(token *jwt.Token) (interface{}, error) {
  // Validate the alg is HMAC signature
  if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
    return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
  }

  kid, ok := token.Header["kid"].(string)
  if !ok {
    return nil, ErrMissingKID
  }

  var err error
  secret, err = cache.get(kid)
  if err != nil {
    return nil, ErrMissingSecret
  }

  return []byte(secret.Key), nil
}
```
可以看到，keyFunc 接受 *Token 类型的变量，并获取 Token Header 中的 kid，kid 即为密钥 ID：secretID。接着，调用 cache.get(kid) 获取密钥 secretKey。cache.get 函数即为 getSecretFunc，getSecretFunc 函数会根据 kid，从内存中查找密钥信息，密钥信息中包含了 secretKey。



从 Token 中获取 Signature 签名字符串 ZZ，也即 Token 的第三段。获取到 secretKey 之后，token.Method.Verify 验证 Signature 签名字符串 ZZ，也即 Token 的第三段是否合法。token.Method.Verify 实际上是使用了相同的加密算法和相同的 secretKey 加密 XX.YY 字符串。假设加密之后的字符串为 WW，接下来会用 WW 和 ZZ base64 解码后的字符串进行比较，如果相等则认证通过，如果不相等则认证失败。

第三步，调用 KeyExpired，验证 secret 是否过期。secret 信息中包含过期时间，你只需要拿该过期时间和当前时间对比就行。第四步，设置 HTTP Headerusername: colin。


到这里，iam-authz-server 的 Bearer 认证分析就完成了。我们来做个总结：iam-authz-server 通过加载 Gin 中间件的方式，在请求/v1/authz接口时进行访问认证。因为 Bearer 认证具有过期时间，而且可以在认证字符串中携带更多有用信息，还具有不可逆加密等优点，**所以 /v1/authz 采用了 Bearer 认证，Token 格式采用了 JWT 格式，这也是业界在 API 认证中最受欢迎的认证方式。**


Bearer 认证需要 secretID 和 secretKey，这些信息会通过 gRPC 接口调用，从 iam-apisaerver 中获取，并缓存在 iam-authz-server 的内存中供认证时查询使用。当请求来临时，iam-authz-server Bearer 认证中间件从 JWT Token 中解析出 Header，并从 Header 的 kid 字段中获取到 secretID，根据 secretID 查找到 secretKey，最后使用 secretKey 加密 JWT Token 的 Header 和 Payload，并与 Signature 部分进行对比。如果相等，则认证通过；如果不等，则认证失败。



#### iam-apiserver Bearer 认证实现
再来看下 iam-apiserver 的 Bearer 认证。


iam-apiserver 的 Bearer 认证通过以下代码（位于router.go文件中）指定使用了 auto 认证策略：

```go
v1.Use(auto.AuthFunc())
```
我们来看下auto.AuthFunc()的实现：


```go
func (a AutoStrategy) AuthFunc() gin.HandlerFunc {
  return func(c *gin.Context) {
    operator := middleware.AuthOperator{}
    authHeader := strings.SplitN(c.Request.Header.Get("Authorization"), " ", 2)

    if len(authHeader) != authHeaderCount {
      core.WriteResponse(
        c,
        errors.WithCode(code.ErrInvalidAuthHeader, "Authorization header format is wrong."),
        nil,
      )
      c.Abort()

      return
    }

    switch authHeader[0] {
    case "Basic":
      operator.SetStrategy(a.basic)
    case "Bearer":
      operator.SetStrategy(a.jwt)
      // a.JWT.MiddlewareFunc()(c)
    default:
      core.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, "unrecognized Authorization header."), nil)
      c.Abort()

      return
    }

    operator.AuthFunc()(c)

    c.Next()
  }
}
```
从上面代码中可以看到，AuthFunc 函数会从 Authorization Header 中解析出认证方式是 Basic 还是 Bearer。如果是 Bearer，就会使用 JWT 认证策略；如果是 Basic，就会使用 Basic 认证策略。


我们再来看下 JWT 认证策略的AuthFunc函数实现：


```go
func (j JWTStrategy) AuthFunc() gin.HandlerFunc {
  return j.MiddlewareFunc()
}
```
我们跟随代码，可以定位到MiddlewareFunc函数最终调用了github.com/appleboy/gin-jwt包GinJWTMiddleware结构体的middlewareImpl方法：



```go
func (mw *GinJWTMiddleware) middlewareImpl(c *gin.Context) {
  claims, err := mw.GetClaimsFromJWT(c)
  if err != nil {
    mw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(err, c))
    return
  }

  if claims["exp"] == nil {
    mw.unauthorized(c, http.StatusBadRequest, mw.HTTPStatusMessageFunc(ErrMissingExpField, c))
    return
  }

  if _, ok := claims["exp"].(float64); !ok {
    mw.unauthorized(c, http.StatusBadRequest, mw.HTTPStatusMessageFunc(ErrWrongFormatOfExp, c))
    return
  }

  if int64(claims["exp"].(float64)) < mw.TimeFunc().Unix() {
    mw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(ErrExpiredToken, c))
    return
  }

  c.Set("JWT_PAYLOAD", claims)
  identity := mw.IdentityHandler(c)

  if identity != nil {
    c.Set(mw.IdentityKey, identity)
  }

  if !mw.Authorizator(identity, c) {
    mw.unauthorized(c, http.StatusForbidden, mw.HTTPStatusMessageFunc(ErrForbidden, c))
    return
  }

  c.Next()
}
```
分析上面的代码，我们可以知道，middlewareImpl 的 Bearer 认证流程为：第一步：调用GetClaimsFromJWT函数，从 HTTP 请求中获取 Authorization Header，并解析出 Token 字符串，进行认证，最后返回 Token Payload。第二步：校验 Payload 中的exp是否超过当前时间，如果超过就说明 Token 过期，校验不通过。第三步：给 gin.Context 中添加JWT_PAYLOAD键，供后续程序使用（当然也可能用不到）。第四步：通过以下代码，在 gin.Context 中添加 IdentityKey 键，IdentityKey 键可以在创建GinJWTMiddleware结构体时指定，这里我们设置为middleware.UsernameKey，也就是 username。


```go
identity := mw.IdentityHandler(c)

if identity != nil {
    c.Set(mw.IdentityKey, identity)
}
```
IdentityKey 键的值由 IdentityHandler 函数返回，IdentityHandler 函数为：


```go
func(c *gin.Context) interface{} {
    claims := jwt.ExtractClaims(c)

    return claims[jwt.IdentityKey]
}
```
上述函数会从 Token 的 Payload 中获取 identity 域的值，identity 域的值是在签发 Token 时指定的，它的值其实是用户名，你可以查看payloadFunc函数了解。

第五步：接下来，会调用Authorizator方法，Authorizator是一个 callback 函数，成功时必须返回真，失败时必须返回假。Authorizator也是在创建 GinJWTMiddleware 时指定的，例如：


```go
func authorizator() func(data interface{}, c *gin.Context) bool {    
    return func(data interface{}, c *gin.Context) bool {    
        if v, ok := data.(string); ok {    
            log.L(c).Infof("user `%s` is authenticated.", v)         
                                                                     
            return true                            
        }                                                        
                                                                 
        return false                     
    }    
}    

```
authorizator函数返回了一个匿名函数，匿名函数在认证成功后，会打印一条认证成功日志。

### IAM 项目认证功能设计技巧
我在设计 IAM 项目的认证功能时，也运用了一些技巧，这里分享给你。


#### 技巧 1：面向接口编程
在使用NewAutoStrategy函数创建 auto 认证策略时，传入了middleware.AuthStrategy接口类型的参数，这意味着 Basic 认证和 Bearer 认证都可以有不同的实现，这样后期可以根据需要扩展新的认证方式。


#### 技巧 2：使用抽象工厂模式
auth.go文件中，通过 newBasicAuth、newJWTAuth、newAutoAuth 创建认证策略时，返回的都是接口。通过返回接口，可以在不公开内部实现的情况下，让调用者使用你提供的各种认证功能。



#### 技巧 3：使用策略模式
在 auto 认证策略中，我们会根据 HTTP 请求头Authorization: XXX X.Y.X中的 XXX 来选择并设置认证策略（Basic 或 Bearer）。具体可以查看AutoStrategy的[AuthFunc](https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/auto.go#L38)函数：


```go
func (a AutoStrategy) AuthFunc() gin.HandlerFunc {
  return func(c *gin.Context) {
    operator := middleware.AuthOperator{}
    authHeader := strings.SplitN(c.Request.Header.Get("Authorization"), " ", 2)
        ...
    switch authHeader[0] {
    case "Basic":
      operator.SetStrategy(a.basic)
    case "Bearer":
      operator.SetStrategy(a.jwt)
      // a.JWT.MiddlewareFunc()(c)
    default:
      core.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, "unrecognized Authorization header."), nil)
      c.Abort()

      return
    }

    operator.AuthFunc()(c)

    c.Next()
  }
}
```
上述代码中，如果是 Basic，则设置为 Basic 认证方法operator.SetStrategy(a.basic)；如果是 Bearer，则设置为 Bearer 认证方法operator.SetStrategy(a.jwt)。 SetStrategy方法的入参是 AuthStrategy 类型的接口，都实现了AuthFunc() gin.HandlerFunc函数，用来进行认证，所以最后我们调用operator.AuthFunc()(c)即可完成认证。

### 总结
在 IAM 项目中，iam-apiserver 实现了 Basic 认证和 Bearer 认证，iam-authz-server 实现了 Bearer 认证。这一讲重点介绍了 iam-apiserver 的认证实现。


用户要访问 iam-apiserver，首先需要通过 Basic 认证，认证通过之后，会返回 JWT Token 和 JWT Token 的过期时间。前端将 Token 缓存在 LocalStorage 或 Cookie 中，后续的请求都通过 Token 来认证。执行 Basic 认证时，iam-apiserver 会从 HTTP Authorization Header 中解析出用户名和密码，将密码再加密，并和数据库中保存的值进行对比。如果不匹配，则认证失败，否则认证成功。认证成功之后，会返回 Token，并在 Token 的 Payload 部分设置用户名，Key 为 username 。


执行 Bearer 认证时，iam-apiserver 会从 JWT Token 中解析出 Header 和 Payload，并从 Header 中获取加密算法。接着，用获取到的加密算法和从配置文件中获取到的密钥对 Header.Payload 进行再加密，得到 Signature，并对比两次的 Signature 是否相等。如果不相等，则返回 HTTP 401 Unauthorized 错误；如果相等，接下来会判断 Token 是否过期，如果过期则返回认证不通过，否则认证通过。认证通过之后，会将 Payload 中的 username 添加到 gin.Context 类型的变量中，供后面的业务逻辑使用。我绘制了整个流程的示意图，你可以对照着再回顾一遍。


![img](https://static001.geekbang.org/resource/image/64/7e/642a010388e759dd76d411055bbd637e.jpg?wh=2248x1104)

## 27 | 权限模型：5大权限模型是如何进行资源授权的？
在开始讲解如何开发服务之前，我先来介绍一个比较重要的背景知识：权限模型。在你的研发生涯中，应该会遇到这样一种恐怖的操作：张三因为误操作删除了李四的资源。你在刷新闻时，也可能会刷到这么一个爆款新闻：某某程序员删库跑路。操作之所以恐怖，新闻之所以爆款，是因为这些行为往往会带来很大的损失。


那么如何避免这些风险呢？答案就是对资源做好权限管控，这也是项目开发中绕不开的话题。腾讯云会强制要求所有的云产品都对接 访问管理（CAM） 服务（阿里云也有这种要求），之所以这么做，是因为保证资源的安全是一件非常非常重要的事情。

可以说，保证应用的资源安全，已经成为一个应用的必备能力。作为开发人员，你也一定要知道如何保障应用的资源安全。那么如何才能保障资源的安全呢？我认为你至少需要掌握下面这两点：


- 权限模型：你需要了解业界成熟的权限模型，以及这些模型的适用场景。只有具备足够宽广的知识面和视野，我们才能避免闭门造车，设计出优秀的资源授权方案。
- 编码实现：选择或设计出了优秀的资源授权方案后，你就要编写代码实现该方案。这门课的 IAM 应用，就是一个资源授权方案的落地项目。你可以通过对 IAM 应用的学习，来掌握如何实现一个资源授权系统。


无论是第一点还是第二点，都需要你掌握基本的权限模型知识。那么这一讲，我就来介绍下业界优秀的权限模型，以及这些模型的适用场景，以使你今后设计出更好的**资源授权系统。**


### 权限相关术语介绍
在介绍业界常见的权限模型前，我们先来看下在权限模型中出现的术语。我把常见的术语总结在了下面的表格里：


![img](https://static001.geekbang.org/resource/image/6a/1d/6aa623500bb76b3d40a5c4c6d15be91d.jpg?wh=2248x1623)

为了方便你理解，这一讲我分别用用户、操作和资源来替代 Subject、Action 和 Object。



### 权限模型介绍
接下来，我就详细介绍下一些常见的权限模型，让你今后在设计权限系统时，能够根据需求选择合适的权限模型。


不同的权限模型具有不同的特点，可以满足不同的需求。常见的权限模型有下面这 5 种：
- 权限控制列表（ACL，Access Control List）。
- 自主访问控制（DAC，Discretionary Access Control）。
- 强制访问控制（MAC，Mandatory Access Control）。
- 基于角色的访问控制（RBAC，Role-Based Access Control）。
- 基于属性的权限验证（ABAC，Attribute-Based Access Control）。


这里先简单介绍下这 5 种权限模型。ACL 是一种简单的权限模型；DAC 基于 ACL，将权限下放给具有此权限的主题；但 DAC 因为权限下放，导致它对权限的控制过于分散，为了弥补 DAC 的这个缺陷，诞生了 MAC 权限模型。



DAC 和 MAC 都是基于 ACL 的权限模型。ACL 及其衍生的权限模型可以算是旧时代的权限模型，灵活性和功能性都满足不了现代应用的权限需求，所以诞生了 RBAC。RBAC 也是迄今为止最为普及的权限模型。但是，随着组织和应用规模的增长，所需的角色数量越来越多，变得难以管理，进而导致角色爆炸和职责分离（SoD）失败。最后，引入了一种新的、更动态的访问控制形式，称为基于属性的访问控制，也就是 ABAC。ABAC 被一些人看作是权限系统设计的未来。腾讯云的 CAM、AWS 的 IAM、阿里云的 RAM 都是 ABAC 类型的权限访问服务。

接下来，我会详细介绍这些权限模型的基本概念。


#### 简单的权限模型：权限控制列表（ACL）
ACL（Access Control List，权限控制列表），用来判断用户是否可以对资源做特定的操作。例如，允许 Colin 创建文章的 ACL 策略为：


```
Subject: Colin
Action: Create
Object: Article
```
在 ACL 权限模型下，权限管理是围绕资源 Object 来设定的，ACL 权限模型也是比较简单的一种模型。




#### 基于 ACL 下放权限的权限模型：自主访问控制（DAC）
DAC (Discretionary Access Control，自主访问控制)，是 ACL 的扩展模型，灵活性更强。使用这种模型，不仅可以判断 Subject 是否可以对 Object 做 Action 操作，同时也能让 Subject 将 Object、Action 的相同权限授权给其他的 Subject。例如，Colin 可以创建文章：


```
Subject: Colin
Action: Create
Object: Article
```
因为 Colin 具有创建文章的权限，所以 Colin 也可以授予 James 创建文章的权限：


```
Subject: James
Action: Create
Object: Article
```
经典的 ACL 模型权限集中在同一个 Subject 上，缺乏灵活性，为了加强灵活性，在 ACL 的基础上，DAC 模型将权限下放，允许拥有权限的 Subject 自主地将权限授予其他 Subject。

#### 基于 ACL 且安全性更高的权限模型：强制访问控制（MAC）
MAC (Mandatory Access Control，强制访问控制)，是 ACL 的扩展模型，安全性更高。MAC 权限模型下，Subject 和 Object 同时具有安全属性。在做授权时，需要同时满足两点才能授权通过：


- Subject 可以对 Object 做 Action 操作。
- Object 可以被 Subject 做 Action 操作。


例如，我们设定了“Colin 和 James 可以创建文章”这个 MAC 策略：


```
Subject: Colin
Action: Create
Object: Article

Subject: James
Action: Create
Object: Article
```
我们还有另外一个 MAC 策略“文章可以被 Colin 创建”：


```
Subject: Article
Action: Create
Object: Colin
```
在上述策略中，Colin 可以创建文章，但是 James 不能创建文章，因为第二条要求没有满足。这里你需要注意，在 ACL 及其扩展模型中，Subject 可以是用户，也可以是组或群组。ACL、DAC 和 MAC 是旧时代的权限控制模型，无法满足现代应用对权限控制的需求，于是诞生了新时代的权限模型：RBAC 和 ABAC。


#### 最普及的权限模型：基于角色的访问控制（RBAC）
RBAC (Role-Based Access Control，基于角色的访问控制)，引入了 Role（角色）的概念，并且将权限与角色进行关联。用户通过扮演某种角色，具有该角色的所有权限。具体如下图所示：


![img](https://static001.geekbang.org/resource/image/c5/cf/c5ab6b1a77069caac2c5de709dff32cf.jpg?wh=2248x902)

如图所示，每个用户关联一个或多个角色，每个角色关联一个或多个权限，每个权限又包含了一个或者多个操作，操作包含了对资源的操作集合。通过用户和权限解耦，可以实现非常灵活的权限管理。例如，可以满足以下两个权限场景：


第一，可以通过角色批量给一个用户授权。例如，公司新来了一位同事，需要授权虚拟机的生产、销毁、重启和登录权限。这时候，我们可以将这些权限抽象成一个运维角色。如果再有新同事来，就可以通过授权运维角色，直接批量授权这些权限，不用一个个地给用户授权这些权限。第二，可以批量修改用户的权限。例如，我们有很多用户，同属于运维角色，这时候对运维角色的任何权限变更，就相当于对运维角色关联的所有用户的权限变更，不用一个个去修改这些用户的权限。


RBAC 又分为 RBAC0、RBAC1、RBAC2、RBAC3。RBAC0 是 RBAC 的核心思想，RBAC1 是基于 RBAC 的角色分层模型，RBAC2 增加了 RBAC 的约束模型。而 RBAC3，其实相当于 RBAC1 + RBAC2。

下面我来详细介绍下这四种 RBAC。

RBAC0：基础模型，只包含核心的四要素，也就是用户（User）、角色（Role）、权限（Permission：Objects-Operations）、会话（Session）。用户和角色可以是多对多的关系，权限和角色也是多对多的关系。RBAC1：包括了 RBAC0，并且添加了角色继承。角色继承，即角色可以继承自其他角色，在拥有其他角色权限的同时，还可以关联额外的权限。RBAC2：包括 RBAC0，并且添加了约束。具有以下核心特性：


- 互斥约束：包括互斥用户、互斥角色、互斥权限。同一个用户不能拥有相互排斥的角色，两个互斥角色不能分配一样的权限集，互斥的权限不能分配给同一个角色，在 Session 中，同一个角色不能拥有互斥权限。
- 基数约束：一个角色被分配的用户数量受限，它指的是有多少用户能拥有这个角色。例如，一个角色是专门为公司 CEO 创建的，那这个角色的数量就是有限的。
- 先决条件角色：指要想获得较高的权限，要首先拥有低一级的权限。例如，先有副总经理权限，才能有总经理权限。
- 静态职责分离(Static Separation of Duty)：用户无法同时被赋予有冲突的角色。
- 动态职责分离(Dynamic Separation of Duty)：用户会话中，无法同时激活有冲突的角色。


RBAC3：全功能的 RBAC，合并了 RBAC0、RBAC1、RBAC2。此外，RBAC 也可以很方便地模拟出 DAC 和 MAC 的效果。这里举个例子，来协助你理解 RBAC。例如，我们有 write article 和 manage article 的权限：


```
Permission:
    - Name: write_article
        - Effect: "allow"
        - Action: ["Create", "Update", "Read"]
        - Object: ["Article"]
    - Name: manage_article
        - Effect: "allow"
        - Action: ["Delete", "Read"]
        - Object: ["Article"]
```
同时，我们也有 Writer、Manager 和 CEO 3 个角色，Writer 具有 write_article 权限，Manager 具有 manage_article 权限，CEO 具有所有权限：



```
Role:
    - Name: Writer
      Permissions:
        - write_article
    - Name: Manager
      Permissions:
        - manage_article
    - Name: CEO
      Permissions:
        - write_article
        - manage_article
```
接下来，我们对 Colin 用户授予 Writer 角色：


```
Subject: Colin
Roles:
    - Writer
```
那么现在 Colin 就具有 Writer 角色的所有权限 write_article，write_article 权限可以创建文章。接下来，再对 James 用户授予 Writer 和 Manager 角色：


```
Subject: James
Roles:
    - Writer
    - Manager
```
那么现在 James 就具有 Writer 角色和 Manager 角色的所有权限：write_article、manage_article，这些权限允许 James 创建和删除文章。


#### 最强大的权限模型：基于属性的权限验证（ABAC）
ABAC (Attribute-Based Access Control，基于属性的权限验证），规定了哪些属性的用户可以对哪些属性的资源在哪些限制条件下进行哪些操作。跟 RBAC 相比，ABAC 对权限的控制粒度更细，主要规定了下面这四类属性：


用户属性，例如性别、年龄、工作等。资源属性，例如创建时间、所属位置等。操作属性，例如创建、修改等。环境属性，例如来源 IP、当前时间等。


下面是一个 ABAC 策略：



```
Subject:
    Name: Colin
    Department: Product
    Role: Writer
Action:
    - create
    - update
Resource:
    Type: Article
    Tag:
        - technology
        - software
    Mode:
        - draft
Contextual:
    IP: 10.0.0.10
```
上面权限策略描述的意思是，产品部门的 Colin 作为一个 Writer 角色，可以通过来源 IP 是 10.0.0.10 的客户端，创建和更新带有 technology 和 software 标签的草稿文章。这里提示一点：ABAC 有时也被称为 PBAC（Policy-Based Access Control）或 CBAC（Claims-Based Access Control）。



这里，我通过现实中的 ABAC 授权策略，帮你理解 ABAC 权限模型。下面是一个腾讯云的 CAM 策略，也是一种 ABAC 授权模式：



```
{
  "version": "2.0",
  "statement": [
    {
      "effect": "allow",
      "action": [
        "cos:List*",
        "cos:Get*",
        "cos:Head*",
        "cos:OptionsObject"
      ],
      "resource": "qcs::cos:ap-shanghai:uid/1250000000:Bucket1-1250000000/dir1/*",
      "condition": {
        "ip_equal": {
          "qcs:ip": [
            "10.217.182.3/24",
            "111.21.33.72/24"
          ]
        }
      }
    }
  ]
}
```
上面的授权策略表示：用户必须在 10.217.182.3/24 或者 111.21.33.72/24 网段才能调用云 API（cos:List*、cos:Get*、cos:Head*、cos:OptionsObject），对 1250000000 用户下的 dir1 目录下的文件进行读取操作。这里，ABAC 规定的四类属性分别是：


- 用户属性：用户为 1250000000。
- 资源属性：dir1 目录下的文件。
- 操作属性：读取（cos:List*、cos:Get*、cos:Head*、cos:OptionsObject 都是读取 API）。
- 环境属性：10.217.182.3/24 或者 111.21.33.72/24 网段。



### 相关开源项目
上面我介绍了权限模型的相关知识，但是现在如果让你真正去实现一个权限系统，你可能还是不知从何入手。在这里，我列出了一些 GitHub 上比较优秀的开源项目，你可以学习这些项目是如何落地一个权限模型的，也可以基于这些项目进行二次开发，开发一个满足业务需求的权限系统。


#### Casbin
Casbin 是一个用 Go 语言编写的访问控制框架，功能强大，支持 ACL、RBAC、ABAC 等访问模型，很多优秀的权限管理系统都是基于 Casbin 来构建的。Casbin 的核心功能都是围绕着访问控制来构建的，不负责身份认证。如果以后老板让你实现一个权限管理系统，Casbin 是一定要好好研究的开源项目。


#### keto
keto 是一个云原生权限控制服务，通过提供 REST API 进行授权，支持 RBAC、ABAC、ACL、AWS IAM 策略、Kubernetes Roles 等权限模型，可以解决下面这些问题：是否允许某些用户修改此博客文章？是否允许某个服务打印该文档？是否允许 ACME 组织的成员修改其租户中的数据？是否允许在星期一的下午 4 点到下午 5 点，从 IP 10.0.0.2 发出的请求执行某个 Job？


#### go-admin
go-admin 是一个基于 Gin + Vue + Element UI 的前后端分离权限管理系统脚手架，它的访问控制模型采用了 Casbin 的 RBAC 访问控制模型，功能强大，包含了如下功能：

基础用户管理功能；JWT 鉴权；代码生成器；RBAC 权限控制；表单构建；……

该项目还支持 RESTful API 设计规范、Swagger 文档、GORM 库等。go-admin 不仅是一个优秀的权限管理系统，也是一个优秀的、功能齐全的 Go 开源项目。你在做项目开发时，也可以参考该项目的构建思路。go-admin 管理系统自带前端，如下图所示。


![img](https://static001.geekbang.org/resource/image/21/98/21c8307e034fc6e082833d1c9fd0f498.png?wh=2535x827)

#### LyricTian/gin-admin
[gin-admin](https://github.com/LyricTian/gin-admin) 类似于 go-admin，是一个基于 Gin+Gorm+Casbin+Wire 实现的权限管理脚手架，并自带前端，在做权限管理系统调研时，也非常值得参考。gin-admin 大量采用了 Go 后端开发常用的技术，比如 Gin、GORM、JWT 认证、RESTful API、Logrus 日志包、Swagger 文档等。因此，你在做 Go 后端服务开发时，也可以学习该项目的构建方法。


#### gin-vue-admin
gin-vue-admin 是一个基于 Gin 和 Vue 开发的全栈前后端分离的后台管理系统，集成了 JWT 鉴权、动态路由、动态菜单、Casbin 鉴权、表单生成器、代码生成器等功能。gin-vue-admin 集成了 RBAC 权限管理模型，界面如下图所示：


![img](https://static001.geekbang.org/resource/image/a3/f3/a391723e154f862d5c7bf796edcf5bf3.png?wh=2527x627)

### 选择建议
介绍了那么多优秀的开源项目，最后我想给你一些选择建议。如果你想研究 ACL、RBAC、ABAC 等权限模型如何落地，我强烈建议你学习 Casbin 项目，Casbin 目前有近万的 GitHub star 数，处于活跃的开发状态。有很多项目在使用 Casbin，例如 go-admin、 gin-admin 、 gin-vue-admin 等。


keto 类似于 Casbin，主要通过 Go 包的方式，对外提供授权能力。keto 也是一个非常优秀的权限类项目，当你研究完 Casbin 后，如果还想再研究下其他授权类项目，建议你读下 keto 的源码。


go-admin、gin-vue-admin、gin-admin 这 3 个都是基于 Casbin 的 Go 项目。其中，gin-vue-admin 是后台管理系统框架，里面包含了 RBAC 权限管理模块；go-admin 和 gin-admin 都是 RBAC 权限管理脚手架。所以，如果你想找一个比较完整的 RBAC 授权系统（自带前后端），建议你优先研究下 go-admin，如果还有精力，可以再研究下 gin-admin、gin-vue-admin。


### 总结
这一讲，我介绍了 5 种常见的权限模型。其中，ACL 最简单，ABAC 最复杂，但是功能最强大，也最灵活。RBAC 则介于二者之间。对于一些云计算厂商来说，因为它们面临的授权场景复杂多样，需要一个非常强大的授权模型，所以腾讯云、阿里云和 AWS 等云厂商普遍采用了 ABAC 模型。


如果你的资源授权需求不复杂，可以考虑 RBAC；如果你需要一个能满足复杂场景的资源授权系统，建议选择 ABAC，ABAC 的设计思路可以参考下腾讯云的 CAM、阿里云的 RAM 和 AWS 的 IAM。另外，如果你想深入了解权限模型如何具体落地，建议你阅读 [Casbin](https://github.com/casbin/casbin) 源码。

## 28 | 控制流（上）：通过iam-apiserver设计，看Web服务的构建

前面我们讲了很多关于应用构建的内容，你一定迫不及待地想看下 IAM 项目的应用是如何构建的。那么接下来，我就**讲解下 IAM 应用的源码**。在讲解过程中，我不会去讲解具体如何 Code，但会讲解一些构建过程中的重点、难点，以及 Code 背后的设计思路、想法。我相信这是对你更有帮助的。IAM 项目有很多组件，这一讲，我先来介绍下 IAM 项目的门面服务：iam-apiserver（管理流服务）。我会先给你介绍下 iam-apiserver 的功能和使用方法，再介绍下 iam-apiserver 的代码实现。


### iam-apiserver 服务介绍
iam-apiserver 是一个 Web 服务，通过一个名为 iam-apiserver 的进程，对外提供 RESTful API 接口，完成用户、密钥、策略三种 REST 资源的增删改查。接下来，我从功能和使用方法两个方面来具体介绍下。


### iam-apiserver 功能介绍
这里，我们可以通过 iam-apiserver 提供的 RESTful API 接口，来看下 iam-apiserver 具体提供的功能。iam-apiserver 提供的 RESTful API 接口可以分为四类，具体如下：



认证相关接口


![img](https://static001.geekbang.org/resource/image/43/6d/43ec9261ccdb165c56e9c25b45e6af6d.jpg?wh=1920x1062)

用户相关接口


![img](https://static001.geekbang.org/resource/image/60/24/60f8a05f4cb43cbac84c0fb12c40c824.jpg?wh=1920x1314)

密钥相关接口


![img](https://static001.geekbang.org/resource/image/e8/95/e8f6aee66a29ff2a5aefeb00c5045c95.jpg?wh=1920x1326)

策略相关接口


![img](https://static001.geekbang.org/resource/image/0f/9e/0f3fcaa80020c3f72229fbab2f014a9e.jpg?wh=1920x1275)


### iam-apiserver 使用方法介绍
上面我介绍了 iam-apiserver 的功能，接下来就介绍下如何使用这些功能。


我们可以通过不同的客户端来访问 iam-apiserver，例如前端、API 调用、SDK、iamctl 等。这些客户端最终都会执行 HTTP 请求，调用 iam-apiserver 提供的 RESTful API 接口。所以，我们首先需要有一个顺手的 REST API 客户端工具来执行 HTTP 请求，完成开发测试。



因为不同的开发者执行 HTTP 请求的方式、习惯不同，为了方便讲解，这里我统一通过 cURL 工具来执行 HTTP 请求。接下来先介绍下 cURL 工具。


标准的 Linux 发行版都安装了 cURL 工具。cURL 可以很方便地完成 RESTful API 的调用场景，比如设置 Header、指定 HTTP 请求方法、指定 HTTP 消息体、指定权限认证信息等。通过-v选项，也能输出 REST 请求的所有返回信息。cURL 功能很强大，有很多参数，这里列出 cURL 工具常用的参数：


```
-X/--request [GET|POST|PUT|DELETE|…]  指定请求的 HTTP 方法
-H/--header                           指定请求的 HTTP Header
-d/--data                             指定请求的 HTTP 消息体（Body）
-v/--verbose                          输出详细的返回信息
-u/--user                             指定账号、密码
-b/--cookie                           读取 cookie
```
此外，如果你想使用带 UI 界面的工具，这里我推荐你使用 Insomnia 。Insomnia 是一个跨平台的 REST API 客户端，与 Postman、Apifox 是一类工具，用于接口管理、测试。Insomnia 功能强大，支持以下功能：

发送 HTTP 请求；创建工作区或文件夹；导入和导出数据；导出 cURL 格式的 HTTP 请求命令；支持编写 swagger 文档；快速切换请求；URL 编码和解码。…


Insomnia 界面如下图所示：


![img](https://static001.geekbang.org/resource/image/63/e0/635aa6f3374af05ec2bff7e193314ae0.png?wh=1920x749)

当然了，也有很多其他优秀的带 UI 界面的 REST API 客户端，例如 Postman、Apifox 等，你可以根据需要自行选择。接下来，我用对 secret 资源的 CURD 操作，来给你演示下如何使用 iam-apiserver 的功能。你需要执行 6 步操作。


1. 登录 iam-apiserver，获取 token。
2. 创建一个名为 secret0 的 secret。
3. 获取 secret0 的详细信息。
4. 更新 secret0 的描述。
5. 获取 secret 列表。
6. 删除 secret0。


具体操作如下：登录 iam-apiserver，获取 token：


```
$ curl -s -XPOST -H"Authorization: Basic `echo -n 'admin:Admin@2021'|base64`" http://127.0.0.1:8080/login | jq -r .token
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI
```
这里，为了便于使用，我们将 token 设置为环境变量：



```
TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI
```
创建一个名为 secret0 的 secret：

```
$ curl -v -XPOST -H "Content-Type: application/json" -H"Authorization: Bearer ${TOKEN}" -d'{"metadata":{"name":"secret0"},"expires":0,"description":"admin secret"}' http://iam.api.marmotedu.com:8080/v1/secrets
* About to connect() to iam.api.marmotedu.com port 8080 (#0)
*   Trying 127.0.0.1...
* Connected to iam.api.marmotedu.com (127.0.0.1) port 8080 (#0)
> POST /v1/secrets HTTP/1.1
> User-Agent: curl/7.29.0
> Host: iam.api.marmotedu.com:8080
> Accept: */*
> Content-Type: application/json
> Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI
> Content-Length: 72
> 
* upload completely sent off: 72 out of 72 bytes
< HTTP/1.1 200 OK
< Content-Type: application/json; charset=utf-8
< X-Request-Id: ff825bea-53de-4020-8e68-4e87574bd1ba
< Date: Mon, 26 Jul 2021 07:20:26 GMT
< Content-Length: 313
< 
* Connection #0 to host iam.api.marmotedu.com left intact
{"metadata":{"id":60,"instanceID":"secret-jedr3e","name":"secret0","createdAt":"2021-07-26T15:20:26.885+08:00","updatedAt":"2021-07-26T15:20:26.907+08:00"},"username":"admin","secretID":"U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD","secretKey":"fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf","expires":0,"description":"admin secret"}
```
可以看到，请求返回头中返回了X-Request-Id Header，X-Request-Id唯一标识这次请求。如果这次请求失败，就可以将X-Request-Id提供给运维或者开发，通过X-Request-Id定位出失败的请求，进行排障。另外X-Request-Id在微服务场景中，也可以透传给其他服务，从而实现请求调用链。

获取 secret0 的详细信息：


```
$ curl -XGET -H"Authorization: Bearer ${TOKEN}" http://iam.api.marmotedu.com:8080/v1/secrets/secret0
{"metadata":{"id":60,"instanceID":"secret-jedr3e","name":"secret0","createdAt":"2021-07-26T15:20:26+08:00","updatedAt":"2021-07-26T15:20:26+08:00"},"username":"admin","secretID":"U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD","secretKey":"fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf","expires":0,"description":"admin secret"}
```
更新 secret0 的描述：


```
$ curl -XPUT -H"Authorization: Bearer ${TOKEN}" -d'{"metadata":{"name":"secret"},"expires":0,"description":"admin secret(modify)"}' http://iam.api.marmotedu.com:8080/v1/secrets/secret0
{"metadata":{"id":60,"instanceID":"secret-jedr3e","name":"secret0","createdAt":"2021-07-26T15:20:26+08:00","updatedAt":"2021-07-26T15:23:35.878+08:00"},"username":"admin","secretID":"U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD","secretKey":"fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf","expires":0,"description":"admin secret(modify)"}
```
获取 secret 列表：


```
$ curl -XGET -H"Authorization: Bearer ${TOKEN}" http://iam.api.marmotedu.com:8080/v1/secrets
{"totalCount":1,"items":[{"metadata":{"id":60,"instanceID":"secret-jedr3e","name":"secret0","createdAt":"2021-07-26T15:20:26+08:00","updatedAt":"2021-07-26T15:23:35+08:00"},"username":"admin","secretID":"U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD","secretKey":"fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf","expires":0,"description":"admin secret(modify)"}]}
```
删除 secret0：


```
$ curl -XDELETE -H"Authorization: Bearer ${TOKEN}" http://iam.api.marmotedu.com:8080/v1/secrets/secret0
null
```
上面，我给你演示了密钥的使用方法。用户和策略资源类型的使用方法跟密钥类似。详细的使用方法你可以参考 [test.sh](https://github.com/marmotedu/iam/blob/v1.0.6/scripts/install/test.sh) 脚本，该脚本是用来测试 IAM 应用的，里面包含了各个接口的请求方法。


这里，我还想顺便介绍下如何测试 IAM 应用中的各个部分。确保 iam-apiserver、iam-authz-server、iam-pump 等服务正常运行后，进入到 IAM 项目的根目录，执行以下命令：


```
$ ./scripts/install/test.sh iam::test::test # 测试整个IAM应用是否正常运行
$ ./scripts/install/test.sh iam::test::login # 测试登陆接口是否可以正常访问
$ ./scripts/install/test.sh iam::test::user # 测试用户接口是否可以正常访问
$ ./scripts/install/test.sh iam::test::secret # 测试密钥接口是否可以正常访问
$ ./scripts/install/test.sh iam::test::policy # 测试策略接口是否可以正常访问
$ ./scripts/install/test.sh iam::test::apiserver # 测试iam-apiserver服务是否正常运行
$ ./scripts/install/test.sh iam::test::authz # 测试authz接口是否可以正常访问
$ ./scripts/install/test.sh iam::test::authzserver # 测试iam-authz-server服务是否正常运行
$ ./scripts/install/test.sh iam::test::pump # 测试iam-pump是否正常运行
$ ./scripts/install/test.sh iam::test::iamctl # 测试iamctl工具是否可以正常使用
$ ./scripts/install/test.sh iam::test::man # 测试man文件是否正确安装
```
所以，每次发布完 iam-apiserver 后，你可以执行以下命令来完成 iam-apiserver 的冒烟测试：


```
$ export IAM_APISERVER_HOST=127.0.0.1 # iam-apiserver部署服务器的IP地址
$ export IAM_APISERVER_INSECURE_BIND_PORT=8080 # iam-apiserver HTTP服务的监听端口
$ ./scripts/install/test.sh iam::test::apiserver
```
### iam-apiserver 代码实现
上面，我介绍了 iam-apiserver 的功能和使用方法，这里我们再来看下 iam-apiserver 具体的代码实现。我会从配置处理、启动流程、请求处理流程、代码架构 4 个方面来讲解。


#### iam-apiserver 配置处理
iam-apiserver 服务的 main 函数位于apiserver.go文件中，你可以跟读代码，了解 iam-apiserver 的代码实现。这里，我来介绍下 iam-apiserver 服务的一些设计思想。


首先，来看下 iam-apiserver 中的 3 种配置：
- Options 配置、应用配置和 HTTP/GRPC 服务配置。Options 配置：用来构建命令行参数，它的值来自于命令行选项或者配置文件（也可能是二者 Merge 后的配置）。Options 可以用来构建应用框架，Options 配置也是应用配置的输入。
- 应用配置：iam-apiserver 组件中需要的一切配置。有很多地方需要配置，例如，启动 HTTP/GRPC 需要配置监听地址和端口，初始化数据库需要配置数据库地址、用户名、密码等。
- HTTP/GRPC 服务配置：启动 HTTP 服务或者 GRPC 服务需要的配置。


这三种配置的关系如下图：


![img](https://static001.geekbang.org/resource/image/8c/b5/8ca8d9fa1efaab21e012471874e89cb5.jpg?wh=1346x727)

Options 配置接管命令行选项，应用配置接管整个应用的配置，HTTP/GRPC 服务配置接管跟 HTTP/GRPC 服务相关的配置。这 3 种配置独立开来，可以解耦命令行选项、应用和应用内的服务，使得这 3 个部分可以独立扩展，又不相互影响。


iam-apiserver 根据 Options 配置来构建命令行参数和应用配置。



我们通过github.com/marmotedu/iam/pkg/app包的buildCommand方法来构建命令行参数。这里的核心是，通过NewApp函数构建 Application 实例时，传入的Options实现了Flags() (fss cliflag.NamedFlagSets)方法，通过 buildCommand 方法中的以下代码，将 option 的 Flag 添加到 cobra 实例的 FlagSet 中：


```go
  if a.options != nil {
      namedFlagSets = a.options.Flags()
      fs := cmd.Flags()
      for _, f := range namedFlagSets.FlagSets {
        fs.AddFlagSet(f)
      }
  
            ...
    }
```
通过[CreateConfigFromOptions](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/config/config.go#L16)函数来构建应用配置：


```
        cfg, err := config.CreateConfigFromOptions(opts)                      
        if err != nil {                                               
            return err                                                
        }  
```
根据应用配置来构建 HTTP/GRPC 服务配置。例如，以下代码根据应用配置，构建了 HTTP 服务器的 Address 参数：



```go
func (s *InsecureServingOptions) ApplyTo(c *server.Config) error {
    c.InsecureServing = &server.InsecureServingInfo{
        Address: net.JoinHostPort(s.BindAddress, strconv.Itoa(s.BindPort)),
    }

    return nil
}

```
其中，c *server.Config是 HTTP 服务器的配置，s *InsecureServingOptions是应用配置。


#### iam-apiserver 启动流程设计
接下来，我们来详细看下 iam-apiserver 的启动流程设计。启动流程如下图所示：


![img](https://static001.geekbang.org/resource/image/8a/c7/8a94938bc087ed96d0ec87261db292c7.jpg?wh=4770x1487)

首先，通过opts := options.NewOptions()创建带有默认值的 Options 类型变量 opts。opts 变量作为github.com/marmotedu/iam/pkg/app包的NewApp函数的输入参数，最终在 App 框架中，被来自于命令行参数或配置文件的配置（也可能是二者 Merge 后的配置）所填充，opts 变量中各个字段的值会用来创建应用配置。


接着，会注册run函数到 App 框架中。run 函数是 iam-apiserver 的启动函数，里面封装了我们自定义的启动逻辑。run 函数中，首先会初始化日志包，这样我们就可以根据需要，在后面的代码中随时记录日志了。


然后，会创建应用配置。应用配置和 Options 配置其实是完全独立的，二者可能完全不同，但在 iam-apiserver 中，二者配置项是相同的。之后，根据应用配置，创建 HTTP/GRPC 服务器所使用的配置。在创建配置后，会先分别进行配置补全，再使用补全后的配置创建 Web 服务实例，例如：


```go
genericServer, err := genericConfig.Complete().New()
if err != nil {
    return nil, err
}
extraServer, err := extraConfig.complete().New()
if err != nil {
    return nil, err
}
...
func (c *ExtraConfig) complete() *completedExtraConfig {
    if c.Addr == "" {
        c.Addr = "127.0.0.1:8081"
    }

    return &completedExtraConfig{c}
}
```
上面的代码中，首先调用Complete/complete函数补全配置，再基于补全后的配置，New 一个 HTTP/GRPC 服务实例。


这里有个设计技巧：complete函数返回的是一个*completedExtraConfig类型的实例，在创建 GRPC 实例时，是调用completedExtraConfig结构体提供的New方法，这种设计方法可以确保我们创建的 GRPC 实例一定是基于 complete 之后的配置（completed）。

在实际的 Go 项目开发中，我们需要提供一种机制来处理或补全配置，这在 Go 项目开发中是一个非常有用的步骤。

最后，调用PrepareRun方法，进行 HTTP/GRPC 服务器启动前的准备。在准备函数中，我们可以做各种初始化操作，例如初始化数据库，安装业务相关的 Gin 中间件、RESTful API 路由等。完成 HTTP/GRPC 服务器启动前的准备之后，调用Run方法启动 HTTP/GRPC 服务。在Run方法中，分别启动了 GRPC 和 HTTP 服务。


可以看到，整个 iam-apiserver 的软件框架是比较清晰的。服务启动后，就可以处理请求了。所以接下来，我们再来看下 iam-apiserver 的 RESTAPI 请求处理流程。


#### iam-apiserver 的 REST API 请求处理流程
iam-apiserver 的请求处理流程也是清晰、规范的，具体流程如下图所示：


![img](https://static001.geekbang.org/resource/image/94/76/9400e9855b10yyac47871a7af87e9776.jpg?wh=5771x1691)

结合上面这张图，我们来看下 iam-apiserver 的 REST API 请求处理流程，来帮你更好地理解 iam-apiserver 是如何处理 HTTP 请求的。


首先，我们通过 API 调用（ + ）请求 iam-apiserver 提供的 RESTful API 接口。接着，Gin Web 框架接收到 HTTP 请求之后，会通过认证中间件完成请求的认证，iam-apiserver 提供了 Basic 认证和 Bearer 认证两种认证方式。认证通过后，请求会被我们加载的一系列中间件所处理，例如跨域、RequestID、Dump 等中间件。最后，根据 + 进行路由匹配。


举个例子，假设我们请求的 RESTful API 是POST + /v1/secrets，Gin Web 框架会根据 HTTP Method 和 HTTP Request Path，查找注册的 Controllers，最终匹配到[secretController.Create](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/controller/v1/secret/create.go)Controller。在 Create Controller 中，我们会依次执行请求参数解析、请求参数校验、调用业务层的方法创建 Secret、处理业务层的返回结果，最后返回最终的 HTTP 请求结果。


#### iam-apiserver 代码架构
iam-apiserver 代码设计遵循简洁架构设计，一个简洁架构具有以下 5 个特性：


- 独立于框架：该架构不会依赖于某些功能强大的软件库存在。这可以让你使用这样的框架作为工具，而不是让你的系统陷入到框架的约束中。
- 可测试性：业务规则可以在没有 UI、数据库、Web 服务或其他外部元素的情况下进行测试，在实际的开发中，我们通过 Mock 来解耦这些依赖。
- 独立于 UI ：在无需改变系统其他部分的情况下，UI 可以轻松地改变。例如，在没有改变业务规则的情况下，Web UI 可以替换为控制台 UI。
- 独立于数据库：你可以用 Mongo、Oracle、Etcd 或者其他数据库来替换 MariaDB，你的业务规则不要绑定到数据库。
- 独立于外部媒介：实际上，你的业务规则可以简单到根本不去了解外部世界。


所以，基于这些约束，每一层都必须是独立的和可测试的。iam-apiserver 代码架构分为 4 层：模型层（Models）、控制层（Controller）、业务层 （Service）、仓库层（Repository）。从控制层、业务层到仓库层，从左到右层级依次加深。模型层独立于其他层，可供其他层引用。如下图所示：


![img](https://static001.geekbang.org/resource/image/f2/f0/f2fffd84dfbc1a6643887db3d5d541f0.jpg?wh=2498x747)


层与层之间导入包时，都有严格的导入关系，这可以防止包的循环导入问题。导入关系如下：
- 模型层的包可以被仓库层、业务层和控制层导入；
- 控制层能够导入业务层和仓库层的包。这里需要注意，如果没有特殊需求，控制层要避免导入仓库层的包，控制层需要完成的业务功能都通过业务层来完成。这样可以使代码逻辑更加清晰、规范。
- 业务层能够导入仓库层的包。


接下来，我们就来详细看下每一层所完成的功能，以及其中的一些注意点。


模型层（Models）模型层在有些软件架构中也叫做实体层（Entities），模型会在每一层中使用，在这一层中存储对象的结构和它的方法。IAM 项目模型层中的模型存放在github.com/marmotedu/api/apiserver/v1目录下，定义了User、UserList、Secret、SecretList、Policy、PolicyList、AuthzPolicy模型及其方法。例如：

```go
type Secret struct {
  // May add TypeMeta in the future.
  // metav1.TypeMeta `json:",inline"`

  // Standard object's metadata.
  metav1.ObjectMeta `       json:"metadata,omitempty"`
  Username          string `json:"username"           gorm:"column:username"  validate:"omitempty"`
  SecretID          string `json:"secretID"           gorm:"column:secretID"  validate:"omitempty"`
  SecretKey         string `json:"secretKey"          gorm:"column:secretKey" validate:"omitempty"`

  // Required: true
  Expires     int64  `json:"expires"     gorm:"column:expires"     validate:"omitempty"`
  Description string `json:"description" gorm:"column:description" validate:"description"`
}
```
之所以将模型层的模型存放在github.com/marmotedu/api项目中，而不是github.com/marmotedu/iam项目中，是为了让这些模型能够被其他项目使用。例如，iam 的模型可以被github.com/marmotedu/shippy应用导入。同样，shippy 应用的模型也可以被 iam 项目导入，导入关系如下图所示：


![img](https://static001.geekbang.org/resource/image/13/c9/1307e374f4193ecc3d5b73a987cdd0c9.jpg?wh=3896x1433)
上面的依赖关系都是单向的，依赖关系清晰，不存在循环依赖的情况。要增加 shippy 的模型定义，只需要在 api 目录下创建新的目录即可。例如，shippy 应用中有一个 vessel 服务，其模型所在的包可以为github.com/marmotedu/api/vessel。

另外，这里的模型既可以作为数据库模型，又可以作为 API 接口的请求模型（入参、出参）。如果我们能够确保**创建资源时的属性、资源保存在数据库中的属性、返回资源的属性三者一致**，就可以使用同一个模型。通过使用同一个模型，可以使我们的代码更加简洁、易维护，并能提高开发效率。如果这三个属性有差异，你可以另外新建模型来适配。


仓库层（Repository)
仓库层用来跟数据库 / 第三方服务进行 CURD 交互，作为应用程序的数据引擎进行应用数据的输入和输出。这里需要注意，仓库层仅对数据库 / 第三方服务执行 CRUD 操作，不封装任何业务逻辑。仓库层也负责选择应用中将要使用什么样的数据库，可以是 MySQL、MongoDB、MariaDB、Etcd 等。无论使用哪种数据库，都要在这层决定。仓库层依赖于连接数据库或其他第三方服务（如果存在的话）。

这一层也会起到数据转换的作用：将从数据库 / 微服务中获取的数据转换为控制层、业务层能识别的数据结构，将控制层、业务层的数据格式转换为数据库或微服务能识别的数据格式。iam-apiserver 的仓库层位于internal/apiserver/store/mysql目录下，里面的方法用来跟 MariaDB 进行交互，完成 CURD 操作，例如，从数据库中获取密钥：



```go
func (s *secrets) Get(ctx context.Context, username, name string, opts metav1.GetOptions) (*v1.Secret, error) {
    secret := &v1.Secret{}
    err := s.db.Where("username = ? and name= ?", username, name).First(&secret).Error
    if err != nil {
        if errors.Is(err, gorm.ErrRecordNotFound) {
            return nil, errors.WithCode(code.ErrSecretNotFound, err.Error())
        }

        return nil, errors.WithCode(code.ErrDatabase, err.Error())
    }

    return secret, nil
}

```
业务层 (Service)
业务层主要用来完成业务逻辑处理，我们可以把所有的业务逻辑处理代码放在业务层。业务层会处理来自控制层的请求，并根据需要请求仓库层完成数据的 CURD 操作。业务层功能如下图所示：


![img](https://static001.geekbang.org/resource/image/61/b6/6103c58d837fd81769977bc3c947ffb6.jpg?wh=1796x1236)

iam-apiserver 的业务层位于internal/apiserver/service目录下。下面是 iam-apiserver 业务层中，用来创建密钥的函数：



```go
func (s *secretService) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {
    if err := s.store.Secrets().Create(ctx, secret, opts); err != nil {
        return errors.WithCode(code.ErrDatabase, err.Error())
    }

    return nil
}
```
可以看到，业务层最终请求仓库层的s.store的Create方法，将密钥信息保存在 MariaDB 数据库中。


控制层（Controller）
控制层接收 HTTP 请求，并进行参数解析、参数校验、逻辑分发处理、请求返回这些操作。控制层会将逻辑分发给业务层，业务层处理后返回，返回数据在控制层中被整合再加工，最终返回给请求方。控制层相当于实现了业务路由的功能。具体流程如下图所示：


![img](https://static001.geekbang.org/resource/image/12/08/120137fc2749aa12a013099ec11e1b08.jpg?wh=960x1029)


这里我有个建议，不要在控制层写复杂的代码，如果需要，请将这些代码分发到业务层或其他包中。iam-apiserver 的控制层位于internal/apiserver/controller目录下。下面是 iam-apiserver 控制层中创建密钥的代码：


```go
func (s *SecretHandler) Create(c *gin.Context) {
  log.L(c).Info("create secret function called.")

  var r v1.Secret

  if err := c.ShouldBindJSON(&r); err != nil {
    core.WriteResponse(c, errors.WithCode(code.ErrBind, err.Error()), nil)

    return
  }

  if errs := r.Validate(); len(errs) != 0 {
    core.WriteResponse(c, errors.WithCode(code.ErrValidation, errs.ToAggregate().Error()), nil)

    return
  }

  username := c.GetString(middleware.UsernameKey)

  secrets, err := s.srv.Secrets().List(c, username, metav1.ListOptions{
    Offset: pointer.ToInt64(0),
    Limit:  pointer.ToInt64(-1),
  })
  if err != nil {
    core.WriteResponse(c, errors.WithCode(code.ErrDatabase, err.Error()), nil)

    return
  }

  if secrets.TotalCount >= maxSecretCount {
    core.WriteResponse(c, errors.WithCode(code.ErrReachMaxCount, "secret count: %d", secrets.TotalCount), nil)

    return
  }

  // must reassign username
  r.Username = username

  if err := s.srv.Secrets().Create(c, &r, metav1.CreateOptions{}); err != nil {
    core.WriteResponse(c, err, nil)

    return
  }

  core.WriteResponse(c, nil, r)
}

```
上面的代码完成了以下操作：
- 解析 HTTP 请求参数。
- 进行参数验证，这里可以添加一些业务性质的参数校验，例如：secrets.TotalCount >= maxSecretCount。
- 调用业务层s.srv的Create方法，完成密钥的创建。
- 返回 HTTP 请求参数。


上面，我们介绍了 iam-apiserver 采用的 4 层结构，接下来我们再看看每一层之间是如何通信的。

除了模型层，控制层、业务层、仓库层之间都是通过接口进行通信的。通过接口通信，一方面可以使相同的功能支持不同的实现（也就是说具有插件化能力），另一方面也使得每一层的代码变得可测试。


这里，我用创建密钥 API 请求的例子，来给你讲解下层与层之间是如何进行通信的。



首先，**来看下控制层如何跟业务层进行通信。**对密钥的请求处理都是通过 SecretController 提供的方法来处理的，创建密钥调用的是它的Create方法：



```go
func (s *SecretController) Create(c *gin.Context) {
    ...
  if err := s.srv.Secrets().Create(c, &r, metav1.CreateOptions{}); err != nil {
    core.WriteResponse(c, err, nil)

    return
  }
  ...
}
```
在Create方法中，调用了s.srv.Secrets().Create()来创建密钥，s.srv是一个接口类型，定义如下：


```go
type Service interface {
    Users() UserSrv
    Secrets() SecretSrv
    Policies() PolicySrv
}

type SecretSrv interface {                                                             
    Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error    
    Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) error            
    Delete(ctx context.Context, username, secretID string, opts metav1.DeleteOptions) error                        
    DeleteCollection(ctx context.Context, username string, secretIDs []string, opts metav1.DeleteOptions) error    
    Get(ctx context.Context, username, secretID string, opts metav1.GetOptions) (*v1.Secret, error)    
    List(ctx context.Context, username string, opts metav1.ListOptions) (*v1.SecretList, error)    
} 
```
可以看到，控制层通过业务层提供的Service接口类型，剥离了业务层的具体实现。业务层的 Service 接口类型提供了Secrets()方法，该方法返回了一个实现了SecretSrv接口的实例。在控制层中，通过调用该实例的Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error方法来完成密钥的创建。至于业务层是如何创建密钥的，控制层不需要知道，也就是说创建密钥可以有多种实现。


这里使用到了设计模式中的**工厂方法模式。**Service是工厂接口，里面包含了一系列创建具体业务层对象的工厂函数：Users()、Secrets()、Policies()。通过工厂方法模式，不仅隐藏了业务层对象的创建细节，而且还可以很方便地在Service工厂接口实现方法中添加新的业务层对象。例如，我们想新增一个Template业务层对象，用来在 iam-apiserver 中预置一些策略模板，可以这么来加：


```go
type Service interface {
    Users() UserSrv
    Secrets() SecretSrv
    Policies() PolicySrv
    Templates() TemplateSrv
}

func (s *service) Templates() TemplateSrv {
    return newTemplates(s)
}

```
接下来，新建一个template.go文件：



```go
type TemplateSrv interface {
    Create(ctx context.Context, template *v1.Template, opts metav1.CreateOptions) error
    // Other methods
}

type templateService struct {
    store store.Factory
}

var _ TemplateSrv = (*templateService)(nil)

func newTemplates(srv *service) *TemplateService {
    // more create logic
    return &templateService{store: srv.store}
}

func (u *templateService) Create(ctx context.Context, template *v1.Template, opts metav1.CreateOptions) error {
    // normal code

    return nil
}
```
可以看到，我们通过以下三步新增了一个业务层对象：
1. 在Service接口定义中，新增了一个入口：Templates() TemplateSrv。
2. 在service.go文件中，新增了一个函数：Templates()。
3. 新建了template.go文件，在template.go中定义了 templateService 结构体，并为它实现了TemplateSrv接口。

可以看到，我们新增的 Template 业务对象的代码几乎都闭环在template.go文件中。对已有的Service工厂接口的创建方法，除了新增一个工厂方法Templates() TemplateSrv外，没有其他任何入侵。这样做可以避免影响已有业务。


在实际项目开发中，你也有可能会想到下面这种错误的创建方式：



```go
// 错误方法一
type Service interface {
    UserSrv
    SecretSrv
    PolicySrv
    TemplateSrv
}
```
上面的创建方式中，我们如果想创建 User 和 Secret，那只能定义两个不同的方法：CreateUser 和 CreateSecret，远没有在 User 和 Secret 各自的域中提供同名的 Create 方法来得优雅。IAM 项目中还有其他地方也使用了工厂方法模式，例如[Factory](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/store.go#L12)工厂接口。

再来看下**业务层和仓库层是如何通信的**。业务层和仓库层也是通过接口来通信的。例如，在业务层中创建密钥的代码如下：


```go
func (s *secretService) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {
    if err := s.store.Secrets().Create(ctx, secret, opts); err != nil {
        return errors.WithCode(code.ErrDatabase, err.Error())
    }

    return nil
}
```
Create方法中调用了s.store.Secrets().Create()方法来将密钥保存到数据库中。s.store是一个接口类型，定义如下：


```go
type Factory interface {
    Users() UserStore
    Secrets() SecretStore
    Policies() PolicyStore
    Close() error
}
```
业务层与仓库层的通信实现，和控制层与业务层的通信实现类似，所以这里不再详细介绍。到这里我们知道了，控制层、业务层和仓库层之间是通过接口来通信的。通过接口通信有一个好处，就是可以让各层变得可测。那接下来，我们就来看下如何测试各层的代码。因为第 38 讲和第 39 讲会详细介绍**如何测试 Go 代码**，所以这里只介绍下测试思路。


模型层
因为模型层不依赖其他任何层，我们只需要测试其中定义的结构及其函数和方法即可。


控制层
控制层依赖于业务层，意味着该层需要业务层来支持测试。你可以通过golang/mock来 mock 业务层，测试用例可参考[TestUserController_Create](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/controller/v1/user/create_test.go#L19)。


业务层
因为该层依赖于仓库层，意味着该层需要仓库层来支持测试。我们有两种方法来模拟仓库层：通过golang/mock来 mock 仓库层。自己开发一个 fake 仓库层。


使用golang/mock的测试用例，你可以参考[Test_secretService_Create](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/service/v1/secret_test.go#L19)。fake 的仓库层可以参考[fake](https://github.com/marmotedu/iam/tree/v1.0.4/internal/apiserver/store/fake)，使用该 fake 仓库层进行测试的测试用例为 [Test_userService_List](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/service/v1/user_test.go#L76)。


仓库层
仓库层依赖于数据库，如果调用了其他微服务，那还会依赖第三方服务。我们可以通过sqlmock来模拟数据库连接，通过httpmock来模拟 HTTP 请求。


### 总结
这一讲，我主要介绍了 iam-apiserver 的功能和使用方法，以及它的代码实现。iam-apiserver 是一个 Web 服务，提供了 REST API 来完成用户、密钥、策略三种 REST 资源的增删改查。我们可以通过 cURL、Insomnia 等工具，来完成 REST API 请求。


iam-apiserver 包含了 3 种配置：Options 配置、应用配置、HTTP/GRPC 服务配置。这三种配置分别用来构建命令行参数、应用和 HTTP/GRPC 服务。


iam-apiserver 在启动时，会先构建应用框架，接着会设置应用选项，然后对应用进行初始化，最后创建 HTTP/GRPC 服务的配置和实例，最终启动 HTTP/GRPC 服务。服务启动之后，就可以接收 HTTP 请求了。一个 HTTP 请求会先进行认证，接着会被注册的中间件处理，然后，会根据(HTTP Method, HTTP Request Path)匹配到处理函数。在处理函数中，会解析请求参数、校验参数、调用业务逻辑处理函数，最终返回请求结果。


iam-apiserver 采用了简洁架构，整个应用分为 4 层：模型层、控制层、业务层和仓库层。模型层存储对象的结构和它的方法；仓库层用来跟数据库 / 第三方服务进行 CURD 交互；业务层主要用来完成业务逻辑处理；控制层接收 HTTP 请求，并进行参数解析、参数校验、逻辑分发处理、请求返回操作。控制层、业务层、仓库层之间通过接口通信，通过接口通信可以使相同的功能支持不同的实现，并使每一层的代码变得可测试。

## 29｜控制流（下）：iam-apiserver服务核心功能实现讲解
上一讲，我介绍了 iam-apiserver 是如何构建 Web 服务的。这一讲，我们再来看下 iam-apiserver 中的核心功能实现。在对这些核心功能的讲解中，我会向你传达我的程序设计思路。


iam-apiserver 中包含了很多优秀的设计思想和实现，这些点可能比较零碎，但我觉得很值得分享给你。我将这些关键代码设计分为 3 类，分别是**应用框架相关的特性、编程规范相关的特性和其他特性**。接下来，我们就来详细看看这些设计点，以及它们背后的设计思想。


### 应用框架相关的特性
应用框架相关的特性包括三个，分别是优雅关停、健康检查和插件化加载中间件。


#### 优雅关停
在讲优雅关停之前，先来看看不优雅的停止服务方式是什么样的。当我们需要重启服务时，首先需要停止服务，这时可以通过两种方式来停止我们的服务：

- 在 Linux 终端键入 Ctrl + C（其实是发送 SIGINT 信号）。
- 发送 SIGTERM 信号，例如 kill 或者 systemctl stop 等。



当我们使用以上两种方式停止服务时，都会产生下面两个问题：


- 有些请求正在处理，如果服务端直接退出，会造成客户端连接中断，请求失败。
- 我们的程序可能需要做一些清理工作，比如等待进程内任务队列的任务执行完成，或者拒绝接受新的消息等。

这些问题都会对业务造成影响，所以我们需要一种优雅的方式来关停我们的应用。在 Go 开发中，通常通过拦截 SIGINT 和 SIGTERM 信号，来实现优雅关停。当收到这两个信号时，应用进程会做一些清理工作，然后结束阻塞状态，继续执行余下的代码，最后自然退出进程。

先来看一个简单的优雅关停的示例代码：

```go
package main

import (
    "context"
    "log"
    "net/http"
    "os"
    "os/signal"
    "time"

    "github.com/gin-gonic/gin"
)

func main() {
    router := gin.Default()
    router.GET("/", func(c *gin.Context) {
        time.Sleep(5 * time.Second)
        c.String(http.StatusOK, "Welcome Gin Server")
    })

    srv := &http.Server{
        Addr:    ":8080",
        Handler: router,
    }

    go func() {
        // 将服务在 goroutine 中启动
        if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatalf("listen: %s\n", err)
        }
    }()

    quit := make(chan os.Signal)
    signal.Notify(quit, os.Interrupt)
    <-quit // 阻塞等待接收 channel 数据
    log.Println("Shutdown Server ...")

    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) // 5s 缓冲时间处理已有请求
    defer cancel()
    if err := srv.Shutdown(ctx); err != nil { // 调用 net/http 包提供的优雅关闭函数：Shutdown
        log.Fatal("Server Shutdown:", err)
    }
    log.Println("Server exiting")
}

```
上面的代码实现优雅关停的思路如下：
1. 将 HTTP 服务放在 goroutine 中运行，程序不阻塞，继续执行。
2. 创建一个无缓冲的 channel quit，调用 signal.Notify(quit, os.Interrupt)。通过 signal.Notify 函数调用，可以将进程收到的 os.Interrupt（SIGINT）信号，发送给 channel quit。
3. <-quit 阻塞当前 goroutine（也就是 main 函数所在的 goroutine），等待从 channel quit 接收关停信号。通过以上步骤，我们成功启动了 HTTP 服务，并且 main 函数阻塞，防止启动 HTTP 服务的 goroutine 退出。当我们键入 Ctrl + C时，进程会收到 SIGINT 信号，并将该信号发送到 channel quit 中，这时候<-quit收到了 channel 另一端传来的数据，结束阻塞状态，程序继续执行。这里，<-quit唯一目的是阻塞当前的 goroutine，所以对收到的数据直接丢弃。
4. 打印退出消息，提示准备退出当前服务。
5. 调用 net/http 包提供的 Shutdown 方法，Shutdown 方法会在指定的时间内处理完现有请求，并返回。
6. 最后，程序执行完 log.Println("Server exiting") 代码后，退出 main 函数。


iam-apiserver 也实现了优雅关停，优雅关停思路跟上面的代码类似。具体可以分为三个步骤，流程如下：

第一步，创建 channel 用来接收 os.Interrupt（SIGINT）和 syscall.SIGTERM（SIGKILL）信号。代码见 internal/pkg/server/signal.go 。


```go
var onlyOneSignalHandler = make(chan struct{})

var shutdownHandler chan os.Signal

func SetupSignalHandler() <-chan struct{} {
    close(onlyOneSignalHandler) // panics when called twice

    shutdownHandler = make(chan os.Signal, 2)

    stop := make(chan struct{})

    signal.Notify(shutdownHandler, shutdownSignals...)

    go func() {
        <-shutdownHandler
        close(stop)
        <-shutdownHandler
        os.Exit(1) // second signal. Exit directly.
    }()

    return stop
}
```
SetupSignalHandler 函数中，通过 close(onlyOneSignalHandler)来确保 iam-apiserver 组件的代码只调用一次 SetupSignalHandler 函数。否则，可能会因为信号传给了不同的 shutdownHandler，而造成信号丢失。SetupSignalHandler 函数还实现了一个功能：收到一次 SIGINT/ SIGTERM 信号，程序优雅关闭。收到两次 SIGINT/ SIGTERM 信号，程序强制关闭。实现代码如下：

```go
go func() {
    <-shutdownHandler
    close(stop)
    <-shutdownHandler
    os.Exit(1) // second signal. Exit directly.
}()
```
这里要注意：signal.Notify(c chan<- os.Signal, sig ...os.Signal)函数不会为了向 c 发送信息而阻塞。也就是说，如果发送时 c 阻塞了，signal 包会直接丢弃信号。为了不丢失信号，我们创建了有缓冲的 channel shutdownHandler。最后，SetupSignalHandler 函数会返回 stop，后面的代码可以通过关闭 stop 来结束代码的阻塞状态。



第二步，将 channel stop 传递给启动 HTTP（S）、gRPC 服务的函数，在函数中以 goroutine 的方式启动 HTTP（S）、gRPC 服务，然后执行 <-stop 阻塞 goroutine。


第三步，当 iam-apiserver 进程收到 SIGINT/SIGTERM 信号后，关闭 stop channel，继续执行 <-stop 后的代码，在后面的代码中，我们可以执行一些清理逻辑，或者调用 google.golang.org/grpc和 net/http包提供的优雅关停函数 GracefulStop 和 Shutdown。例如下面这个代码（位于 internal/apiserver/grpc.go 文件中）：


```go
func (s *grpcAPIServer) Run(stopCh <-chan struct{}) {
    listen, err := net.Listen("tcp", s.address)
    if err != nil {
        log.Fatalf("failed to listen: %s", err.Error())
    }

    log.Infof("Start grpc server at %s", s.address)

    go func() {
        if err := s.Serve(listen); err != nil {
            log.Fatalf("failed to start grpc server: %s", err.Error())
        }
    }()

    <-stopCh

    log.Infof("Grpc server on %s stopped", s.address)
    s.GracefulStop()
}
```
除了上面说的方法，iam-apiserver 还通过 github.com/marmotedu/iam/pkg/shutdown 包，实现了另外一种优雅关停方法，这个方法更加友好、更加灵活。实现代码见 [PrepareRun](https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/server.go#L81) 函数。github.com/marmotedu/iam/pkg/shutdown 包的使用方法如下：


```go
package main
import (
  "fmt"
  "time"
  "github.com/marmotedu/iam/pkg/shutdown"
  "github.com/marmotedu/iam/pkg/shutdown/shutdownmanagers/posixsignal"
)
func main() {
  // initialize shutdown
  gs := shutdown.New()
  // add posix shutdown manager
  gs.AddShutdownManager(posixsignal.NewPosixSignalManager())
  // add your tasks that implement ShutdownCallback
  gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {
    fmt.Println("Shutdown callback start")
    time.Sleep(time.Second)
    fmt.Println("Shutdown callback finished")
    return nil
  }))
  // start shutdown managers
  if err := gs.Start(); err != nil {
    fmt.Println("Start:", err)
    return
  }
  // do other stuff
  time.Sleep(time.Hour)
}
```
上面的代码中，通过 gs := shutdown.New() 创建 shutdown 实例；通过 AddShutdownManager 方法添加监听的信号；通过 AddShutdownCallback 方法设置监听到指定信号时，需要执行的回调函数。这些回调函数可以执行一些清理工作。最后，通过 Start 方法启动 shutdown 实例。


#### 健康检查
通常，我们会根据进程是否存在来判定 iam-apiserver 是否健康，例如执行 ps -ef|grep iam-apiserver。在实际开发中，我发现有时候服务进程仍然存在，但是 HTTP 服务却不能接收和处理请求，所以更加靠谱的检查方法是，直接请求 iam-apiserver 的健康检查接口。



我们可以在启动 iam-apiserver 进程后，手动调用 iam-apiserver 健康检查接口进行检查。但还有更方便的方法：启动服务后自动调用健康检查接口。这个方法的具体实现，你可以查看 GenericAPIServer 提供的 ping 方法。在 [ping](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/server/genericapiserver.go#L219) 方法中，你需要注意函数中的如下代码：


```go
url := fmt.Sprintf("http://%s/healthz", s.InsecureServingInfo.Address)
if strings.Contains(s.InsecureServingInfo.Address, "0.0.0.0") {
    url = fmt.Sprintf("http://127.0.0.1:%s/healthz", strings.Split(s.InsecureServingInfo.Address, ":")[1])
}
```
当 HTTP 服务监听在所有网卡时，请求 IP 为 127.0.0.1；当 HTTP 服务监听在指定网卡时，我们需要请求该网卡的 IP 地址。


#### 插件化加载中间件
iam-apiserver 支持插件化地加载 Gin 中间件，通过这种插件机制，我们可以根据需要选择中间件。


那么，为什么要将中间件做成一种插件化的机制呢？一方面，每个中间件都完成某种功能，这些功能不是所有情况下都需要的；另一方面，中间件是追加在 HTTP 请求链路上的一个处理函数，会影响 API 接口的性能。为了保证 API 接口的性能，我们也需要选择性地加载中间件。



例如，在测试环境中为了方便 Debug，可以选择加载 dump 中间件。dump 中间件可以打印请求包和返回包信息，这些信息可以协助我们 Debug。但是在现网环境中，我们不需要 dump 中间件来协助 Debug，而且如果加载了 dump 中间件，请求时会打印大量的请求信息，严重影响 API 接口的性能。这时候，我们就期望中间件能够按需加载。

iam-apiserver 通过 InstallMiddlewares 函数来安装 Gin 中间件，函数代码如下：


```go
func (s *GenericAPIServer) InstallMiddlewares() {
    // necessary middlewares
    s.Use(middleware.RequestID())
    s.Use(middleware.Context())

    // install custom middlewares
    for _, m := range s.middlewares {
        mw, ok := middleware.Middlewares[m]
        if !ok {
            log.Warnf("can not find middleware: %s", m)

            continue
        }

        log.Infof("install middleware: %s", m)
        s.Use(mw)
    }
}
```
可以看到，安装中间件时，我们不仅安装了一些必备的中间件，还安装了一些可配置的中间件。上述代码安装了两个默认的中间件： [RequestID](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go#L22) 和 [Context](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/context.go#L17) 。


RequestID 中间件，主要用来在 HTTP 请求头和返回头中设置 X-Request-ID Header。如果 HTTP 请求头中没有 X-Request-ID HTTP 头，则创建 64 位的 UUID，如果有就复用。UUID 是调用 github.com/satori/go.uuid包提供的 NewV4().String()方法来生成的：

```go
rid = uuid.NewV4().String()
```
另外，这里有个 Go 常量的设计规范需要你注意：常量要跟该常量相关的功能包放在一起，不要将一个项目的常量都集中放在 const 这类包中。例如， [requestid.go](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go) 文件中，我们定义了 XRequestIDKey = "X-Request-ID"常量，其他地方如果需要使用 XRequestIDKey，只需要引入 XRequestIDKey所在的包，并使用即可。


Context 中间件，用来在 gin.Context 中设置 requestID和 username键，在打印日志时，将 gin.Context 类型的变量传递给 log.L() 函数，log.L() 函数会在日志输出中输出 requestID和 username域：

```
2021-07-09 13:33:21.362 DEBUG   apiserver       v1/user.go:106  get 2 users from backend storage.       {"requestID": "f8477cf5-4592-4e47-bdcf-82f7bde2e2d0", "username": "admin"}
```
requestID和 username字段可以方便我们后期过滤并查看日志。除了默认的中间件，iam-apiserver 还支持一些可配置的中间件，我们可以通过配置 iam-apiserver 配置文件中的 server.middlewares 配置项，来配置这些这些中间件。


可配置以下中间件：
- recovery：捕获任何 panic，并恢复。
- secure：添加一些安全和资源访问相关的 HTTP 头。
- nocache：禁止客户端缓存 HTTP 请求的返回结果。
- cors：HTTP 请求跨域中间件。
- dump：打印出 HTTP 请求包和返回包的内容，方便 debug。注意，生产环境禁止加载该中间件。


当然，你还可以根据需要，添加更多的中间件。方法很简单，只需要编写中间件，并将中间件添加到一个 map[string]gin.HandlerFunc 类型的变量中即可：


```go
func defaultMiddlewares() map[string]gin.HandlerFunc {      
    return map[string]gin.HandlerFunc{                          
        "recovery":  gin.Recovery(),                            
        "secure":    Secure,                                
        "options":   Options,             
        "nocache":   NoCache,             
        "cors":      Cors(),                        
        "requestid": RequestID(),                       
        "logger":    Logger(),                                                           
        "dump":      gindump.Dump(),                                                               
    }                                                                                              
}  

```
上述代码位于 internal/pkg/middleware/middleware.go 文件中。


### 编程规范相关的特性
编程规范相关的特性有四个，分别是 API 版本、统一的资源元数据、统一的返回、并发处理模板。


#### API 版本
RESTful API 为了方便以后扩展，都需要支持 API 版本。在 12 讲 中，我们介绍了 API 版本号的 3 种标识方法，iam-apiserver 选择了将 API 版本号放在 URL 中，例如/v1/secrets。放在 URL 中的好处是很直观，看 API 路径就知道版本号。另外，API 的路径也可以很好地跟控制层、业务层、模型层的代码路径相映射。例如，密钥资源相关的代码存放位置如下：


```
internal/apiserver/controller/v1/secret/  # 控制几层代码存放位置
internal/apiserver/service/v1/secret.go # 业务层代码存放位置
github.com/marmotedu/api/apiserver/v1/secret.go # 模型层代码存放位置
```
关于代码存放路径，我还有一些地方想跟你分享。对于 Secret 资源，通常我们需要提供 CRUD 接口。

C：Create（创建 Secret）。R：Get（获取详情）、List（获取 Secret 资源列表）。U：Update（更新 Secret）。D：Delete（删除指定的 Secret）、DeleteCollection（批量删除 Secret）。


每个接口相互独立，为了减少更新 A 接口代码时因为误操作影响到 B 接口代码的情况，这里建议 CRUD 接口每个接口一个文件，从物理上将不同接口的代码隔离开。这种接口还可以方便我们查找 A 接口的代码所在位置。例如，Secret 控制层相关代码的存放方式如下：


```
$ ls internal/apiserver/controller/v1/secret/
create.go  delete_collection.go  delete.go  doc.go  get.go  list.go  secret.go  update.go
```
业务层和模型层的代码也可以这么组织。iam-apiserver 中，因为 Secret 的业务层和模型层代码比较少，所以我放在了 internal/apiserver/service/v1/secret.go和 github.com/marmotedu/api/apiserver/v1/secret.go文件中。如果后期 Secret 业务代码增多，我们也可以修改成下面这种方式：


```
 $ ls internal/apiserver/service/v1/secret/
 create.go  delete_collection.go  delete.go  doc.go  get.go  list.go  secret.go  update.go
```
这里再说个题外话：/v1/secret/和/secret/v1/这两种目录组织方式都可以，你选择一个自己喜欢的就行。当我们需要升级 API 版本时，相关代码可以直接放在 v2 目录下，例如：

```
internal/apiserver/controller/v2/secret/ # v2 版本控制几层代码存放位置
internal/apiserver/service/v2/secret.go # v2 版本业务层代码存放位置
github.com/marmotedu/api/apiserver/v2/secret.go # v2 版本模型层代码存放位置
```
这样既能够跟 v1 版本的代码物理隔离开，互不影响，又方便查找 v2 版本的代码。


#### 统一的资源元数据
iam-apiserver 设计的一大亮点是，像 Kubernetes REST 资源一样，支持统一的资源元数据。

iam-apiserver 中所有的资源都是 REST 资源，iam-apiserver 将 REST 资源的属性也进一步规范化了，这里的规范化是指所有的 REST 资源均支持两种属性：公共属性。资源自有的属性。



例如，Secret 资源的定义方式如下：


```go
type Secret struct {
    // May add TypeMeta in the future.
    // metav1.TypeMeta `json:",inline"`

    // Standard object's metadata.
    metav1.ObjectMeta `       json:"metadata,omitempty"`
    Username          string `json:"username"           gorm:"column:username"  validate:"omitempty"`
    SecretID          string `json:"secretID"           gorm:"column:secretID"  validate:"omitempty"`
    SecretKey         string `json:"secretKey"          gorm:"column:secretKey" validate:"omitempty"`

    // Required: true
    Expires     int64  `json:"expires"     gorm:"column:expires"     validate:"omitempty"`
    Description string `json:"description" gorm:"column:description" validate:"description"`
}
```
资源自有的属性，会因资源不同而不同。这里，我们来重点看一下公共属性 ObjectMeta ，它的定义如下：

```
type ObjectMeta struct {
  ID uint64 `json:"id,omitempty" gorm:"primary_key;AUTO_INCREMENT;column:id"`
  InstanceID string `json:"instanceID,omitempty" gorm:"unique;column:instanceID;type:varchar(32);not null"`
  Name string `json:"name,omitempty" gorm:"column:name;type:varchar(64);not null" validate:"name"`
  Extend Extend `json:"extend,omitempty" gorm:"-" validate:"omitempty"`
  ExtendShadow string `json:"-" gorm:"column:extendShadow" validate:"omitempty"`
  CreatedAt time.Time `json:"createdAt,omitempty" gorm:"column:createdAt"`
  UpdatedAt time.Time `json:"updatedAt,omitempty" gorm:"column:updatedAt"`
}
```
接下来，我来详细介绍公共属性中每个字段的含义及作用。


ID
这里的 ID，映射为 MariaDB 数据库中的 id 字段。id 字段在一些应用中，会作为资源的唯一标识。但 iam-apiserver 中没有使用 ID 作为资源的唯一标识，而是使用了 InstanceID。iam-apiserver 中 ID 唯一的作用是跟数据库 id 字段进行映射，代码中并没有使用到 ID。

InstanceID
InstanceID 是资源的唯一标识，格式为-xxxxxx。其中，是资源的英文标识符号，xxxxxx是随机字符串。字符集合为 abcdefghijklmnopqrstuvwxyz1234567890，长度 >=6，例如 secret-yj8m30、user-j4lz3g、policy-3v18jq。


**腾讯云、阿里云、华为云也都是采用这种格式的字符串作为资源唯一标识的。**InstanceID 的生成和更新都是自动化的，通过 gorm 提供的 AfterCreate Hooks 在记录插入数据库之后，生成并更新到数据库的 instanceID字段：

```go
func (s *Secret) AfterCreate(tx *gorm.DB) (err error) {
    s.InstanceID = idutil.GetInstanceID(s.ID, "secret-")

    return tx.Save(s).Error
}
```
上面的代码，在 Secret 记录插入到 iam 数据库的 secret 表之后，调用 idutil.GetInstanceID生成 InstanceID，并通过 tx.Save(s)更新到数据库 secret 表的 instanceID字段。


因为通常情况下，应用中的 REST 资源只会保存到数据库中的一张表里，这样就能保证应用中每个资源的数据库 ID 是唯一的。所以 GetInstanceID(uid uint64, prefix string) string函数使用 github.com/speps/go-hashids包提供的方法，对这个数据库 ID 进行哈希，最终得到一个数据库级别的唯一的字符串（例如：3v18jq），并根据传入的 prefix，得到资源的 InstanceID。


使用这种方式生成资源的唯一标识，有下面这两个优点：
- 数据库级别唯一。
- InstanceID 是长度可控的字符串，长度最小是 6 个字符，但会根据表中的记录个数动态变长。根据我的测试，2176782336 条记录以内生成的 InstanceID 长度都在 6 个字符以内。长度可控的另外一个好处是方便记忆和传播。


这里需要你注意：如果同一个资源分别存放在不同的表中，那在使用这种方式时，生成的 InstanceID 可能相同，不过概率很小，几乎为零。这时候，我们就需要使用分布式 ID 生成技术。这又是另外一个话题了，这里不再扩展讲解。

在实际的开发中，不少开发者会使用数据库数字段 ID（例如 121）和 36/64 位的 UUID（例如 20cd59d4-08c6-4e86-a9d4-a0e51c420a04 ）来作为资源的唯一标识。相较于这两种资源标识方式，使用-xxxxxx这种标识方式具有以下优点：
- 看标识名就知道是什么类型的资源，例如：secret-yj8m30说明该资源是 secret 类型的资源。在实际的排障过程中，能够有效减少误操作。
- 长度可控，占用数据库空间小。iam-apiserver 的资源标识长度基本可以认为是 12 个字符（secret/policy 是 6 个字符，再加 6 位随机字符）。
- 如果使用 121 这类数值作为资源唯一标识，相当于间接向友商透漏系统的规模，是一定要禁止的。

另外，还有一些系统如 Kubernetes 中，使用资源名作为资源唯一标识。这种方式有个弊端，就是当系统中同类资源太多时，创建资源很容易重名，你自己想要的名字往往填不了，所以 iam-apiserver 不采用这种设计方式。

我们使用 instanceID 来作为资源的唯一标识，在代码中，就经常需要根据 instanceID 来查询资源。所以，在数据库中要设置该字段为唯一索引，一方面可以防止 instanceID 不唯一，另一方面也能加快查询速度。



Name
Name 即资源的名字，我们可以通过名字很容易地辨别一个资源。


Extend、ExtendShadow
**Extend 和 ExtendShadow 是 iam-apiserver 设计的又一大亮点。**

在实际开发中，我们经常会遇到这个问题：随着业务发展，某个资源需要增加一些属性，这时，我们可能会选择在数据库中新增一个数据库字段。但是，随着业务系统的演进，数据库中的字段越来越多，我们的 Code 也要做适配，最后就会越来越难维护。


我们还可能遇到这种情况：我们将上面说的字段保存在数据库中叫 meta的字段中，数据库中 meta字段的数据格式是{"disable":true,"tag":"colin"}。但是，我们如果想在代码中使用这些字段，需要 Unmarshal 到一个结构体中，例如：


```go
metaData := `{"disable":true,"tag":"colin"}`
meta := make(map[string]interface{})
if err := json.Unmarshal([]byte(metaData), &meta); err != nil {
    return err
}
```
再存入数据中时，又要 Marshal 成 JSON 格式的字符串，例如：


```go
meta := map[string]interface{}{"disable": true, "tag": "colin"}
data, err := json.Marshal(meta)
if err != nil {
    return err
}
```
你可以看到，这种 Unmarshal 和 Marshal 操作有点繁琐。


因为每个资源都可能需要用到扩展字段，那么有没有一种通用的解决方案呢？iam-apiserver 就通过 Extend 和 ExtendShadow 解决了这个问题。


Extend 是 Extend 类型的字段，Extend 类型其实是 map[string]interface{}的类型别名。在程序中，我们可以很方便地引用 Extend 包含的属性，也就是 map 的 key。Extend 字段在保存到数据库中时，会自动 Marshal 成字符串，保存在 ExtendShadow 字段中。


ExtendShadow 是 Extend 在数据库中的影子。同样，当从数据库查询数据时，ExtendShadow 的值会自动 Unmarshal 到 Extend 类型的变量中，供程序使用。具体实现方式如下：

- 借助 gorm 提供的 BeforeCreate、BeforeUpdate Hooks，在插入记录、更新记录时，将 Extend 的值转换成字符串，保存在 ExtendShadow 字段中，并最终保存在数据库的 ExtendShadow 字段中。
- 借助 gorm 提供的 AfterFind Hooks，在查询数据后，将 ExtendShadow 的值 Unmarshal 到 Extend 字段中，之后程序就可以通过 Extend 字段来使用其中的属性。


CreatedAt
资源的创建时间。每个资源在创建时，我们都应该记录资源的创建时间，可以帮助后期进行排障、分析等。


UpdatedAt
资源的更新时间。每个资源在更新时，我们都应该记录资源的更新时间。资源更新时，该字段由 gorm 自动更新。可以看到，ObjectMeta 结构体包含了很多字段，每个字段都完成了很酷的功能。那么，如果把 ObjectMeta 作为所有资源的公共属性，这些资源就会自带这些能力。


当然，有些开发者可能会说，User 资源其实是不需要 user-xxxxxx这种资源标识的，所以 InstanceID 这个字段其实是无用的字段。但是在我看来，和功能冗余相比，功能规范化、不重复造轮子，以及 ObjectMeta 的其他功能更加重要。所以，也建议所有的 REST 资源都使用统一的资源元数据。


#### 统一的返回
在18 讲 中，我们介绍过 API 的接口返回格式应该是统一的。要想返回一个固定格式的消息，最好的方式就是使用同一个返回函数。因为 API 接口都是通过同一个函数来返回的，其返回格式自然是统一的。


IAM 项目通过 github.com/marmotedu/component-base/pkg/core 包提供的 WriteResponse 函数来返回结果。WriteResponse 函数定义如下：

```go
func WriteResponse(c *gin.Context, err error, data interface{}) {
    if err != nil {
        log.Errorf("%#+v", err)
        coder := errors.ParseCoder(err)
        c.JSON(coder.HTTPStatus(), ErrResponse{
            Code:      coder.Code(),
            Message:   coder.String(),
            Reference: coder.Reference(),
        })

        return
    }

    c.JSON(http.StatusOK, data)
}
```
可以看到，WriteResponse 函数会判断 err 是否为 nil。如果不为 nil，则将 err 解析为 github.com/marmotedu/errors包中定义的 Coder 类型的错误，并调用 Coder 接口提供的 Code() 、String() 、Reference() 方法，获取该错误的业务码、对外展示的错误信息和排障文档。如果 err 为 nil，则调用 c.JSON返回 JSON 格式的数据。

#### 并发处理模板
在 Go 项目开发中，经常会遇到这样一种场景：查询列表接口时，查询出了多条记录，但是需要针对每一条记录做一些其他逻辑处理。因为是多条记录，比如 100 条，处理每条记录延时如果为 X 毫秒，串行处理完 100 条记录，整体延时就是 100 * X 毫秒。如果 X 比较大，那整体处理完的延时是非常高的，会严重影响 API 接口的性能。


这时候，我们自然就会想到利用 CPU 的多核能力，并发来处理这 100 条记录。这种场景我们在实际开发中经常遇到，有必要抽象成一个并发处理模板，这样以后在查询时，就可以使用这个模板了。例如，iam-apiserver 中，查询用户列表接口 List ，还需要返回每个用户所拥有的策略个数。这就用到了并发处理。这里，我试着将其抽象成一个模板，模板如下：


```go
func (u *userService) List(ctx context.Context, opts metav1.ListOptions) (*v1.UserList, error) {
  users, err := u.store.Users().List(ctx, opts)
  if err != nil {
    log.L(ctx).Errorf("list users from storage failed: %s", err.Error())

    return nil, errors.WithCode(code.ErrDatabase, err.Error())
  }

  wg := sync.WaitGroup{}
  errChan := make(chan error, 1)
  finished := make(chan bool, 1)

  var m sync.Map

  // Improve query efficiency in parallel
  for _, user := range users.Items {
    wg.Add(1)

    go func(user *v1.User) {
      defer wg.Done()

            // some cost time process
      policies, err := u.store.Policies().List(ctx, user.Name, metav1.ListOptions{})
      if err != nil {
        errChan <- errors.WithCode(code.ErrDatabase, err.Error())

        return
      }

      m.Store(user.ID, &v1.User{
                ...
        Phone:       user.Phone,
        TotalPolicy: policies.TotalCount,
      })
    }(user)
  }

  go func() {
    wg.Wait()
    close(finished)
  }()

  select {
  case <-finished:
  case err := <-errChan:
    return nil, err
  }

  // infos := make([]*v1.User, 0)
  infos := make([]*v1.User, 0, len(users.Items))
  for _, user := range users.Items {
    info, _ := m.Load(user.ID)
    infos = append(infos, info.(*v1.User))
  }

  log.L(ctx).Debugf("get %d users from backend storage.", len(infos))

  return &v1.UserList{ListMeta: users.ListMeta, Items: infos}, nil
}
```
在上面的并发模板中，我实现了并发处理查询结果中的三个功能：


第一个功能，**goroutine 报错即返回**。goroutine 中代码段报错时，会将错误信息写入 errChan中。我们通过 List 函数中的 select 语句，实现只要有一个 goroutine 发生错误，即返回：


```go
select {
case <-finished:
case err := <-errChan:
    return nil, err
}
```
第二个功能，**保持查询顺序**。我们从数据库查询出的列表是有顺序的，比如默认按数据库 ID 字段升序排列，或者我们指定的其他排序方法。在并发处理中，这些顺序会被打断。但为了确保最终返回的结果跟我们预期的排序效果一样，在并发模板中，我们还需要保证最终返回结果跟查询结果保持一致的排序。上面的模板中，我们将处理后的记录保存在 map 中，map 的 key 为数据库 ID。并且，在最后按照查询的 ID 顺序，依次从 map 中取出 ID 的记录，例如：



```go
    var m sync.Map
  for _, user := range users.Items {
        ...
    go func(user *v1.User) {
            ...
      m.Store(user.ID, &v1.User{})
    }(user)
  }
    ...
  infos := make([]*v1.User, 0, len(users.Items))
  for _, user := range users.Items {
    info, _ := m.Load(user.ID)
    infos = append(infos, info.(*v1.User))
  }
```
通过上面这种方式，可以确保最终返回的结果跟从数据库中查询的结果保持一致的排序。



第三个功能，**并发安全**。Go 语言中的 map 不是并发安全的，要想实现并发安全，需要自己实现（如加锁），或者使用 sync.Map。上面的模板使用了 sync.Map。


当然了，如果期望 List 接口能在期望时间内返回，还可以添加超时机制，例如：


```go
    select {
    case <-finished:
    case err := <-errChan:
        return nil, err
    case <-time.After(time.Duration(30 * time.Second)):
        return nil, fmt.Errorf("list users timeout after 30 seconds")

    }
```
goroutine 虽然很轻量，但还是会消耗资源，如果我们需要处理几百上千的并发，就需要用协程池来复用协程，达到节省资源的目的。有很多优秀的协程包可供我们直接使用，比如 ants 、 tunny 等。


### 其他特性
除了上面那两大类，这里我还想给你介绍下关键代码设计中的其他特性，包括插件化选择 JSON 库、调用链实现、数据一致性。


#### 插件化选择 JSON 库
Golang 提供的标准 JSON 解析库 encoding/json，在开发高性能、高并发的网络服务时会产生性能问题。所以很多开发者在实际的开发中，往往会选用第三方的高性能 JSON 解析库，例如 jsoniter 、 easyjson 、 jsonparser 等。


我见过的很多开发者选择了 jsoniter，也有一些开发者使用了 easyjson。jsoniter 的性能略高于 encoding/json。但随着 go 版本的迭代，encoding/json 库的性能也越来越高，jsoniter 的性能优势也越来越有限。所以，IAM 项目使用了 jsoniter 库，并准备随时切回 encoding/json 库。

为了方便切换不同的 JSON 包，iam-apiserver 采用了一种插件化的机制来使用不同的 JSON 包。具体是通过使用 go 的标签编译选择运行的解析库来实现的。


标签编译就是在源代码里添加标注，通常称之为编译标签（build tag）。编译标签通过注释的方式在靠近源代码文件顶部的地方添加。go build 在构建一个包的时候，会读取这个包里的每个源文件并且分析编译便签，这些标签决定了这个源文件是否参与本次编译。例如：



```go
// +build jsoniter

package json

import jsoniter "github.com/json-iterator/go"
```
+build jsoniter就是编译标签。这里要注意，一个源文件可以有多个编译标签，多个编译标签之间是逻辑“与”的关系；一个编译标签可以包括由空格分割的多个标签，这些标签是逻辑“或”的关系。例如：



```
// +build linux darwin
// +build 386
```
这里要注意，编译标签和包的声明之间应该使用空行隔开，否则编译标签会被当作包声明的注释，而不是编译标签。那具体来说，**我们是如何实现插件化选择 JSON 库的呢？**

首先，我自定义了一个 github.com/marmotedu/component-base/pkg/json json 包，来适配 encoding/json 和 json-iterator。github.com/marmotedu/component-base/pkg/json 包中有两个文件：


- json.go：映射了 encoding/json 包的 Marshal、Unmarshal、MarshalIndent、NewDecoder、NewEncoder 方法。
- jsoniter.go：映射了 github.com/json-iterator/go 包的 Marshal、Unmarshal、MarshalIndent、NewDecoder、NewEncoder。


json.go 和 jsoniter.go 通过编译标签，让 Go 编译器在构建代码时选择使用哪一个 json 文件。接着，通过在执行 go build时指定 [-tags](https://github.com/marmotedu/iam/blob/master/scripts/make-rules/golang.mk#L19) 参数，来选择编译哪个 json 文件。


json/json.go、json/jsoniter.go 这两个 Go 文件的顶部，都有一行注释：


```
// +build !jsoniter

// +build jsoniter
```
// +build !jsoniter表示，tags 不是 jsoniter 的时候编译这个 Go 文件。// +build jsoniter表示，tags 是 jsoniter 的时候编译这个 Go 文件。也就是说，这两种条件是互斥的，只有当 tags=jsoniter 的时候，才会使用 json-iterator，其他情况使用 encoding/json。

例如，如果我们想使用包，可以这么编译项目：


```
$ go build -tags=jsoniter
```
在实际开发中，**我们需要根据场景来选择合适的 JSON 库**。这里我给你一些建议。


场景一：结构体序列化和反序列化场景

在这个场景中，我个人首推的是官方的 JSON 库。可能你会比较意外，那我就来说说我的理由：

首先，虽然 easyjson 的性能压倒了其他所有开源项目，但它有一个最大的缺陷，那就是需要额外使用工具来生成这段代码，而对额外工具的版本控制就增加了运维成本。当然，如果你的团队已经能够很好地处理 protobuf 了，也是可以用同样的思路来管理 easyjson 的。其次，虽然 Go 1.8 之前，官方 JSON 库的性能总是被大家吐槽，但现在（1.16.3）官方 JSON 库的性能已不可同日而语。此外，作为使用最为广泛，而且没有之一的 JSON 库，官方库的 bug 是最少的，兼容性也是最好的最后，jsoniter 的性能虽然依然优于官方，但没有达到逆天的程度。如果你追求的是极致的性能，那么你应该选择 easyjson 而不是 jsoniter。jsoniter 近年已经不活跃了，比如说，我前段时间提了一个 issue 没人回复，于是就上去看了下 issue 列表，发现居然还遗留着一些 2018 年的 issue。


场景二：非结构化数据的序列化和反序列化场景


这个场景下，我们要分高数据利用率和低数据利用率两种情况来看。你可能对数据利用率的高低没啥概念，那我举个例子：JSON 数据的正文中，如果说超过四分之一的数据都是业务需要关注和处理的，那就算是高数据利用率。

在高数据利用率的情况下，我推荐使用 jsonvalue。至于低数据利用率的情况，还可以根据 JSON 数据是否需要重新序列化，分成两种情况。


如果无需重新序列化，这个时候选择 jsonparser 就行了，因为它的性能实在是耀眼。如果需要重新序列化，这种情况下你有两种选择：如果对性能要求相对较低，可以使用 jsonvalue；如果对性能的要求高，并且只需要往二进制序列中插入一条数据，那么可以采用 jsoniter 的 Set 方法。



实际操作中，超大 JSON 数据量，并且同时需要重新序列化的情况非常少，往往是在代理服务器、网关、overlay 中继服务等，同时又需要往原数据中注入额外信息的时候。换句话说，jsoniter 的适用场景比较有限。下面是从 10% 到 60% 数据覆盖率下，不同库的操作效率对比（纵坐标单位：μs/op）：


![img](https://static001.geekbang.org/resource/image/fc/a6/fcc79727a26a37345af705df1179c1a6.png?wh=1920x1266)

可以看到，当 jsoniter 的数据利用率达到 25% 时，和 jsonvalue、jsonparser 相比就已经没有任何优势；至于 jsonvalue，由于对数据做了一次性的全解析，因此解析后的数据存取耗时极少，因此在不同数据覆盖率下的耗时都很稳定。


#### 调用链实现
调用链对查日志、排障帮助非常大。所以，在 iam-apiserver 中也实现了调用链，通过 requestID来串联整个调用链。


具体是通过以下两步来实现的：第一步，将 ctx context.Context 类型的变量作为函数的第一个参数，在函数调用时传递。第二步，不同函数中，通过 log.L(ctx context.Context)来记录日志。


在请求到来时，请求会通过 [Context](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/context.go#L17) 中间件处理：


```go
func Context() gin.HandlerFunc {
  return func(c *gin.Context) {
    c.Set(log.KeyRequestID, c.GetString(XRequestIDKey))
    c.Set(log.KeyUsername, c.GetString(UsernameKey))
    c.Next()
  }
}
```
在 Context 中间件中，会在 gin.Context 类型的变量中设置 log.KeyRequestID键，其值为 36 位的 UUID。UUID 通过 [RequestID](https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go#L22) 中间件来生成，并设置在 gin 请求的 Context 中。


RequestID 中间件在 Context 中间件之前被加载，所以在 Context 中间件被执行时，能够获取到 RequestID 生成的 UUID。log.L(ctx context.Context)函数在记录日志时，会从头 ctx 中获取到 log.KeyRequestID，并作为一个附加字段随日志打印。

通过以上方式，我们最终可以形成 iam-apiserver 的请求调用链，日志示例如下：


```
2021-07-19 19:41:33.472 INFO    apiserver       apiserver/auth.go:205   user `admin` is authenticated.  {"requestID": "b6c56cd3-d095-4fd5-a928-291a2e33077f", "username": "admin"}
2021-07-19 19:41:33.472 INFO    apiserver       policy/create.go:22     create policy function called.  {"requestID": "b6c56cd3-d095-4fd5-a928-291a2e33077f", "username": "admin"}
...
```
另外，ctx context.Context作为函数 / 方法的第一个参数，还有一个好处是方便后期扩展。例如，如果我们有以下调用关系：


```go
package main

import "fmt"

func B(name, address string) string {
    return fmt.Sprintf("name: %s, address: %s", name, address)
}

func A() string {
    return B("colin", "sz")
}

func main() {
    fmt.Println(A())
}
```
上面的代码最终调用 B函数打印出用户名及其地址。如果随着业务的发展，希望 A 调用 B 时，传入用户的电话，B 中打印出用户的电话号码。这时候，我们可能会考虑给 B 函数增加一个电话号参数，例如：


```go
func B(name, address, phone string) string {
    return fmt.Sprintf("name: %s, address: %s, phone: %s", name, address)
}
```
如果我们后面还要增加年龄、性别等属性呢？按这种方式不断增加 B 函数的参数，不仅麻烦，而且还要改动所有调用 B 的函数，工作量也很大。这时候，可以考虑通过 ctx context.Context 来传递这些扩展参数，实现如下：


```go
package main

import (
    "context"
    "fmt"
)

func B(ctx context.Context, name, address string) string {
    return fmt.Sprintf("name: %s, address: %s, phone: %v", name, address, ctx.Value("phone"))
}

func A() string {
    ctx := context.WithValue(context.TODO(), "phone", "1812884xxxx")
    return B(ctx, "colin", "sz")
}

func main() {
    fmt.Println(A())
}
```
这样，我们下次需要新增参数的话，只需要调用 context 的 WithValue 方法：


```go
ctx = context.WithValue(ctx, "sex", "male")
```
在 B 函数中，通过 context.Context 类型的变量提供的 Value 方法，从 context 中获取 sex key 即可：


```go
return fmt.Sprintf("name: %s, address: %s, phone: %v, sex: %v", name, address, ctx.Value("phone"), ctx.Value("sex"))
```
#### 数据一致性
为了提高 iam-authz-server 的响应性能，我将密钥和授权策略信息缓存在 iam-authz-server 部署机器的内存中。同时，为了实现高可用，我们需要保证 iam-authz-server 启动的实例个数至少为两个。这时候，我们会面临数据一致性的问题：所有 iam-authz-server 缓存的数据要一致，并且跟 iam-apiserver 数据库中保存的一致。iam-apiserver 通过如下方式来实现数据一致性：


![img](https://static001.geekbang.org/resource/image/4c/b7/4ce0ff51e4cecb12f7234241137c20b7.jpg?wh=2248x798)

具体流程如下：



第一步，iam-authz-server 启动时，会通过 grpc 调用 iam-apiserver 的 GetSecrets 和 GetPolicies 接口，获取所有的密钥和授权策略信息。第二步，当我们通过控制台调用 iam-apiserver 密钥 / 授权策略的写接口（POST、PUT、DELETE）时，会向 Redis 的 iam.cluster.notifications通道发送 SecretChanged/PolicyChanged 消息。第三步，iam-authz-server 会订阅 iam.cluster.notifications通道，当监听到有 SecretChanged/PolicyChanged 消息时，会请求 iam-apiserver 拉取所有的密钥 / 授权策略。



通过 Redis 的 Sub/Pub 机制，保证每个 iam-authz-server 节点的缓存数据跟 iam-apiserver 数据库中保存的数据一致。所有节点都调用 iam-apiserver 的同一个接口来拉取数据，通过这种方式保证所有 iam-authz-server 节点的数据是一致的。


### 总结
今天，我和你分享了 iam-apiserver 的一些关键功能实现，并介绍了我的设计思路。这里我再简要梳理下。


- 为了保证进程关停时，HTTP 请求执行完后再断开连接，进程中的任务正常完成，iam-apiserver 实现了优雅关停功能。
- 为了避免进程存在，但服务没成功启动的异常场景，iam-apiserver 实现了健康检查机制。
- Gin 中间件可通过配置文件配置，从而实现按需加载的特性。
- 为了能够直接辨别出 API 的版本，iam-apiserver 将 API 的版本标识放在 URL 路径中，例如 /v1/secrets。
- 为了能够最大化地共享功能代码，iam-apiserver 抽象出了统一的元数据，每个 REST 资源都具有这些元数据。
- 因为 API 接口都是通过同一个函数来返回的，其返回格式自然是统一的。
- 因为程序中经常需要处理并发逻辑，iam-apiserver 抽象出了一个通用的并发模板。
- 为了方便根据需要切换 JSON 库，我们实现了插件化选择 JSON 库的功能。
- 为了实现调用链功能，iam-apiserver 不同函数之间通过 ctx context.Context 来传递 RequestID。
- iam-apiserver 通过 Redis 的 Sub/Pub 机制来保证数据一致性。

## 30 | ORM：CURD 神器 GORM 包介绍及实战

在用 Go 开发项目时，我们免不了要和数据库打交道。每种语言都有优秀的 ORM 可供选择，在 Go 中也不例外，比如gorm、xorm、gorose等。目前，GitHub 上 star 数最多的是 GORM，它也是当前 Go 项目中使用最多的 ORM。


IAM 项目也使用了 GORM。这一讲，我就来详细讲解下 GORM 的基础知识，并介绍 iam-apiserver 是如何使用 GORM，对数据进行 CURD 操作的。


### GORM 基础知识介绍
GORM 是 Go 语言的 ORM 包，功能强大，调用方便。像腾讯、华为、阿里这样的大厂，都在使用 GORM 来构建企业级的应用。GORM 有很多特性，开发中常用的核心特性如下：

功能全。使用 ORM 操作数据库的接口，GORM 都有，可以满足我们开发中对数据库调用的各类需求。支持钩子方法。这些钩子方法可以应用在 Create、Save、Update、Delete、Find 方法中。开发者友好，调用方便。支持 Auto Migration。支持关联查询。支持多种关系数据库，例如 MySQL、Postgres、SQLite、SQLServer 等。


GORM 有两个版本，V1和V2。遵循用新不用旧的原则，IAM 项目使用了最新的 V2 版本。



### 通过示例学习 GORM
接下来，我们先快速看一个使用 GORM 的示例，通过该示例来学习 GORM。示例代码存放在marmotedu/gopractise-demo/gorm/main.go文件中。因为代码比较长，你可以使用以下命令克隆到本地查看：


```
$ mkdir -p $GOPATH/src/github.com/marmotedu
$ cd $GOPATH/src/github.com/marmotedu
$ git clone https://github.com/marmotedu/gopractise-demo
$ cd gopractise-demo/gorm/
```
假设我们有一个 MySQL 数据库，连接地址和端口为 127.0.0.1:3306 ，用户名为 iam ，密码为 iam1234 。创建完 main.go 文件后，执行以下命令来运行：


```go
$ go run main.go -H 127.0.0.1:3306 -u iam -p iam1234 -d test
2020/10/17 15:15:50 totalcount: 1
2020/10/17 15:15:50   code: D42, price: 100
2020/10/17 15:15:51 totalcount: 1
2020/10/17 15:15:51   code: D42, price: 200
2020/10/17 15:15:51 totalcount: 0
```
在企业级 Go 项目开发中，使用 GORM 库主要用来完成以下数据库操作：
- 连接和关闭数据库。连接数据库时，可能需要设置一些参数，比如最大连接数、最大空闲连接数、最大连接时长等。
- 插入表记录。可以插入一条记录，也可以批量插入记录。
- 更新表记录。可以更新某一个字段，也可以更新多个字段。
- 查看表记录。可以查看某一条记录，也可以查看符合条件的记录列表。
- 删除表记录。可以删除某一个记录，也可以批量删除。删除还支持永久删除和软删除。
- **在一些小型项目中，还会用到 GORM 的表结构自动迁移功能。**


GORM 功能强大，上面的示例代码展示的是比较通用的一种操作方式。


上述代码中，首先定义了一个 GORM 模型（Models），Models 是标准的 Go struct，用来代表数据库中的一个表结构。我们可以给 Models 添加 TableName 方法，来告诉 GORM 该 Models 映射到数据库中的哪张表。Models 定义如下：


```go
type Product struct {
    gorm.Model
    Code  string `gorm:"column:code"`
    Price uint   `gorm:"column:price"`
}

// TableName maps to mysql table name.
func (p *Product) TableName() string {
    return "product"
}
```
如果没有指定表名，则 GORM 使用结构体名的蛇形复数作为表名。例如：结构体名为 DockerInstance ，则表名为 dockerInstances 。


在之后的代码中，使用 Pflag 来解析命令行的参数，通过命令行参数指定数据库的地址、用户名、密码和数据库名。之后，使用这些参数生成建立 MySQL 连接需要的配置文件，并调用 gorm.Open 建立数据库连接：


```go
var (
    host     = pflag.StringP("host", "H", "127.0.0.1:3306", "MySQL service host address")
    username = pflag.StringP("username", "u", "root", "Username for access to mysql service")
    password = pflag.StringP("password", "p", "root", "Password for access to mysql, should be used pair with password")
    database = pflag.StringP("database", "d", "test", "Database name to use")
    help     = pflag.BoolP("help", "h", false, "Print this help message")
)

func main() {
    // Parse command line flags
    pflag.CommandLine.SortFlags = false
    pflag.Usage = func() {
        pflag.PrintDefaults()
    }
    pflag.Parse()
    if *help {
        pflag.Usage()
        return
    }

    dsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&parseTime=%t&loc=%s`,
        *username,
        *password,
        *host,
        *database,
        true,
        "Local")
    db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{})
    if err != nil {
        panic("failed to connect database")
    }
}

```
创建完数据库连接之后，会返回数据库实例 db ，之后就可以调用 db 实例中的方法，完成数据库的 CURD 操作。具体操作如下，一共可以分为六个操作：


第一个操作，自动迁移表结构。


```go
// 1. Auto migration for given models
db.AutoMigrate(&Product{})
```
**我不建议你在正式的代码中自动迁移表结构。**因为变更现网数据库是一个高危操作，现网数据库字段的添加、类型变更等，都需要经过严格的评估才能实施。这里将变更隐藏在代码中，在组件发布时很难被研发人员感知到，如果组件启动，就可能会自动修改现网表结构，也可能会因此引起重大的现网事故。

GORM 的 AutoMigrate 方法，只对新增的字段或索引进行变更，理论上是没有风险的。在实际的 Go 项目开发中，也有很多人使用 AutoMigrate 方法自动同步表结构。但我更倾向于规范化、可感知的操作方式，所以我在实际开发中，都是手动变更表结构的。当然，具体使用哪种方法，你可以根据需要自行选择。


第二个操作，插入表记录。


```go
// 2. Insert the value into database
if err := db.Create(&Product{Code: "D42", Price: 100}).Error; err != nil {
    log.Fatalf("Create error: %v", err)
}
PrintProducts(db)
```
通过 db.Create 方法创建了一条记录。插入记录后，通过调用 PrintProducts 方法打印当前表中的所有数据记录，来测试是否成功插入。第三个操作，获取符合条件的记录。


```go
// 3. Find first record that match given conditions
product := &Product{}
if err := db.Where("code= ?", "D42").First(&product).Error; err != nil {
    log.Fatalf("Get product error: %v", err)
}
```
First 方法只会返回符合条件的记录列表中的第一条，你可以使用 First 方法来获取某个资源的详细信息。第四个操作，更新表记录。


```go
// 4. Update value in database, if the value doesn't have primary key, will insert it
product.Price = 200
if err := db.Save(product).Error; err != nil {
    log.Fatalf("Update product error: %v", err)
}
PrintProducts(db)
```
通过 Save 方法，可以把 product 变量中所有跟数据库不一致的字段更新到数据库中。具体操作是：先获取某个资源的详细信息，再通过 product.Price = 200 这类赋值语句，对其中的一些字段重新赋值。最后，调用 Save 方法更新这些字段。你可以将这些操作看作一种更新数据库的更新模式。

第五个操作，删除表记录。通过 Delete 方法删除表记录，代码如下：

```go
// 5. Delete value match given conditions
if err := db.Where("code = ?", "D42").Delete(&Product{}).Error; err != nil {
    log.Fatalf("Delete product error: %v", err)
}
PrintProducts(db)
```
这里需要注意，因为 Product 中有 gorm.DeletedAt 字段，所以，上述删除操作不会真正把记录从数据库表中删除掉，而是通过设置数据库 product 表 deletedAt 字段为当前时间的方法来删除。第六个操作，获取表记录列表。


```go
products := make([]*Product, 0)
var count int64
d := db.Where("code like ?", "%D%").Offset(0).Limit(2).Order("id desc").Find(&products).Offset(-1).Limit(-1).Count(&count)
if d.Error != nil {
    log.Fatalf("List products error: %v", d.Error)
}
```
在 PrintProducts 函数中，会打印当前的所有记录，你可以根据输出，判断数据库操作是否成功。


### GORM 常用操作讲解
看完上面的示例，我想你已经初步掌握了 GORM 的使用方法。接下来，我再来给你详细介绍下 GORM 所支持的数据库操作。



#### 模型定义
GORM 使用模型（Models）来映射一个数据库表。默认情况下，使用 ID 作为主键，使用结构体名的 snake_cases 作为表名，使用字段名的 snake_case 作为列名，并使用 CreatedAt、UpdatedAt、DeletedAt 字段追踪创建、更新和删除时间。


使用 GORM 的默认规则，可以减少代码量，但**我更喜欢的方式是直接指明字段名和表名。**例如，有以下模型：


```go
type Animal struct {
  AnimalID int64        // 列名 `animal_id`
  Birthday time.Time    // 列名 `birthday`
  Age      int64        // 列名 `age`
}
```
上述模型对应的表名为 animals ，列名分别为 animal_id 、 birthday 和 age 。我们可以通过以下方式来重命名表名和列名，并将 AnimalID 设置为表的主键：


```go
type Animal struct {
    AnimalID int64     `gorm:"column:animalID;primarykey"` // 将列名设为 `animalID`
    Birthday time.Time `gorm:"column:birthday"`            // 将列名设为 `birthday`
    Age      int64     `gorm:"column:age"`                 // 将列名设为 `age`
}

func (a *Animal) TableName() string {
    return "animal"
}
```
上面的代码中，通过 primaryKey 标签指定主键，使用 column 标签指定列名，通过给 Models 添加 TableName 方法指定表名。



数据库表通常会包含 4 个字段。ID：自增字段，也作为主键。CreatedAt：记录创建时间。UpdatedAt：记录更新时间。DeletedAt：记录删除时间（软删除时有用）。


GORM 也预定义了包含这 4 个字段的 Models，在我们定义自己的 Models 时，可以直接内嵌到结构体内，例如：


```go
type Animal struct {
    gorm.Model
    AnimalID int64     `gorm:"column:animalID"` // 将列名设为 `animalID`
    Birthday time.Time `gorm:"column:birthday"` // 将列名设为 `birthday`
    Age      int64     `gorm:"column:age"`      // 将列名设为 `age`
}
```
Models 中的字段能支持很多 GORM 标签，但如果我们不使用 GORM 自动创建表和迁移表结构的功能，很多标签我们实际上是用不到的。在开发中，用得最多的是 column 标签。

#### 连接数据库
在进行数据库的 CURD 操作之前，我们首先需要连接数据库。你可以通过以下代码连接 MySQL 数据库：


```go
import (
  "gorm.io/driver/mysql"
  "gorm.io/gorm"
)

func main() {
  // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情
  dsn := "user:pass@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4&parseTime=True&loc=Local"
  db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{})
}
```
如果需要 GORM 正确地处理 time.Time 类型，在连接数据库时需要带上 parseTime 参数。如果要支持完整的 UTF-8 编码，可将charset=utf8更改为charset=utf8mb4。

GORM 支持连接池，底层是用 database/sql 包来维护连接池的，连接池设置如下：


```go
sqlDB, err := db.DB()
sqlDB.SetMaxIdleConns(100)              // 设置MySQL的最大空闲连接数（推荐100）
sqlDB.SetMaxOpenConns(100)             // 设置MySQL的最大连接数（推荐100）
sqlDB.SetConnMaxLifetime(time.Hour)    // 设置MySQL的空闲连接最大存活时间（推荐10s）
```
上面这些设置，也可以应用在大型后端项目中。


#### 创建记录
我们可以通过 db.Create 方法来创建一条记录：

```go
type User struct {
  gorm.Model
  Name         string
  Age          uint8
  Birthday     *time.Time
}
user := User{Name: "Jinzhu", Age: 18, Birthday: time.Now()}
result := db.Create(&user) // 通过数据的指针来创建
```
db.Create 函数会返回如下 3 个值：user.ID：返回插入数据的主键，这个是直接赋值给 user 变量。result.Error：返回 error。result.RowsAffected：返回插入记录的条数。

当需要插入的数据量比较大时，可以批量插入，以提高插入性能：


```go
var users = []User{ {Name: "jinzhu1"}, {Name: "jinzhu2"}, {Name: "jinzhu3"} }
DB.Create(&users)

for _, user := range users {
  user.ID // 1,2,3
}
```
#### 删除记录
我们可以通过 Delete 方法删除记录：


```go
// DELETE from users where id = 10 AND name = "jinzhu";
db.Where("name = ?", "jinzhu").Delete(&user)
```
goRM 也支持根据主键进行删除，例如：


```go
// DELETE FROM users WHERE id = 10;
db.Delete(&User{}, 10)
```
不过，**我更喜欢使用 db.Where 的方式进行删除，这种方式有两个优点。**


第一个优点是删除方式更通用。使用 db.Where 不仅可以根据主键删除，还能够随意组合条件进行删除。第二个优点是删除方式更显式，这意味着更易读。如果使用db.Delete(&User{}, 10)，你还需要确认 User 的主键，如果记错了主键，还可能会引入 Bug。


此外，GORM 也支持批量删除：


```go
db.Where("name in (?)", []string{"jinzhu", "colin"}).Delete(&User{})
```
goRM 支持两种删除方法：软删除和永久删除。下面我来分别介绍下。



软删除
软删除是指执行 Delete 时，记录不会被从数据库中真正删除。GORM 会将 DeletedAt 设置为当前时间，并且不能通过正常的方式查询到该记录。如果模型包含了一个 gorm.DeletedAt 字段，GORM 在执行删除操作时，会软删除该记录。

下面的删除方法就是一个软删除：


```go
// UPDATE users SET deleted_at="2013-10-29 10:23" WHERE age = 20;
db.Where("age = ?", 20).Delete(&User{})

// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL;
db.Where("age = 20").Find(&user)
```
可以看到，GORM 并没有真正把记录从数据库删除掉，而是只更新了 deleted_at 字段。在查询时，GORM 查询条件中新增了AND deleted_at IS NULL条件，所以这些被设置过 deleted_at 字段的记录不会被查询到。对于一些比较重要的数据，我们可以通过软删除的方式删除记录，软删除可以使这些重要的数据后期能够被恢复，并且便于以后的排障。

我们可以通过下面的方式查找被软删除的记录：


```go
// SELECT * FROM users WHERE age = 20;
db.Unscoped().Where("age = 20").Find(&users)
```
永久删除
如果想永久删除一条记录，可以使用 Unscoped：


```go
// DELETE FROM orders WHERE id=10;
db.Unscoped().Delete(&order)
```
或者，你也可以在模型中去掉 gorm.DeletedAt。



#### 更新记录
GORM 中，最常用的更新方法如下：


```go
db.First(&user)

user.Name = "jinzhu 2"
user.Age = 100
// UPDATE users SET name='jinzhu 2', age=100, birthday='2016-01-01', updated_at = '2013-11-17 21:34:10' WHERE id=111;
db.Save(&user)
```
上述方法会保留所有字段，所以执行 Save 时，需要先执行 First，获取某个记录的所有列的值，然后再对需要更新的字段设置值。还可以指定更新单个列：


```go
// UPDATE users SET age=200, updated_at='2013-11-17 21:34:10' WHERE name='colin';
db.Model(&User{}).Where("name = ?", "colin").Update("age", 200)
```
也可以指定更新多个列：


```go
// UPDATE users SET name='hello', age=18, updated_at = '2013-11-17 21:34:10' WHERE name = 'colin';
db.Model(&user).Where("name", "colin").Updates(User{Name: "hello", Age: 18, Active: false})
```
这里要注意，这个方法只会更新非零值的字段。


#### 查询数据
GORM 支持不同的查询方法，下面我来讲解三种在开发中经常用到的查询方式，分别是检索单个记录、查询所有符合条件的记录和智能选择字段。


检索单个记录下面是检索单个记录的示例代码：


```go
// 获取第一条记录（主键升序）
// SELECT * FROM users ORDER BY id LIMIT 1;
db.First(&user)

// 获取最后一条记录（主键降序）
// SELECT * FROM users ORDER BY id DESC LIMIT 1;
db.Last(&user)
result := db.First(&user)
result.RowsAffected // 返回找到的记录数
result.Error        // returns error

// 检查 ErrRecordNotFound 错误
errors.Is(result.Error, gorm.ErrRecordNotFound)
```
如果 model 类型没有定义主键，则按第一个字段排序。


查询所有符合条件的记录
示例代码如下：


```go
users := make([]*User, 0)

// SELECT * FROM users WHERE name <> 'jinzhu';
db.Where("name <> ?", "jinzhu").Find(&users)
```
智能选择字段
你可以通过 Select 方法，选择特定的字段。我们可以定义一个较小的结构体来接受选定的字段：


```go
type APIUser struct {
  ID   uint
  Name string
}

// SELECT `id`, `name` FROM `users` LIMIT 10;
db.Model(&User{}).Limit(10).Find(&APIUser{})
```
除了上面讲的三种常用的基本查询方法，GORM 还支持高级查询，下面我来介绍下。



#### 高级查询
GORM 支持很多高级查询功能，这里我主要介绍 4 种。

指定检索记录时的排序方式示例代码如下：

```go
// SELECT * FROM users ORDER BY age desc, name;
db.Order("age desc, name").Find(&users)
```
Limit & Offset
Offset 指定从第几条记录开始查询，Limit 指定返回的最大记录数。Offset 和 Limit 值为 -1 时，消除 Offset 和 Limit 条件。另外，Limit 和 Offset 位置不同，效果也不同。

```go
// SELECT * FROM users OFFSET 5 LIMIT 10;
db.Limit(10).Offset(5).Find(&users)
```
Distinct
Distinct 可以从数据库记录中选择不同的值。


```go
db.Distinct("name", "age").Order("name, age desc").Find(&results)
```
Count
Count 可以获取匹配的条数。


```go
var count int64
// SELECT count(1) FROM users WHERE name = 'jinzhu'; (count)
db.Model(&User{}).Where("name = ?", "jinzhu").Count(&count)
```
goRM 还支持很多高级查询功能，比如内联条件、Not 条件、Or 条件、Group & Having、Joins、Group、FirstOrInit、FirstOrCreate、迭代、FindInBatches 等。因为 IAM 项目中没有用到这些高级特性，我在这里就不展开介绍了。你如果感兴趣，可以看下GORM 的官方文档。


#### 原生 SQL
GORM 支持原生查询 SQL 和执行 SQL。原生查询 SQL 用法如下：


```go
type Result struct {
  ID   int
  Name string
  Age  int
}

var result Result
db.Raw("SELECT id, name, age FROM users WHERE name = ?", 3).Scan(&result)
```
原生执行 SQL 用法如下；

```go
db.Exec("DROP TABLE users")
db.Exec("UPDATE orders SET shipped_at=? WHERE id IN ?", time.Now(), []int64{1,2,3})
```
#### GORM 钩子
GORM 支持钩子功能，例如下面这个在插入记录前执行的钩子：


```go
func (u *User) BeforeCreate(tx *gorm.DB) (err error) {
  u.UUID = uuid.New()

    if u.Name == "admin" {
        return errors.New("invalid name")
    }
    return
}
```
goRM 支持的钩子见下表：


![img](https://static001.geekbang.org/resource/image/20/2c/20fb0b6a11dbcebd9ddf428517240d2c.jpg?wh=1920x1338)

### iam-apiserver 中的 CURD 操作实战
接下来，我来介绍下 iam-apiserver 是如何使用 GORM，对数据进行 CURD 操作的。


首先，我们需要配置连接 MySQL 的各类参数。iam-apiserver 通过NewMySQLOptions函数创建了一个带有默认值的MySQLOptions类型的变量，将该变量传给NewApp函数。在 App 框架中，最终会调用 MySQLOptions 提供的 AddFlags 方法，将 MySQLOptions 提供的命令行参数添加到 Cobra 命令行中。

接着，在PrepareRun函数中，调用GetMySQLFactoryOr函数，初始化并获取仓库层的实例mysqlFactory。实现了仓库层store.Factory接口：


```go
type Factory interface {
    Users() UserStore
    Secrets() SecretStore
    Policies() PolicyStore
    Close() error
}
```
GetMySQLFactoryOr 函数采用了我们在 11 讲 中提过的单例模式，确保 iam-apiserver 进程中只有一个仓库层的实例，这样可以减少内存开支和系统的性能开销。


GetMySQLFactoryOr 函数中，使用github.com/marmotedu/iam/pkg/db包提供的 New 函数，创建了 MySQL 实例。New 函数代码如下：


```go
func New(opts *Options) (*gorm.DB, error) {    
    dsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&parseTime=%t&loc=%s`,    
        opts.Username,                                                                 
        opts.Password,                                 
        opts.Host,                   
        opts.Database,    
        true,                               
        "Local")    
                                                  
    db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{    
        Logger: logger.New(opts.LogLevel),                                                                             
    })    
    if err != nil {                                   
        return nil, err         
    }    
    
    sqlDB, err := db.DB()                              
    if err != nil {                                                                
        return nil, err                              
    }                                                                  
                                                             
    // SetMaxOpenConns sets the maximum number of open connections to the database.
    sqlDB.SetMaxOpenConns(opts.MaxOpenConnections)

    // SetConnMaxLifetime sets the maximum amount of time a connection may be reused.
    sqlDB.SetConnMaxLifetime(opts.MaxConnectionLifeTime)

    // SetMaxIdleConns sets the maximum number of connections in the idle connection pool.
    sqlDB.SetMaxIdleConns(opts.MaxIdleConnections)

    return db, nil
}
```
上述代码中，我们先创建了一个 *gorm.DB 类型的实例，并对该实例进行了如下设置：
- 通过 SetMaxOpenConns 方法，设置了 MySQL 的最大连接数（推荐 100）。
- 通过 SetConnMaxLifetime 方法，设置了 MySQL 的空闲连接最大存活时间（推荐 10s）。
- 通过 SetMaxIdleConns 方法，设置了 MySQL 的最大空闲连接数（推荐 100）。


GetMySQLFactoryOr 函数最后创建了 datastore 类型的变量 mysqlFactory，该变量是仓库层的变量。mysqlFactory 变量中，又包含了 *gorm.DB 类型的字段 db 。

最终，我们通过仓库层的变量 mysqlFactory，调用其 db 字段提供的方法来完成数据库的 CURD 操作。例如，创建密钥、更新密钥、删除密钥、获取密钥详情、查询密钥列表，具体代码如下（代码位于secret.go文件中）：


```go
// Create creates a new secret.
func (s *secrets) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {
  return s.db.Create(&secret).Error
}

// Update updates an secret information by the secret identifier.
func (s *secrets) Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) error {
  return s.db.Save(secret).Error
}

// Delete deletes the secret by the secret identifier.
func (s *secrets) Delete(ctx context.Context, username, name string, opts metav1.DeleteOptions) error {
  if opts.Unscoped {
    s.db = s.db.Unscoped()
  }

  err := s.db.Where("username = ? and name = ?", username, name).Delete(&v1.Secret{}).Error
  if err != nil && !errors.Is(err, gorm.ErrRecordNotFound) {
    return errors.WithCode(code.ErrDatabase, err.Error())
  }

  return nil
}

// Get return an secret by the secret identifier.
func (s *secrets) Get(ctx context.Context, username, name string, opts metav1.GetOptions) (*v1.Secret, error) {
  secret := &v1.Secret{}
  err := s.db.Where("username = ? and name= ?", username, name).First(&secret).Error
  if err != nil {
    if errors.Is(err, gorm.ErrRecordNotFound) {
      return nil, errors.WithCode(code.ErrSecretNotFound, err.Error())
    }

    return nil, errors.WithCode(code.ErrDatabase, err.Error())
  }

  return secret, nil
}

// List return all secrets.
func (s *secrets) List(ctx context.Context, username string, opts metav1.ListOptions) (*v1.SecretList, error) {
  ret := &v1.SecretList{}
  ol := gormutil.Unpointer(opts.Offset, opts.Limit)

  if username != "" {
    s.db = s.db.Where("username = ?", username)
  }

  selector, _ := fields.ParseSelector(opts.FieldSelector)
  name, _ := selector.RequiresExactMatch("name")

  d := s.db.Where(" name like ?", "%"+name+"%").
    Offset(ol.Offset).
    Limit(ol.Limit).
    Order("id desc").
    Find(&ret.Items).
    Offset(-1).
    Limit(-1).
    Count(&ret.TotalCount)

  return ret, d.Error
}
```
上面的代码中， s.db 就是 *gorm.DB 类型的字段。

上面的代码段执行了以下操作：
- 通过 s.db.Save 来更新数据库表的各字段；
- 通过 s.db.Unscoped 来永久性从表中删除一行记录。对于支持软删除的资源，我们还可以通过 opts.Unscoped 选项来控制是否永久删除记录。 true 永久删除， false 软删除，默认软删除。
- 通过 errors.Is(err, gorm.ErrRecordNotFound) 来判断 GORM 返回的错误是否是没有找到记录的错误类型。
- 通过下面两行代码，来获取查询条件 name 的值：


```go
selector, _ := fields.ParseSelector(opts.FieldSelector)    
name, _ := selector.RequiresExactMatch("name")
```
我们的整个调用链是：控制层 -> 业务层 -> 仓库层。这里你可能要问：**我们是如何调用到仓库层的实例 mysqlFactory的呢？**

这是因为我们的控制层实例包含了业务层的实例。在创建控制层实例时，我们传入了业务层的实例：


```go
type UserController struct {                                        
    srv srvv1.Service                                                      
}                                                                          
                                                                                            
// NewUserController creates a user handler.          
func NewUserController(store store.Factory) *UserController {
    return &UserController{                                     
        srv: srvv1.NewService(store),                                             
    }                                                      
} 
```
业务层的实例包含了仓库层的实例。在创建业务层实例时，传入了仓库层的实例：


```go
type service struct {                                                      
    store store.Factory                                                                     
}                                                     
                                                             
// NewService returns Service interface.                        
func NewService(store store.Factory) Service {                                    
    return &service{                                       
        store: store,                                             
    }
}

```
通过这种包含关系，我们在控制层可以调用业务层的实例，在业务层又可以调用仓库层的实例。这样，我们最终通过仓库层实例的 db 字段（*gorm.DB 类型）完成数据库的 CURD 操作。


### 总结
在 Go 项目中，我们需要使用 ORM 来进行数据库的 CURD 操作。在 Go 生态中，当前最受欢迎的 ORM 是 GORM，IAM 项目也使用了 GORM。GORM 有很多功能，常用的功能有模型定义、连接数据库、创建记录、删除记录、更新记录和查询数据。这些常用功能的常见使用方式如下：

```go
package main

import (
  "fmt"
  "log"

  "github.com/spf13/pflag"
  "gorm.io/driver/mysql"
  "gorm.io/gorm"
)

type Product struct {
  gorm.Model
  Code  string `gorm:"column:code"`
  Price uint   `gorm:"column:price"`
}

// TableName maps to mysql table name.
func (p *Product) TableName() string {
  return "product"
}

var (
  host     = pflag.StringP("host", "H", "127.0.0.1:3306", "MySQL service host address")
  username = pflag.StringP("username", "u", "root", "Username for access to mysql service")
  password = pflag.StringP("password", "p", "root", "Password for access to mysql, should be used pair with password")
  database = pflag.StringP("database", "d", "test", "Database name to use")
  help     = pflag.BoolP("help", "h", false, "Print this help message")
)

func main() {
  // Parse command line flags
  pflag.CommandLine.SortFlags = false
  pflag.Usage = func() {
    pflag.PrintDefaults()
  }
  pflag.Parse()
  if *help {
    pflag.Usage()
    return
  }

  dsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&parseTime=%t&loc=%s`,
    *username,
    *password,
    *host,
    *database,
    true,
    "Local")
  db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{})
  if err != nil {
    panic("failed to connect database")
  }

  // 1. Auto migration for given models
  db.AutoMigrate(&Product{})

  // 2. Insert the value into database
  if err := db.Create(&Product{Code: "D42", Price: 100}).Error; err != nil {
    log.Fatalf("Create error: %v", err)
  }
  PrintProducts(db)

  // 3. Find first record that match given conditions
  product := &Product{}
  if err := db.Where("code= ?", "D42").First(&product).Error; err != nil {
    log.Fatalf("Get product error: %v", err)
  }

  // 4. Update value in database, if the value doesn't have primary key, will insert it
  product.Price = 200
  if err := db.Save(product).Error; err != nil {
    log.Fatalf("Update product error: %v", err)
  }
  PrintProducts(db)

  // 5. Delete value match given conditions
  if err := db.Where("code = ?", "D42").Delete(&Product{}).Error; err != nil {
    log.Fatalf("Delete product error: %v", err)
  }
  PrintProducts(db)
}

// List products
func PrintProducts(db *gorm.DB) {
  products := make([]*Product, 0)
  var count int64
  d := db.Where("code like ?", "%D%").Offset(0).Limit(2).Order("id desc").Find(&products).Offset(-1).Limit(-1).Count(&count)
  if d.Error != nil {
    log.Fatalf("List products error: %v", d.Error)
  }

  log.Printf("totalcount: %d", count)
  for _, product := range products {
    log.Printf("\tcode: %s, price: %d\n", product.Code, product.Price)
  }
}
```
此外，GORM 还支持原生查询 SQL 和原生执行 SQL，可以满足更加复杂的 SQL 场景。GORM 中，还有一个非常有用的功能是支持 Hooks。Hooks 可以在执行某个 CURD 操作前被调用。在 Hook 中，可以添加一些非常有用的功能，例如生成唯一 ID。目前，GORM 支持 BeforeXXX 、 AfterXXX 和 AfterFind Hook，其中 XXX 可以是 Save、Create、Delete、Update。最后，我还介绍了 IAM 项目的 GORM 实战，具体使用方式跟总结中的示例代码大体保持一致，你可以返回文稿查看。

## 31 | 数据流：通过iam-authz-server设计，看数据流服务的设计
在 28 讲 和 29 讲 ，我介绍了 IAM 的控制流服务 iam-apiserver 的设计和实现。这一讲，我们再来看下 IAM 数据流服务 iam-authz-server 的设计和实现。因为 iam-authz-server 是数据流服务，对性能要求较高，所以采用了一些机制来最大化 API 接口的性能。另外，为了提高开发效率，避免重复造轮子，iam-authz-server 和 iam-apiserver 共享了大部分的功能代码。接下来，我们就来看下，iam-authz-server 是如何跟 iam-apiserver 共享代码的，以及 iam-authz-server 是如何保证 API 接口性能的。


### iam-authz-server 的功能介绍
iam-authz-server 目前的唯一功能，是通过提供 /v1/authz RESTful API 接口完成资源授权。 /v1/authz 接口是通过github.com/ory/ladon来完成资源授权的。

因为 iam-authz-server 承载了数据流的请求，需要确保 API 接口具有较高的性能。为了保证 API 接口的性能，iam-authz-server 在设计上使用了大量的缓存技术。


### github.com/ory/ladon 包介绍
因为 iam-authz-server 资源授权是通过 github.com/ory/ladon 来完成的，为了让你更好地理解 iam-authz-server 的授权策略，在这里我先介绍下 github.com/ory/ladon 包。

Ladon 是用 Go 语言编写的用于实现访问控制策略的库，类似于 RBAC（基于角色的访问控制系统，Role Based Access Control）和 ACL（访问控制列表，Access Control Lists）。但是与 RBAC 和 ACL 相比，Ladon 可以实现更细粒度的访问控制，并且能够在更为复杂的环境中（例如多租户、分布式应用程序和大型组织）工作。


Ladon 解决了这个问题：在特定的条件下，谁能够 / 不能够对哪些资源做哪些操作。为了解决这个问题，Ladon 引入了授权策略。授权策略是一个有语法规范的文档，这个文档描述了谁在什么条件下能够对哪些资源做哪些操作。Ladon 可以用请求的上下文，去匹配设置的授权策略，最终判断出当前授权请求是否通过。下面是一个 Ladon 的授权策略样例：


```
{
  "description": "One policy to rule them all.",
  "subjects": ["users:<peter|ken>", "users:maria", "groups:admins"],
  "actions" : ["delete", "<create|update>"],
  "effect": "allow",
  "resources": [
    "resources:articles:<.*>",
    "resources:printer"
  ],
  "conditions": {
    "remoteIP": {
        "type": "CIDRCondition",
        "options": {
            "cidr": "192.168.0.1/16"
        }
    }
  }
}
```
策略（Policy）由若干元素构成，用来描述授权的具体信息，你可以把它们看成一组规则。核心元素包括主题（Subject）、操作（Action）、效力（Effect）、资源（Resource）以及生效条件（Condition）。元素保留字仅支持小写，它们在描述上没有顺序要求。对于没有特定约束条件的策略，Condition 元素是可选项。一条策略包含下面 6 个元素：

- 主题（Subject），主题名是唯一的，代表一个授权主题。例如，“ken” or “printer-service.mydomain.com”。
- 操作（Action），描述允许或拒绝的操作。
- 效力（Effect），描述策略产生的结果是“允许”还是“拒绝”，包括 allow（允许）和 deny（拒绝）。
- 资源（Resource），描述授权的具体数据。
- 生效条件（Condition），描述策略生效的约束条件。
- 描述（Description），策略的描述。


有了授权策略，我们就可以传入请求上下文，由 Ladon 来决定请求是否能通过授权。下面是一个请求示例：



```
{
  "subject": "users:peter",
  "action" : "delete",
  "resource": "resources:articles:ladon-introduction",
  "context": {
    "remoteIP": "192.168.0.5"
  }
}
```
可以看到，在 remoteIP="192.168.0.5" 生效条件（Condition）下，针对主题（Subject） users:peter 对资源（Resource） resources:articles:ladon-introduction 的 delete 操作（Action），授权策略的效力（Effect）是 allow 的。所以 Ladon 会返回如下结果：



```
{
    "allowed": true
}
```
Ladon 支持很多 Condition，具体见下表：


![img](https://static001.geekbang.org/resource/image/b8/dd/b84d2a1dc0e9ac07605a867594d734dd.jpg?wh=1920x1521)

至于如何使用这些 Condition，你可以参考 [Ladon Condition 使用示例](https://github.com/marmotedu/geekbang-go/blob/master/LadonCondition%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B.md)。此外，Ladon 还支持自定义 Condition。


另外，Ladon 还支持授权审计，用来记录授权历史。我们可以通过在 ladon.Ladon 中附加一个 ladon.AuditLogger 来实现：


```go
import "github.com/ory/ladon"
import manager "github.com/ory/ladon/manager/memory"

func main() {

    warden := ladon.Ladon{
        Manager: manager.NewMemoryManager(),
        AuditLogger: &ladon.AuditLoggerInfo{}
    }

    // ...
}
```
在上面的示例中，我们提供了 ladon.AuditLoggerInfo，该 AuditLogger 会在授权时打印调用的策略到标准错误。AuditLogger 是一个 interface：


```go
// AuditLogger tracks denied and granted authorizations.
type AuditLogger interface {
    LogRejectedAccessRequest(request *Request, pool Policies, deciders Policies)
    LogGrantedAccessRequest(request *Request, pool Policies, deciders Policies)
}
```
要实现一个新的 AuditLogger，你只需要实现 AuditLogger 接口就可以了。比如，我们可以实现一个 AuditLogger，将授权日志保存到 Redis 或者 MySQL 中。

Ladon 支持跟踪一些授权指标，比如 deny、allow、not match、error。你可以通过实现 ladon.Metric 接口，来对这些指标进行处理。ladon.Metric 接口定义如下：


```go
// Metric is used to expose metrics about authz
type Metric interface {
    // RequestDeniedBy is called when we get explicit deny by policy
    RequestDeniedBy(Request, Policy)
    // RequestAllowedBy is called when a matching policy has been found.
    RequestAllowedBy(Request, Policies)
    // RequestNoMatch is called when no policy has matched our request
    RequestNoMatch(Request)
    // RequestProcessingError is called when unexpected error occured
    RequestProcessingError(Request, Policy, error)
}
```
例如，你可以通过下面的示例，将这些指标暴露给 prometheus：



```go
type prometheusMetrics struct{}

func (mtr *prometheusMetrics) RequestDeniedBy(r ladon.Request, p ladon.Policy) {}
func (mtr *prometheusMetrics) RequestAllowedBy(r ladon.Request, policies ladon.Policies) {}
func (mtr *prometheusMetrics) RequestNoMatch(r ladon.Request) {}
func (mtr *prometheusMetrics) RequestProcessingError(r ladon.Request, err error) {}

func main() {

    warden := ladon.Ladon{
        Manager: manager.NewMemoryManager(),
        Metric:  &prometheusMetrics{},
    }

    // ...
}
```
在使用 Ladon 的过程中，有两个地方需要你注意：
- 所有检查都区分大小写，因为主题值可能是区分大小写的 ID。
- 如果 ladon.Ladon 无法将策略与请求匹配，会默认授权结果为拒绝，并返回错误。


### iam-authz-server 使用方法介绍
上面，我介绍了 iam-authz-server 的资源授权功能，这里介绍下如何使用 iam-authz-server，也就是如何调用 /v1/authz 接口完成资源授权。你可以通过下面的 3 大步骤，来完成资源授权请求。



**第一步，登陆 iam-apiserver，创建授权策略和密钥。**

这一步又分为 3 个小步骤。登陆 iam-apiserver 系统，获取访问令牌：

```
$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{"username":"admin","password":"Admin@2021"}' http://127.0.0.1:8080/login | jq -r .token`
```
创建授权策略：


```
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"policy":{"description":"One policy to rule them all.","subjects":["users:<peter|ken>","users:maria","groups:admins"],"actions":["delete","<create|update>"],"effect":"allow","resources":["resources:articles:<.*>","resources:printer"],"conditions":{"remoteIP":{"type":"CIDRCondition","options":{"cidr":"192.168.0.1/16"}}}}}' http://127.0.0.1:8080/v1/policies
```
创建密钥，并从请求结果中提取 secretID 和 secretKey：


```
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"expires":0,"description":"admin secret"}' http://127.0.0.1:8080/v1/secrets
{"metadata":{"id":23,"name":"authztest","createdAt":"2021-04-08T07:24:50.071671422+08:00","updatedAt":"2021-04-08T07:24:50.071671422+08:00"},"username":"admin","secretID":"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox","secretKey":"7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8","expires":0,"description":"admin secret"}
```
**第二步，生成访问 iam-authz-server 的 token。**

iamctl 提供了 jwt sigin 子命令，可以根据 secretID 和 secretKey 签发 Token，方便使用。



```
$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey
eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ
```
你可以通过 iamctl jwt show 来查看 Token 的内容：


```
$ iamctl jwt show eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ
Header:
{
    "alg": "HS256",
    "kid": "ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox",
    "typ": "JWT"
}
Claims:
{
    "aud": "iam.authz.marmotedu.com",
    "exp": 1617845195,
    "iat": 1617837995,
    "iss": "iamctl",
    "nbf": 1617837995
}
```
我们生成的 Token 包含了下面这些信息。


Header
alg：生成签名的算法。kid：密钥 ID。typ：Token 的类型，这里是 JWT。



Claims
aud：JWT Token 的接受者。exp：JWT Token 的过期时间（UNIX 时间格式）。iat：JWT Token 的签发时间（UNIX 时间格式）。iss：签发者，因为我们是用 iamctl 工具签发的，所以这里的签发者是 iamctl。nbf：JWT Token 的生效时间（UNIX 时间格式），默认是签发时间。




**第三步，调用/v1/authz接口，完成资源授权请求**。请求方法如下：


```
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{"subject":"users:maria","action":"delete","resource":"resources:articles:ladon-introduction","context":{"remoteIP":"192.168.0.5"}}' http://127.0.0.1:9090/v1/authz
{"allowed":true}
```
如果授权通过，会返回：{"allowed":true} 。 如果授权失败，则返回：


```
{"allowed":false,"denied":true,"reason":"Request was denied by default"}
```
### iam-authz-server 的代码实现
接下来，我们来看下 iam-authz-server 的具体实现，我会从配置处理、启动流程、请求处理流程和代码架构 4 个方面来讲解。



#### iam-authz-server 的配置处理
iam-authz-server 服务的 main 函数位于authzserver.go文件中，你可以跟读代码，了解 iam-authz-server 的代码实现。iam-authz-server 的服务框架设计跟 iam-apiserver 的服务框架设计保持一致，也是有 3 种配置：Options 配置、组件配置和 HTTP 服务配置。


Options 配置见options.go文件：


```go
type Options struct {
    RPCServer               string
    ClientCA                string
    GenericServerRunOptions *genericoptions.ServerRunOptions
    InsecureServing         *genericoptions.InsecureServingOptions
    SecureServing           *genericoptions.SecureServingOptions
    RedisOptions            *genericoptions.RedisOptions
    FeatureOptions          *genericoptions.FeatureOptions
    Log                     *log.Options
    AnalyticsOptions        *analytics.AnalyticsOptions
}
```
和 iam-apiserver 相比，iam-authz-server 多了 AnalyticsOptions，用来配置 iam-authz-server 内的 Analytics 服务，Analytics 服务会将授权日志异步写入到 Redis 中。

iam-apiserver 和 iam-authz-server 共用了 GenericServerRunOptions、InsecureServing、SecureServing、FeatureOptions、RedisOptions、Log 这些配置。所以，我们只需要用简单的几行代码，就可以将很多配置项都引入到 iam-authz-server 的命令行参数中，这也是命令行参数分组带来的好处：批量共享。


#### iam-authz-server 启动流程设计
接下来，我们来详细看下 iam-authz-server 的启动流程。

iam-authz-server 的启动流程也和 iam-apiserver 基本保持一致。二者比较大的不同在于 Options 参数配置和应用初始化内容。另外，和 iam-apiserver 相比，iam-authz-server 只提供了 REST API 服务。启动流程如下图所示：


![img](https://static001.geekbang.org/resource/image/19/35/195178d37854bac7d5243d80e42a4c35.jpg?wh=2248x799)

#### iam-authz-server 的 RESTful API 请求处理流程
iam-authz-server 的请求处理流程也是清晰、规范的，具体流程如下图所示：


![img](https://static001.geekbang.org/resource/image/5a/89/5a83384f5762c41831190628bfa60989.jpg?wh=2248x780)

首先，我们通过 API 调用（ + ）请求 iam-authz-server 提供的 RESTful API 接口 POST /v1/authz 。接着，Gin Web 框架接收到 HTTP 请求之后，会通过认证中间件完成请求的认证，iam-authz-server 采用了 Bearer 认证方式。


然后，请求会被我们加载的一系列中间件所处理，例如跨域、RequestID、Dump 等中间件。最后，根据 + 进行路由匹配。

比如，我们请求的 RESTful API 是POST /v1/authz，Gin Web 框架会根据 HTTP Method 和 HTTP Request Path，查找注册的 Controllers，最终匹配到 authzController.Authorize Controller。在 Authorize Controller 中，会先解析请求参数，接着校验请求参数、调用业务层的方法进行资源授权，最后处理业务层的返回结果，返回最终的 HTTP 请求结果。


#### iam-authz-server 的代码架构
iam-authz-server 的代码设计和 iam-apiserver 一样，遵循简洁架构设计。


iam-authz-server 的代码架构也分为 4 层，分别是模型层（Models）、控制层（Controller）、业务层 （Service）和仓库层（Repository）。从控制层、业务层到仓库层，从左到右层级依次加深。模型层独立于其他层，可供其他层引用。如下图所示：


![img](https://static001.geekbang.org/resource/image/a5/dd/a57832495c9e031a94282f0a8a3a61dd.jpg?wh=2248x702)

iam-authz-server 和 iam-apiserver 的代码架构有这三点不同：iam-authz-server 客户端不支持前端和命令行。iam-authz-server 仓库层对接的是 iam-apiserver 微服务，而非数据库。iam-authz-server 业务层的代码存放在目录authorization中。



### iam-authz-server 关键代码分析
和 iam-apiserver 一样，iam-authz-server 也包含了一些优秀的设计思路和关键代码，这里我来一一介绍下。


#### 资源授权
先来看下，iam-authz-server 是如何实现资源授权的。

我们可以调用 iam-authz-server 的 /v1/authz API 接口，实现资源的访问授权。 /v1/authz 对应的 controller 方法是Authorize：


```go
func (a *AuthzController) Authorize(c *gin.Context) {
  var r ladon.Request
  if err := c.ShouldBind(&r); err != nil {
    core.WriteResponse(c, errors.WithCode(code.ErrBind, err.Error()), nil)

    return
  }

  auth := authorization.NewAuthorizer(authorizer.NewAuthorization(a.store))
  if r.Context == nil {
    r.Context = ladon.Context{}
  }

  r.Context["username"] = c.GetString("username")
  rsp := auth.Authorize(&r)

  core.WriteResponse(c, nil, rsp)
}
```
该函数使用 github.com/ory/ladon 包进行资源访问授权，授权流程如下图所示：


![img](https://static001.geekbang.org/resource/image/7c/a6/7c251c61cb535714edd390eac18df8a6.jpg?wh=2248x920)
具体分为以下几个步骤：第一步，在 Authorize 方法中调用 c.ShouldBind(&r) ，将 API 请求参数解析到 ladon.Request 类型的结构体变量中。第二步，调用authorization.NewAuthorizer函数，该函数会创建并返回包含 Manager 和 AuditLogger 字段的Authorizer类型的变量。

Manager 包含一些函数，比如 Create、Update 和 FindRequestCandidates 等，用来对授权策略进行增删改查。AuditLogger 包含 LogRejectedAccessRequest 和 LogGrantedAccessRequest 函数，分别用来记录被拒绝的授权请求和被允许的授权请求，将其作为审计数据使用。



第三步，调用auth.Authorize函数，对请求进行访问授权。auth.Authorize 函数内容如下：


```go
func (a *Authorizer) Authorize(request *ladon.Request) *authzv1.Response {
  log.Debug("authorize request", log.Any("request", request))

  if err := a.warden.IsAllowed(request); err != nil {
    return &authzv1.Response{
      Denied: true,
      Reason: err.Error(),
    }
  }

  return &authzv1.Response{
    Allowed: true,
  }
}
```
该函数会调用 a.warden.IsAllowed(request) 完成资源访问授权。IsAllowed 函数会调用 FindRequestCandidates(r) 查询所有的策略列表，这里要注意，我们只需要查询请求用户的 policy 列表。在 Authorize 函数中，我们将 username 存入 ladon Request 的 context 中：



```
r.Context["username"] = c.GetHeader("username")
```
在FindRequestCandidates函数中，我们可以从 Request 中取出 username，并根据 username 查询缓存中的 policy 列表，FindRequestCandidates 实现如下：



```go
func (m *PolicyManager) FindRequestCandidates(r *ladon.Request) (ladon.Policies, error) {
    username := ""
  
    if user, ok := r.Context["username"].(string); ok {
      username = user
    }
  
    policies, err := m.client.List(username)
    if err != nil {
      return nil, errors.Wrap(err, "list policies failed")
    }
  
    ret := make([]ladon.Policy, 0, len(policies))
    for _, policy := range policies {
      ret = append(ret, policy)
    }
  
    return ret, nil
  }

```
IsAllowed 函数代码如下：



```go
func (l *Ladon) IsAllowed(r *Request) (err error) {
    policies, err := l.Manager.FindRequestCandidates(r)
    if err != nil {
        go l.metric().RequestProcessingError(*r, nil, err)
        return err
    }

    return l.DoPoliciesAllow(r, policies)
}
```
IsAllowed 会调用 DoPoliciesAllow(r, policies) 函数进行权限校验。如果权限校验不通过（请求在指定条件下不能够对资源做指定操作），就调用 LogRejectedAccessRequest 函数记录拒绝的请求，并返回值为非 nil 的 error，error 中记录了授权失败的错误信息。如果权限校验通过，则调用 LogGrantedAccessRequest 函数记录允许的请求，并返回值为 nil 的 error。


为了降低请求延时，LogRejectedAccessRequest 和 LogGrantedAccessRequest 会将授权记录存储在 Redis 中，之后由 iam-pump 进程读取 Redis，并将授权记录持久化存储在 MongoDB 中。



#### 缓存设计
iam-authz-server 主要用来做资源访问授权，属于数据流的组件，对接口访问性能有比较高的要求，所以该组件采用了缓存的机制。如下图所示：


![img](https://static001.geekbang.org/resource/image/05/51/05d1c9a9acdc451f915684c18c8b9f51.jpg?wh=2248x822)
iam-authz-server 组件通过缓存密钥和授权策略信息到内存中，加快密钥和授权策略的查询速度。通过缓存授权记录到内存中，提高了授权数据的写入速度，从而大大降低了授权请求接口的延时。

上面的缓存机制用到了 Redis key-value 存储，所以在 iam-authz-server 初始化阶段，需要先建立 Redis 连接（位于initialize函数中）：


```
go storage.ConnectToRedis(ctx, s.buildStorageConfig())
```
这个代码会维护一个 Redis 连接，如果 Redis 连接断掉，会尝试重连。这种方式可以使我们在调用 Redis 接口进行数据读写时，不用考虑连接断开的问题。

接下来，我们就来详细看看，iam-authz-server 是如何实现缓存机制的。


**先来看下密钥和策略缓存。**iam-authz-server 通过load包来完成密钥和策略的缓存。


在 iam-authz-server 进程启动时，会创建并启动一个 Load 服务（位于initialize函数中）：


```
load.NewLoader(ctx, cacheIns).Start() 
```
**先来看创建 Load 服务**。创建 Load 服务时，传入了 cacheIns 参数，cacheIns 是一个实现了Loader接口的实例：


```
type Loader interface {
    Reload() error
}
```
然后看启动 Load 服务。通过 Load 实例的 Start 方法来启动 Load 服务：


```go
func (l *Load) Start() {
    go startPubSubLoop()
    go l.reloadQueueLoop()
    go l.reloadLoop()

    l.DoReload()
}
```
Start 函数先启动了 3 个协程，再调用 l.DoReload() 完成一次密钥和策略的同步：


```go
func (l *Load) DoReload() {
    l.lock.Lock()
    defer l.lock.Unlock()

    if err := l.loader.Reload(); err != nil {
        log.Errorf("faild to refresh target storage: %s", err.Error())
    }

    log.Debug("refresh target storage succ")
}
```
上面我们说了，创建 Load 服务时，传入的 cacheIns 实例是一个实现了 Loader 接口的实例，所以在DoReload方法中，可以直接调用 Reload 方法。cacheIns 的 Reload 方法会从 iam-apiserver 中同步密钥和策略信息到 iam-authz-server 缓存中。

我们再来看下，startPubSubLoop、reloadQueueLoop、reloadLoop 这 3 个 Go 协程分别完成了什么功能。



startPubSubLoop 协程
startPubSubLoop函数通过StartPubSubHandler函数，订阅 Redis 的 iam.cluster.notifications channel，并注册一个回调函数：

```go
func(v interface{}) {
    handleRedisEvent(v, nil, nil)
}
```
handleRedisEvent函数中，会将消息解析为Notification类型的消息，并判断 Command 的值。如果是 NoticePolicyChanged 或 NoticeSecretChanged，就会向 reloadQueue channel 中写入一个回调函数。因为我们不需要用回调函数做任何事情，所以这里回调函数是 nil。 reloadQueue 主要用来告诉程序，需要完成一次密钥和策略的同步。


reloadQueueLoop 协程
reloadQueueLoop 函数会监听 reloadQueue ，当发现有新的消息（这里是回调函数）写入时，会实时将消息缓存到 requeue 切片中，代码如下：

```go
func (l *Load) reloadQueueLoop(cb ...func()) {
    for {
      select {
      case <-l.ctx.Done():
        return
      case fn := <-reloadQueue:
        requeueLock.Lock()
        requeue = append(requeue, fn)
        requeueLock.Unlock()
        log.Info("Reload queued")
        if len(cb) != 0 {
          cb[0]()
        }
      }
    }
  }

```
reloadLoop 协程
通过reloadLoop函数启动一个 timer 定时器，每隔 1 秒会检查 requeue 切片是否为空，如果不为空，则调用 l.DoReload 方法，从 iam-apiserver 中拉取密钥和策略，并缓存在内存中。


密钥和策略的缓存模型如下图所示：


![img](https://static001.geekbang.org/resource/image/a2/11/a2f5694e5d6291ca610b84ee49469211.jpg?wh=2248x890)


**密钥和策略缓存的具体流程如下：**接收上游消息（这里是从 Redis 中接收），将消息缓存到切片或者带缓冲的 channel 中，并启动一个消费协程去消费这些消息。这里的消费协程是 reloadLoop，reloadLoop 会每隔 1s 判断 requeue 切片是否长度为 0，如果不为 0，则执行 l.DoReload() 缓存密钥和策略。


讲完了密钥和策略缓存，再**来看下授权日志缓存。**


在启动 iam-authz-server 时，还会启动一个 Analytics 服务，代码如下（位于internal/authzserver/server.go文件中）：


```go
    if s.analyticsOptions.Enable {    
        analyticsStore := storage.RedisCluster{KeyPrefix: RedisKeyPrefix}    
        analyticsIns := analytics.NewAnalytics(s.analyticsOptions, &analyticsStore)    
        analyticsIns.Start()    
        s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {    
            analyticsIns.Stop()    
    
            return nil    
        }))    
    }
```
NewAnalytics函数会根据配置，创建一个 Analytics 实例：


```go
func NewAnalytics(options *AnalyticsOptions, store storage.AnalyticsHandler) *Analytics {
    ps := options.PoolSize
    recordsBufferSize := options.RecordsBufferSize
    workerBufferSize := recordsBufferSize / uint64(ps)
    log.Debug("Analytics pool worker buffer size", log.Uint64("workerBufferSize", workerBufferSize))
  
    recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)
  
    return &Analytics{
      store:                      store,
      poolSize:                   ps,
      recordsChan:                recordsChan,
      workerBufferSize:           workerBufferSize,
      recordsBufferFlushInterval: options.FlushInterval,
    }
  } 
```
上面的代码创建了一个带缓冲的 recordsChan ：


```go
recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)
```
recordsChan 存放的数据类型为AnalyticsRecord，缓冲区的大小为 recordsBufferSize （通过 --analytics.records-buffer-size 选项指定）。可以通过RecordHit函数，向recordsChan 中写入 AnalyticsRecord 类型的数据：


```go
func (r *Analytics) RecordHit(record *AnalyticsRecord) error {                                                         
    // check if we should stop sending records 1st                                                                     
    if atomic.LoadUint32(&r.shouldStop) > 0 {                                                                          
        return nil                                                                                                     
    }                                                                                                                  
                                                                                                                       
    // just send record to channel consumed by pool of workers                                                         
    // leave all data crunching and Redis I/O work for pool workers                                                    
    r.recordsChan <- record                                                                                            
                                                                                                                       
    return nil                                                                                                         
}   
```
iam-authz-server 是通过调用 LogGrantedAccessRequest 和 LogRejectedAccessRequest 函数来记录授权日志的。在记录授权日志时，会将授权日志写入 recordsChan channel 中。LogGrantedAccessRequest函数代码如下：


```go
func (auth *Authorization) LogGrantedAccessRequest(r *ladon.Request, p ladon.Policies, d ladon.Policies) {
    conclusion := fmt.Sprintf("policies %s allow access", joinPoliciesNames(d))                               
    rstring, pstring, dstring := convertToString(r, p, d)                          
    record := analytics.AnalyticsRecord{                     
        TimeStamp:  time.Now().Unix(),                              
        Username:   r.Context["username"].(string),                 
        Effect:     ladon.AllowAccess,                       
        Conclusion: conclusion,                              
        Request:    rstring,       
        Policies:   pstring,                                                   
        Deciders:   dstring,                                                   
    }                           
                           
    record.SetExpiry(0)
    _ = analytics.GetAnalytics().RecordHit(&record)         
} 
```
上面的代码，会创建 AnalyticsRecord 类型的结构体变量，并调用 RecordHit 将变量的值写入 recordsChan channel 中。将授权日志写入 recordsChan   channel 中，而不是直接写入 Redis 中，这可以大大减少写入延时，减少接口的响应延时。


还有一个 worker 进程从 recordsChan 中读取数据，并在数据达到一定阈值之后，批量写入 Redis 中。在Start函数中，我们创建了一批 worker，worker 个数可以通过 --analytics.pool-size 来指定 。Start 函数内容如下：



```go
func (r *Analytics) Start() {
    analytics = r
    r.store.Connect()
  
    // start worker pool
    atomic.SwapUint32(&r.shouldStop, 0)
    for i := 0; i < r.poolSize; i++ {
      r.poolWg.Add(1)
      go r.recordWorker()
    }
  
    // stop analytics workers
    go r.Stop()
  }
```
上面的代码通过 go r.recordWorker() 创建了 由poolSize 指定个数的recordWorker（worker），recordWorker 函数会从 recordsChan 中读取授权日志并存入 recordsBuffer 中，recordsBuffer 的大小为 workerBufferSize，workerBufferSize 计算公式为：


```go
ps := options.PoolSize
recordsBufferSize := options.RecordsBufferSize
workerBufferSize := recordsBufferSize / uint64(ps)
```
其中，options.PoolSize 由命令行参数 --analytics.pool-size 指定，代表 worker 的个数，默认 50；options.RecordsBufferSize 由命令行参数 --analytics.records-buffer-size 指定，代表缓存的授权日志消息数。也就是说，我们把缓存的记录平均分配给所有的 worker。


当 recordsBuffer 存满或者达到投递最大时间后，调用 r.Store.AppendToSetPipelined(analyticsKeyName, recordsBuffer) 将记录批量发送给 Redis，为了提高传输速率，这里将日志内容编码为 msgpack 格式后再传输。


上面的缓存方法可以抽象成一个缓存模型，满足实际开发中的大部分需要异步转存的场景，如下图所示：


![img](https://static001.geekbang.org/resource/image/47/95/479fyy2cd16a6c1fa5f6074f7ce6fe95.jpg?wh=2248x668)

Producer 将数据投递到带缓冲的 channel 中，后端有多个 worker 消费 channel 中的数据，并进行批量投递。你可以设置批量投递的条件，**一般至少包含最大投递日志数和最大投递时间间隔这两个。**

通过以上缓冲模型，你可以将日志转存的时延降到最低。



#### 数据一致性
上面介绍了 iam-authz-server 的 /v1/authz 接口，为了最大化地提高性能，采用了大量的缓存设计。因为数据会分别在持久化存储和内存中都存储一份，就可能会出现数据不一致的情况。所以，我们也要确保缓存中的数据和数据库中的数据是一致的。数据一致性架构如下图所示：


![img](https://static001.geekbang.org/resource/image/72/a4/72c2afe63d197e7335deec1ac9f550a4.jpg?wh=2248x1006)

密钥和策略同步流程如下：


1. 通过 iam-webconsole 请求 iam-apiserver 创建（或更新、删除）密钥（或策略）。
2. iam-apiserver 收到“写”请求后，会向 Redis iam.cluster.notifications channel 发送 PolicyChanged 或 SecretChanged 消息。
3. Loader 收到消息后，会触发 cache loader 实例执行 Reload 方法，重新从 iam-apiserver 中同步密钥和策略信息。

Loader 不会关心 Reload 方法的具体实现，只会在收到指定消息时，执行 Reload 方法。通过这种方式，我们可以实现不同的缓存策略。


在 cache 实例的 Reload 方法中，我们其实是调用仓库层 Secret 和 Policy 的 List 方法来获取密钥和策略列表。仓库层又是通过执行 gRPC 请求，从 iam-apiserver 中获取密钥和策略列表。

cache 的Reload方法，会将获取到的密钥和策略列表缓存在ristretto类型的 Cache 中，供业务层调用。业务层代码位于internal/authzserver/authorization目录下。



### 总结
这一讲中，我介绍了 IAM 数据流服务 iam-authz-server 的设计和实现。iam-authz-server 提供了 /v1/authz RESTful API 接口，供第三方用户完成资源授权功能，具体是使用 Ladon 包来完成资源授权的。Ladon 包解决了“在特定的条件下，谁能够 / 不能够对哪些资源做哪些操作”的问题。


iam-authz-server 的配置处理、启动流程和请求处理流程跟 iam-apiserver 保持一致。此外，iam-authz-server 也实现了简洁架构。iam-authz-server 通过缓存密钥和策略信息、缓存授权日志来提高 /v1/authz 接口的性能。

在缓存密钥和策略信息时，为了和 iam-apiserver 中的密钥和策略信息保持一致，使用了 Redis Pub/Sub 机制。当 iam-apiserver 有密钥 / 策略变更时，会往指定的 Redis channel Pub 一条消息。iam-authz-server 订阅相同的 channel，在收到新消息时，会解析消息，并重新从 iam-apiserver 中获取密钥和策略信息，缓存在内存中。

iam-authz-server 执行完资源授权之后，会将授权日志存放在一个带缓冲的 channel 中。后端有多个 worker 消费 channel 中的数据，并进行批量投递。可以设置批量投递的条件，例如最大投递日志数和最大投递时间间隔。

## 32 | 数据处理：如何高效处理应用程序产生的数据？
我们来聊聊，如何更好地进行异步数据处理。一个大型应用为了后期的排障、运营等，会将一些请求数据保存在存储系统中，供日后使用。例如：应用将请求日志保存到 Elasticsearch 中，方便排障；网关将 API 请求次数、请求消息体等数据保存在数据库中，供控制台查询展示。为了满足这些需求，我们需要进行数据采集，数据采集在大型应用中很常见，但我发现不少开发者设计的数据采集服务，通常会存在下面这些问题：

- 采集服务只针对某个采集需求开发，如果采集需求有变，需要修改主代码逻辑，代码改动势必会带来潜在的 Bug，增加开发测试工作量。
- 数据采集服务会导致已有的服务请求延时变高。
- 采集数据性能差，需要较长时间才能采集完一批数据。
- 启停服务时，会导致采集的数据丢失。


这一讲，我就来详细教你如何设计和落地一个数据采集服务，解决上面这些问题。



### 数据采集方式的分类
首先，你需要知道当前数据采集有哪些方式，以便更好地理解异步数据处理方案。


目前，数据采集主要有两种方式，分别是同步采集和异步采集。二者的概念和优缺点如下表所示：


![img](https://static001.geekbang.org/resource/image/d4/b9/d4d4d6547225de5b565f99957106dbb9.jpg?wh=1920x1058)

现代应用对性能的要求越来越高，而异步采集对应用程序的性能影响更小，因此异步采集更受开发者欢迎，得到了大规模的应用。接下来，我要介绍的 IAM Pump Server 服务，采用的就是异步采集的方式。


### 数据采集系统设计
这一讲，我采用**理论 + 实战的方式来展示如何设计一个数据采集服务**，这里先来介绍下关于数据采集的理论知识，后面会有具体的实战案例。


在过往的项目开发中，我发现很多开发人员添加了数据采集功能后，因为同步上报数据、单线程、上报逻辑不对等原因，让整个应用程序的性能受到了严重影响。那么，如何在采集过程中不影响程序的性能？答案就是让数据采集模型化。通过模型化，可以使设计出来的采集系统功能更加通用，能够满足未来的很多同类需求，我们也就不需要重复开发相同的系统了。我今天就来给你详细介绍下，**如何将数据采集功能模型化，以及该模型是如何解决上面说的的各种问题的。**



#### 设计数据采集系统时需要解决的核心问题
采集系统首先需要一个数据源 Input，Input 可以是一个或者多个，Input 中的数据来自于应用程序上报。采集后的数据通常需要经过处理，比如格式化、增删字段、过滤无用的数据等，然后将处理后的数据存储到下游系统（Output）中，如下图所示：


![img](https://static001.geekbang.org/resource/image/a9/75/a91db8c7818af0898a1774073e9bfe75.jpg?wh=1920x1145)


这里，我们需要解决这 3 个核心问题：
- 进行数据采集，就需要在正常流程中多加一个上报数据环节，这势必会影响程序的性能。那么，如何让程序的性能损失最小化？
- 如果 Input 产生数据的速度大于 Output 的消费能力，产生数据堆积怎么办？
- 数据采集后需要存储到下游系统。在存储之前，我们需要对数据进行不同的处理，并可能会存储到不同的下游系统，这种可变的需求如何满足？


对于让程序性能损失最小化这一点，最好的方法是异步上报。如果是异步，我们需要先把数据缓存在内存中，然后再异步上报到目标系统中。当然，为了提高上报的效率，可以采用批量上报的方式。对于数据堆积这个问题，比较好的解决方法是，将采集的数据先上报到一些具有高吞吐量、可以存储大量数据的中间组件，比如 Kafka、Redis 中。这种方式也是业界标准的处理方式。对于采集需求多样化这个问题，我们可以将采集程序做成插件化、可扩展的，满足可变的需求。要解决这 3 个问题，其实就涉及到了数据采集系统中的两个功能点的设计，它们分别是数据上报功能和数据采集功能。接下来我们就来看下，如何设计这两个功能点。



#### 数据上报功能设计
为了提高异步上报的吞吐量，你可以将数据缓存在内存中（Go 中可以使用有缓冲 channel），并使用多个 worker 去消费内存中的数据。使用多个 worker ，可以充分发挥 CPU 的多核能力。另外，上报给下游系统时，你也可以采用批量上报的方式。


#### 数据采集功能设计
现代应用程序越来越讲究插件化、扩展性，在设计采集系统时，也应该考虑到未来的需求。比如，未来你可能需要将数据从上报到 MongoDB 切换到 HBase 中，或者同时将数据上报到 MongoDB 和 HBase 中。因此，上报给下游的程序逻辑要具有插件化的能力，并能通过配置选择需要的插件。


为了提高程序性能，会先把数据缓存在内存中。但是这样有个缺点：在关停程序时，内存中的数据就会丢失。所以，在程序结束之前，我们需要确保内存中的数据能够上报成功，也就是说采集程序需要实现优雅关停功能。优雅关停不仅要确保缓存中的数据被成功上报，还要确保正在处理的数据被成功上报。当然了，既然是数据采集，还要能够配置采集的频率。最后，因为采集程序通常是非 API 类型的，所以还需要对外暴露一个特殊的 API，用来返回采集程序的健康状态。


#### 数据采集应用模型
通过上面的分析和设计，可以绘制出下面这个采集模型：


![img](https://static001.geekbang.org/resource/image/2e/34/2ecccdb3c851577f9cd5a56bb7197c34.jpg?wh=1920x910)

异步上报需要额外的异步逻辑，会增加开发工作量和程序复杂度，所以，对于一些 Input 数据生产速度小于 Output 消费速度，并且 Output 具有高吞吐量、低延时特性的场景，也可以采用同步上报，例如同步上报给 Redis。


### 数据采集系统落地项目：iam-authz-server + iam-pump
上面，我介绍了数据采集系统的架构，但是只有模型和理论，肯定还不足以解决你对数据采集程序的开发需求。所以，接下来我来介绍下如何落地上面的数据采集架构。整个架构包括两个部分，分别由不同的服务实现：


iam-authz-server：实现数据上报功能。iam-pump：实现数据采集功能。



整个采集系统的架构，跟上面描述的数据采集架构完全一致，这里就不重复说明了。



#### iam-authz-server：数据上报
数据上报的最大难点，就是如何减少上报逻辑对应用性能的影响。对此，我们主要的解决思路就是异步上报数据。


接下来我会介绍 iam-authz-server 的数据上报设计。这是一个非常成熟的设计，在我所开发和了解的项目中被大量采用，有些项目可以承载十亿级 / 天的请求量。通过介绍这个设计，我们来看看异步上报的具体方法，以及上报过程中要考虑的因素。iam-authz-server 的数据上报架构如下图所示：


![img](https://static001.geekbang.org/resource/image/4d/3f/4d288a15fa6ebaae5ef25df8af5ac13f.jpg?wh=1920x764)

iam-authz-server 服务中的数据上报功能可以选择性开启，开启代码见 internal/authzserver/server.go ，代码如下：



```go
 if s.analyticsOptions.Enable {                                           
        analyticsStore := storage.RedisCluster{KeyPrefix: RedisKeyPrefix}              
        analyticsIns := analytics.NewAnalytics(s.analyticsOptions, &analyticsStore)    
        analyticsIns.Start()                                                   
        s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {    
            analyticsIns.Stop()    
                          
            return nil    
        }))    
    }     
```
上面的代码中，当 s.analyticsOptions.Enable 为 true 时，开启数据上报功能。因为数据上报会影响程序的性能，而且在未来可能会存在禁掉数据上报功能的场景，所以在设计 iam-authz-server 时，就把数据上报功能做成了可配置的，也就是说可以通过配置文件来启用 / 禁用数据上报功能。配置方式也很简单：将 iam-authz-server.yaml 的 analytics.enable 设置为 true，代表开启数据上报功能；设置为 false ，则代表关闭数据上报功能。


这里，我建议你在设计程序时，将未来的可能变量考虑进去，并将这些变量做成可配置的。这样，如果哪天需求变化，我们就能通过修改配置文件，而不是修改代码的方式来满足需求。这种方式可以将应用程序的变动局限在配置文件中，从而大大减小现网服务出现故障的概率，做到只变更配置文件就可以缩短发布变更的周期。

在上面的代码中，通过 NewAnalytics 创建一个数据上报服务，代码如下：


```go
func NewAnalytics(options *AnalyticsOptions, store storage.AnalyticsHandler) *Analytics {                              
    ps := options.PoolSize                                                                                             
    recordsBufferSize := options.RecordsBufferSize                                                                     
    workerBufferSize := recordsBufferSize / uint64(ps)                                                                 
    log.Debug("Analytics pool worker buffer size", log.Uint64("workerBufferSize", workerBufferSize))                   
                                                                                                                       
    recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)                                                      
                                                                                                                       
    return &Analytics{                                                                                                 
        store:                      store,                                                                             
        poolSize:                   ps,                                                                                
        recordsChan:                recordsChan,                                                                       
        workerBufferSize:           workerBufferSize,                                                                  
        recordsBufferFlushInterval: options.FlushInterval,                                                             
    }                                                                                                                  
}      
```
这里的代码根据传入的参数，创建 Analytics 类型的变量并返回，变量中有 5 个字段需要你关注：

- store： storage.AnalyticsHandler 接口类型，提供了 Connect() bool和 AppendToSetPipelined(string, byte)函数，分别用来连接 storage 和上报数据给 storage。iam-authz-server 用了 redis storage。
- recordsChan：授权日志会缓存在 recordsChan 带缓冲 channel 中，其长度可以通过 iam-authz-server.yaml 配置文件中的 analytics.records-buffer-size 配置。
- poolSize：指定开启 worker 的个数，也就是开启多少个 Go 协程来消费 recordsChan 中的消息。
- workerBufferSize：批量投递给下游系统的的消息数。通过批量投递，可以进一步提高消费能力、减少 CPU 消耗。
- recordsBufferFlushInterval：设置最迟多久投递一次，也就是投递数据的超时时间。


analytics.ecords-buffer-size 和 analytics.pool-size 建议根据部署机器的 CPU 和内存来配置。在应用真正上线前，我建议你通过压力和负载测试，来配置一个合适的值。


Analytics 提供了 3 种方法：
- Start()，用来启动数据上报服务。
- Stop()，用来关停数据上报服务。主程序在收到系统的终止命令后，调用 Stop 方法优雅关停数据上报服务，确保缓存中的数据都上报成功。
- RecordHit(record *AnalyticsRecord) error，用来记录 AnalyticsRecord 的数据。


通过 NewXxx （NewAnalytics）返回一个 Xxx （Analytics）类型的结构体，Xxx（Analytics） 类型带有一些方法，如下：


```go
func NewAnalytics(options) *Analytics {
    ...
}

func (r *Analytics) Start() {
    ...
}
func (r *Analytics) Stop() {
    ...
}
func (r *Analytics) RecordHit(record *AnalyticsRecord) error {
    ...
}
```
其实，上述代码段是一种常见的 Go 代码编写方式 / 设计模式。你在以后的开发生涯中，会经常遇到这种设计方式。使用上述代码设计方式有下面两个好处。


- 功能模块化：将数据上报的功能封装成一个服务模块，数据和方法都围绕着 Xxx 结构体来展开。这和 C++、Java、Python 的类有相似的地方，你可以这么理解：Xxx 相当于类，NewXxx 相当于初始化一个类实例，Start、Stop、RecordHit 是这个类提供的方法。功能模块化可以使程序逻辑更加清晰，功能更独立、更好维护，也可以供其他应用使用。
- 方便数据传递：可以将数据存放在 Xxx 结构体字段中，供不同的方法共享使用，如果有并发，数据共享时，注意要给非并发安全的类型加锁，例如 recordsChan。


接下来，我会介绍 iam-authz-server 服务中跟数据上报相关的 3 部分核心代码，分别是启动数据上报服务、异步上报授权日志和优雅关停数据上报。


#### 启动服务：启动数据上报服务
在服务启动时，首先要启动数据上报功能模块。我们通过调用 analyticsIns.Start() 启动数据上报服务。Start 代码如下：


```go
func (r *Analytics) Start() {
    analytics = r
    r.store.Connect()

    // start worker pool
    atomic.SwapUint32(&r.shouldStop, 0)
    for i := 0; i < r.poolSize; i++ {
        r.poolWg.Add(1)
        go r.recordWorker()
    }

    // stop analytics workers
    go r.Stop()
}
```
这里有一点需要你注意，数据上报和数据采集都大量应用了 Go 协程来并发地执行操作，为了防止潜在的并发读写引起的 Bug，建议你的测试程序编译时加上 -race，例如 go build -race cmd/iam-authz-server/authzserver.go。然后，在测试过程中，观察程序日志，看有无并发问题出现。

Start 中会开启 poolSize 个数的 worker 协程，这些协程共同消费 recordsChan 中的消息，消费逻辑见 recordWorker() ，代码如下：


```go
func (r *Analytics) recordWorker() {
  defer r.poolWg.Done()

  // this is buffer to send one pipelined command to redis
  // use r.recordsBufferSize as cap to reduce slice re-allocations
  recordsBuffer := make([][]byte, 0, r.workerBufferSize)

  // read records from channel and process
  lastSentTS := time.Now()
  for {
    readyToSend := false
    select {
    case record, ok := <-r.recordsChan:
      // check if channel was closed and it is time to exit from worker
      if !ok {
        // send what is left in buffer
        r.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)
        return
      }

      // we have new record - prepare it and add to buffer

      if encoded, err := msgpack.Marshal(record); err != nil {
        log.Errorf("Error encoding analytics data: %s", err.Error())
      } else {
        recordsBuffer = append(recordsBuffer, encoded)
      }

      // identify that buffer is ready to be sent
      readyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize

    case <-time.After(r.recordsBufferFlushInterval):
      // nothing was received for that period of time
      // anyways send whatever we have, don't hold data too long in buffer
      readyToSend = true
    }

    // send data to Redis and reset buffer
    if len(recordsBuffer) > 0 && (readyToSend || time.Since(lastSentTS) >= recordsBufferForcedFlushInterval) {
      r.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)
      recordsBuffer = recordsBuffer[:0]
      lastSentTS = time.Now()
    }
  }
}
```
recordWorker 函数会将接收到的授权日志保存在 recordsBuffer 切片中，当数组内元素个数为 workerBufferSize ，或者距离上一次投递时间间隔为 recordsBufferFlushInterval 时，就会将 recordsBuffer 数组中的数据上报给目标系统（Input）。


recordWorker() 中有些设计技巧，很值得你参考。

- 使用 msgpack 序列化消息：msgpack 是一个高效的二进制序列化格式。它像 JSON 一样，让你可以在各种语言之间交换数据。但是它比 JSON 更快、更小。
- 支持 Batch Windows：当 worker 的消息数达到指定阈值时，会批量投递消息给 Redis，阈值判断代码为readyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize。
- 超时投递：为了避免因为产生消息太慢，一直达不到 Batch Windows，无法投递消息这种情况，投递逻辑也支持超时投递，通过 case <-time.After(r.recordsBufferFlushInterval)代码段实现。
- 支持优雅关停：当 recordsChan 关闭时，将 recordsBuffer 中的消息批量投递给 Redis，之后退出 worker 协程。


这里有个注意事项：投递完成后，你需要重置 recordsBuffer 和计时器，否则会重复投递数据：


```go
recordsBuffer = recordsBuffer[:0]
lastSentTS = time.Now()
```
这里还设置了一个最大的超时时间 recordsBufferForcedFlushInterval，确保消息最迟被投递的时间间隔。也就是说， iam-authz-server 强制要求最大投递间隔为 recordsBufferForcedFlushInterval 秒，这是为了防止配置文件将 recordsBufferFlushInterval 设得过大。

#### 运行服务：异步上报授权日志
开启了数据上报服务后，当有授权日志产生时，程序就会自动上报数据。接下来，我会详细介绍下如何高效上报数据。

iam-authz-server 会在授权成功时调用 LogGrantedAccessRequest 函数，在授权失败时调用 LogRejectedAccessRequest 函数。并且，在这两个函数中，调用 RecordHit 函数，记录授权日志。iam-authz-server 通过调用 RecordHit(record *AnalyticsRecord) error 函数，异步缓存授权日志。调用 RecordHit 后，会将 AnalyticsRecord 类型的消息存放到 recordsChan 有缓冲 channel 中。

这里要注意：在缓存前，需要判断上报服务是否在优雅关停中，如果在关停中，则丢弃该消息：

```go
if atomic.LoadUint32(&r.shouldStop) > 0 {
    return nil
}
```
通过将授权日志缓写入 recordsChan 有缓冲 channel 中，LogGrantedAccessRequest 和 LogRejectedAccessRequest 函数可以不用等待授权日志上报成功就返回，这样就使得整个授权请求的性能损耗几乎为零。



#### 关停服务：优雅关停数据上报
完成数据上报之后的下一步，就是要优雅地将数据上报关停。为了确保在应用关停时，缓存中的数据和正在投递中的数据都能够投递到 Redis，iam-authz-server 实现了数据上报关停功能，代码如下：


```go
gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {
    analyticsIns.Stop()
    return nil
}))
```
当收到 os.Interrupt 和 syscall.SIGTERM 系统信号后，调用 analyticsIns.Stop() 函数，关停数据上报服务， Stop 函数会停止接收新的授权日志，并等待正在上报的数据上报完成。上面我介绍了数据上报部分的功能设计，接下来，我来介绍下数据采集部分的功能设计。

### iam-pump：数据采集
iam-authz-server 将数据上报到 Redis，iam-pump 消费 Redis 中的数据，并保存在 MongoDB 中做持久化存储。

iam-pump 的设计要点是：插件化、可配置地将 Redis 中的数据处理后存储到下游系统中，并且实现优雅关停功能，这些也是设计数据采集程序的要点和难点所在。下面，我们就来看下 iam-pump 是如何插件化地实现一个数据采集程序的。这个数据采集程序的设计思路，在我开发的大型企业应用中有实际的落地验证，你可以放心使用。


iam-pump 数据采集架构如下图所示：


![img](https://static001.geekbang.org/resource/image/91/ed/913b92d58cfd7cba0dff26612be9e9ed.jpg?wh=1920x1129)

在 iam-pump 服务启动时，要启动数据采集功能，启动代码见 internal/pump/server.go。接下来，我会介绍下 iam-pump 服务中的 5 部分核心代码：


数据采集插件定义。初始化数据采集插件。健康检查。启动 Loop 周期性消费 Redis 数据。优雅关停数据采集服务。


#### 初始化服务：数据采集插件定义
数据采集组件设计的核心是插件化，这里我将需要上报的系统抽象成一个个的 pump，那么如何定义 pump 接口呢？接口定义需要参考实际的采集需求，通常来说，至少需要下面这几个函数。


- New：创建一个 pump。
- Init：初始化一个 pump，例如，可以在 Init 中创建下游系统的网络连接。
- WriteData：往下游系统写入数据。为了提高性能，最好支持批量写入。
- SetFilters：设置是否过滤某条数据，这也是一个非常常见的需求，因为不是所有的数据都是需要的。
- SetTimeout：设置超时时间。我就在开发过程中遇到过一个坑，连接 Kafka 超时，导致整个采集程序超时。所以这里需要有超时处理，通过超时处理，可以保证整个采集框架正常运行。

我之前开发过公有云的网关服务，网关服务需要把网关的请求数据转存到 MongoDB 中。我们的网关服务曾经遇到一个比较大的坑：有些用户会通过网关上传非常大的文件（百 M 级别），这些数据转存到 MongoDB 中，快速消耗了 MongoDB 的存储空间（500G 存储空间）。为了避免这个问题，在转存数据时，需要过滤掉一些比较详细的数据，所以 iam-pump 添加了 SetOmitDetailedRecording 来过滤掉详细的数据。


所以，最后 iam-pump 的插件接口定义为 internal/pump/pumps/pump.go ：


```go
type Pump interface {
  GetName() string
  New() Pump
  Init(interface{}) error
  WriteData(context.Context, []interface{}) error
  SetFilters(analytics.AnalyticsFilters)
  GetFilters() analytics.AnalyticsFilters
  SetTimeout(timeout int)
  GetTimeout() int
  SetOmitDetailedRecording(bool)
  GetOmitDetailedRecording() bool
}
```
你在实际开发中，如果有更多的需求，可以在 Pump interface 定义中继续添加需要的处理函数。



#### 初始化服务：初始化数据采集插件
定义好插件之后，需要初始化插件。在 initialize 函数中初始化 pumps：


```go
func (s *pumpServer) initialize() {
  pmps = make([]pumps.Pump, len(s.pumps))
  i := 0
  for key, pmp := range s.pumps {
    pumpTypeName := pmp.Type
    if pumpTypeName == "" {
      pumpTypeName = key
    }

    pmpType, err := pumps.GetPumpByName(pumpTypeName)
    if err != nil {
      log.Errorf("Pump load error (skipping): %s", err.Error())
    } else {
      pmpIns := pmpType.New()
      initErr := pmpIns.Init(pmp.Meta)
      if initErr != nil {
        log.Errorf("Pump init error (skipping): %s", initErr.Error())
      } else {
        log.Infof("Init Pump: %s", pmpIns.GetName())
        pmpIns.SetFilters(pmp.Filters)
        pmpIns.SetTimeout(pmp.Timeout)
        pmpIns.SetOmitDetailedRecording(pmp.OmitDetailedRecording)
        pmps[i] = pmpIns
      }
    }
    i++
  }
}
```
initialize 会创建、初始化，并调用 SetFilters、SetTimeout、SetOmitDetailedRecording 来设置这些 pump。Filters、Timeout、OmitDetailedRecording 等信息在 pump 的配置文件中指定。


这里有个技巧你也可以注意下：pump 配置文件支持通用的配置，也支持自定义的配置，配置结构为 PumpConfig ：

```go
type PumpConfig struct {
  Type                  string
  Filters               analytics.AnalyticsFilters
  Timeout               int
  OmitDetailedRecording bool
  Meta                  map[string]interface{}
}
```
pump 自定义的配置可以存放在 map 类型的变量 Meta 中。通用配置可以使配置共享，减少开发和维护工作量，自定义配置可以适配不同 pump 的差异化配置。


#### 初始化服务：健康检查
因为 iam-pump 是一个非 API 服务，为了监控其运行状态，这里也设置了一个健康检查接口。iam-pump 组件通过调用 server.ServeHealthCheck 函数启动一个 HTTP 服务，ServeHealthCheck 函数代码如下：


```go
func ServeHealthCheck(healthPath string, healthAddress string) {
  http.HandleFunc("/"+healthPath, func(w http.ResponseWriter, r *http.Request) {
    w.Header().Set("Content-type", "application/json")
    w.WriteHeader(http.StatusOK)
    _, _ = w.Write([]byte(`{"status": "ok"}`))
  })

  if err := http.ListenAndServe(healthAddress, nil); err != nil {
    log.Fatalf("Error serving health check endpoint: %s", err.Error())
  }
}
```
该函数启动了一个 HTTP 服务，服务监听地址通过 health-check-address 配置，健康检查路径通过 health-check-path 配置。如果请求 http:///返回{"status": "ok"}，说明 iam-pump 可以正常工作。

这里的健康检查只是简单返回了一个字符串，实际开发中，可以封装更复杂的逻辑。比如，检查进程是否可以成功 ping 通数据库，进程内的工作进程是否处于 worker 状态等。

iam-pump 默认的健康检查请求地址为http://127.0.0.1:7070/healthz 。



#### 运行服务：启动 Loop 周期性消费 Redis 数据
初始化 pumps 之后，就可以通过 Run 函数启动消费逻辑了。在 Run 函数中，会定期（通过配置 purge-delay 设置轮训时间）从 Redis 中获取所有数据，经过 msgpack.Unmarshal 解压后，传给 writeToPumps 处理：



```go
func (s preparedPumpServer) Run(stopCh <-chan struct{}) error {
  ticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)
  defer ticker.Stop()

  for {
    select {
    case <-ticker.C:
      analyticsValues := s.analyticsStore.GetAndDeleteSet(storage.AnalyticsKeyName)
      if len(analyticsValues) > 0 {
        // Convert to something clean
        keys := make([]interface{}, len(analyticsValues))

        for i, v := range analyticsValues {
          decoded := analytics.AnalyticsRecord{}
          err := msgpack.Unmarshal([]byte(v.(string)), &decoded)
          log.Debugf("Decoded Record: %v", decoded)
          if err != nil {
            log.Errorf("Couldn't unmarshal analytics data: %s", err.Error())
          } else {
            if s.omitDetails {
              decoded.Policies = ""
              decoded.Deciders = ""
            }
            keys[i] = interface{}(decoded)
          }
        }

        // Send to pumps
        writeToPumps(keys, s.secInterval)
      }
    // exit consumption cycle when receive SIGINT and SIGTERM signal
    case <-stopCh:
      log.Info("stop purge loop")

      return nil
    }
  }
}
```
writeToPumps 函数通过调用 execPumpWriting 函数，异步调用 pump 的 WriteData 函数写入数据。execPumpWriting 函数中有一些设计技巧，你可以注意下这两个：
- 将一些通用的处理，例如 Filters、Timeout、OmitDetailedRecording 放在 pump 之外处理，这样可以减少 pump 中代码的重复性。
- 优雅关停。通过如下代码实现优雅关停功能：


```go
select {
    case <-stopCh:
        log.Info("stop purge loop")
        return
    default:
}
```
上面的代码需要放在 writeToPumps 之后，这样可以确保所有数据都成功写入 pumps 之后，再停止采集逻辑。


#### 关停服务：优雅关停数据采集服务
在关停服务时，为了确保正在处理的数据被成功存储，还需要提供优雅关停功能。iam-pump 通过 channel 传递 SIGINT 和 SIGTERM 信号，当消费逻辑收到这两个信号后，会退出消费循环，见 Run 函数。代码如下：


```go
func (s preparedPumpServer) Run(stopCh <-chan struct{}) error {    
    ticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)    
    defer ticker.Stop()                                                     
    
    for {    
        select {    
        case <-ticker.C:    
         // 消费逻辑
         ...
        // exit consumption cycle when receive SIGINT and SIGTERM signal
        case <-stopCh:    
            log.Info("stop purge loop")    
    
            return nil
        }
    }
}
```
### 总结
这一讲，我主要介绍了如何将数据采集需求转化成一个数据采集模型，并从这个模型出发，设计出一个可扩展、高性能的数据采集服务，并通过 iam-pump 组件来落地该采集模型。最后，我还想给你一个建议：在开发中，你也可以将一些功能抽象成一些通用的模型，并为该模型实现基本框架（引擎），然后将一些需要定制化的部分插件化。通过这种方式，可以设计出一个高扩展的服务，使得服务不仅能够满足现在的需求，还能够满足未来的需求。

## 33 | SDK 设计（上）：如何设计出一个优秀的 Go SDK？

后端服务通过 API 接口对外提供应用的功能，但是用户直接调用 API 接口，需要编写 API 接口调用的逻辑，并且需要构造入参和解析返回的数据包，使用起来效率低，而且有一定的开发工作量。


在实际的项目开发中，通常会提供对开发者更友好的 SDK 包，供客户端调用。很多大型服务在发布时都会伴随着 SDK 的发布，例如腾讯云很多产品都提供了 SDK：


![img](https://static001.geekbang.org/resource/image/e1/fa/e1bb8eb03c2f26f546710e95751c17fa.png?wh=1920x747)

既然 SDK 如此重要，那么如何设计一个优秀的 Go SDK 呢？这一讲我就来详细介绍一下。


### 什么是 SDK？首先，我们来看下什么是 SDK。

对于 SDK（Software Development Kit，软件开发工具包），不同场景下有不同的解释。但是对于一个 Go 后端服务来说，SDK 通常是指**封装了 Go 后端服务 API 接口的软件包**，里面通常包含了跟软件相关的库、文档、使用示例、封装好的 API 接口和工具。


调用 SDK 跟调用本地函数没有太大的区别，所以可以极大地提升开发者的开发效率和体验。SDK 可以由服务提供者提供，也可以由其他组织或个人提供。为了鼓励开发者使用其系统或语言，SDK 通常都是免费提供的。


通常，服务提供者会提供不同语言的 SDK，比如针对 Python 开发者会提供 Python 版的 SDK，针对 Go 开发者会提供 Go 版的 SDK。一些比较专业的团队还会有 SDK 自动生成工具，可以根据 API 接口定义，自动生成不同语言的 SDK。例如，Protocol Buffers 的编译工具 protoc，就可以基于 Protobuf 文件生成 C++、Python、Java、JavaScript、PHP 等语言版本的 SDK。阿里云、腾讯云这些一线大厂，也可以基于 API 定义，生成不同编程语言的 SDK。



### SDK 设计方法
那么，我们如何才能设计一个好的 SDK 呢？对于 SDK，不同团队会有不同的设计方式，我调研了一些优秀 SDK 的实现，发现这些 SDK 有一些共同点。根据我的调研结果，结合我在实际开发中的经验，我总结出了一套 SDK 设计方法，接下来就分享给你。


### 如何给 SDK 命名？
在讲设计方法之前，我先来介绍两个重要的知识点：SDK 的命名方式和 SDK 的目录结构。SDK 的名字目前没有统一的规范，但比较常见的命名方式是 xxx-sdk-go / xxx-sdk-python / xxx-sdk-java 。其中， xxx 可以是项目名或者组织名，例如腾讯云在 GitHub 上的组织名为 tencentcloud，那它的 SDK 命名如下图所示：


![img](https://static001.geekbang.org/resource/image/e2/1e/e269d5d0e19a73d45ccdf5f5561c611e.png?wh=1210x863)

### SDK 的目录结构
不同项目 SDK 的目录结构也不相同，但一般需要包含下面这些文件或目录。目录名可能会有所不同，但目录功能是类似的。


- README.md：SDK 的帮助文档，里面包含了安装、配置和使用 SDK 的方法。
- examples/sample/：SDK 的使用示例。
- sdk/：SDK 共享的包，里面封装了最基础的通信功能。如果是 HTTP 服务，基本都是基于 net/http 包进行封装。
- api：如果 xxx-sdk-go 只是为某一个服务提供 SDK，就可以把该服务的所有 API 接口封装代码存放在 api 目录下。
- services/{iam, tms} ：如果 xxx-sdk-go 中， xxx 是一个组织，那么这个 SDK 很可能会集成该组织中很多服务的 API，就可以把某类服务的 API 接口封装代码存放在 services/<服务名>下，例如 AWS 的[Go SDK](https://github.com/aws/aws-sdk-go/tree/main/service)。

一个典型的目录结构如下：


```
├── examples            # 示例代码存放目录
│   └── authz.go
├── README.md           # SDK使用文档
├── sdk                 # 公共包，封装了SDK配置、API请求、认证等代码
│   ├── client.go
│   ├── config.go
│   ├── credential.go
│   └── ...
└── services            # API封装
    ├── common
    │   └── model
    ├── iam             # iam服务的API接口
    │   ├── authz.go
    │   ├── client.go
    │   └── ...
    └── tms             # tms服务的API接口
```
### SDK 设计方法
SDK 的设计方法如下图所示：


![img](https://static001.geekbang.org/resource/image/9f/ca/9fb7aa8d3da4210223e9b0c87943e8ca.jpg?wh=1920x841)

我们可以通过 Config 配置创建客户端 Client，例如 func NewClient(config sdk.Config) (Client, error)，配置中可以指定下面的信息。
- 服务的后端地址：服务的后端地址可以通过配置文件来配置，也可以直接固化在 SDK 中，推荐后端服务地址可通过配置文件配置。
- 认证信息：最常用的认证方式是通过密钥认证，也有一些是通过用户名和密码认证。
- 其他配置：例如超时时间、重试次数、缓存时间等。


创建的 Client 是一个结构体或者 Go interface。这里我建议你使用 interface 类型，这样可以将定义和具体实现解耦。Client 具有一些方法，例如 CreateUser、DeleteUser 等，每一个方法对应一个 API 接口，下面是一个 Client 定义：

```go
type Client struct {
    client *sdk.Request
}

func (c *Client) CreateUser(req *CreateUserRequest) (*CreateUserResponse, error) {
    // normal code
    resp := &CreateUserResponse{}
    err := c.client.Send(req, resp)
    return resp, err
}

```
调用 client.CreateUser(req) 会执行 HTTP 请求，在 req 中可以指定 HTTP 请求的方法 Method、路径 Path 和请求 Body。 CreateUser 函数中，会调用 c.client.Send(req) 执行具体的 HTTP 请求。


c.client 是 *Request 类型的变量， *Request 类型的变量具有一些方法，可以根据传入的请求参数 req 和 config 配置构造出请求路径、认证头和请求 Body，并调用 net/http 包完成最终的 HTTP 请求，最后将返回结果 Unmarshal 到传入的 resp 结构体中。


根据我的调研，目前有两种 SDK 设计方式可供参考，一种是各大公有云厂商采用的 SDK 设计方式，一种是 Kubernetes client-go 的设计方式。IAM 项目分别实现了这两种 SDK 设计方式，但我还是更倾向于对外提供 client-go 方式的 SDK，我会在下一讲详细介绍它。这两种设计方式的设计思路跟上面介绍的是一致的。


### 公有云厂商采用的 SDK 设计方式
这里，我先来简单介绍下公有云厂商采用的 SDK 设计模式。SDK 架构如下图所示：


![img](https://static001.geekbang.org/resource/image/82/ce/82ebe90b0490b9a2a76e2f302dd896ce.jpg?wh=1920x866)

SDK 框架分为两层，分别是 API 层和基础层。API 层主要用来构建客户端实例，并调用客户端实例提供的方法来完成 API 请求，每一个方法对应一个 API 接口。API 层最终会调用基础层提供的能力，来完成 REST API 请求。基础层通过依次执行构建请求参数（Builder）、签发并添加认证头（Signer）、执行 HTTP 请求（Request）三大步骤，来完成具体的 REST API 请求。


为了让你更好地理解公有云 SDK 的设计方式，接下来我会结合一些真实的代码，给你讲解 API 层和基础层的具体设计，SDK 代码见medu-sdk-go。



### API 层：创建客户端实例
客户端在使用服务 A 的 SDK 时，首先需要根据 Config 配置创建一个服务 A 的客户端 Client，Client 实际上是一个 struct，定义如下：


```go
type Client struct {
    sdk.Client
}
```
在创建客户端时，需要传入认证（例如密钥、用户名 / 密码）、后端服务地址等配置信息。例如，可以通过NewClientWithSecret方法来构建一个带密钥对的客户端：


```go
func NewClientWithSecret(secretID, secretKey string) (client *Client, err error) {
    client = &Client{}
    config := sdk.NewConfig().WithEndpoint(defaultEndpoint)
    client.Init(serviceName).WithSecret(secretID, secretKey).WithConfig(config)
    return
}
```
这里要注意，上面创建客户端时，传入的密钥对最终会在基础层中被使用，用来签发 JWT Token。


Client 有多个方法（Sender），例如 Authz 等，每个方法代表一个 API 接口。Sender 方法会接收 AuthzRequest 等结构体类型的指针作为输入参数。我们可以调用 client.Authz(req) 来执行 REST API 调用。可以在 client.Authz 方法中添加一些业务逻辑处理。client.Authz 代码如下：


```go
type AuthzRequest struct {
    *request.BaseRequest
    Resource *string `json:"resource"`
    Action *string `json:"action"`
    Subject *string `json:"subject"`
    Context *ladon.Context
}

func (c *Client) Authz(req *AuthzRequest) (resp *AuthzResponse, err error) {
    if req == nil {
        req = NewAuthzRequest()
    }

    resp = NewAuthzResponse()
    err = c.Send(req, resp)
    return
}
```
请求结构体中的字段都是指针类型的，使用指针的好处是可以判断入参是否有被指定，如果req.Subject == nil 就说明传参中没有 Subject 参数，如果req.Subject != nil就说明参数中有传 Subject 参数。根据某个参数是否被传入，执行不同的业务逻辑，这在 Go API 接口开发中非常常见。


另外，因为 Client 通过匿名的方式继承了基础层中的Client：


```go
type Client struct {
  sdk.Client
}
```
所以，API 层创建的 Client 最终可以直接调用基础层中的 Client 提供的Send(req, resp) 方法，来执行 RESTful API 调用，并将结果保存在 resp 中。为了方便和 API 层的 Client 进行区分，我下面统一将基础层中的 Client 称为 **sdk.Client**。最后，一个完整的客户端调用示例代码如下：


```go
package main

import (
  "fmt"

  "github.com/ory/ladon"

  "github.com/marmotedu/medu-sdk-go/sdk"
  iam "github.com/marmotedu/medu-sdk-go/services/iam/authz"
)

func main() {
  client, _ := iam.NewClientWithSecret("XhbY3aCrfjdYcP1OFJRu9xcno8JzSbUIvGE2", "bfJRvlFwsoW9L30DlG87BBW0arJamSeK")

  req := iam.NewAuthzRequest()
  req.Resource = sdk.String("resources:articles:ladon-introduction")
  req.Action = sdk.String("delete")
  req.Subject = sdk.String("users:peter")
  ctx := ladon.Context(map[string]interface{}{"remoteIPAddress": "192.168.0.5"})
  req.Context = &ctx

  resp, err := client.Authz(req)
  if err != nil {
    fmt.Println("err1", err)
    return
  }
  fmt.Printf("get response body: `%s`\n", resp.String())
  fmt.Printf("allowed: %v\n", resp.Allowed)
}
```
### 基础层：构建并执行 HTTP 请求
上面我们创建了客户端实例，并调用了它的 Send 方法来完成最终的 HTTP 请求。这里，我们来看下 Send 方法具体是如何构建 HTTP 请求的。


sdk.Client 通过 Send 方法，完成最终的 API 调用，代码如下：


```go
func (c *Client) Send(req request.Request, resp response.Response) error {
  method := req.GetMethod()
  builder := GetParameterBuilder(method, c.Logger)
  jsonReq, _ := json.Marshal(req)
  encodedUrl, err := builder.BuildURL(req.GetURL(), jsonReq)
  if err != nil {
    return err
  }

  endPoint := c.Config.Endpoint
  if endPoint == "" {
    endPoint = fmt.Sprintf("%s/%s", defaultEndpoint, c.ServiceName)
  }
  reqUrl := fmt.Sprintf("%s://%s/%s%s", c.Config.Scheme, endPoint, req.GetVersion(), encodedUrl)

  body, err := builder.BuildBody(jsonReq)
  if err != nil {
    return err
  }

  sign := func(r *http.Request) error {
    signer := NewSigner(c.signMethod, c.Credential, c.Logger)
    _ = signer.Sign(c.ServiceName, r, strings.NewReader(body))
    return err
  }

  rawResponse, err := c.doSend(method, reqUrl, body, req.GetHeaders(), sign)
  if err != nil {
    return err
  }

  return response.ParseFromHttpResponse(rawResponse, resp)
}
```
上面的代码大体上可以分为四个步骤。


#### 第一步，Builder：构建请求参数。
根据传入的 AuthzRequest 和客户端配置 Config，构造 HTTP 请求参数，包括请求路径和请求 Body。接下来，我们来看下如何构造 HTTP 请求参数。



HTTP 请求路径构建
在创建客户端时，我们通过NewAuthzRequest函数创建了 /v1/authz REST API 接口请求结构体 AuthzRequest，代码如下：

```go
func NewAuthzRequest() (req *AuthzRequest) {    
    req = &AuthzRequest{    
        BaseRequest: &request.BaseRequest{    
            URL:     "/authz",    
            Method:  "POST",    
            Header:  nil,    
            Version: "v1",    
        },    
    }    
    return                                
}
```
可以看到，我们创建的 req 中包含了 API 版本（Version）、API 路径（URL）和请求方法（Method）。这样，我们就可以在 Send 方法中，构建出请求路径：


```go
endPoint := c.Config.Endpoint                                                 
if endPoint == "" {                                                          
    endPoint = fmt.Sprintf("%s/%s", defaultEndpoint, c.ServiceName)           
}                                                                  
reqUrl := fmt.Sprintf("%s://%s/%s%s", c.Config.Scheme, endPoint, req.GetVersion(), encodedUrl) 

```
上述代码中，c.Config.Scheme=http/https、endPoint=iam.api.marmotedu.com:8080、req.GetVersion()=v1 和 encodedUrl，我们可以认为它们等于 /authz。所以，最终构建出的请求路径为http://iam.api.marmotedu.com:8080/v1/authz 。



HTTP 请求 Body 构建
在BuildBody方法中构建请求 Body。BuildBody 会将 req Marshal 成 JSON 格式的 string。HTTP 请求会以该字符串作为 Body 参数。


#### 第二步，Signer：签发并添加认证头。
访问 IAM 的 API 接口需要进行认证，所以在发送 HTTP 请求之前，还需要给 HTTP 请求添加认证 Header。


medu-sdk-go 代码提供了 JWT 和 HMAC 两种认证方式，最终采用了 JWT 认证方式。JWT 认证签发方法为[Sign](https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/signer.go#L108-L113)，代码如下：


```go
func (v1 SignatureV1) Sign(serviceName string, r *http.Request, body io.ReadSeeker) http.Header {
  tokenString := auth.Sign(v1.Credentials.SecretID, v1.Credentials.SecretKey, "medu-sdk-go", serviceName+".marmotedu.com")
  r.Header.Set("Authorization", fmt.Sprintf("Bearer %s", tokenString))
  return r.Header

}
```
auth.Sign 方法根据 SecretID 和 SecretKey 签发 JWT Token。接下来，我们就可以调用doSend方法来执行 HTTP 请求了。调用代码如下：


```go
rawResponse, err := c.doSend(method, reqUrl, body, req.GetHeaders(), sign)
if err != nil {                                                               
    return err     
} 
```
可以看到，我们传入了 HTTP 请求方法 method 、HTTP 请求 URL reqUrl 、HTTP 请求 Body body，以及用来签发 JWT Token 的 sign 方法。我们在调用 NewAuthzRequest 创建 req 时，指定了 HTTP Method，所以这里的 method := req.GetMethod() 、reqUrl 和请求 Body 都是通过 Builder 来构建的。


#### 第三步，Request：执行 HTTP请求。
调用doSend方法执行 HTTP 请求，doSend 通过调用 net/http 包提供的 http.NewRequest 方法来发送 HTTP 请求，执行完 HTTP 请求后，会返回 *http.Response 类型的 Response。代码如下：


```go
func (c *Client) doSend(method, url, data string, header map[string]string, sign SignFunc) (*http.Response, error) {
    client := &http.Client{Timeout: c.Config.Timeout}

    req, err := http.NewRequest(method, url, strings.NewReader(data))
    if err != nil {
        c.Logger.Errorf("%s", err.Error())
        return nil, err
    }

    c.setHeader(req, header)

    err = sign(req)
    if err != nil {
        return nil, err
    }

    return client.Do(req)
}

```
#### 第四步，处理 HTTP请求返回结果。
调用 doSend 方法返回 *http.Response 类型的 Response 后，Send 方法会调用ParseFromHttpResponse函数来处理 HTTP Response，ParseFromHttpResponse 函数代码如下：


```go
func ParseFromHttpResponse(rawResponse *http.Response, response Response) error {
  defer rawResponse.Body.Close()
  body, err := ioutil.ReadAll(rawResponse.Body)
  if err != nil {
    return err
  }
  if rawResponse.StatusCode != 200 {
    return fmt.Errorf("request fail with status: %s, with body: %s", rawResponse.Status, body)
  }

  if err := response.ParseErrorFromHTTPResponse(body); err != nil {
    return err
  }

  return json.Unmarshal(body, &response)
}
```
可以看到，在 ParseFromHttpResponse 函数中，会先判断 HTTP Response 中的 StatusCode 是否为 200，如果不是 200，则会报错。如果是 200，会调用传入的 resp 变量提供的ParseErrorFromHTTPResponse方法，来将 HTTP Response 的 Body Unmarshal 到 resp 变量中。


通过以上四步，SDK 调用方调用了 API，并获得了 API 的返回结果 resp 。


下面这些公有云厂商的 SDK 采用了此设计模式：腾讯云 SDK：tencentcloud-sdk-go。AWS SDK：aws-sdk-go。阿里云 SDK：alibaba-cloud-sdk-go。京东云 SDK：jdcloud-sdk-go。Ucloud SDK：ucloud-sdk-go。

IAM 公有云方式的 SDK 实现为 medu-sdk-go。

此外，IAM 还设计并实现了 Kubernetes client-go 方式的 Go SDK：marmotedu-sdk-go，marmotedu-sdk-go 也是 IAM Go SDK 所采用的 SDK。下一讲中，我会具体介绍 marmotedu-sdk-go 的设计和实现。


### 总结
这一讲，我主要介绍了如何设计一个优秀的 Go SDK。通过提供 SDK，可以提高 API 调用效率，减少 API 调用难度，所以大型应用通常都会提供 SDK。不同团队有不同的 SDK 设计方法，但目前比较好的实现是公有云厂商采用的 SDK 设计方式。公有云厂商的 SDK 设计方式中，SDK 按调用顺序从上到下可以分为 3 个模块，如下图所示：


![img](https://static001.geekbang.org/resource/image/b9/a9/b9bd3020ae56f6bb49bc3a38bcaf64a9.jpg?wh=1920x878)
Client 构造 SDK 客户端，在构造客户端时，会创建请求参数 req ， req 中会指定 API 版本、HTTP 请求方法、API 请求路径等信息。Client 会请求 Builder 和 Signer 来构建 HTTP 请求的各项参数：HTTP 请求方法、HTTP 请求路径、HTTP 认证头、HTTP 请求 Body。Builder 和 Signer 是根据 req 配置来构造这些 HTTP 请求参数的。构造完成之后，会请求 Request 模块，Request 模块通过调用 net/http 包，来执行 HTTP 请求，并返回请求结果。

## 34 | SDK 设计（下）：IAM项目Go SDK设计和实现

上一讲，我介绍了公有云厂商普遍采用的 SDK 设计方式。其实，还有一些比较优秀的 SDK 设计方式，比如 Kubernetes 的 client-go SDK 设计方式。IAM 项目参考 client-go，也实现了 client-go 风格的 SDK：marmotedu-sdk-go。

和 33 讲 介绍的 SDK 设计方式相比，client-go 风格的 SDK 具有以下优点：大量使用了 Go interface 特性，将接口的定义和实现解耦，可以支持多种实现方式。接口调用层级跟资源的层级相匹配，调用方式更加友好。多版本共存。

所以，我更推荐你使用 marmotedu-sdk-go。接下来，我们就来看下 marmotedu-sdk-go 是如何设计和实现的。


### marmotedu-sdk-go 设计
和 medu-sdk-go 相比，marmotedu-sdk-go 的设计和实现要复杂一些，但功能更强大，使用体验也更好。

这里，我们先来看一个使用 SDK 调用 iam-authz-server /v1/authz 接口的示例，代码保存在 marmotedu-sdk-go/examples/authz_clientset/main.go文件中：


```go
package main

import (
  "context"
  "flag"
  "fmt"
  "path/filepath"

  "github.com/ory/ladon"

  metav1 "github.com/marmotedu/component-base/pkg/meta/v1"
  "github.com/marmotedu/component-base/pkg/util/homedir"

  "github.com/marmotedu/marmotedu-sdk-go/marmotedu"
  "github.com/marmotedu/marmotedu-sdk-go/tools/clientcmd"
)

func main() {
  var iamconfig *string
  if home := homedir.HomeDir(); home != "" {
    iamconfig = flag.String(
      "iamconfig",
      filepath.Join(home, ".iam", "config"),
      "(optional) absolute path to the iamconfig file",
    )
  } else {
    iamconfig = flag.String("iamconfig", "", "absolute path to the iamconfig file")
  }
  flag.Parse()

  // use the current context in iamconfig
  config, err := clientcmd.BuildConfigFromFlags("", *iamconfig)
  if err != nil {
    panic(err.Error())
  }

  // create the clientset
  clientset, err := marmotedu.NewForConfig(config)
  if err != nil {
    panic(err.Error())
  }

  request := &ladon.Request{
    Resource: "resources:articles:ladon-introduction",
    Action:   "delete",
    Subject:  "users:peter",
    Context: ladon.Context{
      "remoteIP": "192.168.0.5",
    },
  }

  // Authorize the request
  fmt.Println("Authorize request...")
  ret, err := clientset.Iam().AuthzV1().Authz().Authorize(context.TODO(), request, metav1.AuthorizeOptions{})
  if err != nil {
    panic(err.Error())
  }

  fmt.Printf("Authorize response: %s.\n", ret.ToString())
}
```
在上面的代码示例中，包含了下面的操作。首先，调用 BuildConfigFromFlags 函数，创建出 SDK 的配置实例 config；接着，调用 marmotedu.NewForConfig(config) 创建了 IAM 项目的客户端 clientset ;最后，调用以下代码请求 /v1/authz 接口执行资源授权请求：


```go
ret, err := clientset.Iam().AuthzV1().Authz().Authorize(context.TODO(), request, metav1.AuthorizeOptions{})    
if err != nil {           
    panic(err.Error())    
}    

fmt.Printf("Authorize response: %s.\n", ret.ToString())
```
调用格式为项目客户端.应用客户端.服务客户端.资源名.接口 。所以，上面的代码通过创建项目级别的客户端、应用级别的客户端和服务级别的客户端，来调用资源的 API 接口。接下来，我们来看下如何创建这些客户端。


### marmotedu-sdk-go 客户端设计
在讲客户端创建之前，我们先来看下客户端的设计思路。

Go 项目的组织方式是有层级的：Project -> Application -> Service。marmotedu-sdk-go 很好地体现了这种层级关系，使得 SDK 的调用更加易懂、易用。marmotedu-sdk-go 的层级关系如下图所示：


![img](https://static001.geekbang.org/resource/image/3a/21/3a4721afa7fe365c0954019087d82021.jpg?wh=2248x1043)

marmotedu-sdk-go 定义了 3 类接口，分别代表了项目、应用和服务级别的 API 接口：


```go
// 项目级别的接口
type Interface interface {
    Iam() iam.IamInterface
    Tms() tms.TmsInterface
}

// 应用级别的接口
type IamInterface interface {
    APIV1() apiv1.APIV1Interface
    AuthzV1() authzv1.AuthzV1Interface
}

// 服务级别的接口
type APIV1Interface interface {
    RESTClient() rest.Interface
    SecretsGetter
    UsersGetter
    PoliciesGetter
}

// 资源级别的客户端
type SecretsGetter interface {
    Secrets() SecretInterface
}

// 资源的接口定义
type SecretInterface interface {
    Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) (*v1.Secret, error)
    Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) (*v1.Secret, error)
    Delete(ctx context.Context, name string, opts metav1.DeleteOptions) error
    DeleteCollection(ctx context.Context, opts metav1.DeleteOptions, listOpts metav1.ListOptions) error
    Get(ctx context.Context, name string, opts metav1.GetOptions) (*v1.Secret, error)
    List(ctx context.Context, opts metav1.ListOptions) (*v1.SecretList, error)
    SecretExpansion
}
```
Interface 代表了项目级别的接口，里面包含了 Iam 和 Tms 两个应用； IamInterface 代表了应用级别的接口，里面包含了 api（iam-apiserver）和 authz（iam-authz-server）两个服务级别的接口。api 和 authz 服务中，又包含了各自服务中 REST 资源的 CURD 接口。


marmotedu-sdk-go 通过 XxxV1 这种命名方式来支持不同版本的 API 接口，好处是可以在程序中同时调用同一个 API 接口的不同版本，例如：clientset.Iam().AuthzV1().Authz().Authorize() 、clientset.Iam().AuthzV2().Authz().Authorize() 分别调用了 /v1/authz 和 /v2/authz 两个版本的 API 接口。

上述关系也可以从目录结构中反映出来，marmotedu-sdk-go 目录设计如下（只列出了一些重要的文件）：


```
├── examples                        # 存放SDK的使用示例
├── Makefile                        # 管理SDK源码，静态代码检查、代码格式化、测试、添加版权信息等
├── marmotedu
│   ├── clientset.go                # clientset实现，clientset中包含多个应用，多个服务的API接口
│   ├── fake                        # clientset的fake实现，主要用于单元测试
│   └── service                     # 按应用进行分类，存放应用中各服务API接口的具体实现
│       ├── iam                     # iam应用的API接口实现，包含多个服务
│       │   ├── apiserver           # iam应用中，apiserver服务的API接口，包含多个版本
│       │   │   └── v1              # apiserver v1版本API接口
│       │   ├── authz               # iam应用中，authz服务的API接口
│       │   │   └── v1              # authz服务v1版本接口
│       │   └── iam_client.go       # iam应用的客户端，包含了apiserver和authz 2个服务的客户端
│       └── tms                     # tms应用的API接口实现
├── pkg                             # 存放一些共享包，可对外暴露
├── rest                            # HTTP请求的底层实现
├── third_party                     # 存放修改过的第三方包，例如：gorequest
└── tools
    └── clientcmd                   # 一些函数用来帮助创建rest.Config配置
```
每种类型的客户端，都可以通过以下相似的方式来创建：


```go
config, err := clientcmd.BuildConfigFromFlags("", "/root/.iam/config")
clientset, err := xxxx.NewForConfig(config)
```
/root/.iam/config 为配置文件，里面包含了服务的地址和认证信息。BuildConfigFromFlags 函数加载配置文件，创建并返回 rest.Config 类型的配置变量，并通过 xxxx.NewForConfig 函数创建需要的客户端。xxxx 是所在层级的 client 包，例如 iam、tms。



marmotedu-sdk-go 客户端定义了 3 类接口，这可以带来两个好处。


第一，API 接口调用格式规范，层次清晰，可以使 API 接口调用更加清晰易记。第二，可以根据需要，自行选择客户端类型，调用灵活。举个例子，在 A 服务中需要同时用到 iam-apiserver 和 iam-authz-server 提供的接口，就可以创建应用级别的客户端 IamClient，然后通过 iamclient.APIV1() 和 iamclient.AuthzV1() ，来切换调用不同服务的 API 接口。


接下来，我们来看看如何创建三个不同级别的客户端。


#### 项目级别客户端创建
Interface 对应的客户端实现为Clientset，所在的包为 marmotedu-sdk-go/marmotedu，Clientset 客户端的创建方式为：


```go
config, err := clientcmd.BuildConfigFromFlags("", "/root/.iam/config")
clientset, err := marmotedu.NewForConfig(config)
```
调用方式为 clientset.应用.服务.资源名.接口 ，例如：


```go
rsp, err := clientset.Iam().AuthzV1().Authz().Authorize()

```
参考示例为 marmotedu-sdk-go/examples/authz_clientset/main.go。


#### 应用级别客户端创建
IamInterface 对应的客户端实现为IamClient，所在的包为 marmotedu-sdk-go/marmotedu/service/iam，IamClient 客户端的创建方式为：


```go
config, err := clientcmd.BuildConfigFromFlags("", "/root/.iam/config")
iamclient,, err := iam.NewForConfig(config)
```
调用方式为 iamclient.服务.资源名.接口 ，例如：

```go
rsp, err := iamclient.AuthzV1().Authz().Authorize()
```
参考示例为 marmotedu-sdk-go/examples/authz_iam/main.go。


#### 服务级别客户端创建
AuthzV1Interface 对应的客户端实现为AuthzV1Client，所在的包为 marmotedu-sdk-go/marmotedu/service/iam/authz/v1，AuthzV1Client 客户端的创建方式为：


```go
config, err := clientcmd.BuildConfigFromFlags("", "/root/.iam/config")
client, err := v1.NewForConfig(config)
```
调用方式为 client.资源名.接口 ，例如：

```go
rsp, err := client.Authz().Authorize()
```
参考示例为 marmotedu-sdk-go/examples/authz/main.go。上面我介绍了 marmotedu-sdk-go 的客户端创建方法，接下来我们再来看下，这些客户端具体是如何执行 REST API 请求的。

### marmotedu-sdk-go 的实现
marmotedu-sdk-go 的实现和 medu-sdk-go 一样，也是采用分层结构，分为 API 层和基础层。如下图所示：


![img](https://static001.geekbang.org/resource/image/c4/b2/c40439c97998a01758923394116c33b2.jpg?wh=2248x2097)

[RESTClient](https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/client.go#L95-L105)是整个 SDK 的核心，RESTClient 向下通过调用Request模块，来完成 HTTP 请求方法、请求路径、请求体、认证信息的构建。Request 模块最终通过调用gorequest包提供的方法，完成 HTTP 的 POST、PUT、GET、DELETE 等请求，获取 HTTP 返回结果，并解析到指定的结构体中。RESTClient 向上提供 Post() 、 Put() 、 Get() 、 Delete() 等方法来供客户端完成 HTTP 请求。


marmotedu-sdk-go 提供了两类客户端，分别是 RESTClient 客户端和基于 RESTClient 封装的客户端。


- RESTClient：Raw 类型的客户端，可以通过指定 HTTP 的请求方法、请求路径、请求参数等信息，直接发送 HTTP 请求，例如 client.Get().AbsPath("/version").Do().Into() 。
- 基于 RESTClient 封装的客户端：例如 AuthzV1Client、APIV1Client 等，执行特定 REST 资源、特定 API 接口的请求，方便开发者调用。


接下来，我们具体看下如何创建 RESTClient 客户端，以及 Request 模块的实现。


### RESTClient 客户端实现
我通过下面两个步骤，实现了 RESTClient 客户端。



#### 第一步，创建rest.Config类型的变量。
BuildConfigFromFlags函数通过加载 yaml 格式的配置文件，来创建 rest.Config 类型的变量，加载的 yaml 格式配置文件内容为：


```go
apiVersion: v1
user:
  #token: # JWT Token
  username: admin # iam 用户名
  password: Admin@2020 # iam 密码
  #secret-id: # 密钥 ID
  #secret-key: # 密钥 Key
  client-certificate: /home/colin/.iam/cert/admin.pem # 用于 TLS 的客户端证书文件路径
  client-key: /home/colin/.iam/cert/admin-key.pem # 用于 TLS 的客户端 key 文件路径
  #client-certificate-data:
  #client-key-data:

server:
  address: https://127.0.0.1:8443 # iam api-server 地址
  timeout: 10s # 请求 api-server 超时时间
  #max-retries: # 最大重试次数，默认为 0
  #retry-interval: # 重试间隔，默认为 1s
  #tls-server-name: # TLS 服务器名称
  #insecure-skip-tls-verify: # 设置为 true 表示跳过 TLS 安全验证模式，将使得 HTTPS 连接不安全
  certificate-authority: /home/colin/.iam/cert/ca.pem # 用于 CA 授权的 cert 文件路径
  #certificate-authority-data:
```
在配置文件中，我们可以指定服务的地址、用户名 / 密码、密钥、TLS 证书、超时时间、重试次数等信息。创建方法如下：


```go
config, err := clientcmd.BuildConfigFromFlags("", *iamconfig)    
if err != nil {                                                  
    panic(err.Error())    
}  
```
这里的代码中，*iamconfig 是 yaml 格式的配置文件路径。BuildConfigFromFlags 函数中，调用LoadFromFile函数来解析 yaml 配置文件。LoadFromFile 最终是通过 yaml.Unmarshal 的方式来解析 yaml 格式的配置文件的。


#### 第二步，根据 rest.Config 类型的变量，创建 RESTClient 客户端。


通过RESTClientFor函数来创建 RESTClient 客户端：


```go
func RESTClientFor(config *Config) (*RESTClient, error) {
    ...
    baseURL, versionedAPIPath, err := defaultServerURLFor(config)
    if err != nil {
        return nil, err
    }

    // Get the TLS options for this client config
    tlsConfig, err := TLSConfigFor(config)
    if err != nil {
        return nil, err
    }

    // Only retry when get a server side error.
    client := gorequest.New().TLSClientConfig(tlsConfig).Timeout(config.Timeout).
        Retry(config.MaxRetries, config.RetryInterval, http.StatusInternalServerError)
    // NOTICE: must set DoNotClearSuperAgent to true, or the client will clean header befor http.Do
    client.DoNotClearSuperAgent = true

    ...

    clientContent := ClientContentConfig{
        Username:           config.Username,
        Password:           config.Password,
        SecretID:           config.SecretID,
        SecretKey:          config.SecretKey,
        ...
    }

    return NewRESTClient(baseURL, versionedAPIPath, clientContent, client)
}
```
RESTClientFor 函数调用defaultServerURLFor(config)生成基本的 HTTP 请求路径：baseURL=http://127.0.0.1:8080，versionedAPIPath=/v1。然后，通过TLSConfigFor函数生成 TLS 配置，并调用 gorequest.New() 创建 gorequest 客户端，将客户端配置信息保存在变量中。最后，调用NewRESTClient函数创建 RESTClient 客户端。


RESTClient 客户端提供了以下方法，来供调用者完成 HTTP 请求：


```go
func (c *RESTClient) APIVersion() scheme.GroupVersion
func (c *RESTClient) Delete() *Request
func (c *RESTClient) Get() *Request
func (c *RESTClient) Post() *Request
func (c *RESTClient) Put() *Request
func (c *RESTClient) Verb(verb string) *Request
```
可以看到，RESTClient 提供了 Delete 、 Get 、 Post 、 Put 方法，分别用来执行 HTTP 的 DELETE、GET、POST、PUT 方法，提供的 Verb 方法可以灵活地指定 HTTP 方法。这些方法都返回了 Request 类型的变量。Request 类型的变量提供了一些方法，用来完成具体的 HTTP 请求，例如：


```go
  type Response struct {
    Allowed bool   `json:"allowed"`
    Denied  bool   `json:"denied,omitempty"`
    Reason  string `json:"reason,omitempty"`
    Error   string `json:"error,omitempty"`
}

func (c *authz) Authorize(ctx context.Context, request *ladon.Request, opts metav1.AuthorizeOptions) (result *Response, err error) {
    result = &Response{}                                         
    err = c.client.Post().
        Resource("authz").
        VersionedParams(opts).
        Body(request).
        Do(ctx).
        Into(result)

    return
}
```
上面的代码中， c.client 是 RESTClient 客户端，通过调用 RESTClient 客户端的 Post 方法，返回了 *Request 类型的变量。


*Request 类型的变量提供了 Resource 和 VersionedParams 方法，来构建请求 HTTP URL 中的路径 /v1/authz ；通过 Body 方法，指定了 HTTP 请求的 Body。

到这里，我们分别构建了 HTTP 请求需要的参数：HTTP Method、请求 URL、请求 Body。所以，之后就可以调用 Do 方法来执行 HTTP 请求，并将返回结果通过 Into 方法保存在传入的 result 变量中。



### Request 模块实现
RESTClient 客户端的方法会返回 Request 类型的变量，Request 类型的变量提供了一系列的方法用来构建 HTTP 请求参数，并执行 HTTP 请求。


所以，Request 模块可以理解为最底层的通信层，我们来看下 Request 模块具体是如何完成 HTTP 请求的。我们先来看下Request 结构体的定义：


```go
type RESTClient struct {           
    // base is the root URL for all invocations of the client    
    base *url.URL    
    // group stand for the client group, eg: iam.api, iam.authz                       
    group string                                                                          
    // versionedAPIPath is a path segment connecting the base URL to the resource root    
    versionedAPIPath string                                      
    // content describes how a RESTClient encodes and decodes responses.    
    content ClientContentConfig    
    Client  *gorequest.SuperAgent    
}

type Request struct {
  c *RESTClient

  timeout time.Duration

  // generic components accessible via method setters
  verb       string
  pathPrefix string
  subpath    string
  params     url.Values
  headers    http.Header

  // structural elements of the request that are part of the IAM API conventions
  // namespace    string
  // namespaceSet bool
  resource     string
  resourceName string
  subresource  string

  // output
  err  error
  body interface{}
}  
```
再来看下 Request 结构体提供的方法：


```go
func (r *Request) AbsPath(segments ...string) *Request
func (r *Request) Body(obj interface{}) *Request
func (r *Request) Do(ctx context.Context) Result
func (r *Request) Name(resourceName string) *Request
func (r *Request) Param(paramName, s string) *Request
func (r *Request) Prefix(segments ...string) *Request
func (r *Request) RequestURI(uri string) *Request
func (r *Request) Resource(resource string) *Request
func (r *Request) SetHeader(key string, values ...string) *Request
func (r *Request) SubResource(subresources ...string) *Request
func (r *Request) Suffix(segments ...string) *Request
func (r *Request) Timeout(d time.Duration) *Request
func (r *Request) URL() *url.URL
func (r *Request) Verb(verb string) *Request
func (r *Request) VersionedParams(v interface{}) *Request
```
通过 Request 结构体的定义和使用方法，我们不难猜测出：Request 模块通过 Name 、 Resource 、 Body 、 SetHeader 等方法来设置 Request 结构体中的各个字段。这些字段最终用来构建出一个 HTTP 请求，并通过 Do 方法来执行 HTTP 请求。那么，如何构建并执行一个 HTTP 请求呢？我们可以通过以下 5 步，来构建并执行 HTTP 请求：


构建 HTTP URL；构建 HTTP Method；构建 HTTP Body；执行 HTTP 请求；保存 HTTP 返回结果。



接下来，我们就来具体看下 Request 模块是如何构建这些请求参数，并发送 HTTP 请求的。


#### 第一步，构建 HTTP URL。
首先，通过defaultServerURLFor函数返回了http://iam.api.marmotedu.com:8080 和 /v1 ，并将二者分别保存在了 Request 类型结构体变量中 c 字段的 base 字段和 versionedAPIPath 字段中。


通过 [Do](https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/request.go#L379-L416) 方法执行 HTTP 时，会调用r.URL()方法来构建请求 URL。 r.URL 方法中，通过以下代码段构建了 HTTP 请求 URL：


```go
func (r *Request) URL() *url.URL {
    p := r.pathPrefix
    if len(r.resource) != 0 {
        p = path.Join(p, strings.ToLower(r.resource))
    }

    if len(r.resourceName) != 0 || len(r.subpath) != 0 || len(r.subresource) != 0 {
        p = path.Join(p, r.resourceName, r.subresource, r.subpath)
    }
                                                                                   
    finalURL := &url.URL{}
    if r.c.base != nil {
        *finalURL = *r.c.bas
    }
 
    finalURL.Path = p
    ...    
}
```
p := r.pathPrefix 和 r.c.base ，是通过 defaultServerURLFor 调用返回的 v1 和 http://iam.api.marmotedu.com:8080 来构建的。resourceName 通过 func (r *Request) Resource(resource string) *Request 来指定，例如 authz 。所以，最终我们构建的请求 URL 为 http://iam.api.marmotedu.com:8080/v1/authz 。


#### 第二步，构建 HTTP Method。
HTTP Method 通过 RESTClient 提供的 Post 、Delete 、Get 等方法来设置，例如：


```go
func (c *RESTClient) Post() *Request {                                                                                 
    return c.Verb("POST")                                                                                              
}

func (c *RESTClient) Verb(verb string) *Request {                                                                      
    return NewRequest(c).Verb(verb)                                                                                    
}
```
NewRequest(c).Verb(verb) 最终设置了 Request 结构体的 verb 字段，供 Do 方法使用。

#### 第三步，构建 HTTP Body。
HTTP Body 通过 Request 结构体提供的 Body 方法来指定：


```go
func (r *Request) Body(obj interface{}) *Request {                    
    if v := reflect.ValueOf(obj); v.Kind() == reflect.Struct {              
        r.SetHeader("Content-Type", r.c.content.ContentType)                
    }                                                                                                                  
                                                                                                                       
    r.body = obj                                                                                                       
                                                                                                                       
    return r                                                                                                           
} 
```
#### 第四步，执行 HTTP 请求。
通过 Request 结构体提供的 Do 方法来执行具体的 HTTP 请求，代码如下：


```go
func (r *Request) Do(ctx context.Context) Result {
  client := r.c.Client
  client.Header = r.headers

  if r.timeout > 0 {
    var cancel context.CancelFunc
    ctx, cancel = context.WithTimeout(ctx, r.timeout)

    defer cancel()
  }

  client.WithContext(ctx)

  resp, body, errs := client.CustomMethod(r.verb, r.URL().String()).Send(r.body).EndBytes()
  if err := combineErr(resp, body, errs); err != nil {
    return Result{
      response: &resp,
      err:      err,
      body:     body,
    }
  }

  decoder, err := r.c.content.Negotiator.Decoder()
  if err != nil {
    return Result{
      response: &resp,
      err:      err,
      body:     body,
      decoder:  decoder,
    }
  }

  return Result{
    response: &resp,
    body:     body,
    decoder:  decoder,
  }
}
```
在 Do 方法中，使用了 Request 结构体变量中各个字段的值，通过 client.CustomMethod 来执行 HTTP 请求。 client 是 *gorequest.SuperAgent 类型的客户端。


#### 第五步，保存 HTTP 返回结果。
通过 Request 结构体的 Into 方法来保存 HTTP 返回结果：

```go
func (r Result) Into(v interface{}) error {
    if r.err != nil {                                          
        return r.Error()
    }                                                                                 
                                                         
    if r.decoder == nil {                                                                    
        return fmt.Errorf("serializer doesn't exist")
    }                            
                             
    if err := r.decoder.Decode(r.body, &v); err != nil {
        return err                                                                    
    }                                                                                        
                                                             
    return nil                                                                      
}
```
r.body 是在 Do 方法中，执行完 HTTP 请求后设置的，它的值为 HTTP 请求返回的 Body。

### 请求认证
接下来，我再来介绍下 marmotedu-sdk-go 另外一个比较核心的功能：请求认证。


marmotedu-sdk-go 支持两种认证方式：
- Basic 认证：通过给请求添加 Authorization: Basic xxxx 来实现。
- Bearer 认证：通过给请求添加 Authorization: Bearer xxxx 来实现。这种方式又支持直接指定 JWT Token，或者通过指定密钥对由 SDK 自动生成 JWT Token。


Basic 认证和 Bearer 认证，我在 25 讲介绍过，你可以返回查看下。认证头是 RESTClient 客户端发送 HTTP 请求时指定的，具体实现位于NewRequest函数中：



```go
switch {
    case c.content.HasTokenAuth():
        r.SetHeader("Authorization", fmt.Sprintf("Bearer %s", c.content.BearerToken))
    case c.content.HasKeyAuth():
        tokenString := auth.Sign(c.content.SecretID, c.content.SecretKey, "marmotedu-sdk-go", c.group+".marmotedu.com")
        r.SetHeader("Authorization", fmt.Sprintf("Bearer %s", tokenString))
    case c.content.HasBasicAuth():
        // TODO: get token and set header
        r.SetHeader("Authorization", "Basic "+basicAuth(c.content.Username, c.content.Password))
}
```
上面的代码会根据配置信息，自动判断使用哪种认证方式。


### 总结
这一讲中，我介绍了 Kubernetes client-go 风格的 SDK 实现方式。和公有云厂商的 SDK 设计相比，client-go 风格的 SDK 设计有很多优点。marmotedu-sdk-go 在设计时，通过接口实现了 3 类客户端，分别是项目级别的客户端、应用级别的客户端和服务级别的客户端。开发人员可以根据需要，自行创建客户端类型。


marmotedu-sdk-go 通过RESTClientFor，创建了 RESTClient 类型的客户端，RESTClient 向下通过调用Request模块，来完成 HTTP 请求方法、请求路径、请求体、认证信息的构建。Request 模块最终通过调用gorequest包提供的方法，完成 HTTP 的 POST、PUT、GET、DELETE 等请求，获取 HTTP 返回结果，并解析到指定的结构体中。RESTClient 向上提供 Post() 、 Put() 、 Get() 、 Delete() 等方法，来供客户端完成 HTTP 请求。

## 35 | 效率神器：如何设计和实现一个命令行客户端工具？

如果你用过 Kubernetes、Istio、etcd，那你一定用过这些开源项目所提供的命令行工具：kubectl、istioctl、etcdctl。一个 xxx 项目，伴随着一个 xxxctl 命令行工具，这似乎已经成为一种趋势，在一些大型系统中更是常见。提供 xxxctl 命令行工具有这两个好处：


- 实现自动化：可以通过在脚本中调用 xxxctl 工具，实现自动化。
- 提高效率：通过将应用的功能封装成命令和参数，方便运维、开发人员在 Linux 服务器上调用。

其中，kubectl 命令设计的功能最为复杂，也是非常优秀的命令行工具，IAM 项目的 iamctl 客户端工具就是仿照 kubectl 来实现的。这一讲，我就通过剖析 iamctl 命令行工具的实现，来介绍下如何实现一个优秀的客户端工具。

### 常见客户端介绍
在介绍 iamctl 命令行工具的实现之前，我们先来看下常见的客户端。


客户端又叫用户端，与后端服务相对应，安装在客户机上，用户可以使用这些客户端访问后端服务。不同的客户端面向的人群不同，所能提供的访问能力也有差异。常见的客户端有下面这几种：

前端，包括浏览器、手机应用；SDK；命令行工具；其他终端。

接下来，我就来分别介绍下。


浏览器和手机应用提供一个交互界面供用户访问后端服务，使用体验最好，面向的人群是最终的用户。这两类客户端也称为前端。前端由前端开发人员进行开发，并通过 API 接口，调用后端的服务。后端开发人员不需要关注这两类客户端，只需要关注如何提供 API 接口即可。SDK（Software Development Kit）也是一个客户端，供开发者调用。开发者调用 API 时，如果是通过 HTTP 协议，需要编写 HTTP 的调用代码、HTTP 请求包的封装和返回包的解封，还要处理 HTTP 的状态码，使用起来不是很方便。SDK 其实是封装了 API 接口的一系列函数集合，开发者通过调用 SDK 中的函数调用 API 接口，提供 SDK 主要是方便开发者调用，减少工作量。命令行工具是可以在操作系统上执行的一个二进制程序，提供了一种比 SDK 和 API 接口更方便快捷的访问后端服务的途径，供运维或者开发人员在服务器上直接执行使用，或者在自动化脚本中调用。


还有其他各类客户端，这里我列举一些常见的。终端设备：POS 机、学习机、智能音箱等。第三方应用程序：通过调用 API 接口或者 SDK，调用我们提供的后端服务，从而实现自身的功能。脚本：脚本中通过 API 接口或者命令行工具，调用我们提供的后端服务，实现自动化。


这些其他的各类客户端，都是通过调用 API 接口使用后端服务的，它们跟前端一样，也不需要后台开发人员开发。需要后台开发人员投入工作量进行研发的客户端是 SDK 和命令行工具。这两类客户端工具有个调用和被调用的顺序，如下图所示：


![img](https://static001.geekbang.org/resource/image/e9/91/e97e547bec77dc7129615b11792f1291.jpg?wh=1920x568)

你可以看到，命令行工具和 SDK 最终都是通过 API 接口调用后端服务的，通过这种方式可以保证服务的一致性，并减少为适配多个客户端所带来的额外开发工作量。


### 大型系统客户端（xxxctl）的特点
通过学习 kubectl、istioctl、etcdctl 这些优秀的命令行工具，可以发现一个大型系统的命令行工具，通常具有下面这些特点：


- 支持命令和子命令，命令 / 子命名有自己独有的命令行参数。
- 支持一些特殊的命令。比如支持 completion 命令，completion 命令可以输出 bash/zsh 自动补全脚本，实现命令行及参数的自动补全。还支持 version 命令，version 命令不仅可以输出客户端的版本，还可以输出服务端的版本（如果有需要）。
- 支持全局 option，全局 option 可以作为所有命令及子命令的命令行参数。
- 支持 -h/help，-h/help 可以打印 xxxctl 的帮助信息，例如：


```
$ iamctl -h
iamctl controls the iam platform, is the client side tool for iam platform.

 Find more information at:
https://github.com/marmotedu/iam/blob/master/docs/guide/en-US/cmd/iamctl/iamctl.md

Basic Commands:
  info        Print the host information
  color       Print colors supported by the current terminal
  new         Generate demo command code
  jwt         JWT command-line tool

Identity and Access Management Commands:
  user        Manage users on iam platform
  secret      Manage secrets on iam platform
  policy      Manage authorization policies on iam platform

Troubleshooting and Debugging Commands:
  validate    Validate the basic environment for iamctl to run

Settings Commands:
  set         Set specific features on objects
  completion  Output shell completion code for the specified shell (bash or zsh)

Other Commands:
  version     Print the client and server version information

Usage:
  iamctl [flags] [options]

Use "iamctl <command> --help" for more information about a given command.
Use "iamctl options" for a list of global command-line options (applies to all commands).
```
支持 xxxctl help [command | command subcommand] [command | command subcommand] -h ，打印命令 / 子命令的帮助信息，格式通常为 命令描述 + 使用方法 。例如：



```
$ istioctl help register
Registers a service instance (e.g. VM) joining the mesh
 
Usage:
  istioctl register <svcname> <ip> [name1:]port1 [name2:]port2 ... [flags]
```
除此之外，一个大型系统的命令行工具还可以支持一些更高阶的功能，例如：支持命令分组，支持配置文件，支持命令的使用 example，等等。


在 Go 生态中，如果我们要找一个符合上面所有特点的命令行工具，那非kubectl莫属。因为我今天要重点讲的 iamctl 客户端工具，就是仿照它来实现的，所以这里就不展开介绍 kubectl 了，不过还是建议你认真研究下 kubectl 的实现。


### iamctl 的核心实现
接下来，我就来介绍 IAM 系统自带的 iamctl 客户端工具，它是仿照 kubectl 来实现的，能够满足一个大型系统客户端工具的需求。我会从 iamctl 的功能、代码结构、命令行选项和配置文件解析 4 个方面来介绍。


#### iamctl 的功能
iamctl 将命令进行了分类。这里，我也建议你对命令进行分类，因为通过分类，不仅可以协助你理解命令的用途，还能帮你快速定位某类命令。另外，当命令很多时，分类也可以使命令看起来更规整。iamctl 实现的命令如下：


![img](https://static001.geekbang.org/resource/image/1d/da/1dee217f8be94ae1c3c1d9b29d627eda.jpg?wh=1920x1696)

更详细的功能，你可以参考 iamctl -h 。我建议你在实现 xxxctl 工具时，考虑实现下面这几个功能。
- API 功能：平台具有的 API 功能，都能通过 xxxctl 方便地进行调用。
- 工具：一些使用 IAM 系统时有用的功能，比如签发 JWT Token。
- version、completion、validate 命令。


#### 代码结构
iamctl 工具的 main 函数位于iamctl.go文件中。命令的实现存放在internal/iamctl/cmd/cmd.go文件中。iamctl 的命令统一存放在internal/iamctl/cmd目录下，每个命令都是一个 Go 包，包名即为命令名，具体实现存放在 internal/iamctl/cmd/<命令>/<命令>.go 文件中。如果命令有子命令，则子命令的实现存放在 internal/iamctl/cmd/<命令>/<命令>_<子命令>.go 文件中。



使用这种代码组织方式，即使是在命令很多的情况下，也能让代码井然有序，方便定位和维护代码。


#### 命令行选项
添加命令行选项的代码在[NewIAMCtlCommand](https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/cmd.go#L41-L130)函数中，核心代码为：

```
flags := cmds.PersistentFlags()
...                                                                             
iamConfigFlags := genericclioptions.NewConfigFlags(true).WithDeprecatedPasswordFlag().WithDeprecatedSecretFlag()
iamConfigFlags.AddFlags(flags)                                   
matchVersionIAMConfigFlags := cmdutil.NewMatchVersionFlags(iamConfigFlags)                
matchVersionIAMConfigFlags.AddFlags(cmds.PersistentFlags())
```
NewConfigFlags(true) 返回带有默认值的参数，并通过 iamConfigFlags.AddFlags(flags) 添加到 cobra 的命令行 flag 中。NewConfigFlags(true) 返回结构体类型的值都是指针类型，这样做的好处是：程序可以判断出是否指定了某个参数，从而可以根据需要添加参数。例如：可以通过 WithDeprecatedPasswordFlag() 和 WithDeprecatedSecretFlag() 添加密码和密钥认证参数。

NewMatchVersionFlags 指定是否需要服务端版本和客户端版本一致。如果不一致，在调用服务接口时会报错。


#### 配置文件解析
iamctl 需要连接 iam-apiserver，来完成用户、策略和密钥的增删改查，并且需要进行认证。要完成这些功能，需要有比较多的配置项。这些配置项如果每次都在命令行选项指定，会很麻烦，也容易出错。


最好的方式是保存到配置文件中，并加载配置文件。加载配置文件的代码位于 NewIAMCtlCommand 函数中，代码如下：

```go
_ = viper.BindPFlags(cmds.PersistentFlags())
cobra.OnInitialize(func() {
    genericapiserver.LoadConfig(viper.GetString(genericclioptions.FlagIAMConfig), "iamctl")
})  
```
iamctl 会按以下优先级加载配置文件：
- 命令行参 --iamconfig 指定的配置文件。
- 当前目录下的 iamctl.yaml 文件。
- $HOME/.iam/iamctl.yaml 文件。

这种加载方式具有两个好处。首先是可以手动指定不同的配置文件，这在多环境、多配置下尤为重要。其次是方便使用，可以把配置存放在默认的加载路径中，在执行命令时，就不用再指定 --iamconfig 参数。加载完配置文件之后，就可以通过 viper.Get() 函数来获取配置。例如，iamctl 使用了以下 viper.Get 方法：


![img](https://static001.geekbang.org/resource/image/8b/42/8bce5d0b9ab45b5238d70b73175cf642.png?wh=1920x813)


### iamctl 中子命令是如何构建的？
讲完了 iamctl 命令行工具的核心实现，我们再来看看 iamctl 命令行工具中，子命令是如何构建的。命令行工具的核心是命令，有很多种方法可以构建一个命令，但还是有一些比较好的构建方法，值得我们去参考。接下来，我来介绍下如何用比较好的方式去构建命令。


#### 命令构建
命令行工具的核心能力是提供各类命令，来完成不同功能，每个命令构建的方式可以完全不同，但最好能按相同的方式去构建，并抽象成一个模型。如下图所示：


![img](https://static001.geekbang.org/resource/image/1e/93/1e78d2f387be0bcbae573d486e391e93.jpg?wh=1920x916)
你可以将一个命令行工具提供的命令进行分组。每个分组包含多个命令，每个命令又可以具有多个子命令，子命令和父命令在构建方式上完全一致。每个命令可以按下面的四种方式构建。具体代码你可以参考internal/iamctl/cmd/user/user_update.go。

- 通过 NewCmdXyz 函数创建命令框架。 NewCmdXyz 函数通过创建一个 cobra.Command 类型的变量来创建命令；通过指定 cobra.Command 结构体类型的 Short、Long、Example 字段，来指定该命令的使用文档iamctl -h 、详细使用文档iamctl xyz -h 和使用示例。
- 通过 cmd.Flags().XxxxVar 来给该命令添加命令行选项。
- 为了在不指定命令行参数时，能够按照默认的方式执行命令，可以通过 NewXyzOptions 函数返回一个设置了默认选项的 XyzOptions 类型的变量。
- XyzOptions 选项具有 Complete 、Validate 和 Run 三个方法，分别完成选项补全、选项验证和命令执行。命令的执行逻辑可以在 func (o *XyzOptions) Run(args []string) error 函数中编写。


按相同的方式去构建命令，抽象成一个通用模型，这种方式有下面四个好处。
- 减少理解成本：理解一个命令的构建方式，就可以理解其他命令的构建方式。
- 提高新命令的开发效率：可以复用其他命令的开发框架，新命令只需填写业务逻辑即可。
- 自动生成命令：可以按照规定的命令模型，自动生成新的命令。
- 易维护：因为所有的命令都来自于同一个命令模型，所以可以保持一致的代码风格，方便后期维护。


#### 自动生成命令
上面讲到，自动生成命令模型的好处之一是可以自动生成命令，下面让我们来具体看下。iamctl 自带了命令生成工具，下面我们看看生成方法，一共可以分成 5 步。这里假设生成 xyz 命令。


第一步，新建一个 xyz 目录，用来存放 xyz 命令源码：


```
$ mkdir internal/iamctl/cmd/xyz
```
第二步，在 xyz 目录下，使用 iamctl new 命令生成 xyz 命令源码：


```
$ cd internal/iamctl/cmd/xyz/
$ iamctl new xyz
Command file generated: xyz.go
```
第三步，将 xyz 命令添加到 root 命令中，假设 xyz 属于 Settings Commands 命令分组。


在 NewIAMCtlCommand 函数中，找到 Settings Commands 分组，将 NewCmdXyz 追加到 Commands 数组后面：


```
       {
            Message: "Settings Commands:",
            Commands: []*cobra.Command{
                set.NewCmdSet(f, ioStreams),
                completion.NewCmdCompletion(ioStreams.Out, ""),
                xyz.NewCmdXyz(f, ioStreams),
            },
        }, 

```
第四步，编译 iamctl：


```
$ make build BINS=iamctl  
```
第五步，测试：


```
$ iamctl xyz -h
A longer description that spans multiple lines and likely contains examples and usage of using your command. For
example:
 
 Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to
quickly create a Cobra application.
 
Examples:
  # Print all option values for xyz
  iamctl xyz marmotedu marmotedupass
 
Options:
  -b, --bool=false: Bool option.
  -i, --int=0: Int option.
      --slice=[]: String slice option.
      --string='default': String option.
 
Usage:
  iamctl xyz USERNAME PASSWORD [options]
 
Use "iamctl options" for a list of global command-line options (applies to all commands).
$ iamctl xyz marmotedu marmotedupass
The following is option values:
==> --string: default(complete)
==> --slice: []
==> --int: 0
==> --bool: false
 
The following is args values:
==> username: marmotedu
==> password: marmotedupass
```
你可以看到，经过短短的几步，就添加了一个新的命令 xyz 。 iamctl new 命令不仅可以生成不带子命令的命令，还可以生成带有子命令的命令，生成方式如下：



```
$ iamctl new -g xyz
Command file generated: xyz.go
Command file generated: xyz_subcmd1.go
Command file generated: xyz_subcmd2.go
```
#### 命令自动补全
cobra 会根据注册的命令自动生成补全脚本，可以补全父命令、子命令和选项参数。在 bash 下，可以按下面的方式配置自动补全功能。


第一步，生成自动补全脚本：


```
$ iamctl completion bash > ~/.iam/completion.bash.inc
```
第二步，登陆时加载 bash，自动补全脚本：


```
$ echo "source '$HOME/.iam/completion.bash.inc'" >> $HOME/.bash_profile
$ source $HOME/.bash_profile
```
第三步，测试自动补全功能：


```
$ iamctl xy<TAB> # 按TAB键，自动补全为：iamctl xyz
$ iamctl xyz --b<TAB> # 按TAB键，自动补全为：iamctl xyz --bool
```
#### 更友好的输出
在开发命令时，可以通过一些技巧来提高使用体验。我经常会在输出中打印一些彩色输出，或者将一些输出以表格的形式输出，如下图所示：


![img](https://static001.geekbang.org/resource/image/74/42/74ef80708c853c20811e1e7bed7bde42.png?wh=651x226)

这里，使用 github.com/olekukonko/tablewriter 包来实现表格功能，使用 github.com/fatih/color 包来打印带色彩的字符串。具体使用方法，你可以参考internal/iamctl/cmd/validate/validate.go文件。

github.com/fatih/color 包可以给字符串标示颜色，字符串和颜色的对应关系可通过 iamctl color 来查看，如下图所示：


![img](https://static001.geekbang.org/resource/image/47/b9/47593869e1b10b15a35e16c661d818b9.png?wh=991x672)


### iamctl 是如何进行 API 调用的？
上面我介绍了 iamctl 命令的构建方式，那么这里我们再来看下 iamctl 是如何请求服务端 API 接口的。

Go 后端服务的功能通常通过 API 接口来对外暴露，一个后端服务可能供很多个终端使用，比如浏览器、命令行工具、手机等。为了保持功能的一致性，这些终端都会调用同一套 API 来完成相同的功能，如下图所示：


![img](https://static001.geekbang.org/resource/image/fb/bb/fb6de4f63454dd6471e023d73b8548bb.jpg?wh=1920x742)
如果命令行工具需要用到后端服务的功能，也需要通过 API 调用的方式。理想情况下，Go 后端服务对外暴露的所有 API 功能，都可以通过命令行工具来完成。一个 API 接口对应一个命令，API 接口的参数映射到命令的参数。

要调用服务端的 API 接口，最便捷的方法是通过 SDK 来调用，对于一些没有实现 SDK 的接口，也可以直接调用。所以，在命令行工具中，需要支持以下两种调用方式：

通过 SDK 调用服务端 API 接口。直接调用服务端的 API 接口（本专栏是 REST API 接口）。


iamctl 通过cmdutil.NewFactory创建一个 Factory 类型的变量 f ， Factory 定义为：



```go
type Factory interface {
    genericclioptions.RESTClientGetter
    IAMClientSet() (*marmotedu.Clientset, error)
    RESTClient() (*restclient.RESTClient, error)
}
```
将变量 f 传入到命令中，在命令中使用 Factory 接口提供的 RESTClient() 和 IAMClientSet() 方法，分别返回 RESTful API 客户端和 SDK 客户端，从而使用客户端提供的接口函数。代码可参考internal/iamctl/cmd/version/version.go。

### 客户端配置文件
如果要创建 RESTful API 客户端和 SDK 的客户端，需要调用 f.ToRESTConfig() 函数返回 *github.com/marmotedu/marmotedu-sdk-go/rest.Config 类型的配置变量，然后再基于 rest.Config 类型的配置变量创建客户端。


f.ToRESTConfig 函数最终是调用toRawIAMConfigLoader函数来生成配置的，代码如下：

```go
func (f *ConfigFlags) toRawIAMConfigLoader() clientcmd.ClientConfig {
    config := clientcmd.NewConfig()
    if err := viper.Unmarshal(&config); err != nil {
        panic(err)
    }

    return clientcmd.NewClientConfigFromConfig(config)
}
```
toRawIAMConfigLoader 返回 clientcmd.ClientConfig 类型的变量， clientcmd.ClientConfig 类型提供了 ClientConfig 方法，用来返回*rest.Config类型的变量。


在 toRawIAMConfigLoader 函数内部，通过 viper.Unmarshal 将 viper 中存储的配置解析到 clientcmd.Config 类型的结构体变量中。viper 中存储的配置，是在 cobra 命令启动时通过 LoadConfig 函数加载的，代码如下（位于 NewIAMCtlCommand 函数中）：

```go
cobra.OnInitialize(func() {                     
    genericapiserver.LoadConfig(viper.GetString(genericclioptions.FlagIAMConfig), "config")
}) 
```
你可以通过 --config 选项，指定配置文件的路径。



### SDK 调用
通过[IAMClient](https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/util/factory_client_access.go#L41-L47)返回 SDK 客户端，代码如下：

```go
func (f *factoryImpl) IAMClient() (*iam.IamClient, error) {
  clientConfig, err := f.ToRESTConfig()
  if err != nil {
    return nil, err
  }
  return iam.NewForConfig(clientConfig)
}
```
marmotedu.Clientset 提供了 iam-apiserver 的所有接口。


### REST API 调用
通过RESTClient()返回 RESTful API 客户端，代码如下：


```go
func (f *factoryImpl) RESTClient() (*restclient.RESTClient, error) {
  clientConfig, err := f.ToRESTConfig()
  if err != nil {
    return nil, err
  }
  setIAMDefaults(clientConfig)
  return restclient.RESTClientFor(clientConfig)
}
```
可以通过下面的方式访问 RESTful API 接口：

```go
serverVersion *version.Info

client, _ := f.RESTClient()
if err := client.Get().AbsPath("/version").Do(context.TODO()).Into(&serverVersion); err != nil {
    return err
}
```
上面的代码请求了 iam-apiserver 的 /version 接口，并将返回结果保存在 serverVersion 变量中。


### 总结
这一讲，我主要剖析了 iamctl 命令行工具的实现，进而向你介绍了如何实现一个优秀的客户端工具。


对于一个大型系统 xxx 来说，通常需要有一个 xxxctl 命令行工具， xxxctl 命令行工具可以方便开发、运维使用系统功能，并能实现功能自动化。

IAM 项目参考 kubectl，实现了命令行工具 iamctl。iamctl 集成了很多功能，我们可以通过 iamctl 子命令来使用这些功能。例如，我们可以通过 iamctl 对用户、密钥和策略进行 CURD 操作；可以设置 iamctl 自动补全脚本；可以查看 IAM 系统的版本信息。甚至，你还可以使用 iamctl new 命令，快速创建一个 iamctl 子命令模板。


iamctl 使用了 cobra、pflag、viper 包来构建，每个子命令又包含了一些基本的功能，例如短描述、长描述、使用示例、命令行选项、选项校验等。iamctl 命令可以加载不同的配置文件，来连接不同的客户端。iamctl 通过 SDK 调用、REST API 调用两种方式来调用服务端 API 接口。


## 服务测试

## 36 | 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？

在 Go 项目开发中，我们不仅要开发功能，更重要的是确保这些功能稳定可靠，并且拥有一个不错的性能。要确保这些，就要对代码进行测试。开发人员通常会进行单元测试和性能测试，分别用来测试代码的功能是否正常和代码的性能是否满足需求。每种语言通常都有自己的测试包 / 模块，Go 语言也不例外。在 Go 中，我们可以通过testing包对代码进行单元测试和性能测试。这一讲，我会用一些示例来讲解如何编写单元测试和性能测试用例，下一讲则会介绍如何编写其他的测试类型，并介绍 IAM 项目的测试用例。


### 如何测试 Go 代码？
Go 语言有自带的测试框架testing，可以用来实现单元测试（T 类型）和性能测试（B 类型），通过go test命令来执行单元测试和性能测试。



go test 执行测试用例时，是以 go 包为单位进行测试的。执行时需要指定包名，比如go test 包名，如果没有指定包名，默认会选择执行命令时所在的包。go test 在执行时，会遍历以_test.go结尾的源码文件，执行其中以Test、Benchmark、Example开头的测试函数。为了演示如何编写测试用例，我预先编写了 4 个函数。假设这些函数保存在 test 目录下的math.go文件中，包名为test，math.go 代码如下：



```go
package test

import (
  "fmt"
  "math"
  "math/rand"
)

// Abs returns the absolute value of x.
func Abs(x float64) float64 {
  return math.Abs(x)
}

// Max returns the larger of x or y.
func Max(x, y float64) float64 {
  return math.Max(x, y)
}

// Min returns the smaller of x or y.
func Min(x, y float64) float64 {
  return math.Min(x, y)
}

// RandInt returns a non-negative pseudo-random int from the default Source.
func RandInt() int {
  return rand.Int()
}
```
在这一讲后面的内容中，我会演示如何编写测试用例，来对这些函数进行单元测试和性能测试。下面让我们先来看下测试命名规范。


### 测试命名规范
在我们对 Go 代码进行测试时，需要编写测试文件、测试函数、测试变量，它们都需要遵循一定的规范。这些规范有些来自于官方，有些则来自于社区。这里，我分别来介绍下测试文件、包、测试函数和测试变量的命名规范。


#### 测试文件的命名规范
Go 的测试文件名必须以_test.go结尾。例如，如果我们有一个名为person.go的文件，那它的测试文件必须命名为person_test.go。这样做是因为，Go 需要区分哪些文件是测试文件。这些测试文件可以被 go test 命令行工具加载，用来测试我们编写的代码，但会被 Go 的构建程序忽略掉，因为 Go 程序的运行不需要这些测试代码。


#### 包的命名规范
Go 的测试可以分为白盒测试和黑盒测试。


白盒测试：将测试和生产代码放在同一个 Go 包中，这使我们可以同时测试 Go 包中可导出和不可导出的标识符。当我们编写的单元测试需要访问 Go 包中不可导出的变量、函数和方法时，就需要编写白盒测试用例。

黑盒测试：将测试和生产代码放在不同的 Go 包中。这时，我们仅可以测试 Go 包的可导出标识符。这意味着我们的测试包将无法访问生产代码中的任何内部函数、变量或常量。


在白盒测试中，Go 的测试包名称需要跟被测试的包名保持一致，例如：person.go定义了一个person包，则person_test.go的包名也要为person，这也意味着person.go和person_test.go都要在同一个目录中。

在黑盒测试中，Go 的测试包名称需要跟被测试的包名不同，但仍然可以存放在同一个目录下。比如，person.go定义了一个person包，则person_test.go的包名需要跟person不同，通常我们命名为person_test。



如果不是需要使用黑盒测试，我们在做单元测试时要尽量使用白盒测试。一方面，这是 go test 工具的默认行为；另一方面，使用白盒测试，我们可以测试和使用不可导出的标识符。测试文件和包的命名规范，由 Go 语言及 go test 工具来强制约束。


#### 函数的命名规范
测试用例函数必须以Test、Benchmark、Example开头，例如TestXxx、BenchmarkXxx、ExampleXxx，Xxx部分为任意字母数字的组合，首字母大写。这是由 Go 语言和 go test 工具来进行约束的，Xxx一般是需要测试的函数名。

除此之外，还有一些社区的约束，这些约束不是强制的，但是遵循这些约束会让我们的测试函数名更加易懂。例如，我们有以下函数：


```go
package main

type Person struct {
  age  int64
}

func (p *Person) older(other *Person) bool {
  return p.age > other.age
}
```
很显然，我们可以把测试函数命名为TestOlder，这个名称可以很清晰地说明它是Older函数的测试用例。但是，如果我们想用多个测试用例来测试TestOlder函数，这些测试用例该如何命名呢？也许你会说，我们命名为TestOlder1、TestOlder2不就行了？


其实，还有其他更好的命名方法。比如，这种情况下，我们可以将函数命名为TestOlderXxx，其中Xxx代表Older函数的某个场景描述。例如，strings.Compare函数有如下测试函数：TestCompare、TestCompareIdenticalString、TestCompareStrings。



#### 变量的命名规范
Go 语言和 go test 没有对变量的命名做任何约束。但是，在编写单元测试用例时，还是有一些规范值得我们去遵守。

单元测试用例通常会有一个实际的输出，在单元测试中，我们会将预期的输出跟实际的输出进行对比，来判断单元测试是否通过。为了清晰地表达函数的实际输出和预期输出，可以将这两类输出命名为expected/actual，或者got/want。例如：



```go
if c.expected != actual {
  t.Fatalf("Expected User-Agent '%s' does not match '%s'", c.expected, actual)
}
```
或者：


```go
if got, want := diags[3].Description().Summary, undeclPlural; got != want {
  t.Errorf("wrong summary for diagnostic 3\ngot:  %s\nwant: %s", got, want)
}
```
其他的变量命名，我们可以遵循 Go 语言推荐的变量命名方法，例如：

- Go 中的变量名应该短而不是长，对于范围有限的局部变量来说尤其如此。
- 变量离声明越远，对名称的描述性要求越高。
- 像循环、索引之类的变量，名称可以是单个字母（i）。如果是不常见的变量和全局变量，变量名就需要具有更多的描述性。


上面，我介绍了 Go 测试的一些基础知识。接下来，我们来看看如何编写单元测试用例和性能测试用例。


### 单元测试
单元测试用例函数以 Test 开头，例如 TestXxx 或 Test_xxx （ Xxx 部分为任意字母数字组合，首字母大写）。函数参数必须是 *testing.T，可以使用该类型来记录错误或测试状态。


我们可以调用 testing.T 的 Error 、Errorf 、FailNow 、Fatal 、FatalIf 方法，来说明测试不通过；调用 Log 、Logf 方法来记录测试信息。函数列表和相关描述如下表所示：


![img](https://static001.geekbang.org/resource/image/b3/ab/b374d392abfe62459d2c22e6ff76c0ab.jpg?wh=1920x1570)

下面的代码是两个简单的单元测试函数（函数位于文件math_test.go中）：


```go
func TestAbs(t *testing.T) {
    got := Abs(-1)
    if got != 1 {
        t.Errorf("Abs(-1) = %f; want 1", got)
    }
}

func TestMax(t *testing.T) {
    got := Max(1, 2)
    if got != 2 {
        t.Errorf("Max(1, 2) = %f; want 2", got)
    }
}
```
执行go test命令来执行如上单元测试用例：


```
$ go test
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.002s
```
go test命令自动搜集所有的测试文件，也就是格式为*_test.go的文件，从中提取全部测试函数并执行。go test 还支持下面三个参数。


-v，显示所有测试函数的运行细节：


```
$ go test -v
=== RUN   TestAbs
--- PASS: TestAbs (0.00s)
=== RUN   TestMax
--- PASS: TestMax (0.00s)
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.002s
```
-run < regexp>，指定要执行的测试函数：


```
$ go test -v -run='TestA.*'
=== RUN   TestAbs
--- PASS: TestAbs (0.00s)
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.001s
```
上面的例子中，我们只运行了以TestA开头的测试函数。

-count N，指定执行测试函数的次数：


```
$ go test -v -run='TestA.*' -count=2
=== RUN   TestAbs
--- PASS: TestAbs (0.00s)
=== RUN   TestAbs
--- PASS: TestAbs (0.00s)
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.002s
```
#### 多个输入的测试用例
前面介绍的单元测试用例只有一个输入，但是很多时候，我们需要测试一个函数在多种不同输入下是否能正常返回。这时候，我们可以编写一个稍微复杂点的测试用例，用来支持多输入下的用例测试。例如，我们可以将TestAbs改造成如下函数：


```go
func TestAbs_2(t *testing.T) {
    tests := []struct {
        x    float64
        want float64
    }{
        {-0.3, 0.3},
        {-2, 2},
        {-3.1, 3.1},
        {5, 5},
    }

    for _, tt := range tests {
        if got := Abs(tt.x); got != tt.want {
            t.Errorf("Abs() = %f, want %v", got, tt.want)
        }
    }
}
```
上述测试用例函数中，我们定义了一个结构体数组，数组中的每一个元素代表一次测试用例。数组元素的的值包含输入和预期的返回值：

```go
tests := []struct {
    x    float64
    want float64
}{
    {-0.3, 0.3},
    {-2, 2},
    {-3.1, 3.1},
    {5, 5},
}
```
上述测试用例，将被测函数放在 for 循环中执行：


```go
   for _, tt := range tests {
        if got := Abs(tt.x); got != tt.want {
            t.Errorf("Abs() = %f, want %v", got, tt.want)
        }
    }
```
上面的代码将输入传递给被测函数，并将被测函数的返回值跟预期的返回值进行比较。如果相等，则说明此次测试通过，如果不相等则说明此次测试不通过。通过这种方式，我们就可以在一个测试用例中，测试不同的输入和输出，也就是不同的测试用例。如果要新增一个测试用例，根据需要添加输入和预期的返回值就可以了，这些测试用例都共享其余的测试代码。


上面的测试用例中，我们通过got != tt.want来对比实际返回结果和预期返回结果。我们也可以使用github.com/stretchr/testify/assert包中提供的函数来做结果对比，例如：


```go
func TestAbs_3(t *testing.T) {
    tests := []struct {
        x    float64
        want float64
    }{
        {-0.3, 0.3},
        {-2, 2},
        {-3.1, 3.1},
        {5, 5},
    }

    for _, tt := range tests {
        got := Abs(tt.x)
        assert.Equal(t, got, tt.want)
    }
}
```
使用assert来对比结果，有下面这些好处：
- 友好的输出结果，易于阅读。
- 因为少了if got := Xxx(); got != tt.wang {}的判断，代码变得更加简洁。
- 可以针对每次断言，添加额外的消息说明，例如assert.Equal(t, got, tt.want, "Abs test")。


assert 包还提供了很多其他函数，供开发者进行结果对比，例如Zero、NotZero、Equal、NotEqual、Less、True、Nil、NotNil等。如果想了解更多函数，你可以参考go doc github.com/stretchr/testify/assert。


#### 自动生成单元测试用例
通过上面的学习，你也许可以发现，测试用例其实可以抽象成下面的模型：


![img](https://static001.geekbang.org/resource/image/8f/fa/8f06e0a1bf2638a9255467a29e6dfcfa.jpg?wh=1920x688)

用代码可表示为：



```go
func TestXxx(t *testing.T) {
    type args struct {
        // TODO: Add function input parameter definition.
    }

    type want struct {
         // TODO: Add function return parameter definition.
    }
    tests := []struct {
        name string
        args args
        want want
    }{
        // TODO: Add test cases.
    }
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            if got := Xxx(tt.args); got != tt.want {
                t.Errorf("Xxx() = %v, want %v", got, tt.want)
            }
        })
    }
}
```
既然测试用例可以抽象成一些模型，那么我们就可以基于这些模型来自动生成测试代码。Go 社区中有一些优秀的工具可以自动生成测试代码，我推荐你使用gotests工具。


下面，我来讲讲 gotests 工具的使用方法，可以分成三个步骤。第一步，安装 gotests 工具：


```
$ go get -u github.com/cweill/gotests/...
```
gotests 命令执行格式为：gotests [options] [PATH] [FILE] ...。gotests 可以为PATH下的所有 Go 源码文件中的函数生成测试代码，也可以只为某个FILE中的函数生成测试代码。


第二步，进入测试代码目录，执行 gotests 生成测试用例：


```
$ gotests -all -w .
```
上面的命令会为当前目录下所有 Go 源码文件中的函数生成测试代码。


第三步，添加测试用例：生成完测试用例，你只需要添加需要测试的输入和预期的输出就可以了。下面的测试用例是通过 gotests 生成的：


```go
func TestUnpointer(t *testing.T) {
    type args struct {
        offset *int64
        limit  *int64
    }
    tests := []struct {
        name string
        args args
        want *LimitAndOffset
    }{
        // TODO: Add test cases.
    }
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            if got := Unpointer(tt.args.offset, tt.args.limit); !reflect.DeepEqual(got, tt.want) {
                t.Errorf("Unpointer() = %v, want %v", got, tt.want)
            }
        })
    }
}
```
我们只需要补全TODO位置的测试数据即可，补全后的测试用例见gorm_test.go文件。


### 性能测试
上面，我讲了用来测试代码的功能是否正常的单元测试，接下来我们来看下性能测试，它是用来测试代码的性能是否满足需求的。


性能测试的用例函数必须以Benchmark开头，例如BenchmarkXxx或Benchmark_Xxx（ Xxx 部分为任意字母数字组合，首字母大写）。


函数参数必须是*testing.B，函数内以b.N作为循环次数，其中N会在运行时动态调整，直到性能测试函数可以持续足够长的时间，以便能够可靠地计时。下面的代码是一个简单的性能测试函数（函数位于文件math_test.go中）：


```go
func BenchmarkRandInt(b *testing.B) {
    for i := 0; i < b.N; i++ {
        RandInt()
    }
}
```
go test命令默认不会执行性能测试函数，需要通过指定参数-bench 来运行性能测试函数。-bench后可以跟正则表达式，选择需要执行的性能测试函数，例如go test -bench=".*"表示执行所有的压力测试函数。执行go test -bench=".*"后输出如下：


```
$ go test -bench=".*"
goos: linux
goarch: amd64
pkg: github.com/marmotedu/gopractise-demo/31/test
BenchmarkRandInt-4      97384827                12.4 ns/op
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    1.223s
```
上面的结果只显示了性能测试函数的执行结果。BenchmarkRandInt性能测试函数的执行结果如下：



```
BenchmarkRandInt-4     90848414          12.8 ns/op
```
每个函数的性能执行结果一共有 3 列，分别代表不同的意思，这里用上面的函数举例子：


- BenchmarkRandInt-4，BenchmarkRandInt表示所测试的测试函数名，4 表示有 4 个 CPU 线程参与了此次测试，默认是GOMAXPROCS的值。
- 90848414 ，说明函数中的循环执行了90848414次。
- 12.8 ns/op，说明每次循环的执行平均耗时是 12.8 纳秒，该值越小，说明代码性能越高。



如果我们的性能测试函数在执行循环前，需要做一些耗时的准备工作，我们就需要重置性能测试时间计数，例如：


```go
func BenchmarkBigLen(b *testing.B) {
    big := NewBig()
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        big.Len()
    }
}
```
当然，我们也可以先停止性能测试的时间计数，然后再开始时间计数，例如：


```go
func BenchmarkBigLen(b *testing.B) {
  b.StopTimer() // 调用该函数停止压力测试的时间计数
  big := NewBig()
  b.StartTimer() // 重新开始时间
  for i := 0; i < b.N; i++ {
    big.Len()
  }
}
```
B 类型的性能测试还支持下面 4 个参数。

benchmem，输出内存分配统计：


```
$ go test -bench=".*" -benchmem
goos: linux
goarch: amd64
pkg: github.com/marmotedu/gopractise-demo/31/test
BenchmarkRandInt-4      96776823                12.8 ns/op             0 B/op          0 allocs/op
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    1.255s
```
指定了-benchmem参数后，执行结果中又多了两列： 0 B/op，表示每次执行分配了多少内存（字节），该值越小，说明代码内存占用越小；0 allocs/op，表示每次执行分配了多少次内存，该值越小，说明分配内存次数越少，意味着代码性能越高。


benchtime，指定测试时间和循环执行次数（格式需要为 Nx，例如 100x）：


```
$ go test -bench=".*" -benchtime=10s # 指定测试时间
goos: linux
goarch: amd64
pkg: github.com/marmotedu/gopractise-demo/31/test
BenchmarkRandInt-4      910328618               13.1 ns/op
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    13.260s
$ go test -bench=".*" -benchtime=100x # 指定循环执行次数
goos: linux
goarch: amd64
pkg: github.com/marmotedu/gopractise-demo/31/test
BenchmarkRandInt-4           100                16.9 ns/op
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.003s
```
cpu，指定 GOMAXPROCS。
timeout，指定测试函数执行的超时时间：


```
$ go test -bench=".*" -timeout=10s
goos: linux
goarch: amd64
pkg: github.com/marmotedu/gopractise-demo/31/test
BenchmarkRandInt-4      97375881                12.4 ns/op
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    1.224s
```
### 总结
代码开发完成之后，我们需要为代码编写单元测试用例，并根据需要，给一些函数编写性能测试用例。Go 语言提供了 testing 包，供我们编写测试用例，并通过 go test 命令来执行这些测试用例。

go test 在执行测试用例时，会查找具有固定格式的 Go 源码文件名，并执行其中具有固定格式的函数，这些函数就是测试用例。这就要求我们的测试文件名、函数名要符合 go test 工具的要求：Go 的测试文件名必须以 _test.go 结尾；测试用例函数必须以 Test 、 Benchmark 、 Example 开头。此外，我们在编写测试用例时，还要注意包和变量的命名规范。

Go 项目开发中，编写得最多的是单元测试用例。单元测试用例函数以 Test 开头，例如 TestXxx 或 Test_xxx （Xxx 部分为任意字母数字组合，首字母大写）。函数参数必须是 *testing.T ，可以使用该类型来记录错误或测试状态。我们可以调用 testing.T 的 Error 、Errorf 、FailNow 、Fatal 、FatalIf 方法，来说明测试不通过；调用 Log 、Logf 方法来记录测试信息。


下面是一个简单的单元测试函数：



```go
func TestAbs(t *testing.T) {
    got := Abs(-1)
    if got != 1 {
        t.Errorf("Abs(-1) = %f; want 1", got)
    }
}
```
编写完测试用例之后，可以使用 go test 命令行工具来执行这些测试用例。此外，我们还可以使用gotests工具，来自动地生成单元测试用例，从而减少编写测试用例的工作量。

我们在 Go 项目开发中，还经常需要编写性能测试用例。性能测试用例函数必须以Benchmark开头，以*testing.B 作为函数入参，通过 go test -bench 运行。

## 37 | 代码测试（下）：Go 语言其他测试类型及 IAM 测试介绍
上一讲，我介绍了 Go 中的两类测试：单元测试和性能测试。在 Go 中，还有一些其他的测试类型和测试方法，值得我们去了解和掌握。此外，IAM 项目也编写了大量测试用例，这些测试用例使用了不同的编写方法，你可以通过学习 IAM 的测试用例来验证你学到的测试知识。今天，我就来介绍下 Go 语言中的其他测试类型：示例测试、TestMain 函数、Mock 测试、Fake 测试等，并且介绍下 IAM 项目是如何编写和运行测试用例的。

### 示例测试
示例测试以Example开头，没有输入和返回参数，通常保存在example_test.go文件中。示例测试可能包含以Output:或者Unordered output:开头的注释，这些注释放在函数的结尾部分。Unordered output:开头的注释会忽略输出行的顺序。

执行go test命令时，会执行这些示例测试，并且 go test 会将示例测试输出到标准输出的内容，跟注释作对比（比较时将忽略行前后的空格）。如果相等，则示例测试通过测试；如果不相等，则示例测试不通过测试。下面是一个示例测试（位于 example_test.go 文件中）：


```go
func ExampleMax() {
    fmt.Println(Max(1, 2))
    // Output:
    // 2
}
```
执行 go test 命令，测试ExampleMax示例测试：


```
$ go test -v -run='Example.*'
=== RUN   ExampleMax
--- PASS: ExampleMax (0.00s)
PASS
ok      github.com/marmotedu/gopractise-demo/31/test    0.004s
```
可以看到ExampleMax测试通过。这里测试通过是因为fmt.Println(Max(1, 2))向标准输出输出了2，跟// Output:后面的2一致。当示例测试不包含Output:或者Unordered output:注释时，执行go test只会编译这些函数，但不会执行这些函数。


#### 示例测试命名规范
示例测试需要遵循一些命名规范，因为只有这样，Godoc 才能将示例测试和包级别的标识符进行关联。例如，有以下示例测试（位于 example_test.go 文件中）：


```go
package stringutil_test

import (
    "fmt"

    "github.com/golang/example/stringutil"
)

func ExampleReverse() {
    fmt.Println(stringutil.Reverse("hello"))
    // Output: olleh
}
```
godoc 将在Reverse函数的文档旁边提供此示例，如下图所示：


![img](https://static001.geekbang.org/resource/image/d8/93/d8ae5e99fe1d159e9b3ba1f815b24693.png?wh=540x374)

示例测试名以Example开头，后面可以不跟任何字符串，也可以跟函数名、类型名或者类型_方法名，中间用下划线_连接，例如：



```go
func Example() { ... } // 代表了整个包的示例
func ExampleF() { ... } // 函数F的示例
func ExampleT() { ... } // 类型T的示例
func ExampleT_M() { ... } // 方法T_M的示例
```
当某个函数 / 类型 / 方法有多个示例测试时，可以通过后缀来区分，后缀必须以小写字母开头，例如：


```go
func ExampleReverse()
func ExampleReverse_second()
func ExampleReverse_third()
```
#### 大型示例
有时候，我们需要编写一个大型的示例测试，这时候我们可以编写一个整文件的示例（whole file example），它有这几个特点：文件名以_test.go结尾；只包含一个示例测试，文件中没有单元测试函数和性能测试函数；至少包含一个包级别的声明；当展示这类示例测试时，godoc 会直接展示整个文件。例如：


```go
package sort_test

import (
    "fmt"
    "sort"
)

type Person struct {
    Name string
    Age  int
}

func (p Person) String() string {
    return fmt.Sprintf("%s: %d", p.Name, p.Age)
}

// ByAge implements sort.Interface for []Person based on
// the Age field.
type ByAge []Person

func (a ByAge) Len() int           { return len(a) }
func (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
func (a ByAge) Less(i, j int) bool { return a[i].Age < a[j].Age }

func Example() {
    people := []Person{
        {"Bob", 31},
        {"John", 42},
        {"Michael", 17},
        {"Jenny", 26},
    }

    fmt.Println(people)
    sort.Sort(ByAge(people))
    fmt.Println(people)

    // Output:
    // [Bob: 31 John: 42 Michael: 17 Jenny: 26]
    // [Michael: 17 Jenny: 26 Bob: 31 John: 42]
}
```
一个包可以包含多个 whole file example，一个示例一个文件，例如example_interface_test.go、example_keys_test.go、example_search_test.go等。


#### TestMain 函数
有时候，我们在做测试的时候，可能会在测试之前做些准备工作，例如创建数据库连接等；在测试之后做些清理工作，例如关闭数据库连接、清理测试文件等。这时，我们可以在_test.go文件中添加TestMain函数，其入参为*testing.M。



TestMain是一个特殊的函数（相当于 main 函数），测试用例在执行时，会先执行TestMain函数，然后可以在TestMain中调用m.Run()函数执行普通的测试函数。在m.Run()函数前面我们可以编写准备逻辑，在m.Run()后面我们可以编写清理逻辑。我们在示例测试文件[math_test.go](https://github.com/marmotedu/gopractise-demo/blob/master/test/math_test.go)中添加如下 TestMain 函数：


```go
func TestMain(m *testing.M) {
    fmt.Println("do some setup")
    m.Run()
    fmt.Println("do some cleanup")
}
```
执行 go test，输出如下：

```
$ go test -v
do some setup
=== RUN   TestAbs
--- PASS: TestAbs (0.00s)
...
=== RUN   ExampleMax
--- PASS: ExampleMax (0.00s)
PASS
do some cleanup
ok    github.com/marmotedu/gopractise-demo/31/test  0.006s
```
在执行测试用例之前，打印了do some setup，在测试用例运行完成之后，打印了do some cleanup。IAM 项目的测试用例中，使用 TestMain 函数在执行测试用例前连接了一个 fake 数据库，代码如下（位于internal/apiserver/service/v1/user_test.go文件中）：


```go
func TestMain(m *testing.M) {
    fakeStore, _ := fake.NewFakeStore()
    store.SetClient(fakeStore)
    os.Exit(m.Run())
}
```
单元测试、性能测试、示例测试、TestMain 函数是 go test 支持的测试类型。此外，为了测试在函数内使用了 Go Interface 的函数，我们还延伸出了 Mock 测试和 Fake 测试两种测试类型。



### Mock 测试
一般来说，单元测试中是不允许有外部依赖的，那么也就是说，这些外部依赖都需要被模拟。在 Go 中，一般会借助各类 Mock 工具来模拟一些依赖。


GoMock 是由 Golang 官方开发维护的测试框架，实现了较为完整的基于 interface 的 Mock 功能，能够与 Golang 内置的 testing 包良好集成，也能用于其他的测试环境中。GoMock 测试框架包含了 GoMock 包和 mockgen 工具两部分，其中 GoMock 包用来完成对象生命周期的管理，mockgen 工具用来生成 interface 对应的 Mock 类源文件。下面，我来分别详细介绍下 GoMock 包和 mockgen 工具，以及它们的使用方法。


#### 安装 GoMock
要使用 GoMock，首先需要安装 GoMock 包和 mockgen 工具，安装方法如下:


```
$ go get github.com/golang/mock/gomock
$ go install github.com/golang/mock/mockgen
```
下面，我通过一个获取当前 Golang 最新版本的例子，来给你演示下如何使用 GoMock。示例代码目录结构如下（目录下的代码见gomock）：


```
tree .
.
├── go_version.go
├── main.go
└── spider
    └── spider.go
```
spider.go文件中定义了一个Spider接口，spider.go代码如下：


```go
package spider

type Spider interface {
    GetBody() string
}
```
Spider接口中的 GetBody 方法可以抓取https://golang.org首页的Build version字段，来获取 Golang 的最新版本。我们在go_version.go文件中，调用Spider接口的GetBody方法，go_version.go代码如下：

```go
package gomock

import (
    "github.com/marmotedu/gopractise-demo/gomock/spider"
)

func GetGoVersion(s spider.Spider) string {
    body := s.GetBody()
    return body
}

```
GetGoVersion函数直接返回表示版本的字符串。正常情况下，我们会写出如下的单元测试代码：


```go
func TestGetGoVersion(t *testing.T) {
    v := GetGoVersion(spider.CreateGoVersionSpider())
    if v != "go1.8.3" {
        t.Error("Get wrong version %s", v)
    }
}
```
上面的测试代码，依赖spider.CreateGoVersionSpider()返回一个实现了Spider接口的实例（爬虫）。但很多时候，spider.CreateGoVersionSpider()爬虫可能还没有实现，或者在单元测试环境下不能运行（比如，在单元测试环境中连接数据库），这时候TestGetGoVersion测试用例就无法执行。


那么，如何才能在这种情况下运行TestGetGoVersion测试用例呢？这时候，我们就可以通过 Mock 工具，Mock 一个爬虫实例。接下来我讲讲具体操作。首先，用 GoMock 提供的 mockgen 工具，生成要 Mock 的接口的实现，我们在 gomock 目录下执行以下命令：


```
$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider
```
上面的命令会在spider/mock目录下生成mock_spider.go文件：



```
$ tree .
.
├── go_version.go
├── go_version_test.go
├── go_version_test_traditional_method.go~
└── spider
    ├── mock
    │   └── mock_spider.go
    └── spider.go
```
mock_spider.go文件中，定义了一些函数 / 方法，可以支持我们编写TestGetGoVersion测试函数。这时候，我们的单元测试代码如下（见go_version_test.go文件）：


```go
package gomock

import (
  "testing"

  "github.com/golang/mock/gomock"

  spider "github.com/marmotedu/gopractise-demo/gomock/spider/mock"
)

func TestGetGoVersion(t *testing.T) {
  ctrl := gomock.NewController(t)
  defer ctrl.Finish()

  mockSpider := spider.NewMockSpider(ctrl)
  mockSpider.EXPECT().GetBody().Return("go1.8.3")
  goVer := GetGoVersion(mockSpider)

  if goVer != "go1.8.3" {
    t.Errorf("Get wrong version %s", goVer)
  }
}
```
这一版本的TestGetGoVersion通过 GoMock， Mock 了一个Spider接口，而不用去实现一个Spider接口。这就大大降低了单元测试用例编写的复杂度。通过 Mock，很多不能测试的函数也变得可测试了。通过上面的测试用例，我们可以看到，GoMock 和上一讲介绍的 testing 单元测试框架可以紧密地结合起来工作。



#### mockgen 工具介绍
上面，我介绍了如何使用 GoMock 编写单元测试用例。其中，我们使用到了mockgen工具来生成 Mock 代码，mockgen工具提供了很多有用的功能，这里我来详细介绍下。


mockgen工具是 GoMock 提供的，用来 Mock 一个 Go 接口。它可以根据给定的接口，来自动生成 Mock 代码。这里，有两种模式可以生成 Mock 代码，**分别是源码模式和反射模式。**



源码模式
如果有接口文件，则可以通过以下命令来生成 Mock 代码：


```
$ mockgen -destination spider/mock/mock_spider.go -package spider -source spider/spider.go
```
上面的命令，Mock 了spider/spider.go文件中定义的Spider接口，并将 Mock 代码保存在spider/mock/mock_spider.go文件中，文件的包名为spider。mockgen 工具的参数说明见下表：


![img](https://static001.geekbang.org/resource/image/e7/9c/e72102362e2ae3225e868f125654689c.jpg?wh=1920x1210)

反射模式
此外，mockgen 工具还支持通过使用反射程序来生成 Mock 代码。它通过传递两个非标志参数，即导入路径和逗号分隔的接口列表来启用，其他参数和源码模式共用，例如：

```
$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider
```
#### 通过注释使用 mockgen
如果有多个文件，并且分散在不同的位置，那么我们要生成 Mock 文件的时候，需要对每个文件执行多次 mockgen 命令（这里假设包名不相同）。这种操作还是比较繁琐的，mockgen 还提供了一种通过注释生成 Mock 文件的方式，此时需要借助go generate工具。


在接口文件的代码中，添加以下注释（具体代码见spider.go文件）：


```
//go:generate mockgen -destination mock_spider.go -package spider github.com/cz-it/blog/blog/Go/testing/gomock/example/spider Spider
```
这时候，我们只需要在gomock目录下，执行以下命令，就可以自动生成 Mock 代码：


```
$ go generate ./...
```
#### 使用 Mock 代码编写单元测试用例
生成了 Mock 代码之后，我们就可以使用它们了。这里我们结合testing来编写一个使用了 Mock 代码的单元测试用例。


首先，需要在单元测试代码里创建一个 Mock 控制器：


```
ctrl := gomock.NewController(t)
```
将*testing.T传递给 GoMock ，生成一个Controller对象，该对象控制了整个 Mock 的过程。在操作完后，还需要进行回收，所以一般会在NewController后面 defer 一个 Finish，代码如下：


```
defer ctrl.Finish()
```
然后，就可以调用 Mock 的对象了：


```
mockSpider := spider.NewMockSpider(ctrl)
```
这里的spider是 mockgen 命令里面传递的包名，后面是NewMockXxxx格式的对象创建函数，Xxx是接口名。这里，我们需要传递控制器对象进去，返回一个 Mock 实例。接着，有了 Mock 实例，我们就可以调用其断言方法EXPECT()了。

gomock 采用了链式调用法，通过.连接函数调用，可以像链条一样连接下去。例如：


```
mockSpider.EXPECT().GetBody().Return("go1.8.3")
```
Mock 一个接口的方法，我们需要 Mock 该方法的入参和返回值。我们可以通过参数匹配来 Mock 入参，通过 Mock 实例的 Return 方法来 Mock 返回值。下面，我们来分别看下如何指定入参和返回值。先来看如何指定入参。如果函数有参数，我们可以使用参数匹配来指代函数的参数，例如：


```
mockSpider.EXPECT().GetBody(gomock.Any(), gomock.Eq("admin")).Return("go1.8.3")
```
gomock 支持以下参数匹配：
- gomock.Any()，可以用来表示任意的入参。
- gomock.Eq(value)，用来表示与 value 等价的值。
- gomock.Not(value)，用来表示非 value 以外的值。
- gomock.Nil()，用来表示 None 值。

接下来，我们看如何指定返回值。EXPECT()得到 Mock 的实例，然后调用 Mock 实例的方法，该方法返回第一个Call对象，然后可以对其进行条件约束，比如使用 Mock 实例的 Return 方法约束其返回值。Call对象还提供了以下方法来约束 Mock 实例：

```go
func (c *Call) After(preReq *Call) *Call // After声明调用在preReq完成后执行
func (c *Call) AnyTimes() *Call // 允许调用次数为 0 次或更多次
func (c *Call) Do(f interface{}) *Call // 声明在匹配时要运行的操作
func (c *Call) MaxTimes(n int) *Call // 设置最大的调用次数为 n 次
func (c *Call) MinTimes(n int) *Call // 设置最小的调用次数为 n 次
func (c *Call) Return(rets ...interface{}) *Call //  // 声明模拟函数调用返回的值
func (c *Call) SetArg(n int, value interface{}) *Call // 声明使用指针设置第 n 个参数的值
func (c *Call) Times(n int) *Call // 设置调用次数为 n 次
```
上面列出了多个 Call 对象提供的约束方法，接下来我会介绍 3 个常用的约束方法：指定返回值、指定执行次数和指定执行顺序。


指定返回值
我们可以提供调用Call的Return函数，来指定接口的返回值，例如：



```
mockSpider.EXPECT().GetBody().Return("go1.8.3")
```
指定执行次数
有时候，我们需要指定函数执行多少次，例如：对于接受网络请求的函数，计算其执行了多少次。我们可以通过Call的Times函数来指定执行次数：


```
mockSpider.EXPECT().Recv().Return(nil).Times(3)
```
上述代码，执行了三次 Recv 函数，这里 gomock 还支持其他的执行次数限制：
- AnyTimes()，表示执行 0 到多次。
- MaxTimes(n int)，表示如果没有设置，最多执行 n 次。
- MinTimes(n int)，表示如果没有设置，最少执行 n 次。


指定执行顺序
有时候，我们还要指定执行顺序，比如要先执行 Init 操作，然后才能执行 Recv 操作：


```
initCall := mockSpider.EXPECT().Init()
mockSpider.EXPECT().Recv().After(initCall)
```
最后，我们可以使用go test来测试使用了 Mock 代码的单元测试代码：


```
$ go test -v
=== RUN   TestGetGoVersion
--- PASS: TestGetGoVersion (0.00s)
PASS
ok    github.com/marmotedu/gopractise-demo/gomock  0.002s
```
### Fake 测试
在 Go 项目开发中，对于比较复杂的接口，我们还可以 Fake 一个接口实现，来进行测试。所谓 Fake 测试，其实就是针对接口实现一个假（fake）的实例。至于如何实现 Fake 实例，需要你根据业务自行实现。例如：IAM 项目中 iam-apiserver 组件就实现了一个 fake store，代码见fake目录。因为这一讲后面的 IAM 项目测试实战部分有介绍，所以这里不再展开讲解。


### 何时编写和执行单元测试用例？
上面，我介绍了 Go 代码测试的基础知识，这里我再来分享下在做测试时一个比较重要的知识点：何时编写和执行单元测试用例。


#### 编码前：TDD


![img](https://static001.geekbang.org/resource/image/48/b2/4830b21b55d194eccf1ec74637ee3eb2.png?wh=538x516)

Test-Driven Development，也就是测试驱动开发，是敏捷开发的⼀项核心实践和技术，也是⼀种设计方法论。简单来说，TDD 原理就是：开发功能代码之前，先编写测试用例代码，然后针对测试用例编写功能代码，使其能够通过。这样做的好处在于，通过测试的执行代码肯定满足需求，而且有助于面向接口编程，降低代码耦合，也极大降低了 bug 的出现几率。

然而，TDD 的坏处也显而易见：由于测试用例是在进行代码设计之前写的，很有可能限制开发者对代码的整体设计；并且，由于 TDD 对开发⼈员要求非常高，体现的思想跟传统开发思维也不⼀样，因此实施起来比较困难；此外，因为要先编写测试用例，TDD 也可能会影响项目的研发进度。所以，在客观情况不满足的情况下，不应该盲目追求对业务代码使用 TDD 的开发模式。


#### 与编码同步进行：增量
及时为增量代码写单测是一种良好的习惯。一方面是因为，此时我们对需求有一定的理解，能够更好地写出单元测试来验证正确性。并且，在单测阶段就发现问题，而不是等到联调测试中才发现，修复的成本也是最小的。


另一方面，在写单测的过程中，我们也能够反思业务代码的正确性、合理性，推动我们在实现的过程中更好地反思代码的设计，并及时调整。


#### 编码后：存量
在完成业务需求后，我们可能会遇到这种情况：因为上线时间比较紧张、没有单测相关规划，开发阶段只手动测试了代码是否符合功能。

如果这部分存量代码出现较大的新需求，或者维护已经成为问题，需要大规模重构，这正是推动补全单测的好时机。为存量代码补充上单测，一方面能够推进重构者进一步理解原先的逻辑，另一方面也能够增强重构者重构代码后的信心，降低风险。

但是，补充存量单测可能需要再次回忆理解需求和逻辑设计等细节，而有时写单测的人并不是原编码的设计者，所以编码后编写和执行单元测试用例也有一定的不足。


#### 测试覆盖率
我们写单元测试的时候应该想得很全面，能够覆盖到所有的测试用例，但有时也会漏过一些 case，Go 提供了 cover 工具来统计测试覆盖率。具体可以分为两大步骤。

第一步，生成测试覆盖率数据：

```
$ go test -coverprofile=coverage.out
do some setup
PASS
coverage: 40.0% of statements
do some cleanup
ok    github.com/marmotedu/gopractise-demo/test  0.003s

```
上面的命令在当前目录下生成了coverage.out覆盖率数据文件。


![img](https://static001.geekbang.org/resource/image/3c/01/3c11a0d41d6ed736f364c1693a2eff01.png?wh=1920x366)
第二步，分析覆盖率文件：


```
$ go tool cover -func=coverage.out
do some setup
PASS
coverage: 40.0% of statements
do some cleanup
ok    github.com/marmotedu/gopractise-demo/test  0.003s
[colin@dev test]$ go tool cover -func=coverage.out
github.com/marmotedu/gopractise-demo/test/math.go:9:  Abs    100.0%
github.com/marmotedu/gopractise-demo/test/math.go:14:  Max    100.0%
github.com/marmotedu/gopractise-demo/test/math.go:19:  Min    0.0%
github.com/marmotedu/gopractise-demo/test/math.go:24:  RandInt    0.0%
github.com/marmotedu/gopractise-demo/test/math.go:29:  Floor    0.0%
total:              (statements)  40.0%
```
在上述命令的输出中，我们可以查看到哪些函数没有测试，哪些函数内部的分支没有测试完全。cover 工具会根据被执行代码的行数与总行数的比例计算出覆盖率。可以看到，Abs 和 Max 函数的测试覆盖率为 100%，Min 和 RandInt 的测试覆盖率为 0。


我们还可以使用go tool cover -html生成HTML格式的分析文件，可以更加清晰地展示代码的测试情况：


```
$ go tool cover -html=coverage.out -o coverage.html
```
上述命令会在当前目录下生成一个coverage.html文件，用浏览器打开coverage.html文件，可以更加清晰地看到代码的测试情况，如下图所示：


![img](https://static001.geekbang.org/resource/image/f0/5e/f089f5d44ba06f052c1c46c858c2b75e.png?wh=1524x1075)

通过上图，我们可以知道红色部分的代码没有被测试到，可以让我们接下来有针对性地添加测试用例，而不是一头雾水，不知道需要为哪些代码编写测试用例。



在 Go 项目开发中，我们往往会把测试覆盖率作为代码合并的一个强制要求，所以需要在进行代码测试时，同时生成代码覆盖率数据文件。在进行代码测试时，可以通过分析该文件，来判断我们的代码测试覆盖率是否满足要求，如果不满足则代码测试失败。


### IAM 项目测试实战
接下来，我来介绍下 IAM 项目是如何编写和运行测试用例的，你可以通过 IAM 项目的测试用例，加深对上面内容的理解。



#### IAM 项目是如何运行测试用例的？
首先，我们来看下 IAM 项目是如何执行测试用例的。在 IAM 项目的源码根目录下，可以通过运行make test执行测试用例，make test会执行iam/scripts/make-rules/golang.mk文件中的go.test伪目标，规则如下：


```
.PHONY: go.test
go.test: tools.verify.go-junit-report
  @echo "===========> Run unit test"
  @set -o pipefail;$(GO) test -race -cover -coverprofile=$(OUTPUT_DIR)/coverage.out \\
    -timeout=10m -short -v `go list ./...|\
    egrep -v $(subst $(SPACE),'|',$(sort $(EXCLUDE_TESTS)))` 2>&1 | \\
    tee >(go-junit-report --set-exit-code >$(OUTPUT_DIR)/report.xml)
  @sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out # remove mock_.*.go files from test coverage
  @$(GO) tool cover -html=$(OUTPUT_DIR)/coverage.out -o $(OUTPUT_DIR)/coverage.html
```
在上述规则中，我们执行go test时设置了超时时间、竞态检查，开启了代码覆盖率检查，覆盖率测试数据保存在了coverage.out文件中。在 Go 项目开发中，并不是所有的包都需要单元测试，所以上面的命令还过滤掉了一些不需要测试的包，这些包配置在EXCLUDE_TESTS变量中：


```
EXCLUDE_TESTS=github.com/marmotedu/iam/test github.com/marmotedu/iam/pkg/log github.com/marmotedu/iam/third_party github.com/marmotedu/iam/internal/pump/storage github.com/marmotedu/iam/internal/pump github.com/marmotedu/iam/internal/pkg/logger
```
同时，也调用了go-junit-report将 go test 的结果转化成了 xml 格式的报告文件，该报告文件会被一些 CI 系统，例如 Jenkins 拿来解析并展示结果。上述代码也同时生成了 coverage.html 文件，该文件可以存放在制品库中，供我们后期分析查看。


这里需要注意，Mock 的代码是不需要编写测试用例的，为了避免影响项目的单元测试覆盖率，需要将 Mock 代码的单元测试覆盖率数据从coverage.out文件中删除掉，go.test规则通过以下命令删除这些无用的数据：


```
sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out # remove mock_.*.go files from test coverage
```
另外，还可以通过make cover来进行单元测试覆盖率测试，make cover会执行iam/scripts/make-rules/golang.mk文件中的go.test.cover伪目标，规则如下：


```
.PHONY: go.test.cover
go.test.cover: go.test
  @$(GO) tool cover -func=$(OUTPUT_DIR)/coverage.out | \\
    awk -v target=$(COVERAGE) -f $(ROOT_DIR)/scripts/coverage.awk
```
上述目标依赖go.test，也就是说执行单元测试覆盖率目标之前，会先进行单元测试，然后使用单元测试产生的覆盖率数据coverage.out计算出总的单元测试覆盖率，这里是通过coverage.awk脚本来计算的。如果单元测试覆盖率不达标，Makefile 会报错并退出。可以通过 Makefile 的COVERAGE变量来设置单元测试覆盖率阈值。


COVERAGE 的默认值为 60，我们也可以在命令行手动指定，例如：


```
$ make cover COVERAGE=80
```
为了确保项目的单元测试覆盖率达标，需要设置单元测试覆盖率质量红线。一般来说，这些红线很难靠开发者的自觉性去保障，所以好的方法是将质量红线加入到 CICD 流程中。所以，在Makefile文件中，我将cover放在all目标的依赖中，并且位于 build 之前，也就是all: gen add-copyright format lint cover build。这样每次当我们执行 make 时，会自动进行代码测试，并计算单元测试覆盖率，如果覆盖率不达标，则停止构建；如果达标，继续进入下一步的构建流程。

#### IAM 项目测试案例分享
接下来，我会给你展示一些 IAM 项目的测试案例，因为这些测试案例的实现方法，我在36 讲 和这一讲的前半部分已有详细介绍，所以这里，我只列出具体的实现代码，不会再介绍这些代码的实现方法。


单元测试案例
我们可以手动编写单元测试代码，也可以使用 gotests 工具生成单元测试代码。先来看手动编写测试代码的案例。这里单元测试代码见Test_Option，代码如下：

```go
func Test_Option(t *testing.T) {
    fs := pflag.NewFlagSet("test", pflag.ExitOnError)
    opt := log.NewOptions()
    opt.AddFlags(fs)

    args := []string{"--log.level=debug"}
    err := fs.Parse(args)
    assert.Nil(t, err)

    assert.Equal(t, "debug", opt.Level)
}

```
上述代码中，使用了github.com/stretchr/testify/assert包来对比结果。再来看使用 gotests 工具生成单元测试代码的案例（Table-Driven 的测试模式）。出于效率上的考虑，IAM 项目的单元测试用例，基本都是使用 gotests 工具生成测试用例模板代码，并基于这些模板代码填充测试 Case 的。代码见service_test.go文件。



性能测试案例
IAM 项目的性能测试用例，见BenchmarkListUser测试函数。代码如下：

```go
func BenchmarkListUser(b *testing.B) {
  opts := metav1.ListOptions{
    Offset: pointer.ToInt64(0),
    Limit:  pointer.ToInt64(50),
  }
  storeIns, _ := fake.GetFakeFactoryOr()
  u := &userService{
    store: storeIns,
  }

  for i := 0; i < b.N; i++ {
    _, _ = u.List(context.TODO(), opts)
  }
}
```
示例测试案例
IAM 项目的示例测试用例见example_test.go文件。example_test.go中的一个示例测试代码如下：


```go
func ExampleNew() {
  err := New("whoops")
  fmt.Println(err)

  // Output: whoops
}
```
TestMain 测试案例
IAM 项目的 TestMain 测试案例，见user_test.go文件中的TestMain函数：


```go
func TestMain(m *testing.M) {
    _, _ = fake.GetFakeFactoryOr()
    os.Exit(m.Run())
}
```
TestMain函数初始化了 fake Factory，然后调用m.Run执行测试用例。


Mock 测试案例
Mock 代码见internal/apiserver/service/v1/mock_service.go，使用 Mock 的测试用例见internal/apiserver/controller/v1/user/create_test.go文件。因为代码比较多，这里建议你打开链接，查看测试用例的具体实现。我们可以在 IAM 项目的根目录下执行以下命令，来自动生成所有的 Mock 文件：


```
$ go generate ./...
```
Fake 测试案例
fake store 代码实现位于internal/apiserver/store/fake目录下。fake store 的使用方式，见user_test.go文件：


```go
func TestMain(m *testing.M) {
    _, _ = fake.GetFakeFactoryOr()
    os.Exit(m.Run())
}

func BenchmarkListUser(b *testing.B) {
    opts := metav1.ListOptions{
        Offset: pointer.ToInt64(0),
        Limit:  pointer.ToInt64(50),
    }
    storeIns, _ := fake.GetFakeFactoryOr()
    u := &userService{
        store: storeIns,
    }

    for i := 0; i < b.N; i++ {
        _, _ = u.List(context.TODO(), opts)
    }
}
```
上述代码通过TestMain初始化 fake 实例（store.Factory接口类型）：


```go
func GetFakeFactoryOr() (store.Factory, error) {
    once.Do(func() {
        fakeFactory = &datastore{
            users:    FakeUsers(ResourceCount),
            secrets:  FakeSecrets(ResourceCount),
            policies: FakePolicies(ResourceCount),
        }
    })

    if fakeFactory == nil {
        return nil, fmt.Errorf("failed to get mysql store fatory, mysqlFactory: %+v", fakeFactory)
    }

    return fakeFactory, nil
}
```
GetFakeFactoryOr函数，创建了一些 fake users、secrets、policies，并保存在了fakeFactory变量中，供后面的测试用例使用，例如 BenchmarkListUser、Test_newUsers 等。



### 其他测试工具 / 包
最后，我再来分享下 Go 项目测试中常用的工具 / 包，因为内容较多，我就不详细介绍了，如果感兴趣你可以点进链接自行学习。我将这些测试工具 / 包分为了两类，分别是测试框架和 Mock 工具。


#### 测试框架
Testify 框架：Testify 是 Go test 的预判工具，它能让你的测试代码变得更优雅和高效，测试结果也变得更详细。

GoConvey 框架：GoConvey 是一款针对 Golang 的测试框架，可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。


#### Mock 工具
这一讲里，我介绍了 Go 官方提供的 Mock 框架 GoMock，不过还有一些其他的优秀 Mock 工具可供我们使用。这些 Mock 工具分别用在不同的 Mock 场景中，我在 10 讲中已经介绍过。不过，为了使我们这一讲的测试知识体系更加完整，这里我还是再提一次，你可以复习一遍。


- sqlmock：可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。
- httpmock：可以用来 Mock HTTP 请求。
- bouk/monkey：猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果 golang/mock、sqlmock 和 httpmock 这几种方法都不能满足我们的需求，我们可以尝试用猴子补丁的方式来 Mock 依赖。可以这么说，猴子补丁提供了单元测试 Mock 依赖的最终解决方案。


### 总结
这一讲，我介绍了除单元测试和性能测试之外的另一些测试方法。

除了示例测试和 TestMain 函数，我还详细介绍了 Mock 测试，也就是如何使用 GoMock 来测试一些在单元测试环境下不好实现的接口。绝大部分情况下，可以使用 GoMock 来 Mock 接口，但是对于一些业务逻辑比较复杂的接口，我们可以通过 Fake 一个接口实现，来对代码进行测试，这也称为 Fake 测试。此外，我还介绍了何时编写和执行测试用例。我们可以根据需要，选择在编写代码前、编写代码中、编写代码后编写测试用例。

为了保证单元测试覆盖率，我们还应该为整个项目设置单元测试覆盖率质量红线，并将该质量红线加入到 CICD 流程中。我们可以通过 go test -coverprofile=coverage.out 命令来生成测试覆盖率数据，通过go tool cover -func=coverage.out 命令来分析覆盖率文件。


IAM 项目中使用了大量的测试方法和技巧来测试代码，为了加深你对测试知识的理解，我也列举了一些测试案例，供你参考、学习和验证。具体的测试案例，你可以返回前面查看下。除此之外，我们还可以使用其他一些测试框架，例如 Testify 框架和 GoConvey 框架。在 Go 代码测试中，我们最常使用的是 Go 官方提供的 Mock 框架 GoMock，但仍然有其他优秀的 Mock 工具，可供我们在不同场景下使用，例如 sqlmock、httpmock、bouk/monkey 等。

## 38｜性能分析（上）：如何分析 Go 语言代码的性能？

作为开发人员，我们一般都局限在功能上的单元测试中，对一些性能上的细节往往不会太关注。但是，如果我们在上线的时候对项目的整体性能没有一个全面的了解，随着请求量越来越大，可能会出现各种各样的问题，比如 CPU 占用高、内存使用率高、请求延时高等。为了避免这些性能瓶颈，我们在开发的过程中需要通过一定的手段，来对程序进行性能分析。


Go 语言已经为开发者内置了很多性能调优、监控的工具和方法，这大大提升了我们 profile 分析的效率，借助这些工具，我们可以很方便地对 Go 程序进行性能分析。在 Go 语言开发中，开发者基本都是通过内置的pprof工具包来进行性能分析的。

在进行性能分析时，我们会先借助一些工具和包，生成性能数据文件，然后再通过pprof工具分析性能数据文件，从而分析代码的性能。那么接下来，我们就分别来看下如何执行这两步操作。


### 生成性能数据文件
要查看性能数据，需要先生成性能数据文件。生成性能数据文件有三种方法，分别是通过命令行、通过代码和通过net/http/pprof包。这些工具和包会分别生成 CPU 和内存性能数据。接下来，我们就来看下这三种方法分别是如何生成性能数据文件的。

#### 通过命令行生成性能数据文件
我们可以使用go test -cpuprofile来生成性能测试数据。进入internal/apiserver/service/v1目录，执行以下命令：


```
$ go test -bench=".*" -cpuprofile cpu.profile -memprofile mem.profile
goos: linux
goarch: amd64
pkg: github.com/marmotedu/iam/internal/apiserver/service/v1
cpu: AMD EPYC Processor
BenchmarkListUser-8          280     4283077 ns/op
PASS
ok    github.com/marmotedu/iam/internal/apiserver/service/v1  1.798s
```
上面的命令会在当前目录下生成 3 个文件：
- v1.test，测试生成的二进制文件，进行性能分析时可以用来解析各种符号。
- cpu.profile，CPU 性能数据文件。
- mem.profile，内存性能数据文件。


#### 通过代码生成性能数据文件
我们还可以使用代码来生成性能数据文件，例如pprof.go文件：


```go
package main

import (
  "os"
  "runtime/pprof"
)

func main() {
  cpuOut, _ := os.Create("cpu.out")
  defer cpuOut.Close()
  pprof.StartCPUProfile(cpuOut)
  defer pprof.StopCPUProfile()

  memOut, _ := os.Create("mem.out")
  defer memOut.Close()
  defer pprof.WriteHeapProfile(memOut)

  Sum(3, 5)

}

func Sum(a, b int) int {
  return a + b
}

```
运行pprof.go文件：


```
$ go run pprof.go
```
运行pprof.go文件后，会在当前目录生成cpu.profile和mem.profile性能数据文件。



#### 通过net/http/pprof生成性能数据文件
如果要分析 HTTP Server 的性能，我们可以使用net/http/pprof包来生成性能数据文件。IAM 项目使用 Gin 框架作为 HTTP 引擎，所以 IAM 项目使用了github.com/gin-contrib/pprof包来启用 HTTP 性能分析。github.com/gin-contrib/pprof包是net/http/pprof的一个简单封装，通过封装使 pprof 的功能变成了一个 Gin 中间件，这样可以根据需要加载 pprof 中间件。


github.com/gin-contrib/pprof包中的pprof.go文件中有以下代码：


```go
func Register(r *gin.Engine, prefixOptions ...string) {
    prefix := getPrefix(prefixOptions...)

    prefixRouter := r.Group(prefix)
    {
        ...
        prefixRouter.GET("/profile", pprofHandler(pprof.Profile))
        ...
    }
}

func pprofHandler(h http.HandlerFunc) gin.HandlerFunc {
    handler := http.HandlerFunc(h)
    return func(c *gin.Context) {
        handler.ServeHTTP(c.Writer, c.Request)
    }
}
```
通过上面的代码，你可以看到github.com/gin-contrib/pprof包将net/http/pprof.Profile转换成了gin.HandlerFunc，也就是 Gin 中间件。

要开启 HTTP 性能分析，只需要在代码中注册 pprof 提供的 HTTP Handler 即可（位于internal/pkg/server/genericapiserver.go文件中）：


```go
// install pprof handler
if s.enableProfiling {
    pprof.Register(s.Engine)
}
```
上面的代码根据配置--feature.profiling来判断是否开启 HTTP 性能分析功能。我们开启完 HTTP 性能分析，启动 HTTP 服务 iam-apiserver 后，即可访问http:// x.x.x.x:8080/debug/pprof（x.x.x.x是 Linux 服务器的地址）来查看 profiles 信息。profiles 信息如下图所示：


![img](https://static001.geekbang.org/resource/image/6a/6b/6a5fc33b87b6322162c39e9209b6396b.png?wh=1520x1170)
我们可以通过以下命令，来获取 CPU 性能数据文件：

```
$ curl http://127.0.0.1:8080/debug/pprof/profile -o cpu.profile
```
执行完上面的命令后，需要等待 30s，pprof 会采集这 30s 内的性能数据，我们需要在这段时间内向服务器连续发送多次请求，请求的频度可以根据我们的场景来决定。30s 之后，/debug/pprof/profile接口会生成 CPU profile 文件，被 curl 命令保存在当前目录下的 cpu.profile 文件中。


同样的，我们可以执行以下命令来生成内存性能数据文件：


```
$ curl http://127.0.0.1:8080/debug/pprof/heap -o mem.profile
```
上面的命令会自动下载 heap 文件，并被 curl 命令保存在当前目录下的 mem.profile 文件中。


我们可以使用go tool pprof [mem|cpu].profile命令来分析 HTTP 接口的 CPU 和内存性能。我们也可以使用命令go tool pprof http://127.0.0.1:8080/debug/pprof/profile，或者go tool pprof http://127.0.0.1:8080/debug/pprof/heap，来直接进入 pprof 工具的交互 Shell 中。go tool pprof会首先下载并保存 CPU 和内存性能数据文件，然后再分析这些文件。


通过上面的三种方法，我们生成了 cpu.profile 和 mem.profile，接下来我们就可以使用go tool pprof来分析这两个性能数据文件，进而分析我们程序的 CPU 和内存性能了。下面，我来具体讲讲性能分析的过程。


#### 性能分析
使用go tool pprof，来对性能进行分析的流程，你可以参考下图：


![img](https://static001.geekbang.org/resource/image/d4/da/d41d03c41283ea00308682a9yy0400da.jpg?wh=1920x665)

接下来，我先给你介绍下 pprof 工具，再介绍下如何生成性能数据，最后再分别介绍下 CPU 和内存性能分析方法。



#### pprof 工具介绍
pprof是一个 Go 程序性能分析工具，用它可以访问并分析性能数据文件，它还会根据我们的要求，提供高可读性的输出信息。Go 在语言层面上集成了 profile 采样工具，只需在代码中简单地引入runtime/pprof或者net/http/pprof包，即可获取程序的 profile 文件，并通过 profile 文件来进行性能分析。


net/http/pprof基于runtime/pprof包进行封装，并在 HTTP 端口上暴露出来。



#### 生成性能数据
我们在做性能分析时，主要是对内存和 CPU 性能进行分析。为了分析内存和 CPU 的性能，我们需要先生成性能数据文件。在 IAM 源码中，也有包含性能测试的用例，下面我会借助 IAM 源码中的性能测试用例，来介绍如何分析程序的性能。


进入internal/apiserver/service/v1目录，user_test.go 文件包含了性能测试函数 BenchmarkListUser，执行以下命令来生成性能数据文件：



```
$ go test -benchtime=30s -benchmem -bench=".*" -cpuprofile cpu.profile -memprofile mem.profile
goos: linux
goarch: amd64
pkg: github.com/marmotedu/iam/internal/apiserver/service/v1
cpu: AMD EPYC Processor
BenchmarkListUser-8          175   204523677 ns/op     15331 B/op       268 allocs/op
PASS
ok    github.com/marmotedu/iam/internal/apiserver/service/v1  56.514s
```
上面的命令会在当前目录下产生cpu.profile、mem.profile性能数据文件，以及v1.test二进制文件。接下来，我们基于cpu.profile、mem.profile、v1.test文件来分析代码的 CPU 和内存性能。为了获取足够的采样数据，我们将 benchmark 时间设置为30s。


在做性能分析时，我们可以采取不同的手段来分析性能，比如分析采样图、分析火焰图，还可以使用go tool pprof交互模式，查看函数 CPU 和内存消耗数据。下面我会运用这些方法，来分析 CPU 性能和内存性能。



### CPU 性能分析
在默认情况下，Go 语言的运行时系统会以 100 Hz 的的频率对 CPU 使用情况进行采样，也就是说每秒采样 100 次，每 10 毫秒采样一次。每次采样时，会记录正在运行的函数，并统计其运行时间，从而生成 CPU 性能数据。


上面我们已经生成了 CPU 性能数据文件cpu.profile，接下来会运用上面提到的三种方法来分析该性能文件，优化性能。

#### 方法一：分析采样图
要分析性能，最直观的方式当然是看图，所以首先我们需要生成采样图，生成过程可以分为两个步骤。



第一步，确保系统安装了graphviz：

```
$ sudo yum -y install graphviz.x86_64
```
第二步，执行go tool pprof生成调用图：


```
$ go tool pprof -svg cpu.profile > cpu.svg  # svg 格式
$ go tool pprof -pdf cpu.profile > cpu.pdf # pdf 格式
$ go tool pprof -png cpu.profile > cpu.png # png 格式
```
以上命令会生成cpu.pdf、cpu.svg和cpu.png文件，文件中绘制了函数调用关系以及其他采样数据。如下图所示：


![img](https://static001.geekbang.org/resource/image/a7/0c/a737e4d5f25775150545558872aa9e0c.png?wh=438x1259)


这张图片由有向线段和矩形组成。**我们先来看有向线段的含义。**

有向线段描述了函数的调用关系，矩形包含了 CPU 采样数据。从图中，我们看到没箭头的一端调用了有箭头的一端，可以知道v1.(*userService).List函数调用了fake.(*policies).List。线段旁边的数字90ms则说明，v1.(*userService).List调用fake.(*policies).List函数，在采样周期内，一共耗用了90ms。通过函数调用关系，我们可以知道某个函数调用了哪些函数，并且调用这些函数耗时多久。

这里，我们再次解读下图中调用关系中的重要信息：


![img](https://static001.geekbang.org/resource/image/70/32/70e964bc6d8f0b28d434cce47c4e1132.png?wh=835x818)

runtime.schedule的累积采样时间（140ms）中，有 10ms 来自于runtime.goschedImpl函数的直接调用，有 70ms 来自于runtime.park_m函数的直接调用。这些数据可以说明runtime.schedule函数分别被哪些函数调用，并且调用频率有多大。也因为这个原因，函数runtime.goschedImpl对函数runtime.schedule的调用时间必定小于等于函数runtime.schedule的累积采样时间。



我们再来看下矩形里的采样数据。这些矩形基本都包含了 3 类信息：
- 函数名 / 方法名，该类信息包含了包名、结构体名、函数名 / 方法名，方便我们快速定位到函数 / 方法，例如fake(*policies)List说明是 fake 包，policies 结构体的 List 方法。
- 本地采样时间，以及它在采样总数中所占的比例。本地采样时间是指采样点落在该函数中的总时间。
- 累积采样时间，以及它在采样总数中所占的比例。累积采样时间是指采样点落在该函数，以及被它直接或者间接调用的函数中的总时间。

我们可以通过OutDir函数来解释本地采样时间和累积采样时间这两个概念。OutDir函数如下图所示：


![img](https://static001.geekbang.org/resource/image/f5/a5/f55c738c09471094a9a8498e9b73faa5.png?wh=1020x558)

整个函数的执行耗时，我们可以认为是累积采样时间，包含了白色部分的代码耗时和红色部分的函数调用耗时。白色部分的代码耗时，可以认为是本地采样时间。

通过累积采样时间，我们可以知道函数的总调用时间，累积采样时间越大，说明调用它所花费的 CPU 时间越多。但你要注意，这并不一定说明这个函数本身是有问题的，也有可能是函数所调用的函数性能有瓶颈，这时候我们应该根据函数调用关系顺藤摸瓜，去寻找这个函数直接或间接调用的函数中最耗费 CPU 时间的那些。


如果函数的本地采样时间很大，就说明这个函数自身耗时（除去调用其他函数的耗时）很大，这时候需要我们分析这个函数自身的代码，而不是这个函数直接或者间接调用函数的代码。采样图中，矩形框面积越大，说明这个函数的累积采样时间越大。那么，如果一个函数分析采样图中的矩形框面积很大，这时候我们就要认真分析了，因为很可能这个函数就有需要优化性能的地方。


#### 方法二：分析火焰图
上面介绍的采样图，其实在分析性能的时候还不太直观，这里我们可以通过生成火焰图，来更直观地查看性能瓶颈。火焰图是由 Brendan Gregg 大师发明的专门用来把采样到的堆栈轨迹（Stack Trace）转化为直观图片显示的工具，因整张图看起来像一团跳动的火焰而得名。


go tool pprof提供了-http参数，可以使我们通过浏览器浏览采样图和火焰图。执行以下命令：


```
$ go tool pprof -http="0.0.0.0:8081" v1.test cpu.profile
```
然后访问http://x.x.x.x:8081/（x.x.x.x是执行go tool pprof命令所在服务器的 IP 地址），则会在浏览器显示各类采样视图数据，如下图所示：


![img](https://static001.geekbang.org/resource/image/91/9d/91dab469d3d61dd4302d3ef5d483609d.png?wh=1920x679)


上面的 UI 页面提供了不同的采样数据视图：
- Top，类似于 linux top 的形式，从高到低排序。
- Graph，默认弹出来的就是该模式，也就是上一个图的那种带有调用关系的图。
- Flame Graph：pprof 火焰图。
- Peek：类似于 Top 也是从高到底的排序。
- Source：和交互命令式的那种一样，带有源码标注。
- Disassemble：显示所有的总量。

接下来，我们主要来分析火焰图。在 UI 界面选择 Flame Graph（VIEW -> Flame Graph），就会展示火焰图，如下图所示：


![img](https://static001.geekbang.org/resource/image/33/e9/33e427f1a2419e0420e9ef8e9ddd69e9.png?wh=1920x609)

火焰图主要有下面这几个特征：
- 每一列代表一个调用栈，每一个格子代表一个函数。
- 纵轴展示了栈的深度，按照调用关系从上到下排列。最下面的格子代表采样时，正在占用 CPU 的函数。
- 调用栈在横向会按照字母排序，并且同样的调用栈会做合并，所以一个格子的宽度越大，说明这个函数越可能是瓶颈。
- 火焰图格子的颜色是随机的暖色调，方便区分各个调用信息。

查看火焰图时，格子越宽的函数，就越可能存在性能问题，这时候，我们就可以分析该函数的代码，找出问题所在。



#### 方法三：用go tool pprof交互模式查看详细数据
我们可以执行go tool pprof命令，来查看 CPU 的性能数据文件：


```
$ go tool pprof v1.test cpu.profile
File: v1.test
Type: cpu
Time: Aug 17, 2021 at 2:17pm (CST)
Duration: 56.48s, Total samples = 440ms ( 0.78%)
Entering interactive mode (type "help" for commands, "o" for options)
(pprof)
```
go tool pprof输出了很多信息：
- File，二进制可执行文件名称。
- Type，采样文件的类型，例如 cpu、mem 等。
- Time，生成采样文件的时间。
- Duration，程序执行时间。上面的例子中，程序总执行时间为37.43s，采样时间为42.37s。采样程序在采样时，会自动分配采样任务给多个核心，所以总采样时间可能会大于总执行时间。
- (pprof)，命令行提示，表示当前在go tool的pprof工具命令行中，go tool还包括cgo、doc、pprof、trace等多种命令。


执行go tool pprof命令后，会进入一个交互 shell。在这个交互 shell 中，我们可以执行多个命令，最常用的命令有三个，如下表所示：


![img](https://static001.geekbang.org/resource/image/d1/98/d10a2c6cbfa4e35fc4efc9a3760d1b98.jpg?wh=1920x1196)
我们在交互界面中执行top命令，可以查看性能样本数据：


```
(pprof) top
Showing nodes accounting for 350ms, 79.55% of 440ms total
Showing top 10 nodes out of 47
      flat  flat%   sum%        cum   cum%
     110ms 25.00% 25.00%      110ms 25.00%  runtime.futex
      70ms 15.91% 40.91%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List
      40ms  9.09% 50.00%       40ms  9.09%  runtime.epollwait
      40ms  9.09% 59.09%      180ms 40.91%  runtime.findrunnable
      30ms  6.82% 65.91%       30ms  6.82%  runtime.write1
      20ms  4.55% 70.45%       30ms  6.82%  runtime.notesleep
      10ms  2.27% 72.73%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List
      10ms  2.27% 75.00%       10ms  2.27%  runtime.checkTimers
      10ms  2.27% 77.27%       10ms  2.27%  runtime.doaddtimer
      10ms  2.27% 79.55%       10ms  2.27%  runtime.mallocgc
```
上面的输出中，每一行表示一个函数的信息。pprof 程序中最重要的命令就是 topN，这个命令用来显示 profile 文件中最靠前的 N 个样本（sample），top 命令会输出多行信息，每一行代表一个函数的采样数据，默认按flat%排序。输出中，各列含义如下：

- flat：采样点落在该函数中的总时间。
- flat%：采样点落在该函数中时间的百分比。
- sum%：前面所有行的 flat% 的累加值，也就是上一项的累积百分比。
- cum：采样点落在该函数中的，以及被它调用的函数中的总时间。
- cum%：采样点落在该函数中的，以及被它调用的函数中的总次数百分比。
- 函数名。


上面这些信息，可以告诉我们函数执行的时间和耗时排名，我们可以根据这些信息，来判断哪些函数可能有性能问题，或者哪些函数的性能可以进一步优化。这里想提示下，如果执行的是go tool pprof mem.profile，那么上面的各字段意义是类似的，只不过这次不是时间而是内存分配大小（字节）。


执行top命令默认是按flat%排序的，在做性能分析时，我们需要先按照cum来排序，通过cum，我们可以直观地看到哪个函数总耗时最多，然后再参考该函数的本地采样时间和调用关系，来判断是该函数性能耗时多，还是它调用的函数耗时多。执行top -cum输出如下：


```
(pprof) top20 -cum
Showing nodes accounting for 280ms, 63.64% of 440ms total
Showing top 20 nodes out of 47
      flat  flat%   sum%        cum   cum%
         0     0%     0%      320ms 72.73%  runtime.mcall
         0     0%     0%      320ms 72.73%  runtime.park_m
         0     0%     0%      280ms 63.64%  runtime.schedule
      40ms  9.09%  9.09%      180ms 40.91%  runtime.findrunnable
     110ms 25.00% 34.09%      110ms 25.00%  runtime.futex
      10ms  2.27% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List
         0     0% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.BenchmarkListUser
         0     0% 36.36%      100ms 22.73%  runtime.futexwakeup
         0     0% 36.36%      100ms 22.73%  runtime.notewakeup
         0     0% 36.36%      100ms 22.73%  runtime.resetspinning
         0     0% 36.36%      100ms 22.73%  runtime.startm
         0     0% 36.36%      100ms 22.73%  runtime.wakep
         0     0% 36.36%      100ms 22.73%  testing.(*B).launch
         0     0% 36.36%      100ms 22.73%  testing.(*B).runN
      70ms 15.91% 52.27%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List
      10ms  2.27% 54.55%       50ms 11.36%  runtime.netpoll
      40ms  9.09% 63.64%       40ms  9.09%  runtime.epollwait
         0     0% 63.64%       40ms  9.09%  runtime.modtimer
         0     0% 63.64%       40ms  9.09%  runtime.resetForSleep
         0     0% 63.64%       40ms  9.09%  runtime.resettimer (inline)

```
从上面的输出可知，v1.BenchmarkListUser、testing.(*B).launch、testing.(*B).runN的本地采样时间占比分别为0%、0%、0%，但是三者的累积采样时间占比却比较高，分别为22.73%、22.73%、22.73%。



本地采样时间占比很小，但是累积采样时间占比很高，说明这 3 个函数耗时多是因为调用了其他函数，它们自身几乎没有耗时。根据采样图，我们可以看到函数的调用关系，具体如下图所示：


![img](https://static001.geekbang.org/resource/image/b0/4c/b0b7624a7922cea801de63b865f6ed4c.jpg?wh=1920x437)

从采样图中，可以知道最终v1.BenchmarkListUser调用了v1.(*userService).List函数。v1.(*userService).List函数是我们编写的函数，该函数的本地采样时间占比为2.27%，但是累积采样时间占比却高达22.73%，说明v1.(*userService).List调用其他函数耗用了大量的 CPU 时间。

再观察采样图，可以看出v1.(*userService).List耗时久是因为调用了fake.(*policies).List函数。我们也可以通过list命令查看函数内部的耗时情况：


![img](https://static001.geekbang.org/resource/image/81/23/81765c7e56cb45d03a0a61de5835d823.png?wh=1920x576)

list userService.*List会列出userService结构体List方法内部代码的耗时情况，从上图也可以看到，u.store.Policies().List耗时最多。fake.(*policies).List的本地采样时间占比为15.91%，说明fake.(*policies).List函数本身可能存在瓶颈。走读fake.(*policies).List代码可知，该函数是查询数据库的函数，查询数据库会有延时。继续查看v1.(*userService).List代码，我们可以发现以下调用逻辑：


```go
func (u *userService) ListWithBadPerformance(ctx context.Context, opts metav1.ListOptions) (*v1.UserList, error) {
    ...
    for _, user := range users.Items {
        policies, err := u.store.Policies().List(ctx, user.Name, metav1.ListOptions{})
        ...
        })
    }
    ...
}
```
我们在for循环中，串行调用了fake.(*policies).List函数，每一次循环都会调用有延时的fake.(*policies).List函数。多次调用，v1.(*userService).List函数的耗时自然会累加起来。


现在问题找到了，那我们怎么优化呢？你可以利用 CPU 多核特性，开启多个 goroutine，这样我们的查询耗时就不是串行累加的，而是取决于最慢一次的fake.(*policies).List调用。优化后的v1.(*userService).List函数代码见internal/apiserver/service/v1/user.go。用同样的性能测试用例，测试优化后的函数，结果如下：



```
$ go test -benchtime=30s -benchmem -bench=".*" -cpuprofile cpu.profile -memprofile mem.profile
goos: linux
goarch: amd64
pkg: github.com/marmotedu/iam/internal/apiserver/service/v1
cpu: AMD EPYC Processor
BenchmarkListUser-8         8330     4271131 ns/op     26390 B/op       484 allocs/op
PASS
ok    github.com/marmotedu/iam/internal/apiserver/service/v1  36.179s
```
上面的代码中，ns/op 为4271131 ns/op，可以看到和第一次的测试结果204523677 ns/op相比，性能提升了97.91%。这里注意下，为了方便你对照，我将优化前的v1.(*userService).List函数重命名为v1.(*userService).ListWithBadPerformance。


#### 内存性能分析
Go 语言运行时，系统会对程序运行期间的所有堆内存分配进行记录。不管在采样的哪一时刻，也不管堆内存已用字节数是否有增长，只要有字节被分配且数量足够，分析器就会对它进行采样。



内存性能分析方法和 CPU 性能分析方法比较类似，这里就不再重复介绍了。你可以借助前面生成的内存性能数据文件mem.profile自行分析。接下来，给你展示下内存优化前和优化后的效果。在v1.(*userService).List函数（位于internal/apiserver/service/v1/user.go文件中）中，有以下代码：


```go
infos := make([]*v1.User, 0)
for _, user := range users.Items {
    info, _ := m.Load(user.ID)
    infos = append(infos, info.(*v1.User))
}

```
此时，我们运行go test命令，测试下内存性能，作为优化后的性能数据，进行对比：

```
$ go test -benchmem -bench=".*" -cpuprofile cpu.profile -memprofile mem.profile
goos: linux
goarch: amd64
pkg: github.com/marmotedu/iam/internal/apiserver/service/v1
cpu: AMD EPYC Processor
BenchmarkListUser-8          278     4284660 ns/op     27101 B/op       491 allocs/op
PASS
ok    github.com/marmotedu/iam/internal/apiserver/service/v1  1.779s
```
B/op和allocs/op分别为27101 B/op和491 allocs/op。我们通过分析代码，发现可以将infos := make([]*v1.User, 0)优化为infos := make([]*v1.User, 0, len(users.Items))，来减少 Go 切片的内存重新分配的次数。优化后的代码为：

```go
//infos := make([]*v1.User, 0)
infos := make([]*v1.User, 0, len(users.Items))
for _, user := range users.Items {
    info, _ := m.Load(user.ID)
    infos = append(infos, info.(*v1.User))
}
```
再执行go test测试下性能：


```
$ go test -benchmem -bench=".*" -cpuprofile cpu.profile -memprofile mem.profile
goos: linux
goarch: amd64
pkg: github.com/marmotedu/iam/internal/apiserver/service/v1
cpu: AMD EPYC Processor
BenchmarkListUser-8          276     4318472 ns/op     26457 B/op       484 allocs/op
PASS
ok    github.com/marmotedu/iam/internal/apiserver/service/v1  1.856s
```
优化后的B/op和allocs/op分别为26457 B/op和484 allocs/op。跟第一次的27101 B/op和491 allocs/op相比，内存分配次数更少，每次分配的内存也更少。我们可以执行go tool pprof命令，来查看 CPU 的性能数据文件：



```
$ go tool pprof v1.test mem.profile
File: v1.test
Type: alloc_space
Time: Aug 17, 2021 at 8:33pm (CST)
Entering interactive mode (type "help" for commands, "o" for options)
(pprof)
```
该命令会进入一个交互界面，在交互界面中执行 top 命令，可以查看性能样本数据，例如：


```
(pprof) top
Showing nodes accounting for 10347.32kB, 95.28% of 10859.34kB total
Showing top 10 nodes out of 52
      flat  flat%   sum%        cum   cum%
 3072.56kB 28.29% 28.29%  4096.64kB 37.72%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List.func1
 1762.94kB 16.23% 44.53%  1762.94kB 16.23%  runtime/pprof.StartCPUProfile
 1024.52kB  9.43% 53.96%  1024.52kB  9.43%  go.uber.org/zap/buffer.NewPool.func1
 1024.08kB  9.43% 63.39%  1024.08kB  9.43%  time.Sleep
  902.59kB  8.31% 71.70%   902.59kB  8.31%  compress/flate.NewWriter
  512.20kB  4.72% 76.42%  1536.72kB 14.15%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List
  512.19kB  4.72% 81.14%   512.19kB  4.72%  runtime.malg
  512.12kB  4.72% 85.85%   512.12kB  4.72%  regexp.makeOnePass
  512.09kB  4.72% 90.57%   512.09kB  4.72%  github.com/marmotedu/iam/internal/apiserver/store/fake.FakeUsers
  512.04kB  4.72% 95.28%   512.04kB  4.72%  runtime/pprof.allFrames
```
上面的内存性能数据，各字段的含义依次是：
- flat，采样点落在该函数中的总内存消耗。
- flat% ，采样点落在该函数中的百分比。
- sum% ，上一项的累积百分比。
- cum ，采样点落在该函数，以及被它调用的函数中的总内存消耗。
- cum%，采样点落在该函数，以及被它调用的函数中的总次数百分比。
- 函数名。



### 总结
在 Go 项目开发中，程序性能低下时，我们需要分析出问题所在的代码。Go 语言提供的 go tool pprof 工具可以支持我们分析代码的性能。我们可以通过两步来分析代码的性能，分别是生成性能数据文件和分析性能数据文件。Go 中可以用来生成性能数据文件的方式有三种：通过命令行生成性能数据文件、通过代码生成性能数据文件、通过 net/http/pprof 生成性能数据文件。


生成性能数据文件之后，就可以使用 go tool pprof 工具来分析性能数据文件了。我们可以分别获取到 CPU 和内存的性能数据，通过分析就可以找到性能瓶颈。有 3 种分析性能数据文件的方式，分别是分析采样图、分析火焰图和用 go tool pprof 交互模式查看详细数据。因为火焰图直观高效，所以我建议你多使用火焰图来分析性能。

## 39｜性能分析（下）：API Server性能测试和调优实战

上一讲，我们学习了如何分析 Go 代码的性能。掌握了性能分析的基本知识之后，这一讲，我们再来看下如何分析 API 接口的性能。在 API 上线之前，我们需要知道 API 的性能，以便知道 API 服务器所能承载的最大请求量、性能瓶颈，再根据业务对性能的要求，来对 API 进行性能调优或者扩缩容。通过这些，可以使 API 稳定地对外提供服务，并且让请求在合理的时间内返回。这一讲，我就介绍如何用 wrk 工具来测试 API Server 接口的性能，并给出分析方法和结果。



### API 性能测试指标
API 性能测试，往大了说其实包括 API 框架的性能和指定 API 的性能。不过，因为指定 API 的性能跟该 API 具体的实现（比如有无数据库连接，有无复杂的逻辑处理等）有关，我认为脱离了具体实现来探讨单个 API 的性能是毫无意义的，所以这一讲只探讨 API 框架的性能。


用来衡量 API 性能的指标主要有 3 个：
- 并发数（Concurrent）：并发数是指某个时间范围内，同时在使用系统的用户个数。广义上的并发数是指同时使用系统的用户个数，这些用户可能调用不同的 API；严格意义上的并发数是指同时请求同一个 API 的用户个数。这一讲我们讨论的并发数是严格意义上的并发数。
- 每秒查询数（QPS）：每秒查询数 QPS 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。QPS = 并发数 / 平均请求响应时间。
- 请求响应时间（TTLB）：请求响应时间指的是从客户端发出请求到得到响应的整个时间。这个过程从客户端发起的一个请求开始，到客户端收到服务器端的响应结束。在一些工具中，请求响应时间通常会被称为 TTLB（Time to last byte，意思是从发送一个请求开始，到客户端收到最后一个字节的响应为止所消费的时间）。请求响应时间的单位一般为“秒”或“毫秒”。

这三个指标中，衡量 API 性能的最主要指标是 QPS，但是在说明 QPS 时，需要指明是多少并发数下的 QPS，否则毫无意义，因为不同并发数下的 QPS 是不同的。举个例子，单用户 100 QPS 和 100 用户 100 QPS 是两个不同的概念，前者说明 API 可以在一秒内串行执行 100 个请求，而后者说明在并发数为 100 的情况下，API 可以在一秒内处理 100 个请求。当 QPS 相同时，并发数越大，说明 API 性能越好，并发处理能力越强。


在并发数设置过大时，API 同时要处理很多请求，会频繁切换上下文，而真正用于处理请求的时间变少，反而使得 QPS 会降低。并发数设置过大时，请求响应时间也会变长。API 会有一个合适的并发数，在该并发数下，API 的 QPS 可以达到最大，但该并发数不一定是最佳并发数，还要参考该并发数下的平均请求响应时间。


此外，在有些 API 接口中，也会测试 API 接口的 TPS（Transactions Per Second，每秒事务数）。一个事务是指客户端向服务器发送请求，然后服务器做出反应的过程。客户端在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。


那么，TPS 和 QPS 有什么区别呢？如果是对一个查询接口（单场景）压测，且这个接口内部不会再去请求其他接口，那么 TPS=QPS，否则，TPS≠QPS。如果是对多个接口（混合场景）压测，假设 N 个接口都是查询接口，且这个接口内部不会再去请求其他接口，QPS=N*TPS。

### API 性能测试方法
Linux 下有很多 Web 性能测试工具，常用的有 Jmeter、AB、Webbench 和 wrk。每个工具都有自己的特点，IAM 项目使用 wrk 来对 API 进行性能测试。wrk 非常简单，安装方便，测试结果也相对专业，并且可以支持 Lua 脚本来创建更复杂的测试场景。下面，我来介绍下 wrk 的安装方法和使用方法。


#### wrk 安装方法
wrk 的安装很简单，一共可分为两步。第一步，Clone wrk repo：


```
$ git clone https://github.com/wg/wrk
```
第二步，编译并安装：


```
$ cd wrk
$ make
$ sudo cp ./wrk /usr/bin
```
#### wrk 使用简介
这里我们来看下 wrk 的使用方法。wrk 使用起来不复杂，执行wrk --help可以看到 wrk 的所有运行参数：


```
$ wrk --help
Usage: wrk <options> <url>
  Options:
    -c, --connections <N>  Connections to keep open
    -d, --duration    <T>  Duration of test
    -t, --threads     <N>  Number of threads to use

    -s, --script      <S>  Load Lua script file
    -H, --header      <H>  Add header to request
        --latency          Print latency statistics
        --timeout     <T>  Socket/request timeout
    -v, --version          Print version details

  Numeric arguments may include a SI unit (1k, 1M, 1G)
  Time arguments may include a time unit (2s, 2m, 2h)

```
常用的参数有下面这些：
- -t，线程数（线程数不要太多，是核数的 2 到 4 倍就行，多了反而会因为线程切换过多造成效率降低）。
- -c，并发数。
- -d，测试的持续时间，默认为 10s。
- -T，请求超时时间。
- -H，指定请求的 HTTP Header，有些 API 需要传入一些 Header，可通过 wrk 的 -H 参数来传入。
- –latency，打印响应时间分布。
- -s，指定 Lua 脚本，Lua 脚本可以实现更复杂的请求。


然后，我们来看一个 wrk 的测试结果，并对结果进行解析。一个简单的测试如下（确保 iam-apiserver 已经启动，并且开启了健康检查）：


```
$ wrk -t144 -c30000 -d30s -T30s --latency http://10.0.4.57:8080/healthz
Running 30s test @ http://10.0.4.57:8080/healthz
  144 threads and 30000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   508.77ms  604.01ms   9.27s    81.59%
    Req/Sec   772.48      0.94k   10.45k    86.82%
  Latency Distribution
     50%  413.35ms
     75%  948.99ms
     90%    1.33s
     99%    2.44s
  2276265 requests in 30.10s, 412.45MB read
  Socket errors: connect 1754, read 40, write 0, timeout 0
Requests/sec:  75613.16
Transfer/sec:     13.70MB
```
下面是对测试结果的解析。
- 144 threads and 30000 connections：用 144 个线程模拟 20000 个连接，分别对应 -t 和 -c 参数。
- Thread Stats 是线程统计，包括 Latency 和 Req/Sec。
  - Latency：响应时间，有平均值、标准偏差、最大值、正负一个标准差占比。
  - Req/Sec：每个线程每秒完成的请求数, 同样有平均值、标准偏差、最大值、正负一个标准差占比。
- Latency Distribution 是响应时间分布。
  - 50%：50% 的响应时间为 413.35ms。
  - 75%：75% 的响应时间为 948.99ms。
  - 90%：90% 的响应时间为 1.33s。
  - 99%：99% 的响应时间为 2.44s。

- 2276265 requests in 30.10s, 412.45MB read：30.10s 完成的总请求数（2276265）和数据读取量（412.45MB）。
- Socket errors: connect 1754, read 40, write 0, timeout 0：错误统计，会统计 connect 连接失败请求个数（1754）、读失败请求个数、写失败请求个数、超时请求个数。
- Requests/sec：QPS。
- Transfer/sec：平均每秒读取 13.70MB 数据（吞吐量）。


### API Server 性能测试实践
接下来，我们就来测试下 API Server 的性能。影响 API Server 性能的因素有很多，除了 iam-apiserver 自身的原因之外，服务器的硬件和配置、测试方法、网络环境等都会影响。为了方便你对照性能测试结果，我给出了我的测试环境配置，你可以参考下。

- 客户端硬件配置：1 核 4G。
- 客户端软件配置：干净的CentOS Linux release 8.2.2004 (Core)。
- 服务端硬件配置：2 核 8G。
- 服务端软件配置：干净的CentOS Linux release 8.2.2004 (Core)。
- 测试网络环境：腾讯云 VPC 内访问，除了性能测试程序外，没有其他资源消耗型业务程序。


测试架构如下图所示：


![img](https://static001.geekbang.org/resource/image/7d/c4/7df51487bc7b761d79247a5d547745c4.jpg?wh=2248x575)

#### 性能测试脚本介绍
在做 API Server 的性能测试时，需要先执行 wrk，生成性能测试数据。为了能够更直观地查看性能数据，我们还需要以图表的方式展示这些性能数据。这一讲，我使用 gnuplot 工具来自动化地绘制这些性能图，为此我们需要确保 Linux 服务器已经安装了 gnuplot 工具。你可以通过以下方式安装：



```
$ sudo yum -y install gnuplot
```
在这一讲的测试中，我会绘制下面这两张图，通过它们来观测和分析 API Server 的性能。
- QPS & TTLB 图：X轴为并发数（Concurrent），Y轴为每秒查询数（QPS）和请求响应时间（TTLB）。
- 成功率图：X轴为并发数（Concurrent），Y轴为请求成功率。


为了方便你测试 API 接口性能，我将性能测试和绘图逻辑封装在[scripts/wrktest.sh](https://github.com/marmotedu/iam/blob/v1.0.8/scripts/wrktest.sh)脚本中，你可以在 iam 源码根目录下执行如下命令，生成性能测试数据和性能图表：


```
$ scripts/wrktest.sh http://10.0.4.57:8080/healthz
```
上面的命令会执行性能测试，记录性能测试数据，并根据这些性能测试数据绘制出 QPS 和成功率图。接下来，我再来介绍下 wrktest.sh 性能测试脚本，并给出一个使用示例。

wrktest.sh 性能测试脚本，用来测试 API Server 的性能，记录测试的性能数据，并根据性能数据使用 gnuplot 绘制性能图。wrktest.sh 也可以对比前后两次的性能测试结果，并将对比结果通过图表展示出来。wrktest.sh 会根据 CPU 的核数自动计算出适合的 wrk 启动线程数（-t）：CPU核数 * 3。


wrktest.sh 默认会测试多个并发下的 API 性能，默认测试的并发数为200 500 1000 3000 5000 10000 15000 20000 25000 50000。你需要根据自己的服务器配置选择测试的最大并发数，我因为服务器配置不高（主要是8G内存在高并发下，很容易就耗尽），最大并发数选择了50000。如果你的服务器配置够高，可以再依次尝试下测试 100000 、200000 、500000 、1000000 并发下的 API 性能。


wrktest.sh 的使用方法如下：


```
$ scripts/wrktest.sh -h

Usage: scripts/wrktest.sh [OPTION] [diff] URL
Performance automation test script.

  URL                    HTTP request url, like: http://10.0.4.57:8080/healthz
  diff                   Compare two performance test results

OPTIONS:
  -h                     Usage information
  -n                     Performance test task name, default: apiserver
  -d                     Directory used to store performance data and gnuplot graphic, default: _output/wrk

Reprot bugs to <colin404@foxmail.com>.
```
wrktest.sh 提供的命令行参数介绍如下。
- URL：需要测试的 API 接口。
- diff：如果比较两次测试的结果，需要执行 wrktest.sh diff。
- -n：本次测试的任务名，wrktest.sh 会根据任务名命名生成的文件。
- -d：输出文件存放目录。
- -h：打印帮助信息。

下面，我来展示一个 wrktest.sh 使用示例。wrktest.sh 的主要功能有两个，分别是运行性能测试并获取结果和对比性能测试结果。下面我就分别介绍下它们的具体使用方法。


运行性能测试并获取结果执行如下命令：

```
$ scripts/wrktest.sh http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 200 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 500 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 1000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 3000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 5000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 10000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 15000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 20000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 25000 http://10.0.4.57:8080/healthz
Running wrk command: wrk -t3 -d300s -T30s --latency -c 50000 http://10.0.4.57:8080/healthz

Now plot according to /home/colin/_output/wrk/apiserver.dat
QPS graphic file is: /home/colin/_output/wrk/apiserver_qps_ttlb.png
Success rate graphic file is: /home/colin/_output/wrk/apiserver_successrate.pngz
```
上面的命令默认会在_output/wrk/目录下生成 3 个文件：
- apiserver.dat，wrk 性能测试结果，每列含义分别为并发数、QPS 平均响应时间、成功率。
- apiserver_qps_ttlb.png，QPS&TTLB 图。
- apiserver_successrate.png，成功率图。

这里要注意，请求 URL 中的 IP 地址应该是腾讯云 VPC 内网地址，因为通过内网访问，不仅网络延时最低，而且还最安全，所以真实的业务通常都是内网访问的。


对比性能测试结果
假设我们还有另外一次 API 性能测试，测试数据保存在 _output/wrk/http.dat 文件中。执行如下命令，对比两次测试结果：

```
$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat
```
apiserver.dat和http.dat是两个需要对比的 Wrk 性能数据文件。上述命令默认会在_output/wrk目录下生成下面这两个文件：
- apiserver_http.qps.ttlb.diff.png，QPS & TTLB 对比图。
- apiserver_http.success_rate.diff.png，成功率对比图。


#### 关闭 Debug 配置选项
在测试之前，我们需要关闭一些 Debug 选项，以免影响性能测试。执行下面这两步操作，修改 iam-apiserver 的配置文件：

- 将server.mode设置为 release，server.middlewares去掉 dump、logger 中间件。
- 将log.level设置为 info，log.output-paths去掉 stdout。


因为我们要在执行压力测试时分析程序的性能，所以需要设置feature.profiling为 true，以开启性能分析。修改完之后，重新启动 iam-apiserver。


#### 使用 wrktest.sh 测试 IAM API 接口性能
关闭 Debug 配置选项之后，就可以执行wrktest.sh命令测试 API 性能了（默认测试的并发数为200 500 1000 3000 5000 10000 15000 20000 25000 50000）:


```
$ scripts/wrktest.sh http://10.0.4.57:8080/healthz
```
生成的 QPS & TTLB 图和成功率图分别如下图所示：


![img](https://static001.geekbang.org/resource/image/0a/0f/0aca3648e72974c5a32c2fbcfea8670f.png?wh=640x480)

上图中，X轴为并发数（Concurrent），Y轴为每秒查询数（QPS）和请求响应时间（TTLB）。


![img](https://static001.geekbang.org/resource/image/a2/5d/a2d7866536ee96327a10614dd332475d.png?wh=640x480)

上图中，X轴为并发数（Concurrent），Y轴为请求成功率。通过上面两张图，你可以看到，API Server 在并发数为200时，QPS 最大；并发数为500，平均响应时间为56.33ms，成功率为 100.00% 。在并发数达到1000时，成功率开始下降。一些详细数据从图里看不到，你可以直接查看apiserver.dat文件，里面记录了每个并发下具体的 QPS、TTLB 和成功率数据。



现在我们有了 API Server 的性能数据，那么该 API Server 的 QPS 处于什么水平呢？一方面，你可以根据自己的业务需要来对比；另一方面，可以和性能更好的 Web 框架进行对比，总之需要有个参照。这里用 net/http 构建最简单的 HTTP 服务器，使用相同的测试工具和测试服务器，测试性能并作对比。HTTP 服务源码为（位于文件tools/httptest/main.go中）：



```go
package main

import (
  "fmt"
  "log"
  "net/http"
)

func main() {
  http.HandleFunc("/healthz", func(w http.ResponseWriter, r *http.Request) {
    message := `{"status":"ok"}`
    fmt.Fprint(w, message)
  })

  addr := ":6667"
  fmt.Printf("Serving http service on %s\n", addr)
  log.Fatal(http.ListenAndServe(addr, nil))
}

```
我们将上述 HTTP 服务的请求路径设置为/healthz，并且返回{"status":"ok"}，跟 API Server 的接口返回数据完全一样。通过这种方式，你可以排除因为返回数据大小不同而造成的性能差异。可以看到，该 HTTP 服务器很简单，只是利用net/http包最原生的功能，在 Go 中几乎所有的 Web 框架都是基于net/http包封装的。既然是封装，肯定比不上原生的性能，所以我们要把它跟用net/http直接启动的 HTTP 服务接口的性能进行对比，来衡量我们的 API Server 性能。


我们需要执行相同的 wrk 测试，并将结果跟 API Server 的测试结果进行对比，将对比结果绘制成对比图。具体对比过程可以分为 3 步。


第一步，启动 HTTP 服务。在 iam 源码根目录下执行如下命令：


```
$ go run tools/httptest/main.go
```
第二步，执行wrktest.sh脚本，测试该 HTTP 服务的性能：

```
$ scripts/wrktest.sh -n http http://10.0.4.57:6667/healthz
```
上述命令会生成 _output/wrk/http.dat 文件。第三步，对比两次性能测试数据：

```
$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat
```
生成的两张对比图表，如下所示：


![img](https://static001.geekbang.org/resource/image/51/f4/51eacf20d190080bf8b42e2f43yy00f4.png?wh=640x480)



![img](https://static001.geekbang.org/resource/image/e1/99/e1cc646da40036a44e5300ed2bef8999.png?wh=640x480)

通过上面两张对比图，我们可以看出，API Server 在 QPS、响应时间和成功率上都不如原生的 HTTP Server，特别是 QPS，最大 QPS 只有原生 HTTP Server 最大 QPS 的13.68%，性能需要调优。

### API Server 性能分析
上面，我们测试了 API 接口的性能，如果性能不合预期，我们还需要分析性能数据，并优化性能。


在分析前我们需要对 API Server 加压，在加压的情况下，API 接口的性能才更可能暴露出来，所以继续执行如下命令：


```
$ scripts/wrktest.sh http://10.0.4.57:8080/healthz
```
在上述命令执行压力测试期间，可以打开另外一个 Linux 终端，使用go tool pprof工具分析 HTTP 的 profile 文件：


```
$ go tool pprof http://10.0.4.57:8080/debug/pprof/profile
```
执行完go tool pprof后，因为需要采集性能数据，所以该命令会阻塞 30s。在 pprof 交互 shell 中，执行top -cum查看累积采样时间，我们执行top30 -cum，多观察一些函数：


```
(pprof) top20 -cum
Showing nodes accounting for 32.12s, 39.62% of 81.07s total
Dropped 473 nodes (cum <= 0.41s)
Showing top 20 nodes out of 167
(pprof) top30 -cum
Showing nodes accounting for 11.82s, 20.32% of 58.16s total
Dropped 632 nodes (cum <= 0.29s)
Showing top 30 nodes out of 239
      flat  flat%   sum%        cum   cum%
     0.10s  0.17%  0.17%     51.59s 88.70%  net/http.(*conn).serve
     0.01s 0.017%  0.19%     42.86s 73.69%  net/http.serverHandler.ServeHTTP
     0.04s 0.069%  0.26%     42.83s 73.64%  github.com/gin-gonic/gin.(*Engine).ServeHTTP
     0.01s 0.017%  0.28%     42.67s 73.37%  github.com/gin-gonic/gin.(*Engine).handleHTTPRequest
     0.08s  0.14%  0.41%     42.59s 73.23%  github.com/gin-gonic/gin.(*Context).Next (inline)
     0.03s 0.052%  0.46%     42.58s 73.21%  .../internal/pkg/middleware.RequestID.func1
         0     0%  0.46%     41.02s 70.53%  .../internal/pkg/middleware.Context.func1
     0.01s 0.017%  0.48%     40.97s 70.44%  github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1
     0.03s 0.052%  0.53%     40.95s 70.41%  .../internal/pkg/middleware.LoggerWithConfig.func1
     0.01s 0.017%  0.55%     33.46s 57.53%  .../internal/pkg/middleware.NoCache
     0.08s  0.14%  0.69%     32.58s 56.02%  github.com/tpkeeper/gin-dump.DumpWithOptions.func1
     0.03s 0.052%  0.74%     24.73s 42.52%  github.com/tpkeeper/gin-dump.FormatToBeautifulJson
     0.02s 0.034%  0.77%     22.73s 39.08%  github.com/tpkeeper/gin-dump.BeautifyJsonBytes
     0.08s  0.14%  0.91%     16.39s 28.18%  github.com/tpkeeper/gin-dump.format
     0.21s  0.36%  1.27%     16.38s 28.16%  github.com/tpkeeper/gin-dump.formatMap
     3.75s  6.45%  7.72%     13.71s 23.57%  runtime.mallocgc
     ...
```
因为top30内容过多，这里只粘贴了耗时最多的一些关联函数。从上面的列表中，可以看到有 ServeHTTP 类的函数，这些函数是 gin/http 自带的函数，我们无需对此进行优化。还有这样一些函数：

```
.../gin.(*Context).Next (inline)
.../internal/pkg/middleware.RequestID.func1
.../internal/pkg/middleware.Context.func1
github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1
.../internal/pkg/middleware.LoggerWithConfig.func1
.../internal/pkg/middleware.NoCache
github.com/tpkeeper/gin-dump.DumpWithOptions.func1

```
可以看到，middleware.RequestID.func1、middleware.Context.func1、gin.CustomRecoveryWithWriter.func1、middleware.LoggerWithConfig.func1等，这些耗时较久的函数都是我们加载的 Gin 中间件。这些中间件消耗了大量的 CPU 时间，所以我们可以选择性加载这些中间件，删除一些不需要的中间件，来优化 API Server 的性能。

假如我们暂时不需要这些中间件，也可以通过配置 iam-apiserver 的配置文件，将server.middlewares设置为空或者注释掉，然后重启 iam-apiserver。重启后，再次执行wrktest.sh测试性能，并跟原生的 HTTP Server 性能进行对比，对比结果如下面 2 张图所示：

![img](https://static001.geekbang.org/resource/image/7b/c2/7bc94be0d44a5ac54cd0e199d2612ec2.png?wh=640x480)

![img](https://static001.geekbang.org/resource/image/88/a7/88e9fdfe7ba14061e979d0195b45cca7.png?wh=640x480)

可以看到，删除无用的 Gin 中间件后，API Server 的性能有了很大的提升，并发数为200时性能最好，此时 QPS 为47812，响应时间为4.33``ms，成功率为100.00``%。在并发数为50000的时候，其 QPS 是原生 HTTP Server 的75.02%。

### API 接口性能参考
不同团队对 API 接口的性能要求不同，同一团队对每个 API 接口的性能要求也不同，所以并没有一个统一的数值标准来衡量 API 接口的性能，但可以肯定的是，性能越高越好。我根据自己的研发经验，在这里给出一个参考值（并发数可根据需要选择），如下表所示：

![img](https://static001.geekbang.org/resource/image/58/7c/581fc922afedaf36379c5a5d723ebd7c.jpg?wh=2248x585)

### API Server 性能测试注意事项
在进行 API Server 性能测试时，要考虑到 API Server 的性能影响因素。影响 API Server 性能的因素很多，大致可以分为两类，分别是 Web 框架的性能和 API 接口的性能。另外，在做性能测试时，还需要确保测试环境是一致的，最好是一个干净的测试环境。
### Web 框架性能
Web 框架的性能至关重要，因为它会影响我们的每一个 API 接口的性能。在设计阶段，我们会确定所使用的 Web 框架，这时候我们需要对 Web 框架有个初步的测试，确保我们选择的 Web 框架在性能和稳定性上都足够优秀。当整个 Go 后端服务开发完成之后，在上线之前，我们还需要对 Web 框架再次进行测试，确保按照我们最终的使用方式，Web 框架仍然能够保持优秀的性能和稳定性。

我们通常会通过 API 接口来测试 Web 框架的性能，例如健康检查接口/healthz。我们需要保证该 API 接口足够简单，API 接口里面不应该掺杂任何逻辑，只需要象征性地返回一个很小的返回内容即可。比如，这一讲中我们通过/healthz接口来测试 Web 框架的性能：

```go
s.GET("/healthz", func(c *gin.Context) {
    core.WriteResponse(c, nil, map[string]string{"status": "ok"})
})
```
接口中只调用了core.WriteResponse函数，返回了{"status":"ok"}。这里使用core.WriteResponse函数返回请求数据，而不是直接返回ok字符串，这样做是为了保持 API 接口返回格式统一。
### API 接口性能

除了测试 Web 框架的性能，我们还可能需要测试某些重要的 API 接口，甚至所有 API 接口的性能。为了测试 API 接口在真实场景下的接口性能，我们会使用 wrk 这类 HTTP 压力测试工具，来模拟多个 API 请求，进而分析 API 的性能。

因为会模拟大量的请求，这时候测试写类接口，例如Create、Update、Delete等会存在一些问题，比如可能在数据库中插入了很多数据，导致磁盘空间被写满或者数据库被压爆。所以，针对写类接口，我们可以借助单元测试，来测试其性能。根据我的开发经验，写类接口通常不会有性能问题，反而读类接口更可能遇到性能问题。针对读类接口，我们可以使用 wrk 这类 HTTP 压力测试工具来进行测试。


### 测试环境
在做性能 / 压力测试时，为了不影响生产环境，要确保在测试环境进行压测，并且测试环境的网络不能影响到生产环境的网络。另外，为了更好地进行性能对比和分析，也要保证我们的测试方法和测试环境是一致的。这就要求我们最好将性能测试自动化，并且每次在同一个测试环境进行测试。
### 总结
在项目上线前，我们需要对 API 接口进行性能测试。通常 API 接口的性能延时要小于 500ms ，如果大于这个值，需要考虑优化性能。在进行性能测试时，需要确保每次测试都有一个一致的测试环境，这样不同测试之间的数据才具有可对比性。这一讲中，我推荐了一个比较优秀的性能测试工具 wrk ，我们可以编写 shell 脚本，将 wrk 的性能测试数据自动绘制成图，方便我们查看、对比性能。

总结在项目上线前，我们需要对 API 接口进行性能测试。通常 API 接口的性能延时要小于 500ms ，如果大于这个值，需要考虑优化性能。在进行性能测试时，需要确保每次测试都有一个一致的测试环境，这样不同测试之间的数据才具有可对比性。这一讲中，我推荐了一个比较优秀的性能测试工具 wrk ，我们可以编写 shell 脚本，将 wrk 的性能测试数据自动绘制成图，方便我们查看、对比性能。

## 服务部署

## 40 | 软件部署实战（上）：部署方案及负载均衡、高可用组件介绍

接下来，我们就进入到这门课的最后一个模块，服务部署部分的学习。在这一模块中，我会带着你一步一步地部署一个生产级可用的 IAM 应用。在 03 讲 中，我们快速在单机上部署了 IAM 系统，但这样的系统缺少高可用、弹性扩容等能力，是很脆弱的，遇到流量波峰、发布变更很容易出问题。在系统真正上线前，我们需要重新调整部署架构，来保证我们的系统具有负载均衡、高可用、弹性伸缩等核心运维能力。考虑到你手中的系统资源有限，这一模块会尽量简单地展示如何部署一个相对高可用的 IAM 系统。按照我讲的部署方法，基本上可以上线一个中小型的系统。

在这一模块中，我会介绍两种部署方式。第一种是传统的部署方式，基于物理机 / 虚拟机来部署，容灾、弹性伸缩能力要部署人员自己实现。第二种是容器化部署方式，基于 Docker、Kubernetes 来部署，容灾、弹性伸缩等能力，可以借助 Kubernetes 自带的能力来实现。接下来的三讲，我们先来看下传统的部署方式，也就是如何基于虚拟机来部署 IAM 应用。今天我主要讲跟 IAM 部署相关的两个组件，Nginx + Keepalived 的相关功能。

接下来的三讲，我们先来看下传统的部署方式，也就是如何基于虚拟机来部署 IAM 应用。今天我主要讲跟 IAM 部署相关的两个组件，Nginx + Keepalived 的相关功能。

### 部署方案
先来整体看下我们的部署方案。这里，我采用 Nginx + Keepalived 来部署一个高可用的架构，同时将组件都部署在内网，来保证服务的安全和性能。部署需要两台物理机 / 虚拟机，组件之间通过内网访问。所需的服务器如下表所示：

![img](https://static001.geekbang.org/resource/image/e0/1d/e0a3323831768fbe7f45085ca4a53a1d.jpg?wh=1920x719)

两台服务器均为腾讯云 CVM，VIP（Virtual IP，虚拟 IP）为10.0.4.99。部署架构如下图所示：

![img](https://static001.geekbang.org/resource/image/fc/9d/fc5331a780d45a7de6223d6ff3c86f9d.jpg?wh=1920x1197)


这里我来具体介绍下图中的部署架构。部署采用的这两台 CVM 服务器，一主一备，它们共享同一个 VIP。同一时刻，VIP 只在一台主设备上生效，当主服务器出现故障时，备用服务器会自动接管 VIP，继续提供服务。

主服务器上部署了iam-apiserver、iam-authz-server、iam-pump和数据库mongodb、redis、mysql。备服务器部署了iam-apiserver、iam-authz-server和iam-pump。备服务器中的组件通过内网10.0.4.20访问主服务器中的数据库组件。

主备服务器同时安装了 Keepalived 和 Nginx，通过 Nginx 的反向代理功能和负载均衡功能，实现后端服务iam-apiserver和iam-authz-server的高可用，通过 Keepalived 实现 Nginx 的高可用。

我们通过给虚拟 IP 绑定腾讯云弹性公网 IP，从而使客户端可以通过外网 IP 访问内网的 Nginx 服务器（443端口），如果想通过域名访问内网，还可以申请域名指向该弹性公网 IP。

通过以上部署方案，我们可以实现一个具有较高可用性的 IAM 系统，它主要具备下面这几个能力。

- 高性能：可以通过 Nginx 的负载均衡功能，水平扩容 IAM 服务，从而实现高性能。
- 具备容灾能力：通过 Nginx 实现 IAM 服务的高可用，通过 Keepalived 实现 Nginx 的高可用，从而实现核心组件的高可用。
- 具备水平扩容能力：通过 Nginx 的负载均衡功能，实现 IAM 服务的水平扩容。
- 高安全性：将所有组件部署在内网，客户端只能通过VIP:443端口访问 Nginx 服务，并且通过开启 TLS 认证和 JWT 认证，保障服务有一个比较高的安全性。因为是腾讯云 CVM，所以也可以借助腾讯云的能力再次提高服务器的安全性，比如安全组、DDoS 防护、主机安全防护、云监控、云防火墙等。

这里说明下，为了简化 IAM 应用的安装配置过程，方便你上手实操，有些能力，例如数据库高可用、进程监控和告警、自动伸缩等能力的构建方式，这里没有涉及到。这些能力的构建方式，你可以在日后的工作中慢慢学习和掌握。

接下来，我们看下这个部署方案中用到的两个核心组件，Nginx 和 Keepalived。我会介绍下它们的安装和配置方法，为你下一讲的学习做准备。

### Nginx 安装和配置
#### Nginx 功能简介

这里先简单介绍下 Nginx。Nginx 是一个轻量级、高性能、开源的 HTTP 服务器和反向代理服务器。IAM 系统使用了 Nginx 反向代理和负载均衡的功能，下面我就来分别介绍下。

为什么需要反向代理呢？在实际的生产环境中，服务部署的网络（内网）跟外部网络（外网）通常是不通的，这就需要一台既能够访问内网又能够访问外网的服务器来做中转，这种服务器就是反向代理服务器。Nginx 作为反向代理服务器，简单的配置如下：

```
server {
    listen      80;
    server_name  iam.marmotedu.com;
    client_max_body_size 1024M;

    location / {
        proxy_set_header Host $http_host;
        proxy_set_header X-Forwarded-Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass  http://127.0.0.1:8080/;
        client_max_body_size 100m;
    }
}
```
Nginx 的反向代理功能，能够根据不同的配置规则转发到不同的后端服务器上。假如我们在 IP 为x.x.x.x的服务器上，用上面说的 Nginx 配置启动 Nginx，当我们访问http://x.x.x.x:80/时，会将请求转发到http://127.0.0.1:8080/。listen      80指定了 Nginx 服务器的监听端口，proxy_pass  http://127.0.0.1:8080/则指定了转发路径。


Nginx 另一个常用的功能是七层负载均衡。所谓的负载均衡，就是指当 Nginx 收到一个 HTTP 请求后，会根据负载策略将请求转发到不同的后端服务器上。比如 iam-apiserver 部署在两台服务器 A 和 B 上，当请求到达 Nginx 后，Nginx 会根据 A 和 B 服务器上的负载情况，将请求转发到负载较小的那台服务器上。

这里要求 iam-apiserver 是无状态的服务。Nginx 有多种负载均衡策略，可以满足不同场景下的负载均衡需求。

#### Nginx 安装步骤
接下来，我就来介绍下如何安装和配置 Nginx。我们分别在10.0.4.20和10.0.4.21服务器上执行如下步骤，安装 Nginx。


在 CentOS 8.x 系统上，我们可以使用 yum 命令来安装，具体安装过程可以分为下面 4 个步骤。第一步，安装 Nginx：

```
$ sudo yum -y install nginx
```
第二步，确认 Nginx 安装成功：

```
$ nginx -v
nginx version: nginx/1.14.1
```
第三步，启动 Nginx，并设置开机启动：


```
$ sudo systemctl start nginx
$ sudo systemctl enable nginx
```
Nginx 默认监听80端口，启动 Nginx 前要确保80端口没有被占用。当然，你也可以通过修改 Nginx 配置文件/etc/nginx/nginx.conf修改 Nginx 监听端口。

第四步，查看 Nginx 启动状态：

```
$ systemctl status nginx
```
输出中有active (running)字符串，说明成功启动。如果 Nginx 启动失败，你可以查看/var/log/nginx/error.log日志文件，定位错误原因。

### Keepalived 安装和配置
Nginx 自带负载均衡功能，并且当 Nginx 后端某个服务器故障后，Nginx 会自动剔除该服务器，将请求转发到可用的服务器，通过这种方式实现后端 API 服务的高可用。但是 Nginx 是单点的，如果 Nginx 挂了，后端的所有服务器就都不能访问，所以在实际生产环境中，也需要对 Nginx 做高可用。

业界最普遍采用的方法是通过 Keepalived 对前端 Nginx 实现高可用。Keepalived + Nginx 的高可用方案具有服务功能强大、维护简单等特点。接下来，我们来看下如何安装和配置 Keepalived。

#### Keepalived 安装步骤
我们分别在10.0.4.20和10.0.4.21服务器上执行下面 5 个步骤，安装 Keepalived。第一步，下载 Keepalived 的最新版本（这门课安装了当前的最新版本 2.1.5）：

```
$ wget https://www.keepalived.org/software/keepalived-2.1.5.tar.gz
```
第二步，安装 Keepalived：

```
$ sudo yum -y install openssl-devel # keepalived依赖OpenSSL，先安装依赖
$ tar -xvzf keepalived-2.1.5.tar.gz
$ cd keepalived-2.1.5
$ ./configure --prefix=/usr/local/keepalived
$ make
$ sudo make install
```
第三步，配置 Keepalived：


```
$ sudo mkdir /etc/keepalived # 安装后，默认没有创建/etc/keepalived目录
$ sudo cp /usr/local/keepalived/etc/keepalived/keepalived.conf  /etc/keepalived/keepalived.conf
$ sudo cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived
```
Keepalived 的 systemd uint 配置，默认使用了/usr/local/keepalived/etc/sysconfig/keepalived作为其EnvironmentFile，我们还需要把它修改为/etc/sysconfig/keepalived文件。编辑/lib/systemd/system/keepalived.service文件，设置EnvironmentFile，值如下：

```
EnvironmentFile=-/etc/sysconfig/keepalived
```
第四步，启动 Keepalived，并设置开机启动：

```
$ sudo systemctl start keepalived
$ sudo systemctl enable keepalived
```
这里要注意，Keepalived 启动时不会校验配置文件是否正确，所以我们要小心修改配置，防止出现意想不到的问题。第五步，查看 Keepalived 的启动状态：


```
$ systemctl status keepalived
```
输出中有active (running)字符串，说明成功启动。Keepalived 的日志保存在/var/log/messages中，你有需要的话可以查看。

#### Keepalived 配置文件解析
Keepalived 的默认配置文件为/etc/keepalived/keepalived.conf，下面是一个 Keepalived 配置：

```
conf
# 全局定义，定义全局的配置选项
global_defs {
# 指定keepalived在发生切换操作时发送email，发送给哪些email
# 建议在keepalived_notify.sh中发送邮件
  notification_email {
    acassen@firewall.loc
  }
  notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址
    smtp_server 192.168.200.1 # 发送email时smtp服务器地址
    smtp_connect_timeout 30 # 连接smtp的超时时间
    router_id VM-4-21-centos # 机器标识，通常可以设置为hostname
    vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查
    vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0
    vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0
}
# 检测脚本配置
vrrp_script checkhaproxy
{
  script "/etc/keepalived/check_nginx.sh" # 检测脚本路径
    interval 5 # 检测时间间隔（秒）
    weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级
}
# VRRP实例配置
vrrp_instance VI_1 {
  state BACKUP  # 设置初始状态为'备份'
    interface eth0 # 设置绑定VIP的网卡，例如eth0
    virtual_router_id 51  # 配置集群VRID，互为主备的VRID需要是相同的值
    nopreempt               # 设置非抢占模式，只能设置在state为backup的节点上
    priority 50 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master
    advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒
# 验证信息，两个节点必须一致
    authentication {
      auth_type PASS # 认证方式，可以是PASS或AH两种认证方式
        auth_pass 1111 # 认证密码
    }
  unicast_src_ip 10.0.4.21  # 设置本机内网IP地址
    unicast_peer {
      10.0.4.20             # 对端设备的IP地址
    }
# VIP，当state为master时添加，当state为backup时删除
  virtual_ipaddress {
    10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。
  }
  notify_master "/etc/keepalived/keepalived_notify.sh MASTER" # 当切换到master状态时执行脚本
    notify_backup "/etc/keepalived/keepalived_notify.sh BACKUP" # 当切换到backup状态时执行脚本
    notify_fault "/etc/keepalived/keepalived_notify.sh FAULT" # 当切换到fault状态时执行脚本
    notify_stop "/etc/keepalived/keepalived_notify.sh STOP" # 当切换到stop状态时执行脚本
    garp_master_delay 1    # 设置当切为主状态后多久更新ARP缓存
    garp_master_refresh 5   # 设置主节点发送ARP报文的时间间隔
    # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态
    track_interface {
      eth0
    }
  # 要执行的检查脚本
  track_script {
    checkhaproxy
  }
}
```
这里解析下配置文件，大致分为下面 4 个部分。
- global_defs：全局定义，定义全局的配置选项。
- vrrp_script checkhaproxy：检测脚本配置。
- vrrp_instance VI_1：VRRP 实例配置。
- virtual_server：LVS 配置。如果没有配置 LVS+Keepalived，就不用设置这个选项。这门课中，我们使用 Nginx 代替 LVS，所以无需配置virtual_server（配置示例中不再展示）。

只有在网络故障或者自身出问题时，Keepalived 才会进行 VIP 切换。但实际生产环境中，我们往往使用 Keepalived 来监控其他进程，当业务进程出故障时切换 VIP，从而保障业务进程的高可用。

为了让 Keepalived 感知到 Nginx 的运行状况，我们需要指定vrrp_script脚本，vrrp_script脚本可以根据退出码，判断 Nginx 进程是否正常，0正常，非0不正常。当不正常时，Keepalived 会进行 VIP 切换。为了实现业务进程的监控，我们需要设置vrrp_script和track_script：

```
vrrp_script checkhaproxy
{
    script "/etc/keepalived/check_nginx.sh"
    interval 3
    weight -20
}

vrrp_instance test
{
    ...
    track_script
    {
        checkhaproxy
    }
    ...
}
```
这里，我介绍下上面配置中的一些配置项。
- script：指定脚本路径。
- interval：表示 Keepalived 执行脚本的时间间隔（秒）。
- weight：检测权重，可以改变priority的值。例如，-20表示检测失败时，优先级-20，成功时不变。20表示检测成功时，优先级+20，失败时不变。

### 总结
今天我主要讲了跟 IAM 部署相关的两个组件，Nginx + Keepalived 的相关功能。我们可以基于物理机 / 虚拟机来部署 IAM 应用，在部署 IAM 应用时，需要确保整个应用具备高可用和弹性扩缩容能力。你可以通过 Nginx 的反向代理功能和负载均衡功能实现后端服务 iam-apiserver 和 iam-authz-server 的高可用，通过 Keepalived 实现 Nginx 的高可用，通过 Nginx + Keepalived 组合，来实现 IAM 应用的高可用和弹性伸缩能力。

## 41 | 软件部署实战（中）：IAM 系统生产环境部署实战


上一讲，我介绍了 IAM 部署用到的两个核心组件，Nginx 和 Keepalived。那么这一讲，我们就来看下，如何使用 Nginx 和 Keepalived 来部署一个高可用的 IAM 应用。下一讲，我再介绍下 IAM 应用安全和弹性伸缩能力的构建方式。这一讲，我们会通过下面四个步骤来部署 IAM 应用：

1. 在服务器上部署 IAM 应用中的服务。
2. 配置 Nginx，实现反向代理功能。通过反向代理，我们可以通过 Nginx 来访问部署在内网的 IAM 服务。
3. 配置 Nginx，实现负载均衡功能。通过负载均衡，我们可以实现服务的水平扩缩容，使 IAM 应用具备高可用能力。
4. 配置 Keepalived，实现 Nginx 的高可用。通过 Nginx + Keepalived 的组合，可以实现整个应用架构的高可用。

### 部署 IAM 应用
部署一个高可用的 IAM 应用，需要至少两个节点。所以，我们按照先后顺序，分别在10.0.4.20和10.0.4.21服务器上部署 IAM 应用。

#### 在10.0.4.20服务器上部署 IAM 应用
首先，我来介绍下如何在10.0.4.20服务器上部署 IAM 应用。我们要在这个服务器上部署如下组件：

- iam-apiserver
- iam-authz-server
- iam-pump
- MariaDB
- Redis
- MongoDB


这些组件的部署方式，03 讲 有介绍，这里就不再说明。此外，我们还需要设置 MariaDB，给来自于10.0.4.21服务器的数据库连接授权，授权命令如下：

```
$ mysql -hlocalhost -P3306 -uroot -proot # 先以root用户登陆数据库
MariaDB [(none)]> grant all on iam.* TO iam@10.0.4.21 identified by 'iam1234';
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]> flush privileges;
Query OK, 0 rows affected (0.000 sec)
```
#### 在10.0.4.21服务器上部署 IAM 应用
然后，在10.0.4.21服务器上安装好 iam-apiserver、iam-authz-server 和 iam-pump。这些组件通过10.0.4.20 IP 地址，连接10.0.4.20服务器上的 MariaDB、Redis 和 MongoDB。


### 配置 Nginx 作为反向代理
假定要访问的 API Server 和 IAM Authorization Server 的域名分别为iam.api.marmotedu.com和iam.authz.marmotedu.com，我们需要分别为 iam-apiserver 和 iam-authz-server 配置 Nginx 反向代理。整个配置过程可以分为 5 步（在10.0.4.20服务器上操作）。
#### 第一步，配置 iam-apiserver。
新建 Nginx 配置文件/etc/nginx/conf.d/iam-apiserver.conf，内容如下：



```
conf
server {
    listen       80;
    server_name  iam.api.marmotedu.com;
    root         /usr/share/nginx/html;
    location / {
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_pass  http://127.0.0.1:8080/;
      client_max_body_size 5m;
    }

    error_page 404 /404.html;
        location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
        location = /50x.html {
    }
}
```
有几点你在配置时需要注意，这里说明下。
- server_name需要为iam.api.marmotedu.com，我们通过iam.api.marmotedu.com访问 iam-apiserver。
- iam-apiserver 默认启动的端口为8080。
- 由于 Nginx 默认允许客户端请求的最大单文件字节数为1MB，实际生产环境中可能太小，所以这里将此限制改为 5MB（client_max_body_size 5m）。如果需要上传图片之类的，可能需要设置成更大的值，比如50m。
- server_name 用来说明访问 Nginx 服务器的域名，例如curl -H 'Host: iam.api.marmotedu.com' http://x.x.x.x:80/healthz，x.x.x.x为 Nginx 服务器的 IP 地址。
- proxy_pass 表示反向代理的路径。因为这里是本机的 iam-apiserver 服务，所以 IP 为127.0.0.1。端口要和 API 服务端口一致，为8080。

最后还要提醒下，因为 Nginx 配置选项比较多，跟实际需求和环境有关，所以这里的配置是基础的、未经优化的配置，在实际生产环境中需要你再做调节。


#### 第二步，配置 iam-authz-server。
新建 Nginx 配置文件/etc/nginx/conf.d/iam-authz-server.conf，内容如下：


```
conf
server {
    listen       80;
    server_name  iam.authz.marmotedu.com;
    root         /usr/share/nginx/html;
    location / {
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_pass  http://127.0.0.1:9090/;
      client_max_body_size 5m;
    }

    error_page 404 /404.html;
        location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
        location = /50x.html {
    }
}
```
下面是一些配置说明。
- server_name 需要为iam.authz.marmotedu.com，我们通过iam.authz.marmotedu.com访问 iam-authz-server。
- iam-authz-server 默认启动的端口为9090。
- 其他配置跟/etc/nginx/conf.d/iam-apiserver.conf一致。

#### 第三步，配置完 Nginx 后，重启 Nginx：

```
$ sudo systemctl restart nginx
```
#### 第四步，在 /etc/hosts 中追加下面两行：


```
127.0.0.1 iam.api.marmotedu.com
127.0.0.1 iam.authz.marmotedu.com
```
#### 第五步，发送 HTTP 请求：

```
$ curl http://iam.api.marmotedu.com/healthz
{"status":"ok"}
$ curl http://iam.authz.marmotedu.com/healthz
{"status":"ok"}
```
我们分别请求 iam-apiserver 和 iam-authz-server 的健康检查接口，输出了{"status":"ok"}，说明我们可以成功通过代理访问后端的 API 服务。

在用 curl 请求http://iam.api.marmotedu.com/healthz后，后端的请求流程实际上是这样的：
1. 因为在/etc/hosts中配置了127.0.0.1 iam.api.marmotedu.com，所以请求http://iam.api.marmotedu.com/healthz实际上是请求本机的 Nginx 端口（127.0.0.1:80）。
2. Nginx 在收到请求后，会解析请求，得到请求域名为iam.api.marmotedu.com。根据请求域名去匹配 Nginx 的 server 配置，匹配到server_name  iam.api.marmotedu.com;配置。
3. 匹配到 server 后，把请求转发到该 server 的proxy_pass路径。
4. 等待 API 服务器返回结果，并返回客户端。

### 配置 Nginx 作为负载均衡
这门课采用 Nginx 轮询的负载均衡策略转发请求。负载均衡需要至少两台服务器，所以会分别在10.0.4.20和10.0.4.21服务器上执行相同的操作。下面我分别来介绍下如何配置这两台服务器，并验证配置是否成功。

#### 10.0.4.20服务器配置
登陆10.0.4.20服务器，在/etc/nginx/nginx.conf中添加 upstream 配置，配置过程可以分为 3 步。

第一步，在/etc/nginx/nginx.conf中添加 upstream：

```
http {
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    # Load modular configuration files from the /etc/nginx/conf.d directory.
    # See http://nginx.org/en/docs/ngx_core_module.html#include
    # for more information.
    include /etc/nginx/conf.d/*.conf;
    upstream iam.api.marmotedu.com {
        server 127.0.0.1:8080
        server 10.0.4.21:8080
    }
    upstream iam.authz.marmotedu.com {
        server 127.0.0.1:9090
        server 10.0.4.21:9090
    }
}
```
配置说明：
- upstream 是配置在/etc/nginx/nginx.conf文件中的http{ … }部分的。
- 因为我们要分别为 iam-apiserver 和 iam-authz-server 配置负载均衡，所以我们创建了两个 upstream，分别是iam.api.marmotedu.com和iam.authz.marmotedu.com。为了便于识别，upstream 名称和域名最好保持一致。
- 在 upstream 中，我们需要分别添加所有的 iam-apiserver 和 iam-authz-server 的后端（ip:port），本机的后端为了访问更快，可以使用127.0.0.1:<port>，其他机器的后端，需要使用<内网>:port，例如10.0.4.21:8080、10.0.4.21:9090。

第二步，修改 proxy_pass。修改/etc/nginx/conf.d/iam-apiserver.conf文件，将proxy_pass修改为：

```
proxy_pass http://iam.api.marmotedu.com/;
```
修改/etc/nginx/conf.d/iam-authz-server.conf文件，将proxy_pass修改为：

```
proxy_pass http://iam.authz.marmotedu.com/;
```
当 Nginx 转发到http://iam.api.marmotedu.com/域名时，会从iam.api.marmotedu.com upstream 配置的后端列表中，根据负载均衡策略选取一个后端，并将请求转发过去。转发http://iam.authz.marmotedu.com/域名的逻辑也一样。


第三步，配置完 Nginx 后，重启 Nginx：

```
$ sudo systemctl restart nginx
```
最终配置好的配置文件，你可以参考下面这些（保存在configs/ha/10.0.4.20目录下）：
- nginx.conf：configs/ha/10.0.4.20/nginx.conf。
- iam-apiserver.conf：configs/ha/10.0.4.20/iam-apiserver.conf。
- iam-authz-server.conf：configs/ha/10.0.4.20/iam-authz-server.conf。

#### 10.0.4.21服务器配置
登陆10.0.4.21服务器，在/etc/nginx/nginx.conf中添加 upstream 配置。配置过程可以分为下面 4 步。

第一步，在/etc/nginx/nginx.conf中添加 upstream：

```
http {
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    # Load modular configuration files from the /etc/nginx/conf.d directory.
    # See http://nginx.org/en/docs/ngx_core_module.html#include
    # for more information.
    include /etc/nginx/conf.d/*.conf;
    upstream iam.api.marmotedu.com {
        server 127.0.0.1:8080
        server 10.0.4.20:8080
    }
    upstream iam.authz.marmotedu.com {
        server 127.0.0.1:9090
        server 10.0.4.20:9090
    }
}
```
upstream 中，需要配置10.0.4.20服务器上的 iam-apiserver 和 iam-authz-server 的后端，例如10.0.4.20:8080、10.0.4.20:9090。

第二步，创建/etc/nginx/conf.d/iam-apiserver.conf文件（iam-apiserver 的反向代理 + 负载均衡配置），内容如下：

```
server {
    listen       80;
    server_name  iam.api.marmotedu.com;
    root         /usr/share/nginx/html;
    location / {
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_pass  http://iam.api.marmotedu.com/;
      client_max_body_size 5m;
    }

    error_page 404 /404.html;
        location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
        location = /50x.html {
    }
}
```
第三步，创建/etc/nginx/conf.d/iam-authz-server文件（iam-authz-server 的反向代理 + 负载均衡配置），内容如下：

```
server {
    listen       80;
    server_name  iam.authz.marmotedu.com;
    root         /usr/share/nginx/html;
    location / {
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_pass  http://iam.authz.marmotedu.com/;
      client_max_body_size 5m;
    }

    error_page 404 /404.html;
        location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
        location = /50x.html {
    }
}

```
第四步，配置完 Nginx 后，重启 Nginx：

```
$ sudo systemctl restart nginx
```
最终配置好的配置文件，你可以参考下面这些（保存在configs/ha/10.0.4.21目录下）：
- nginx.conf：configs/ha/10.0.4.21/nginx.conf。
- iam-apiserver.conf：configs/ha/10.0.4.21/iam-apiserver.conf。
- iam-authz-server.conf：configs/ha/10.0.4.21/iam-authz-server.conf。

#### 测试负载均衡
上面，我们配置了 Nginx 负载均衡器，这里我们还需要测试下是否配置成功。

第一步，执行测试脚本（test/nginx/loadbalance.sh）：

```
#!/usr/bin/env bash

for domain in iam.api.marmotedu.com iam.authz.marmotedu.com
do
  for n in $(seq 1 1 10)
  do
    echo $domain
    nohup curl http://${domain}/healthz &>/dev/null &
  done
done
```
第二步，分别查看 iam-apiserver 和 iam-authz-server 的日志。这里我展示下 iam-apiserver 的日志（iam-authz-server 的日志你可自行查看）。
10.0.4.20服务器的 iam-apiserver 日志如下图所示：

![img](https://static001.geekbang.org/resource/image/58/26/58d072c92552fa3068e3ef3acd0ed726.png?wh=1920x498)

10.0.4.21服务器的 iam-apiserver 日志如下图所示：

![img](https://static001.geekbang.org/resource/image/19/85/199066c65ff60007f80f3c2dyy11c785.png?wh=1920x482)

通过上面两张图，你可以看到10.0.4.20和10.0.4.21各收到5个/healthz请求，说明负载均衡配置成功。


### 配置 Keepalived
在 40 讲，我们分别在10.0.4.20和10.0.4.21服务器上安装了 Keepalived。这里，我来介绍下如何配置 Keepalived，实现 Nginx 的高可用。为了避免故障恢复时，VIP 切换造成的服务延时，这一讲采用 Keepalived 的非抢占模式。

配置 Keepalived 的流程比较复杂，分为创建腾讯云 HAVIP、主服务器配置、备服务器配置、测试 Keepalived、VIP 绑定公网 IP 和测试公网访问六大步，每一步中都有很多小步骤，下面我们来一步步地看下。

#### 第一步：创建腾讯云 HAVIP
公有云厂商的普通内网 IP，出于安全考虑（如避免 ARP 欺骗等），不支持主机通过 ARP 宣告 IP 。如果用户直接在keepalived.conf文件中指定一个普通内网 IP 为 virtual IP，当 Keepalived 将 virtual IP 从 MASTER 机器切换到 BACKUP 机器时，将无法更新 IP 和 MAC 地址的映射，而需要调 API 来进行 IP 切换。所以，这里的 VIP 需要申请腾讯云的 HAVIP。

申请的流程可以分为下面 4 步：
- 登录私有网络控制台。
- 在左侧导航栏中，选择【IP 与网卡】>【高可用虚拟 IP】。
- 在 HAVIP 管理页面，选择所在地域，单击【申请】。
- 在弹出的【申请高可用虚拟 IP】对话框中输入名称，选择 HAVIP 所在的私有网络和子网等信息，单击【确定】即可。

这里选择的私有网络和子网，需要和10.0.4.20、10.0.4.21相同。HAVIP 的 IP 地址可以自动分配，也可以手动填写，这里我们手动填写为 10.0.4.99。申请页面如下图所示：

![img](https://static001.geekbang.org/resource/image/a4/11/a49d6e7e080d658392dbb144a1560811.png?wh=827x1016)

#### 第二步：主服务器配置
进行主服务器配置，可以分为两步。

首先，修改 Keepalived 配置文件。登陆服务器10.0.4.20，编辑/etc/keepalived/keepalived.conf，修改配置，修改后配置内容如下（参考：configs/ha/10.0.4.20/keepalived.conf）：

```
conf
# 全局定义，定义全局的配置选项
global_defs {
# 指定keepalived在发生切换操作时发送email，发送给哪些email
# 建议在keepalived_notify.sh中发送邮件
  notification_email {
    acassen@firewall.loc
  }
  notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址
    smtp_server 192.168.200.1 # 发送email时smtp服务器地址
    smtp_connect_timeout 30 # 连接smtp的超时时间
    router_id VM-4-20-centos # 机器标识，通常可以设置为hostname
    vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查
    vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0
    vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0
}
# 检测脚本配置
vrrp_script checkhaproxy
{
  script "/etc/keepalived/check_nginx.sh" # 检测脚本路径
    interval 5 # 检测时间间隔（秒）
    weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级
}
# VRRP实例配置
vrrp_instance VI_1 {
  state BACKUP  # 设置初始状态为'备份'
    interface eth0 # 设置绑定VIP的网卡，例如eth0
    virtual_router_id 51  # 配置集群VRID，互为主备的VRID需要是相同的值
    nopreempt               # 设置非抢占模式，只能设置在state为backup的节点上
    priority 100 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master
    advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒
# 验证信息，两个节点必须一致
    authentication {
      auth_type PASS # 认证方式，可以是PASS或AH两种认证方式
        auth_pass 1111 # 认证密码
    }
  unicast_src_ip 10.0.4.20  # 设置本机内网IP地址
    unicast_peer {
      10.0.4.21             # 对端设备的IP地址
    }
# VIP，当state为master时添加，当state为backup时删除
  virtual_ipaddress {
    10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。
  }
  notify_master "/etc/keepalived/keepalived_notify.sh MASTER" # 当切换到master状态时执行脚本
    notify_backup "/etc/keepalived/keepalived_notify.sh BACKUP" # 当切换到backup状态时执行脚本
    notify_fault "/etc/keepalived/keepalived_notify.sh FAULT" # 当切换到fault状态时执行脚本
    notify_stop "/etc/keepalived/keepalived_notify.sh STOP" # 当切换到stop状态时执行脚本
    garp_master_delay 1    # 设置当切为主状态后多久更新ARP缓存
    garp_master_refresh 5   # 设置主节点发送ARP报文的时间间隔
    # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态
    track_interface {
      eth0
    }
  # 要执行的检查脚本
  track_script {
    checkhaproxy
  }
}
```
这里有几个注意事项：
- 确保已经配置了 garp 相关参数。因为 Keepalived 依赖 ARP 报文更新 IP 信息，如果缺少这些参数，会导致某些场景下主设备不发送 ARP，进而导致通信异常。garp 相关参数配置如下：
```
garp_master_delay 1
garp_master_refresh 5
```
- 确定没有采用 strict 模式，即需要删除 vrrp_strict 配置。
- 配置中的/etc/keepalived/check_nginx.sh和/etc/keepalived/keepalived_notify.sh脚本文件，可分别拷贝自scripts/check_nginx.sh和scripts/keepalived_notify.sh。

然后，重启 Keepalived：


```
$ sudo systemctl restart keepalived
```
#### 第三步：备服务器配置
进行备服务器配置也分为两步。

**首先，修改 Keepalived 配置文件**。登陆服务器10.0.4.21，编辑/etc/keepalived/keepalived.conf，修改配置，修改后配置内容如下（参考：configs/ha/10.0.4.21/keepalived.conf）：

```
conf
# 全局定义，定义全局的配置选项
global_defs {
# 指定keepalived在发生切换操作时发送email，发送给哪些email
# 建议在keepalived_notify.sh中发送邮件
  notification_email {
    acassen@firewall.loc
  }
  notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址
    smtp_server 192.168.200.1 # 发送email时smtp服务器地址
    smtp_connect_timeout 30 # 连接smtp的超时时间
    router_id VM-4-21-centos # 机器标识，通常可以设置为hostname
    vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查
    vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0
    vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0
}
# 检测脚本配置
vrrp_script checkhaproxy
{
  script "/etc/keepalived/check_nginx.sh" # 检测脚本路径
    interval 5 # 检测时间间隔（秒）
    weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级
}
# VRRP实例配置
vrrp_instance VI_1 {
  state BACKUP  # 设置初始状态为'备份'
    interface eth0 # 设置绑定VIP的网卡，例如eth0
    virtual_router_id 51  # 配置集群VRID，互为主备的VRID需要是相同的值
    nopreempt               # 设置非抢占模式，只能设置在state为backup的节点上
    priority 50 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master
    advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒
# 验证信息，两个节点必须一致
    authentication {
      auth_type PASS # 认证方式，可以是PASS或AH两种认证方式
        auth_pass 1111 # 认证密码
    }
  unicast_src_ip 10.0.4.21  # 设置本机内网IP地址
    unicast_peer {
      10.0.4.20             # 对端设备的IP地址
    }
# VIP，当state为master时添加，当state为backup时删除
  virtual_ipaddress {
    10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。
  }
  notify_master "/etc/keepalived/keepalived_notify.sh MASTER" # 当切换到master状态时执行脚本
    notify_backup "/etc/keepalived/keepalived_notify.sh BACKUP" # 当切换到backup状态时执行脚本
    notify_fault "/etc/keepalived/keepalived_notify.sh FAULT" # 当切换到fault状态时执行脚本
    notify_stop "/etc/keepalived/keepalived_notify.sh STOP" # 当切换到stop状态时执行脚本
    garp_master_delay 1    # 设置当切为主状态后多久更新ARP缓存
    garp_master_refresh 5   # 设置主节点发送ARP报文的时间间隔
    # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态
    track_interface {
      eth0
    }
  # 要执行的检查脚本
  track_script {
    checkhaproxy
  }
}
```
然后，重启 Keepalived：


```
$ sudo systemctl restart keepalived
```
#### 第四步：测试 Keepalived
上面的配置中，10.0.4.20的优先级更高，所以正常情况下10.0.4.20将被选择为主节点，如下图所示：

![img](https://static001.geekbang.org/resource/image/54/79/54968f40707b779e2ab70d3ab5a53479.png?wh=1920x500)

接下来，我们分别模拟一些故障场景，来看下配置是否生效。

场景 1：Keepalived 故障
在10.0.4.20服务器上执行sudo systemctl stop keepalived模拟 Keepalived 故障，查看 VIP，如下图所示：

![img](https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544)
可以看到，VIP 从10.0.4.20服务器上，漂移到了10.0.4.21服务器上。查看/var/log/keepalived.log，可以看到10.0.4.20服务器新增如下一行日志：

```
[2020-10-14 14:01:51] notify_stop
```
10.0.4.21服务器新增如下日志：

```
[2020-10-14 14:01:52] notify_master
```
场景 2：Nginx 故障
在10.0.4.20和10.0.4.21服务器上分别执行sudo systemctl restart keepalived，让 VIP 漂移到10.0.4.20服务器上。

在10.0.4.20服务器上，执行 sudo systemctl stop nginx 模拟 Nginx 故障，查看 VIP，如下图所示：

![img](https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544)

可以看到，VIP 从10.0.4.20服务器上，漂移到了10.0.4.21服务器上。查看/var/log/keepalived.log，可以看到10.0.4.20服务器新增如下一行日志：

```
[2020-10-14 14:02:34] notify_fault
```
10.0.4.21 服务器新增如下日志：

```
[2020-10-14 14:02:35] notify_master

```
场景 3：Nginx 恢复
基于场景 2，在10.0.4.20服务器上执行sudo systemctl start nginx恢复 Nginx，查看 VIP，如下图所示：

![img](https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544)

可以看到，VIP 仍然在10.0.4.21服务器上，没有被10.0.4.20抢占。查看/var/log/keepalived.log，可以看到10.0.4.20服务器新增如下一行日志：

```
[2020-10-14 14:03:44] notify_backup
```
10.0.4.21服务器没有新增日志。

#### 第五步：VIP 绑定公网 IP
到这里，我们已经成功配置了 Keepalived + Nginx 的高可用方案。但是，我们的 VIP 是内网，还不能通过外网访问。这时候，我们需要将 VIP 绑定一个外网 IP，供外网访问。在腾讯云上，可通过绑定弹性公网 IP 来实现外网访问，需要先申请公网 IP，然后将 VIP 绑定弹性公网 IP。下面我来讲讲具体步骤。

申请公网 IP：

登录私有网络控制台。在左侧导航栏中，选择【IP 与网卡】>【弹性公网 IP】。在弹性公网 IP 管理页面，选择所在地域，单击【申请】。

将 VIP 绑定弹性公网 IP：

登录私有网络控制台。在左侧导航栏中，选择【IP 与网卡】>【高可用虚拟】。单击需要绑定的 HAVIP 所在行的【绑定】。在弹出界面中，选择需要绑定的公网 IP 即可，如下图所示：

![img](https://static001.geekbang.org/resource/image/83/62/83bc9f4595325e9d339e7c3269aa3462.png?wh=1388x666)
绑定的弹性公网 IP 是106.52.252.139。

这里提示下，腾讯云平台中，如果 HAVIP 没有绑定实例，绑定 HAVIP 的 EIP 会处于闲置状态，按¥0.2/小时 收取闲置费用。所以，你需要正确配置高可用应用，确保绑定成功。

#### 第六步：测试公网访问
最后，你可以通过执行如下命令来测试：

```
$ curl -H"Host: iam.api.marmotedu.com" http://106.52.252.139/healthz -H"iam.api.marmotedu.com"
{"status":"ok"}
```
可以看到，我们可以成功通过公网访问后端的高可用服务。到这里，我们成功部署了一个可用性很高的 IAM 应用。

### 总结
今天，我主要讲了如何使用 Nginx 和 Keepalived，来部署一个高可用的 IAM 应用。


为了部署一个高可用的 IAM 应用，我们至少需要两台服务器，并且部署相同的服务 iam-apiserver、iam-authz-server、iam-pump。而且，选择其中一台服务器部署数据库服务：MariaDB、Redis、MongoDB。为了安全和性能，iam-apiserver、iam-authz-server、iam-pump 服务都是通过内网来访问数据库服务的。这一讲，我还介绍了如何配置 Nginx 来实现负载均衡，如何配置 Keepalived 来实现 Nginx 的高可用。

## 42 | 软件部署实战（下）：IAM系统安全加固、水平扩缩容实战
这一讲和前面两讲，都是介绍如何基于物理机 / 虚拟机来部署 IAM 的。在前面两讲，我们了解了如何部署一个高可用的 IAM 应用，今天就再来看看 IAM 应用安全和弹性伸缩能力的构建方式。在这一讲中，我会带你加固 IAM 应用的安全性，并介绍如何具体执行扩缩容步骤。接下来，我们先来看下如何加固 IAM 应用的安全性。


### IAM 应用安全性加固
iam-apiserver、iam-authz-server、MariaDB、Redis 和 MongoDB 这些服务，都提供了绑定监听网卡的功能。我们可以将这些服务绑定到内网网卡上，从而只接收来自于内网的请求，通过这种方式，可以加固我们的系统。

我们也可以通过 iptables 来实现类似的功能，通过将安全问题统一收敛到 iptables 规则，可以使我们更容易地维护安全类设置。这门课通过 iptables 来加固系统，使系统变得更加安全。下面，我先来对 iptables 工具进行一些简单的介绍。


### iptables 简介
iptables 是 Linux 下最优秀的防火墙工具，也是 Linux 内核中 netfilter 网络子系统用户态的工具。

netfilter 提供了一系列的接口，在一个到达本机的数据包，或者经本机转发的数据包流程中添加了一些可供用户操作的点，这些点被称为 HOOK 点。通过在 HOOK 点注册数据包处理函数，可以实现数据包转发、数据包过滤、地址转换等功能。

用户通过 iptables 工具定义各种规则，这些规则通过 iptables 传给内核中的 netfilter。最终，netfilter 会根据规则对网络包进行过滤。Linux 系统一般会默认安装 iptables 软件。防火墙根据 iptables 里的规则，对收到的网络数据包进行处理。

iptables 里的数据组织结构分为表、链、规则。
- 表（tables）: 表可以提供特定的功能，每个表里包含多个链。iptables 里面一共有 5 个表，分别是 filter、nat、mangle、raw、security。这些表，分别用来实现包过滤、网络地址转换、包重构、数据追踪处理和 SELinux 标记设置。
- 链（chains）: 链是数据包传播的路径，每一条链中可以有一个或多个规则。当一个数据包到达一个链时，iptables 会从链中第一条规则开始，检查该数据包是否满足规则所定义的条件。如果满足，就会根据该条规则所定义的方法，处理该数据包。否则，就继续检查下一条规则。如果该数据包不符合链中任一条规则，iptables 就会根据该链预先定义的默认策略来处理数据包。
- 规则（rules）：规则存储在内核空间的信息包过滤表中，用来描述“如果数据包满足所描述的条件，就按照要求处理这个数据包，如果不满足，就判断下一条规则”。

其中，iptables 中表和链的种类及其功能，如下表所示：

![img](https://static001.geekbang.org/resource/image/11/0f/112df7eb9a1258dd61e3bd0e0b6b210f.png?wh=2248x1941)

上面的表格中，五张表的处理是有顺序的。当数据包到达某一条链时，会按照 RAW、MANGLE、NAT、FILTER、SECURITY 的顺序进行处理。到这里，我介绍了关于 iptables 的一些基础知识，但这还远远不够。要想使用 iptables 来加固你的系统，你还需要掌握 iptables 工具的使用方法。接下来，我先来介绍下 iptables 是如何处理网络数据包的。


### 网络数据包处理流程
网络数据包的处理流程如下图所示：

![img](https://static001.geekbang.org/resource/image/9e/bb/9ece7f3001c022790f1fd1a0yy1246bb.jpg?wh=2248x1414)

具体可以分为两个步骤。

第一步，当数据包进入网卡后，它首先进入 PREROUTING 链，根据目的 IP 判断是否转发出去。第二步分为两种情况：如果数据包目的地是本机，它会到达 INPUT 链。到达后，任何进程都会收到它。本机上的程序可以发送数据包，这些数据包会经过 OUTPUT 链，然后经 POSTROUTING 链输出；如果数据包是要转发出去，并且内核允许转发，那么数据包会经过 FORWARD 链，最后从 POSTROUTING 链输出。

### iptables 工具使用方式介绍
iptables 的功能强大，所以使用方法也非常多样。这里，我来介绍下 iptables 工具的使用方式，并给出一些使用示例。


**命令格式**
iptables 的语法格式为：


```
iptables [-t 表名] 命令选项 [链名] [条件匹配] [-j 目标动作或跳转]
```
下面是一个 iptables 的使用示例：

```
iptables -t nat -I PREROUTING -p tcp --dport 8080 -j DNAT --to 10.0.4.88
```
这里对上面涉及到的一些参数进行说明。
- 表名 / 链名：指定 iptables 命令所操作的表 / 链。
- 命令选项：指定处理 iptables 规则的方式，例如插入、增加、删除、查看等。
- 条件匹配：指定对符合条件的数据包进行处理。
- 目标动作或跳转：防火墙处理数据包的方式。

iptables 的命令选项又分为管理控制选项和通用选项。管理控制选项如下：

![img](https://static001.geekbang.org/resource/image/6d/b2/6d37f77b4cee31eea694cc588ayy3cb2.png?wh=2248x2323)

通用选项如下：

![img](https://static001.geekbang.org/resource/image/0b/ae/0b38f3ba2d722ccf3274a0ae0a5f79ae.png?wh=2248x1498)

处理数据包的方式（目标动作或跳转）有多种，具体如下表所示：

![img](https://static001.geekbang.org/resource/image/f7/dc/f796fc7905c88cf0461f4464cec8cddc.png?wh=2248x1625)

上面，我介绍了 iptables 工具的使用方式。因为内容有点多，你可能仍然不知道如何使用 iptables 工具。没关系，接下来你可以结合我举的一些例子来看下。


**命令示例**
下面的命令示例，默认使用了 FILTER 表，也即规则存放在 FILTER 表中，相当于每一条 iptables 命令都添加了-t filter 参数。


拒绝进入防火墙的所有 ICMP 协议数据包：

```
$ iptables -I INPUT -p icmp -j REJECT
```
允许防火墙转发除 ICMP 协议以外的所有数据包：

```
$ iptables -A FORWARD -p ! icmp -j ACCEPT
```
拒绝转发来自 192.168.1.10 主机的数据，允许转发来自 192.168.0.0/24 网段的数据：

```
$ iptables -A FORWARD -s 192.168.1.11 -j REJECT
$ iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT
```
丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包：

```
$ iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP
$ iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP
$ iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP
```
只允许管理员从 202.13.0.0/16 网段使用 SSH 远程登录防火墙主机：


```
$ iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPT
$ iptables -A INPUT -p tcp --dport 22 -j DROP
```
允许本机开放从 TCP 端口 20-1024 提供的应用服务：

```
$ iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT
$ iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT
```
允许转发来自 192.168.0.0/24 局域网段的 DNS 解析请求数据包：

```
$ iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT
$ iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT
```
禁止其他主机 ping 防火墙主机，但是允许从防火墙上 ping 其他主机：


```
$ iptables -I INPUT -p icmp --icmp-type Echo-Request -j DROP
$ iptables -I INPUT -p icmp --icmp-type Echo-Reply -j ACCEPT
$ iptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT
```
禁止转发来自 MAC 地址为 00：0C：29：27：55：3F 的数据包和主机的数据包：

```
$ iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP
```
对外开放 TCP 端口 20、21、25、110，以及被动模式 FTP 端口 1250-1280：

```
$ iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT
```
禁止转发源 IP 地址为 192.168.1.20-192.168.1.99 的 TCP 数据包：

```
$ iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP
```
禁止转发与正常 TCP 连接无关的非 syn 请求数据包：

```
$ iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP
```
拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包：

```
$ iptables -A INPUT -p tcp -m state --state NEW -j DROP
$ iptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT
```
只开放本机的 web 服务（80）、FTP(20、21、20450-20480)，放行外部主机发往服务器其他端口的应答数据包，将其他入站数据包都进行丢弃处理：

```
$ iptables -I INPUT -p tcp -m multiport --dport 20,21,80 -j ACCEPT
$ iptables -I INPUT -p tcp --dport 20450:20480 -j ACCEPT
$ iptables -I INPUT -p tcp -m state --state ESTABLISHED -j ACCEPT
$ iptables -P INPUT DROP
```
到这里，我们已经了解了 iptables 的功能，下面来看看如何使用 iptables 来加固 IAM 应用。我把它分成内网不安全和内网安全两种情况。

### IAM 安全加固（内网不安全）
在设置 iptables 规则之前，我们需要先梳理系统的访问关系，然后根据这些访问关系设置 iptables 规则。访问关系如下图所示：

![img](https://static001.geekbang.org/resource/image/9a/8d/9a9b8d4283410dc842505f258128d78d.jpg?wh=2248x1386)

你可以看到，IAM 系统服务互访关系分为下面这 4 种：
- 允许公网客户端访问 Nginx 的 80 和 443 端口。
- Keepalived 服务之间能够互发 VRRP 协议包。
- Nginx 访问各节点上 iam-apiserver、iam-authz-server 和 iam-pump 组件开启的 HTTP/HTTPS/GRPC 服务。
- iam 服务可以从各节点访问 Redis、MariaDB、MongoDB 数据库。

这里，我们假定 IAM 系统部署在一个非常大的内网中，该内网部署了很多其他团队的服务，有很多其他团队的研发、测试等人员在内网中执行各种操作。也就是说，我们处在一个不安全的内网中。这时候，如果要加固我们的系统，最安全的方式是屏蔽掉未知的来源 IP。
内网不安全的情况下，加固系统可以分为 3 大步骤，每个步骤中又有一些小步骤。另外，需要新增节点或者删除节点时，也需要进行一些变更操作。下面我们来具体看下。
#### 第一步，设置防火墙规则。
基于上面说到的几种互访关系，我们可以在各个节点上设置 iptables 规则来加固系统。我将这些规则设置编写成了 go 工具，用来自动生成设置这些规则的 shell 脚本。

具体设置的过程可以分为 5 步。


进入 iam 项目源码根目录。

配置 accesss.yaml（工具根据此配置，自动生成 iptables 设置脚本），内容如下（位于configs/access.yaml文件）：

```
yaml
# 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP
ssh-source: 10.0.4.0/24

# IAM应用节点列表（来源IP）
hosts:
  - 10.0.4.20
  - 10.0.4.21

# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）
ports:
  - 8080
  - 8443
  - 9090
  - 9443
  - 7070

# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）
dbports:
  - 3306
  - 6379
  - 27017
```
上面的配置中，我们指定了允许登陆机器的子网、Nginx 需要访问的端口列表和各节点需要访问的数据库端口列表。

生成 iptables 初始化脚本：

```
$ go run tools/geniptables/main.go -c access.yaml -t app -a -o firewall.sh
$ ls firewall.sh
firewall.sh

```
你可以打开 firewall.sh 文件，查看该脚本设置的规则。

将 firewall.sh 脚本拷贝到 10.0.4.20 和 10.0.4.21 节点执行：

```
$ scp firewall.sh root@10.0.4.20:/tmp/
$ scp firewall.sh root@10.0.4.21:/tmp/
```
登陆 10.0.4.20 和 10.0.4.21 机器，执行/tmp/firewall.sh。

在 10.0.4.20（数据库节点）节点上，设置 iptables 规则，以允许各节点访问：因为数据库节点也位于 10.0.4.20 节点，所以只需要添加新的 rule，并将iptables -A INPUT -j DROP规则放到最后执行即可。


```
$ go run tools/geniptables/main.go -c access.yaml -t db -o addrules.sh
```
然后，将 addrules.sh 脚本拷贝到 10.0.4.20 节点执行。注意，因为 iptables 是按顺序进行规则过滤的，所以需要将iptables -A INPUT -j DROP规则放在新设置规则的后面，否则执行不到新设置的规则。你可以在设置完 iptables 规则之后，执行下面的命令来将 DROP 放到最后：

```
iptables -A INPUT -j LOG --log-level 7 --log-prefix "Default Deny"
iptables -A INPUT -j DROP
```
生成的 addrules.sh 脚本加入以上设置。

#### 第二步，设置重启自动加载 iptables 规则。
前面我们在各个节点设置了 iptables 规则，但是这些规则在系统重启后会丢失。为了使系统重启后自动重新设置这些规则，我们需要将当前的 iptables 规则保存起来，让系统重启时自动加载。需要进行下面两个步骤。

保存现有的规则：
```
$ sudo iptables-save > /etc/sysconfig/iptables
```
添加下面的命令行到 /etc/rc.d/rc.local 文件中：

```
$ iptables-restore < /etc/sysconfig/iptables

```
#### 第三步，自动化。
在上面的步骤中，我们自动生成了 iptables 规则，并手动登陆到节点进行设置。你肯定也发现了，整个流程手动操作过多，容易出错，效率还低。你可以参考设置过程，将这些设置工作自动化，比如编写脚本，一键刷新所有节点的 iptables 规则。

另外，我们再来看下在新增节点和删除节点两种场景下，如何设置 iptables 规则。



**场景 1：新增节点**
如果我们要扩容一个节点，也需要在新节点设置防火墙规则，并在数据库节点设置防火墙规则允许来自新节点的访问。假如我们新增一个 10.0.4.22 节点，这里要设置防火墙规则，需要下面的 4 个步骤。

编辑 access.yaml，在 hosts 列表下新增 10.0.4.22 节点 IP。编辑后内容如下：

```
# 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP
ssh-source: 10.0.4.0/24

# IAM应用节点列表（来源IP）
hosts:
  - 10.0.4.20
  - 10.0.4.21
  - 10.0.4.22

# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）
ports:
  - 8080
  - 8443
  - 9090
  - 9443
  - 7070

# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）
dbports:
  - 3306
  - 6379
  - 27017
```
在 10.0.4.22 节点设置 iptables 规则：

```
$ go run tools/geniptables/main.go -c access.yaml -t app -a -o firewall.sh
```
将 firewall.sh 脚本拷贝到 10.0.4.22 节点，并执行。

在已有节点新增规则，允许来自 10.0.4.22 的 Nginx 服务的访问：

```
$ go run tools/geniptables/main.go -c access.yaml -t app 10.0.4.22 -o addrules.sh
```
将 addrules.sh 脚本拷贝到存量节点，并执行。

在数据库节点新增 iptables 规则，以允许来自新节点的访问：

```
$ go run tools/geniptables/main.go -c access.yaml -t db 10.0.4.22 -o addrules.sh
```
将 addrules.sh 脚本拷贝到 10.0.4.20 节点执行即可。

**场景 2：删除节点。**
如果我们要删除一个节点，需要在保留的节点和数据库节点中，将该节点的访问权限删除。假如我们要删除 10.0.4.22 节点，设置防火墙规则需要下面 3 个步骤。

在保留节点删除 10.0.4.22 节点访问权限：

```
$ go run tools/geniptables/main.go -c access.yaml -t app --delete 10.0.4.22 -o delete.sh
```
将 delete.sh 脚本拷贝到 10.0.4.20 节点执行即可。

将下线的节点从 access.yaml 文件中的 hosts 部分删除。



### IAM 安全加固（内网安全）
这里，我们来看第二种情况：假定我们系统部署在一个安全的内网环境中，这时候加固系统就会变得异常简单，只需要允许来源 IP 为内网 IP 的客户端访问我们提供的各类端口即可。在我们设置完 iptables 规则之后，后续再新增或者删除节点，就不需要再做变更了。具体可以分为 5 个步骤。

具体可以分为 5 个步骤。

第一步，进入 iam 项目源码根目录。


第二步，配置 accesss.yaml（工具根据此配置，自动生成 iptables 设置脚本），内容如下（configs/access.yaml文件）：


```
yaml
# 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP
ssh-source: 10.0.4.0/24

# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）
ports:
  - 8080
  - 8443
  - 9090
  - 9443
  - 7070

# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）
dbports:
  - 3306
  - 6379
  - 27017
```
上面配置中，我们仅仅指定了 IAM 服务端口和数据库端口。

第三步，生成 iptables 初始化脚本：

```
$ go run tools/geniptables/main.go -c access.yaml -t app --cidr=10.0.4.0/24 -a -o firewall.sh
$ ls firewall.sh
firewall.sh
```
第四步，将 firewall.sh 脚本拷贝到 10.0.4.20 和 10.0.4.21 节点执行：

```
$ scp firewall.sh root@10.0.4.20:/tmp/
$ scp firewall.sh root@10.0.4.21:/tmp/
```
登陆 10.0.4.20 和 10.0.4.21 机器执行 /tmp/firewall.sh 。

第五步，在 10.0.4.20（数据库节点）节点上，设置 iptables 规则，以允许各节点访问。

因为数据库节点也位于 10.0.4.20 节点，所以只需要添加新的 rule，并将 iptables -A INPUT -j DROP 规则放到最后执行即可。


```
$ go run tools/geniptables/main.go -c access.yaml -t db --cidr=10.0.4.0/24 -o addrules.sh
```
然后，将 addrules.sh 脚本拷贝到 10.0.4.20 节点执行。如果要增加节点，你只需要重新执行第三步，生成 firewall.sh 脚本，并将 firewall.sh 脚本拷贝到新节点上执行即可。删除节点，则不需要做任何操作。

接下来，我们再来看下**如何对 IAM 应用进行弹性伸缩操作。**


### 弹性伸缩
弹性伸缩包括扩容和缩容。扩容是指当业务量越来越大时，能够很容易地增加计算节点，来分散工作负载，从而实现计算等能力的扩展。缩容是指当业务量变小时，能够很容易地减少计算节点，从而减小成本。

在系统上线初期，通常业务量不会很大，但是随着产品的迭代，用户量的增多，系统承载的请求量会越来越多，系统承载的压力也会越来越大。这时，就需要我们的系统架构有能力进行水平扩容，以满足业务需求，同时避免因为系统负载过高造成系统雪崩。一些电商系统，在双 11 这类促销活动之前会提前扩容计算节点，以应对即将到来的流量高峰。但是活动过后，流量会逐渐下降，这时就需要我们的系统有能力进行缩容，以减少计算节点，从而节省成本。

一个可伸缩的系统架构，是我们在进行系统设计时必须要保证的。如果系统不具有伸缩性，那么当我们后期需要扩缩容时，就需要对代码进行大改，不仅会增加额外的工作量，还会拖累产品的迭代速度。而且你想想，改完之后还要测试，发布之后，还可能因为代码变更引入 Bug。总之，不具伸缩性的系统架构可以说是后患无穷。

IAM 系统在设计之初就考虑到了系统的伸缩能力，我们可以很容易地对系统进行扩缩容。下面，我来分别介绍下如何对系统进行扩容和缩容。

#### 系统扩容
系统扩容的步骤很简单，你只需要进行下面这 5 步：

根据需要申请计算节点，如无特殊需求，计算节点的配置、操作系统等要跟已有的节点保持一致。在新的节点上部署 iam-apiserver、iam-authz-server、iam-pump，部署方式跟部署其他节点一样。在新节点部署 Nginx，并将新节点的 IP 加入到已有所有节点的 Nginx upstream 配置中，重启 Nginx。在新节点部署 Keepalived，并将新节点的 IP 加入到已有所有节点的 unicast_peer 配置中，重启 Keepalived。修改 iptables 规则，并刷新所有机器的 iptables。

#### 系统缩容
系统缩容是系统扩容的逆向操作，也是 5 个步骤：

根据需要，确定要删除的节点。关闭待删除节点的 iam-apiserver、iam-authz-server、iam-pump 服务。从所有保留节点的 Nginx upstream 配置中，删除待删除节点的 IP 地址, 重启 Nginx。从所有保留节点的 Keepalived unicast_peer 配置中，删除待删除节点的 IP 地址, 重启 Keepalived。修改 iptables 规则，并刷新所有保留机器的 iptables。

### 总结
安全对于应用软件来说至关重要，在部署应用时，也一定要评估应用的安全性，并采取一定的措施来保证安全性。

在进行软件部署时，保证应用安全性最简单有效的方式是使用 iptables 规则来加固系统。实现思路也很简单，就是使用 iptables 规则，只允许特定来源的 IP 访问特定的端口。在业务正式上线之后，可能会遇到业务高峰期或低峰期。业务高峰期，可能需要添加机器，提高系统的吞吐量，可以在新机器上安装需要扩容的服务组件，并安装和配置好 Nginx 和 Keepalived，之后将该服务器添加到 Nginx 的 upstream 中。在业务低峰期时，可以将服务器从 Nginx 的 upstream 列表中移除，并关停 IAM 应用的服务。

## 43｜技术演进（上）：虚拟化技术演进之路
在前面的三讲中，我介绍了传统应用的部署方式。但是，随着软件架构进入云原生时代，我们越来越多地使用云原生架构来构建和部署我们的应用。为了给你演示如何使用云原生化的方式来部署 IAM 应用，接下来我会介绍如何基于 Kubernetes 来部署 IAM 应用。

在 Kubernetes 集群中部署 IAM 应用，会涉及到一些重要的云原生技术，例如 Docker、Kubernetes、微服务等。另外，云原生架构中还包含了很多其他的技术。为了让你提前了解后面部署需要的相关技术，同时比较通透地了解当前最火热的云原生架构，这一讲我就采用技术演进的思路，来详细讲解下云原生技术栈的演进中的虚拟化技术演进部分。

因为这一讲涉及的技术栈很多，所以我会把重点放在演进过程上，不会详细介绍每种技术的具体实现原理和使用方法。如果你感兴趣，可以自行学习，也可以参考我为你整理的这个资料：[awesome-books](https://github.com/marmotedu/awesome-books#%E4%BA%91%E8%AE%A1%E7%AE%97)。


在讲这个演进过程之前，我们先来看下这个问题：我们为什么使用云？

### 我们为什么使用云？
使用云的原因其实很简单，我们只是想在云上部署一个能够对外稳定输出业务能力的服务，这个服务以应用的形态部署在云上。为了启动一个应用，我们还需要申请系统资源。此外，我们还需要确保应用能够快速迭代和发布，出故障后能够快速恢复等，这就需要我们对应用进行生命周期管理。

应用、系统资源、应用生命周期管理这 3 个维度就构成了我们对云的所有诉求，如下图所示：

![img](https://static001.geekbang.org/resource/image/yy/eb/yyea295d642681444a004d55e8d73eeb.png?wh=1920x1010)

接下来的两讲，我就围绕着这 3 个维度，来给你详细介绍下每个维度的技术演进。这一讲，我会先介绍下系统资源维度的技术演进。在 44 讲，我会再介绍下应用维度和应用生命周期管理维度的技术演进。当前有 3 种系统资源形态，分别是物理机、虚拟机和容器，这 3 种系统资源形态都是围绕着虚拟化来演进的。所以，介绍系统资源技术的演进，其实就是介绍虚拟化技术的演进。接下来，我们就来看下虚拟化技术是如何演进的。


### 虚拟化技术的演进
虚拟化这个概念，其实在 20 世纪 60 年代就已经出现了。但因为技术、场景等限制，虚拟化技术曾沉寂过一段时间，直到 21 世纪虚拟机出现，虚拟化技术又迎来了一波爆发期，并逐渐走向成熟。

那么，什么是虚拟化技术呢？简单来讲，就是把计算机上的硬件、系统资源划分为逻辑组的技术，由此生成的仅仅是一个逻辑角度的视图。通过虚拟化技术，我们可以在一台计算机上运行多个虚拟机进程，进而发挥计算机硬件的最大利用率。

虚拟化分为很多种，例如操作系统虚拟化、存储虚拟化、网络虚拟化、桌面虚拟化等。其中，最重要的是操作系统虚拟化，支撑操作系统虚拟化的是底层 CPU、内存、存储、网络等的虚拟化，这些资源我们统称为计算资源。

因为计算资源的虚拟化在虚拟化领域占主导地位，所以很多时候我们说虚拟化技术演进，其实就是在说计算资源技术的演进。在我看来，虚拟化技术的演进过程如下：物理机阶段 -> 虚拟机阶段 -> 容器阶段（Docker + Kubernetes） -> Serverless 阶段。

#### 物理机阶段
上面我提到虚拟化技术包含很多方面，但是整个虚拟化技术是围绕着 CPU 虚拟化技术来演进的。这是因为，内存虚拟化、I/O 虚拟化的正确实现，都依赖于对内存、I/O 中一些敏感指令的正确处理，这就涉及到 CPU 虚拟化，所以 CPU 虚拟化是虚拟化技术的核心。因此，这一讲我会围绕着 CPU 虚拟化的演进，来讲解虚拟化技术的演进。这里，我先来介绍一下物理机阶段 CPU 的相关知识。

CPU 是由一系列指令集构成的，这些指令集主要分为两种，分别是特权指令集和非特权指令集。特权指令集是指那些可以改变系统状态的指令集，非特权指令集是指那些不会影响系统状态的指令集。我举个例子你就明白了：写内存是特权指令集，因为它可以改变系统的状态；读内存是非特权指令集，因为它不会影响系统的状态。

因为非特权指令集可能会影响整个系统，所以芯片厂商在 x86 架构上又设计了一种新模式，保护模式，这个模式可以避免非特权指令集非法访问系统资源。

保护模式是通过 Ring 来实现的。在 x86 架构上，一共有 4 个 Ring，不同的 Ring 有不同的权限级别：Ring 0 有最高的权限，可以操作所有的系统资源，Ring 3 的权限级别最低。Kernel 运行在 Ring 0 上，Application 运行在 Ring 3 上。Ring 3 的 Application 如果想请求系统资源，需要通过 system call 调用 Ring 0 的内核功能，来申请系统资源。

这种方式有个好处：可以避免 Applicaiton 直接请求系统资源，影响系统稳定性。通过具有更高权限级的 Kernel 统一调度、统一分配资源，可以使整个系统更高效，更安全。

x86 架构的 Ring 和调用关系如下图所示：

![img](https://static001.geekbang.org/resource/image/7e/8d/7e2868cd62baae3154bc4e8957e9b48d.png?wh=1920x708)

在物理机阶段，对外提供物理资源，这种资源提供方式面临很多问题，例如成本高，维护麻烦、需要建机房、安装制冷设备、服务器不方便创建、销毁等等。所以在云时代，和物理机相比，我们用得更多的是虚拟机。下面我们就来看虚拟机阶段。
#### 虚拟机阶段
这里，在讲虚拟化技术之前，我想先介绍下 x86 的虚拟化漏洞，CPU 虚拟化技术的演进也主要是围绕着解决这个漏洞来演进的。
#### 虚拟化漏洞
一个虚拟化环境分为三个部分，分别是硬件、虚拟机监控器（又叫 VMM，Virtual Machine Manager），还有虚拟机。

你可以把虚拟机看作物理机的一种高效隔离的复制，它具有三个特性：同质、高效、资源受控。这三个特点决定了不是所有体系都可以虚拟化，比如目前我们用得最多的 x86 架构，就不是一个可虚拟化的架构，我们称之为虚拟化漏洞。

在虚拟化技术产生后，诞生了一个新的概念：敏感指令。敏感指令是指可以操作特权资源的指令，比如修改虚拟机运行模式、物理机状态，读写敏感寄存器 / 内存等。显然，所有的特权指令都是敏感指令，但不是所有的敏感指令都是特权指令。特权指令和敏感指令的关系，可以简单地用这张图来表示：

![img](https://static001.geekbang.org/resource/image/30/6a/30da714fc8341600f558817789a9096a.png?wh=1920x1942)

在一个可虚拟化的架构中，所有的敏感指令应该都是特权指令。x86 架构中有些敏感指令不是特权指令，最简单的例子是企图访问或修改虚拟机模式的指令。所以，x86 架构是有虚拟化漏洞的。

#### Hypervisor 技术的演进
为了解决 x86 架构的虚拟化漏洞，衍生出了一系列的虚拟化技术，这些虚拟化技术中最核心的是 Hypervisor 技术。所以接下来，我就介绍下 Hypervisor 技术的演进。

Hypervisor，也称为虚拟机监控器 VMM，可用于创建和运行虚拟机 （VM）。它是一种中间软件层，运行在基础物理服务器和操作系统之间，可允许多个操作系统和应用共享硬件。通过让 Hypervisor 以虚拟化的方式共享系统资源（如内存、CPU 资源），一台主机计算机可以支持多台客户机虚拟机。

Hypervisor、物理机和虚拟机的关系如下图：

![img](https://static001.geekbang.org/resource/image/2d/7f/2d471ca14d50b80ffcd421c8719cf17f.png?wh=1920x1080)

按时间顺序，Hypervisor 技术的发展依次经历了下面 3 个阶段：
- 软件辅助的完全虚拟化（Software-assisted full virtualization）：该虚拟化技术在 1999 年出现，里面又包含了解释执行（如 Bochs）、扫描与修补（如 VirtualBox）、二进制代码翻译（如 Vmware、Qemu）三种技术。
- 半虚拟化（Para-virtualization）：该虚拟化技术在 2003 年出现，也叫类虚拟化技术，典型的 Hypervisor 代表是 Xen。
- 硬件辅助的完全虚拟化（Hardware-assistant full virtualization ）：该虚拟化技术在 2006 年出现，典型的 Hypervisor 代表是 KVM。当前普遍使用的主流虚拟化技术，就是以 KVM 为代表的硬件辅助的完全虚拟化。

下面，我就来简单介绍下这三个阶段。

先来看第一个阶段，**软件辅助的完全虚拟化**，它又分为解释执行、扫描与修补、二进制代码翻译三个演进阶段。


解释执行
简单地说，解释执行的过程就是取一条指令，模拟出这条指令的执行效果，再取下一条指令。这种技术因为思路比较简单，所以容易实现，复杂度低。执行时，编译好的二进制代码是不会被载入到物理 CPU 直接运行的，而是由解释器逐条解码，再调入对应的函数来模拟指令的功能。解释过程如下图所示：

![img](https://static001.geekbang.org/resource/image/9d/c7/9d6c29e788e62ec16115d02a7f0807c7.png?wh=1920x1180)

因为每一条指令都要模拟，所以就解决了虚拟化漏洞，同时也可以模拟出一个异构的 CPU 结构，比如在 x86 架构上模拟出一个 ARM 架构的虚拟机。也正是因为每一条指令都需要模拟，不区别对待，导致这种技术的性能很低。

扫描与修补
由于解释执行性能损失很大，再加上虚拟机中模拟的虚拟 CPU 和物理 CPU 的体系结构相同（同质），这样大多数指令可以直接在物理 CPU 上运行。因此，CPU 虚拟化过程中，可以采用更优化的模拟技术来弥补虚拟化漏洞。

扫描与修补技术就是通过这种方式，让大多数指令直接在物理 CPU 上运行，而把操作系统中的敏感指令替换为跳转指令，或者会陷入到 VMM 中去的指令。这样，VMM 一旦运行到敏感指令，控制流就会进入 VMM 中，由 VMM 代为模拟执行。过程如下图所示：

![img](https://static001.geekbang.org/resource/image/f0/4e/f0fdb92c7c1fedc3bbedc90d411d314e.png?wh=1920x1460)

使用这种方式，因为大部分指令不需要模拟，可以直接在 CPU 上运行，所以性能损失相对较小，实现起来比较简单。

二进制代码翻译
这个算是软件辅助的完全虚拟化的主流方式了，早期的 VMware 用的就是这个技术。二进制代码翻译会在 VMM 中开辟一段缓存，将翻译好的代码放在缓存中。在执行到某条指令的时候，直接从内存中找到这条指令对应的翻译后的指令，然后在 CPU 上执行。

在性能上，二进制代码翻译跟扫描与修补技术各有长短，但是实现方式最为复杂。它的过程如下图所示：

![img](https://static001.geekbang.org/resource/image/ba/1a/ba3962c283c567d6f20c8d780930d41a.jpg?wh=1920x1698)

看到这里，你可能会对模拟和翻译这两个概念有疑惑，我在这里解释下模拟和翻译的区别：模拟是将 A 动作模拟成 B 动作，而翻译是将 A 指令翻译成 B 指令，二者是有本质不同的。


**然后，我们来看 Hypervisor 技术发展的第二个阶段，Para-virtualization。**

软件辅助的完全虚拟化对 x86 的指令做了翻译或者模拟，在性能上，多多少少都会有些损失，而这些性能损失在一些生产级的场景是不可接受的。所以，在 2003 年出现了 Para-virtualization 技术，也叫半虚拟化 / 类虚拟化。和之前的虚拟化技术相比，Para-virtualization 在性能上有了大幅度的提升，甚至接近于原生的物理机。

Para-virtualization 的大概原理是这样的：Hypervisor 运行在 Ring 0 中，修改客户机操作系统内核，将其中的敏感指令换成 hypercall。hypercall 是一个可以直接跟 VMM 通信的函数，这样就绕过了虚拟化的漏洞（相当于所有敏感指令都被 VMM 捕获了），同时不存在模拟和翻译的过程，所以性能是最高的。这个过程如下图所示：

![img](https://static001.geekbang.org/resource/image/6e/77/6ea013e621c58fb78d444449fb55f977.png?wh=1920x902)
因为要修改操作系统，所以不能模拟一些闭源的操作系统，比如 Windows 系列。另外，修改客户机操作系统内核还是有些开发和维护工作量的。所以，随着硬件辅助完全虚拟化技术的成熟，Para-virtualization 也逐渐被替换掉了。

**然后，我们来看 Hypervisor 技术发展的第三个阶段，硬件辅助的完全虚拟化。**
在 2006 年，Intel 和 AMD 分别在硬件层面支持了虚拟化，比如 Intel 的 VT-X 技术和 AMD 的 SVM。它们的核心思想都是引入新运行模式，可以理解为增加了一个新的 CPU Ring -1，权限比 Ring 0 还高，使 VMM 运行在 Ring -1 下，客户机内核运行在 Ring 0 下。

通常情况下，客户机的核心指令可以直接下达到计算机系统硬件执行，不需要经过 VMM。当客户机执行到敏感指令的时候，CPU 会从硬件层面截获这部分敏感指令，并切换到 VMM，让 VMM 来处理这部分敏感指令，从而绕开虚拟化漏洞。具体如下图所示：

![img](https://static001.geekbang.org/resource/image/e6/91/e60585ea58107b48af2815a3fd552591.png?wh=1920x929)

因为 CPU 是从硬件层面支持虚拟化的，性能要比软件模拟更高，同时硬件虚拟化可以不用去修改操作系统。所以，即使是现在，硬件辅助的完全虚拟化也是主流的虚拟化方式。


接下来我们来看虚拟化技术演进的第三阶段，容器阶段。

#### 容器阶段
2005 年，诞生了一种新的虚拟化技术，容器技术。容器是一种轻量级的虚拟化技术，能够在单一主机上提供多个隔离的操作系统环境，通过一系列的命名空间隔离进程，每个容器都有唯一的可写文件系统和资源配额。

#### 容器引擎 Docker
容器技术的的代表项目就是 Docker，Docker 是 Docker 公司在 2013 年推出的容器项目，因为轻量、易用的特点，迅速得到了大规模的使用。Docker 的大规模应用使得系统资源的形态由虚拟机阶段进入到了容器阶段。

基于 Docker 容器化技术，开发者可以打包他们的应用以及依赖和配置到一个可移植的容器中，然后发布到任何流行的 Linux/Windows 机器上。开发者无需关注底层系统、环境依赖，这使得容器成为部署单个微服务的最理想的工具。

Docker 通过 Linux Namespace 技术来进行资源隔离，通过 Cgroup 技术来进行资源分配，具有更高的资源利用率。Docker 跟宿主机共用一个内核，不需要模拟整个操作系统，所以具有更快的启动时间。在 Docker 镜像中，已经打包了所有的依赖和配置，这样就可以在不同环境有一个一致的运行环境，所以能够支持更快速的迁移。另外，Docker 的这些特性也促进了 DevOps 技术的发展。

我这里拿 Docker 和虚拟机来做个对比，让你感受下 Docker 的强大。二者的架构对比如下图所示：

![img](https://static001.geekbang.org/resource/image/7e/98/7e24d5667f4d41724c9cc0ab6fee5398.png?wh=1920x822)


可以看到，Container 相比于虚拟机，不用模拟出一个完整的操作系统，非常轻量。因此，和虚拟机相比，容器具有下面这些优势：

![img](https://static001.geekbang.org/resource/image/65/5c/65049ffd61b12de9fcd5ccf8f684385c.png?wh=1920x1209)

从这张表格里你可以看到，在启动时间、硬盘占用量、性能、系统支持量、资源使用率、环境配置这些方面，Docker 和虚拟机相比具有巨大的优势。这些优势，使得 Docker 成为比虚拟机更流行的应用部署媒介。

也许这时你想问了：Docker 就这么好，一点缺点都没有吗？显然不是的，Docker 也有自己的**局限性**。

我们先来看一下生产环境的 Docker 容器是什么样的：一个生产环境的容器数量可能极其庞大，关系错综复杂，并且生产环境的应用可能天生就是集群化的，具备高可用、负载均衡等能力。**Docker 更多是用来解决单个服务的部署问题，无法解决生产环境中的这些问题。并且，不同节点间的 Docker 容器无法相互通信。**

**不过，这些问题都可以通过容器编排技术来解决**。业界目前也有很多优秀的容器编排技术，比较受欢迎的有 Kubernetes、Mesos、Docker Swarm、Rancher 等。这两年，随着 Kubernetes 的发展壮大，Kubernetes 已经成为容器编排的事实标准。

#### 容器编排技术 Kubernetes
因为我们后面会基于 Kubernetes 来部署 IAM 应用，所以这里我会详细介绍下 Kubernetes 服务编排技术。

Kubernetes 是 Google 开源的一个容器编排技术（编排也可以简单理解为调度、管理），用于容器化应用的自动化部署、扩展和管理。它的前身是 Google 内部的 Borg 项目。Kubernetes 的主要特性有网络通信、服务发现与负载均衡、滚动更新 & 回滚、自愈、安全配置管理、资源管理、自动伸缩、监控、服务健康检查等。

Kubernetes 通过这些特性，解决了生产环境中 Docker 存在的问题。Kubernetes 和 Docker 相辅相成，Kubernetes 的成功也使 Docker 有了更大规模的使用，最终使得 Docker 成为比虚拟机更流行的计算资源提供方式。

接下来，我围绕着下面这张架构图来介绍 K8S（Kubernetes）的基本概念：

![img](https://static001.geekbang.org/resource/image/ee/7c/ee25460fdbc4b257440dd4f6b109237c.jpg?wh=1920x1149)

Kubernetes 采用的是 Master-Worker 架构模式。其中，Master 节点是 Kubernetes 最重要的节点，里面部署了 Kubernetes 的核心组件，这些核心组件共同构成了 Kubernetes 的 Control Plane（控制面板）。而 Worker，也就是图中的 Node Cluster，就是节点集群。其中，每一个 Node 就是具体的计算资源，它既可以是一台物理服务器，也可以是虚拟机。

我们先来介绍下 Master 节点上的组件。
- Kube API Server：提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制。
- Kube Scheduler：负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上。
- Kube Controller Manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等。
- Cloud Controller Manager：这个组件是在 Kubernetes 1.6 版本加入的与基础云提供商交互的控制器。
- Etcd：分布式的 K-V 存储，独立于 Kubernetes 的开源组件。主要存储关键的元数据，支持水平扩容保障元数据的高可用性。基于 Raft 算法实现强一致性，独特的 watch 机制是 Kubernetes 设计的关键。


介绍完了 Master，再看看每一个 Kubernetes Node 需要有哪些组件。

- Kubelet：负责维持容器的生命周期，同时也负责 volume（CVI）和网络（CNI）的管理。
- kube-proxy：kube-proxy 是集群中每个节点上运行的网络代理，维护节点上的网络规则，它允许从集群的内部或外部网络与 Pod 进行网络通信，并负责为 Service 提供集群内部的服务发现和负载均衡。
- Container Runtime：负责镜像管理以及 Pod 和容器的真正运行（CRI），默认的容器运行时为 Docker。

上面那张架构图里的 Service、Deployment、Pod 等，都不算是组件，而是属于 Kubernetes 资源对象，我们稍后再做介绍。这里我先简单介绍下架构图的 UI dashboard 和 kubectl。

- UI dashboard 是 Kubernetes 官方提供的 web 控制面板，可以对集群进行各种控制，直接与 API Server 进行交互，其实就是 API Server 暴露出来的可视化接口。在这里可以直观地创建 Kubernetes 对象、查看 Pod 运行状态等。UI dashboard 界面如下图所示：

![img](https://static001.geekbang.org/resource/image/5c/49/5c6acce4e90048e63426b9e896be8b49.png?wh=1920x1148)

- kubectl 是 Kubernetes 的客户端工具，提供了非常多的命令、子命令、命令行选项，支持开发或运维人员在命令行快速操作 Kubernetes 集群，例如对各类 Kubernetes 资源进行增删改查操作，给资源打标签，等等。下面是执行kubectl describe service iam-pump命令获取iam-pump详细信息的命令行截图：

![img](https://static001.geekbang.org/resource/image/60/38/6046e3586eefce16b923aebbf0de2538.png?wh=1269x721)

Kubernetes 有多种多样的 Objects，如果要查看所有 Objects 的 Kind，可以使用命令kubectl api-resources。我们通过这些 Objects 来完成 Kubernetes 各类资源的创建、删除等操作。因为我们这一讲的核心目的是介绍云原生技术的演进，所以不会详细介绍 Kubernetes 资源对象的使用方式。你如果感兴趣，可以查看Kubernetes 官方文档。

我这里简单介绍一下 Kubernetes 对象的一些基本信息，以及在架构图中出现的 Deployment、Pod、Service 三种对象。

下面是一个典型的 Kubernetes 对象 YAML 描述文件：


```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  # ...
```
在这个描述文件中，apiVersion 和 kind 共同决定了当前 YAML 配置文件应该由谁来处理，前者表示描述文件使用的 API 组，后者表示一个 API 组中的一个资源类型。这里的 v1 和 Pod 表示的就是核心 API 组 api/v1 中的 Pod 类型对象。

metadata 则是一些关于该对象的元数据，其中主要有name、namespace、labels、annotations。其中， name 需要在 namespace 下唯一，成为这个对象的唯一标识。label和annotations分别是这个对象的一些标签和一些注解，前者用于筛选，后者主要用来标注提示性的信息。

**接下来，我再介绍下 Pod、Deployment、Service 这 3 种对象。**

Pod
Pod 是 Kubernetes 中运行的最小的、最简单的计算单元，我觉得 Pod 也是 Kubernetes 最核心的对象。Pod 中可以指定运行多个 Containers，可以挂载 volume 来实现部署有状态的服务，这些都在spec中被指定。对于任意类型的对象，spec都是用来描述开发人员或运维人员对这个对象所期望的状态的，对于不同类型的对象，spec有不同的子属性。下面是一个 Pod 示例，我们在 YAML 描述文件里指定了期望 Pod 运行的 Docker 镜像和命令：

```
yaml
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  labels:
    app: busybox
spec:
  containers:
  - image: busybox
    command:
      - sleep
      - "3600"
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Always
```
Deployment
一般来说，我们不会直接部署 Pod，而是部署一个 Deployment 或者 StatefulSet 之类的 Kubernetes 对象。Deployment 一般是无状态服务；StatefulSet 一般是有状态服务，会使用 volume 来持久化数据。下面是一个部署两个 Pod 的示例：

```
yaml
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: my-nginx
spec:
  selector:
    matchLabels:
      run: my-nginx
  replicas: 2
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      containers:
      - name: my-nginx
        image: nginx
        ports:
        - containerPort: 80
```
Service
Service 是 Kubernetes 中另一个常见的对象，它的作用是作为一组 Pod 的负载均衡器，利用 selector 将 Service 和 Pod 关联起来。下面这个示例里，使用的是run: my-nginx这个 label。这个 Service 绑定的就是上面那个 Deployment 部署的 nginx 服务器：

```
yaml
apiVersion: v1
kind: Service
metadata:
  name: my-nginx
  labels:
    run: my-nginx
spec:
  ports:
  - port: 80
    protocol: TCP
  selector:
    run: my-nginx

```
最后我还想介绍下基于 Kubernetes 的容器云平台。各大公有云厂商，都有基于 Kubernetes 的容器管理平台，目前国内容器服务平台做得比较好的有腾讯云容器服务 TKE、阿里云容器服务 ACK。

TKE 基于原生 Kubernetes ，提供以容器为核心的解决方案，解决用户开发、测试及运维过程的环境问题，帮助用户降低成本、提高效率。腾讯云容器服务 TKE 完全兼容原生 Kubernetes API，并扩展了腾讯云的云硬盘、负载均衡等 Kubernetes 插件，同时以腾讯云私有网络为基础，实现了高可靠、高性能的网络方案。


#### Serverless 阶段
容器阶段之后，虚拟化技术的演进方向是什么呢？我们接着来看下 Serverless 阶段。

在 2014 年的时候，AWS 推出了 Lambda 服务，这是一个 Serverless 服务。从此，Serverless 越来越引人注意，成为了这几年最受关注的技术。我先介绍下什么是 Serverless。Serverless 直译过来就是无服务器，无服务器并不代表 Serverless 真的不需要服务器，只不过服务器的管理，以及资源的分配部分对用户不可见，而是由平台开发商维护。Serverless 不是具体的一个编程框架、类库或者工具，它是一种软件系统架构思想和方法。它的核心思想是：用户无需关注支撑应用服务运行的底层资源，比如 CPU、内存和数据库等，只需要关注自己的业务开发就行了。

Serverless 具有很多特点，核心特点主要有下面这几个。
- 无穷弹性计算能力：根据请求，自动水平扩容实例，拥有近乎无限的扩容能力。
- “零”运维：不需要申请和运维服务器。极致的伸缩能力：能够根据 CPU、内存、请求量等指标敏感地弹性伸缩，并支持缩容到 0。
- 按量计费：真正按使用量去计费。


在我看来，Serverless 有 3 种技术形态，分别是云函数、Serverless 容器、BaaS（Backend as a Service），如下图：

![img](https://static001.geekbang.org/resource/image/cb/19/cba931763a846ab8008e5600cd6e5419.jpg?wh=1920x641)

这 3 种 Serverless 技术形态中，Serverless 容器是核心，云函数和 BaaS 起辅助作用。Serverless 容器可以承载业务的核心架构，云函数则可以很好地适配触发器场景，BaaS 则可以满足我们对各种其他 Serverless 组件的需求，例如 Serverless 数据库、Serverless 存储等。

这 3 种技术形态，各大公用云厂商都早已有相应的产品，其中比较优秀的产品是腾讯云推出的 Serverless 产品，SCF、EKS 和 TDSQL-C。下面我分别介绍下。

- EKS：弹性容器服务（Elastic Kubernetes Service）是腾讯云容器服务推出的无需用户购买节点即可部署工作负载的服务模式。EKS 完全兼容原生 Kubernetes，支持使用原生方式购买及管理资源，按照容器真实使用的资源量计费。
- SCF：云函数（Serverless Cloud Function）是腾讯云为企业和开发者们提供的无服务器执行环境，帮助你在无需购买和管理服务器的情况下运行代码。你只需使用平台支持的语言编写核心代码，并设置代码运行的条件，就能在腾讯云基础设施上弹性、安全地运行代码。
- TDSQL-C：云原生数据库（Cloud Native Database TDSQL-C）是腾讯云自研的新一代高性能高可用的企业级分布式云数据库，具有高吞吐量、高可靠性等优点。

我们开始的时候提到，应用、系统资源、应用生命周期管理这 3 个维度构成了我们对云的所有诉求。那么到这里，系统资源维度的技术演进我就介绍完了。下一讲，我会介绍应用维度和应用生命周期管理维度的技术演进。


### 总结
这一讲，我主要通过虚拟化技术的演进，介绍了系统资源维度的技术演进。


虚拟化技术的演进流程为：物理机阶段 -> 虚拟机阶段 -> 容器阶段 -> Serverless 阶段。其中，物理机到虚拟机阶段的演进技术，主要是为了解决 x86 架构的虚拟化漏洞。要虚拟 CPU、内存和 I/O，就需要捕获其中的敏感指令，防止这些敏感指令修改系统状态，影响系统的稳定性。x86 架构有些敏感指令不是特权指令，导致这些指令可以从客户机中直接在物理 CPU 上执行，从而可能会影响系统状态。所以，我们说 x86 架构是有虚拟化漏洞的。

在虚拟机阶段，又诞生了 3 种不同的虚拟化技术，分别是软件辅助的完全虚拟化、半虚拟化和硬件辅助的完全虚拟化。因为硬件辅助的完全虚拟化技术不需要修改客户机内核，并且有着接近物理机的性能，所以成为当前的虚拟化主流技术，并以 KVM 为事实技术标准。

因为容器技术比虚拟机更加轻量，再加上 Docker、Kubernetes 项目的诞生，使得大规模使用容器技术变得可行，所以这几年系统资源的提供形态已经由虚拟机转变成了容器。

系统资源的最终形态，我认为会是 Serverless。Serverless 技术中，又分为 3 种技术形态：云函数、Serverless 容器和 BaaS。在业务架构 Serverless 化的过程中，整个部署架构会以 Serverless 容器为主，云函数为辅。


## 44｜技术演进（下）：软件架构和应用生命周期技术演进之路

应用、系统资源、应用生命周期管理这 3 个维度，构成了我们对云的所有诉求。上一讲，我从系统资源维度，介绍了虚拟化技术的演进之路。这一讲，我会介绍下应用维度和应用生命周期管理维度的技术演进。应用软件架构是用来构建应用的，不同的软件架构，构建应用的方式、效率，以及所构建应用的可维护度、性能都是不同的。随着技术的不断更新迭代，应用软件架构也在不断往前演进。这一讲我们就来看看，应用软件架构都有哪些，这些软件架构都有什么特点，以及它们之间是如何演进的。

至于应用生命周期管理维度，我在 09 讲 中已经介绍了应用生命周期管理技术的演进，这一讲也会再补充一些核心的技术，比如日志、监控告警、调用链等。接下来，我们就先来看下软件架构的演进之路。

### 软件架构的演进
软件架构技术演进如下图所示：

![img](https://static001.geekbang.org/resource/image/f1/cd/f17c948f69e84efef776ee367a145dcd.jpg?wh=2248x618)

最开始，我们使用单体架构来构建应用，后面逐渐演进为 SOA 架构。不管是单体架构，还是 SOA 架构，都很难满足互联网时代应用快速迭代的诉求。所以，在互联网时代，应用软件架构又演进成了微服务架构。当前我们正处在微服务架构阶段，也有很多团队的业务正在尝试使用 Service Mesh 替代微服务架构中的一些功能。

随着 Serverless 云函数的诞生，也诞生了一种新的软件架构，FaaS 架构。这里我先简单介绍下它，后面再详细讲。FaaS 架构因为限制多、使用场景局限，目前还仅仅适用于云函数这种系统资源形态，我个人认为它不会成为未来主流的软件架构。还要说明下，业界目前并没有 FaaS 软件架构这个说法，大家说到 FaaS，一般指的都是云函数这种技术形态。这里为了方便描述，我们先这样表达。

接下来，我仍然以技术演进的思路，来介绍下这些软件架构。首先来看下最早的单体架构。

#### 单体架构
在最早的时候，我们用的软件架构是单体架构。在单体架构中，我们会将应用程序的所有功能都存放在一个代码仓库中，并且发布时，也是发布整个代码仓库的代码和功能。在单体架构中，应用软件一般会包含四层，分别是表示层、业务逻辑层、数据访问层、数据库，如下图所示：

![img](https://static001.geekbang.org/resource/image/cd/a9/cde65byyc639286dbb27ac6a6abd8da9.jpg?wh=2248x3110)

这里简单介绍下每层的功能。

- 表示层：用于直接和用户交互，通常是网页、UI 界面。
- 业务逻辑层：用来进行业务逻辑处理。使用表示层传来的参数，进行业务逻辑处理，并将结果返回给表示层。
- 数据访问层：用来操作数据库，通常包括数据的 CURD 操作。例如，从数据库中查询用户信息，或者往数据库增加一条用户记录。
- 数据库：存储数据的物理介质。我们通过数据访问层来访问数据库中的数据。

单体架构的优点是应用开发简单，技术单一，测试、部署相对简单明了。因此它比较适合用户访问量较小的应用服务端。但它的缺陷也是非常明显的。随着业务的发展，项目越来越大，单体架构会带来开发效率低、发布周期长、维护困难、稳定性差、扩展性差等问题。另外，单体架构的技术栈也不易扩展，只能在原有的基础上，不断地进行局部优化。

#### SOA 架构
为了解决单体架构在业务代码变大时带来的各种问题，SOA 架构出现了。

SOA 架构是面向服务的软件架构，它的核心理念是：基于 SOA 的架构思想，将重复共用的功能抽取为组件，以服务的方式给各系统提供服务，服务之间通过 ESB 企业服务总线进行通信。如下图所示：

![img](https://static001.geekbang.org/resource/image/73/5c/73c40dab7430b1b5d320944b1d13515c.jpg?wh=2248x2489)


SOA 架构中，主要有两个角色，分别是服务提供者和服务消费者。服务消费者可以通过发送消息来调用购买商品、申请售后的服务，这些消息由 ESB 总线转换后，发送给对应的服务，实现 SOA 服务之间的交互通信。SOA 架构主要适用于大型软件服务企业对外提供服务的场景，至于一般业务场景就并不适用了。这是因为，SOA 服务的定义、注册和调用都需要繁琐的编码或者配置来实现，并且 ESB 总线也容易导致系统的单点风险，并拖累整体性能。


#### 微服务架构
在互联网时代，越来越多的企业推出了面向普通大众的网站和应用。这些企业没有能力，也没有必要构建和维护 ESB 企业服务总线。于是，基于 SOA 架构，又演进出了微服务架构。

微服务架构由 Matrin Fowler 在 2014 年提出，它的理念是将业务系统彻底地组件化和服务化，形成多个可以独立开发、部署和维护的服务或应用的集合。微服务之间采用 RESTful 等轻量的传输协议，来应对更快的需求变更和更短的开发迭代周期。如下图所示：

![img](https://static001.geekbang.org/resource/image/a2/8f/a2d303433462c384322a4342ff10fe8f.jpg?wh=2248x1984)

微服务架构提出得比较早，但在这几年才逐渐流行起来。这是什么原因呢？一方面，微服务架构基于自身的特点，确实能够解决其他软件架构中存在的一些问题；另一方面，Docker + Kubernetes 等云原生技术这几年也发展了起来，能够很好地支撑微服务的部署和生命周期管理。

总体来说，微服务架构有下面这几个特点：
- 微服务遵循单一原则，每个微服务负责一个独立的上下文边界；
- 微服务架构提供的服务之间采用 RESTful 等轻量协议传输，比 ESB 更轻量；
- 每个服务都有自己独立的业务开发活动和周期；
- 微服务一般使用容器技术独立部署，运行在自己的独立进程中，合理分配其所需的系统资源。这样，开发者就可以更加方便地制定每个服务的优化方案，提高系统可维护性。


微服务架构有很多优点，但也存在着问题。因为一个应用被拆分成一个个的微服务，随着微服务的增多，就会引入一些问题，比如微服务过多导致服务部署复杂。微服务的分布式特点也带来了一些复杂度，比如需要提供服务发现能力、调用链难以追踪、测试困难，等等。服务之间相互依赖，有可能形成复杂的依赖链路，往往单个服务异常，其他服务都会受到影响，出现服务雪崩效应。

目前业界针对这些问题也有一些标准的解决方案，比如，可以通过 Kubernetes、Helm 和 CI/CD 技术，解决微服务部署复杂的问题。至于微服务的分布式特点所带来的复杂性，可以通过一些微服务开发框架来解决。一些业界比较知名的微服务开发框架，比如 Spring Cloud 和 Dubbo，已经很好地解决了上面的问题。另外，云原生相关的技术也可以解决微服务调用链跟踪复杂、故障排障困难等问题。

另外，在我的日常开发中，经常会有开发者把 SOA 架构和微服务架构给搞混，所以我在这里再来介绍下二者的相同点和不同点。


微服务架构是 SOA 架构设计思想的另一种实现方式，这是二者相同的地方。至于区别，主要有三个。理解了下面这三点，以后你在开发中就很容易区分它们了。

- SOA 中的服务，其实只能属于某个应用的服务之一，微服务中的服务则是一个独立的服务，可以被多个应用共用。
- SOA 强调尽可能多地共享，而微服务强调尽可能少地共享。
- SOA 架构中，服务之间通过 ESB 来通信，而微服务中，服务之间通过轻量化机制，比如 RESTful 来实现通信。

#### Service Mesh
在讲微服务的时候，我提到微服务架构的一些问题可以通过一些微服务开发框架来解决，比如 Spring Cloud 和 Dubbo。但这里也有个问题：这些框架通常是侵入式的，比如语言只能限制在 Java，并且开发的时候要按框架的指定方式来开发。这个理念跟微服务的独立技术栈也是相反的。

2017 年底 Service Mesh（服务网格）的出现解决了这个问题，它是一种非侵入式技术，可以提供服务之间的网络调用、限流、熔断和服务监控等功能。Service Mesh 类似于 TCP/IP 协议，无需应用层感知，开发者只需要开发应用程序即可。所以，Service Mesh 是致力于解决服务间通讯的基础设施层，它具有下面这几个特点：


- 应用程序间通讯的中间层。
- 轻量级网络代理。
- 非侵入式，应用程序无感知。
- 可以将服务治理功能，例如重试、超时、监控、链路追踪、服务发现等功能，以及服务本身解耦。

Service Mesh 目前的发展比较火热，社区有很多优秀的 Service Mesh 开源项目，例如 Istio 、Linkerd 等。当前最受欢迎的开源项目是 Istio。

Istio 是一个完全开源的服务网格，作为透明的一层接入到现有的分布式应用程序里，提供服务治理等功能。它也是一个平台，拥有可以集成任何日志、遥测和策略系统的 API 接口。

Istio 的大概实现原理是：每个服务都会被注入一个 Sidecar（边车）组件，服务之间通信是先通过 Sidecar，然后 Sidecar 再将流量转发给另一个服务。因为所有流量都经过一个 Sidecar，所以可以通过 Sidecar 实现很多功能，比如认证、限流、调用链等。同时还有一个控制面，控制面通过配置 Sidecar 来实现各种服务治理功能。


目前 Istio 的最新版本是 1.8，1.8 版本的 Istio 架构图如下：

![img](https://static001.geekbang.org/resource/image/1b/96/1b47b53095c5baa73609b90834ec3996.jpg?wh=2248x1579)


从图中你可以看到，Istio 主要包含两大平面。一个是数据平面（Data plane），由 Envoy Proxy 充当的 Sidecar 组成。另一个是控制平面（Control plane），主要由三大核心组件 Pilot、Citadel、Galley 组成。下面，我来分别介绍下这三大核心组件的功能。

- Pilot：主要用来管理部署在 Istio 服务网格中的 Envoy 代理实例，为它们提供服务发现、流量管理以及弹性功能，比如 A/B 测试、金丝雀发布、超时、重试、熔断等。
- Citadel：Istio 的核心安全组件，负责服务的密钥和数字证书管理，用于提供自动生成、分发、轮换及撤销密钥和数据证书的功能。
- Galley：负责向 Istio 的其他组件提供支撑功能，可以理解为 Istio 的配置中心，它用于校验进入网络配置信息的格式内容正确性，并将这些配置信息提供给 Pilot。


#### FaaS 架构
这几年，以云函数为代表的 Serverless 技术异常火爆。伴随着 Serverless 技术的发展，一个新的软件开发模式也诞生了，这就是 FaaS 架构。FaaS 架构提供了一种比微服务更加服务碎片化的软件架构模式。简单来说，FaaS 架构就是把之前一个完整的业务拆分成一个个 Function 来部署，通过事件来触发底层 Function 的执行。

Function 里可能会调用第三方组件，比如数据库、消息队列服务等，这些第三方组件在 Serverless 架构中，统称为 BaaS（Backend as a Serivce）。BaaS 把这些后端的服务能力抽象成 API 让用户调用，用户不需要关注这些后端组件的高可用、扩缩容等运维层面的点，只需要去使用就可以了。

下面是 FaaS 架构的示意图：

![img](https://static001.geekbang.org/resource/image/23/43/2388ed22bf86c5f73b06f89ded610b43.jpg?wh=2248x775)


从这张图里你可以看到，用户通过浏览器、手机、小程序等客户端请求触发器服务，例如 API 网关、COS 对象存储、CLS 日志等。这些触发器服务在收到来自用户的请求之后，会触发它们所绑定的云函数，云函数会根据请求量等数据，实时启动多个并发实例。在触发云函数时，也会传递参数给云函数，并在云函数中使用这些参数，进行一些业务逻辑处理。例如，调用第三方的服务，将处理结果保存在后端数据库中。

在我看来，FaaS 架构未来不会成为主流，更多的是存在于云函数的场景中。我这么说是因为，如果将应用拆分成一个个 Function，这些 Function 的部署、维护，以及之间的通信会是一个巨大的挑战，从目前来看，还不存在解决这种挑战的技术和条件。另外，FaaS 架构也不适合承载一些较重的业务逻辑，比如还没法大规模迁移企业的应用系统。

### 应用生命周期管理技术：监控告警、日志、调用链
在这门课的 09 讲 中，我已经详细介绍了应用生命周期管理技术的演进。这里我们可以再回顾一下：应用生命周期，最开始主要是通过研发模式来管理的，按时间线先后出现了瀑布模式、迭代模式、敏捷模式。接着，为了解决研发模式中的一些痛点，出现了另一种管理技术，也就是 CI/CD 技术。随着 CI/CD 技术的成熟，又催生了另一种更高级的管理技术 DevOps。

其他的细节内容，如果有遗忘，你可以返回 09 讲 再复习一下，这里就不再重复介绍了。接下来，对于应用生命周期管理技术，我会补充一些之前没有讲到的重要技术，包括下面这三个：
- 监控告警组件，Prometheus；
- 统一日志管理框架，EFK；
- 调用链跟踪组件，Jaeger。

需要说明的是，这些技术之间不存在演进关系，而是平级的，共同作为应用生命周期管理技术的补充。


#### 监控告警组件：Prometheus
对于应用来说，监控告警功能是必不可少的一项功能，能够让开发者或运维人员及时感知到程序异常，并及时修复。另外，监控也能够收集一些有用的数据，供后面的运营分析使用。云原生技术栈中，也有很多开源的优秀监控告警项目，例如 Zabbix、Prometheus 等，其中最受欢迎的是Prometheus。

Prometheus 是一款开源的、自带时序数据库的监控告警系统。目前，Prometheus 已经成为 Kubernetes 集群中监控告警系统的标配。它具有下面这几个特点：

- 强大的多维度数据模型；
- 在多维度上灵活地查询语言；
- 不依赖分布式存储，单主节点工作；
- 通过基于 HTTP 的 pull 方式，采集时序数据；
- 可以通过 Push Gateway 进行时序列数据推送；
- 可以通过服务发现或者静态配置，去获取要采集的目标服务器；
- 多种可视化图表及仪表盘支持 (Grafana)。

Prometheus 的架构如下图所示：

![img](https://static001.geekbang.org/resource/image/04/04/0428cf195e1c7e8c2fd024c87bc3a904.jpg?wh=2248x1416)

从上图可以看出，Prometheus 的主要模块包括 Prometheus Server、Exporters、Pushgateway、Alertmanager 以及 Grafana 图形界面。这些模块，有些是可选的，有些是必选的，大部分组件使用 Golang 编写。下面我来分别介绍下。

- Prometheus Server（必选）：Prometheus 的核心服务，会定期从 Jobs/exporters 或者 Pushgateway 中拉取监控数据，并将时间序列（time-series）数据保存 TSDB 中，TSDB 是一个时间序列数据库。
- Client Library（必选）: Prometheus 的客户端，应用程序使用 Client Library，可以很方便地生成 metrics，并暴露一个 API 接口，供 Prometheus server 从中拉取（pull）metrics 数据。
- Pushgateway（可选）: 接收短期的 Jobs（Short-lived）推送（push）过来的 metrics 数据并缓存，供 Prometheus server 定期来 pull 这些监控数据。
- Exporters（可选）: 以 agent 的形式运行在需要采集监控数据的应用服务器上，收集应用程序监控数据，并提供 API 接口，供 Prometheus server 来 pull metrics 数据。
- Alertmanager（可选）: Prometheus 的告警组件，接收来自于 Prometheus server 的 alerts，将这些 alerts 去重、分组，并往配置的接收目的地发送告警。
- Grafana（可选）：Grafana 是一款跨平台、开源的可视化数据展示工具，可以用来统计和展示 Prometheus 监控数据，并带有告警功能，采用 Go 语言开发。

Prometheus 大致的工作流程是：

1. Prometheus Server 定期从配置好的 jobs 或者 Exporters 中拉 metrics，或者接收来自 Pushgateway 的 metrics，再或者从其他的 Prometheus Server 中拉 metrics。
2. Prometheus Server 在本地存储收集到的 metrics，并运行已经定义好的 alert.rules，记录新的时间序列，或者向 Alertmanager 推送警报。
3. Alertmanager 根据配置文件，对接收到的警报进行处理，发出告警。
4. Grafana 在图形界面中，可视化地展示采集数据。

Prometheus 会将所有采集到的样本数据以时间序列的方式保存在内存数据库中，并且定时保存到硬盘上。time-series 是按照时间戳和值的序列顺序存放的。每条 time-series 通过指标名称 (metrics name) 和一组标签集 (labelset) 命名，如下所示：

```
<--------------- metric ---------------------><-timestamp -><-value->
http_request_total{status="200", method="GET"}@1434417560938 => 94355
http_request_total{status="200", method="GET"}@1434417561287 => 94334

http_request_total{status="404", method="GET"}@1434417560938 => 38473
http_request_total{status="404", method="GET"}@1434417561287 => 38544

http_request_total{status="200", method="POST"}@1434417560938 => 4748
http_request_total{status="200", method="POST"}@1434417561287 => 4785
```
在 time-series 中的每一个点，我们称为一个样本（sample）。样本由下面三个部分组成。
- 指标 (metric)：metric name 和描述当前样本特征的 labelsets。
- 时间戳 (timestamp)：一个精确到毫秒的时间戳。
- 样本值 (value)： 一个 folat64 的浮点型数据，表示当前样本的值。


#### 统一日志管理框架：EFK
我们通过监控告警服务感知到程序异常，这时候需要开发者或者运维人员介入排障。排障最有效的手段，是查看日志。所以，对于一个应用来说，一个优秀的日志系统也是必不可少的功能。

在一个大型的分布式系统中，有很多组件，这些组件分别部署在不同的服务器上。如果系统出故障，需要查看日志排障。这时候，你可能需要登陆不同的服务器，查看不同组件的日志，这个过程是非常繁琐、低效的，也会导致排障时间变长。故障时间越久，意味着给客户带来的损失越大。

所以，在一个大型系统中，传统的日志查看手段已经满足不了我们的需求了。这时候，我们需要有一个针对分布式系统的日志解决方案。当前，业界有不少成熟的分布式日志解决方案，其中使用最多的是 EFK 日志解决方案。甚至可以说，EFK 已经成为分布式日志解决方案的事实标准。


EFK 中包含三个开源的软件，分别是 Elasticsearch、FlieBeat、Kibana。下面，我来介绍下这三个开源软件：
- Elasticsearch：简称 ES，是一个实时的、分布式的搜索引擎，通常用来索引和搜索大规模的日志数据，并支持全文、结构化的搜索。
- FlieBeat：轻量的数据采集组件，以 agent 的方式运行在需要采集日志的服务器上。FlieBeat 采集指定的文件，并上报给 ES。如果采集日志量大，也可以上报给 Kafka，再由其他组件消费 Kafka 中的日志并转储到 ES 中。
- Kibana：用于展示 ES 中存储的日志数据，支持通过图表进行高级数据分析及展示。

EFK 的架构图如下：

![img](https://static001.geekbang.org/resource/image/64/10/64c523c18ee7d86382db3aea06bf8b10.jpg?wh=2248x669)

通过 Filebeat 采集所在服务器上各服务组件的日志，并上传到 Kafka 中。Logstash 消费 Kafka 中的日志，过滤后上报给 Elasticsearch 进行存储。最后，通过 Kibana 可视化平台来检索这些日志。Kibana 是通过调用 Elasticsearch 提供的 API 接口，来检索日志数据的。

当 Filebeat 的日志生产速度和 Logstash 的日志消费速度不匹配时，中间的 Kafka 服务，会起到削峰填谷的作用。

#### 调用链跟踪组件：Jaeger
在云原生架构中，应用普遍采用微服务。一个应用包含多个微服务，微服务之间会相互调用，这会给排障带来很大的挑战。比如，当我们通过前端访问应用报错时，我们根本不知道具体哪个服务、哪个步骤出问题了。所以这时候，应用就需要有分布式链路追踪能力。目前，业界也有多种分布式链路追踪系统，但用得最多的是Jaeger。


Jaeger 是 Uber 推出的一款开源分布式追踪系统，兼容 OpenTracing API。这里我们先来介绍两个概念：
- OpenTracing：它是一套开源的调用链追踪标准，通过提供厂商无关、平台无关的 API，来支持开发人员方便地添加 / 更换追踪系统的实现。
- 分布式追踪系统：用于记录请求范围内的信息，是我们排查系统问题和系统性能的利器。分布式追踪系统种类繁多，但核心步骤都有三个，分别是代码埋点、数据存储和查询展示。

Jaeger 架构图如下：

![img](https://static001.geekbang.org/resource/image/09/01/09dc7ae3eb2a32381b3940e8f8743901.png?wh=2239x1202)


Jaeger 中有 7 个关键组件，下面我来具体介绍下。
- instrument：将应用程序与 jaeger-client 装载起来，从而使应用程序可以上报调用链数据到 Jaeger。
- jaeger-client：Jaeger 的客户端 SDK，负责收集并发送应用程序的调用链数据到 jaeger-agent。
- jaeger-agent：接收并汇聚 Span 数据，并将这些数据上报给 jaeger-collector。
- jaeger-collector：从 jaeger-agent 收集 traces 信息，并通过处理管道处理这些信息，最后写入后端存储。jaeger-collector 是无状态的组件，可以根据需要水平扩缩容。
- Data Store：Jaeger 的后端存储组件。目前，支持 cassandra、elasticsearch。
- jaeger-ui：jaeger 的前端界面，用于展示调用链等信息。
- jaeger-query：用于从存储中检索 trace，并提供给 jaeger-ui。

下面，我通过一个 Jaeger 官方提供的All in One 教程来让你更好地理解 Jaeger。具体可以分成两个操作步骤。

第一步，使用jaeger-all-in-one安装 Jaeger 服务：

```
$ wget https://github.com/jaegertracing/jaeger/releases/download/v1.25.0/jaeger-1.25.0-linux-amd64.tar.gz
$ tar -xvzf jaeger-1.25.0-linux-amd64.tar.gz
$ mv jaeger-1.25.0-linux-amd64/* $HOME/bin
$ jaeger-all-in-one --collector.zipkin.host-port=:9411
```
第二步，启动一个HotROD示例应用，产生调用链：

```
$ example-hotrod all # 第 1) 我们已经安装了 example-hotrod 命令
```
访问http://$IP:16686/search可以查找调用链（IP 是 Jaeger 部署的服务器 IP 地址），如下图所示：

![img](https://static001.geekbang.org/resource/image/68/17/682b4c1ca9c9fd180f913aa12deb7817.jpg?wh=2249x1011)

查询到调用链列表后，可以点击任意一个调用链，查看其详细的调用过程，如下图所示：

![img](https://static001.geekbang.org/resource/image/b5/ff/b5afaefacfa0f87ecfb13774532ef8ff.jpg?wh=2249x1274)

具体如何使用 Jaeger 来记录调用链，你可以参考[Jaeger](https://github.com/jaegertracing/jaeger/tree/main/examples/hotrod) 官方给出的hotrod示例。


### 总结
最后，我们通过下面这张图，来对整个云技术的演进之路做个整体性的回顾：

通过这张图你可以看到，每种技术并不是孤立存在的，而是相互促进的。在物理机阶段，我们用的是瀑布开发模式和单体架构；在虚拟机阶段，用得比较多的是敏捷开发模式和 SOA 架构；在容器这个阶段，则使用 CI/CD 的开发模式和微服务架构。

在 Serverless 阶段，软件架构仍然采用微服务，不过在一些触发器场景，也可能会编写一些 FaaS 架构的函数，部署在类似腾讯云云函数这样的 FaaS 平台上；底层系统资源主要使用 Serverless 容器，并配合 Kubernetes 资源编排技术。在一些触发器场景中，也可能会使用云函数。应用程序中的第三方服务（BaaS），也都是越来越 Serverless 化的服务。应用生命周期管理技术也会演进为 CI/CD/CO 这种模式，其中 CI/CD 更加智能化，自动化程度更高。

这张图里，阴影部分是我们当前所处的阶段：容器技术得到了大规模普及，业界也在积极探索 Serverless 技术，并取得了卓有成效的结果。


## 45｜基于Kubernetes的云原生架构设计

前面两讲，我们一起看了云技术的演进之路。软件架构已经进入了云原生时代，云原生架构是当下最流行的软件部署架构。那么这一讲，我就和你聊聊什么是云原生，以及如何设计一种基于 Kubernetes 的云原生部署架构。

### 云原生简介

云原生包含的概念很多，对于一个应用开发者来说，主要关注点是如何开发应用，以及如何部署应用。所以，这里我在介绍云原生架构的时候，会主要介绍应用层的云原生架构设计和系统资源层的云原生架构设计。

在设计云原生架构时，应用生命周期管理层的云原生技术，我们主要侧重在使用层面，所以这里我就不详细介绍应用生命周期管理层的云原生架构了。后面的云原生架构鸟瞰图中会提到它，你可以看看。另外，在介绍云原生时，也总是绕不开云原生计算基金会。接下来，我们就先来简单了解下 CNCF 基金会。

### CNCF（云原生计算基金会）简介
CNCF（Cloud Native Computing Foundation，云原生计算基金会），2015 年由谷歌牵头成立，目前已有一百多个企业与机构作为成员，包括亚马逊、微软、思科、红帽等巨头。CNCF 致力于培育和维护一个厂商中立的开源社区生态，用以推广云原生技术。

CNCF 目前托管了非常多的开源项目，其中有很多我们耳熟能详的项目，例如 Kubernetes、Prometheus、Envoy、Istio、etcd 等。更多的项目，你可以参考 CNCF 公布的Cloud Native Landscape，它给出了云原生生态的参考体系，如下图所示：

![img](https://static001.geekbang.org/resource/image/5e/32/5ef7aa9e514ac27b6474165c745dfe32.jpg?wh=2248x1282)


### 什么是云原生？
CNCF 官方在 2018 年发布了云原生 v1.0，并给出了定义：

“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。”

简单点说，云原生（Cloud Native）是一种构建和运行应用程序的方法，是一套技术体系和方法论。云原生中包含了 3 个概念，分别是技术体系、方法论和云原生应用。整个云原生技术栈是围绕着 Kubernetes 来构建的，具体包括了以下核心技术栈：

![img](https://static001.geekbang.org/resource/image/8f/66/8fc9dc16d99e7f2949813fe109986266.jpg?wh=2248x911)

这里来介绍下这些核心技术栈的基本内容。
- 容器：Kubernetes 的底层计算引擎，提供容器化的计算资源。
- 微服务：一种软件架构思想，用来构建云原生应用。
- 服务网格：建立在 Kubernetes 之上，作为服务间通信的底座，提供强大的服务治理功能。
- 声明式 API ：一种新的软件开发模式，通过描述期望的应用状态，来使系统更加健壮。
- 不可变基础设施：一种新的软件部署模式，应用实例一旦被创建，便只能重建不能更新，是现代运维的基础。

在 43 讲 和 44 讲 中，我介绍了容器、服务网格和微服务，这里再补充介绍下不可变基础设施和声明式 API。

不可变基础设施（Immutable Infrastructure）的构想，是由 Chad Fowler 于 2013 年提出的。具体来说就是：一个应用程序的实例，一旦被创建，就会进入只读的状态，后面如果想变更这个应用程序的实例，只能重新创建一个新的实例。通过这种模式，可以确保应用程序实例的一致性，这使得落地 DevOps 更加容易，并可以有效减少运维人员管理配置的负担。

声明式 API 是指我们通过工具描述期望的应用状态，并由工具保障应用一直处在我们期望的状态。

Kubernetes 的 API 设计，就是一种典型的声明式 API。例如，我们在创建 Deployment 时，在 Kubernetes YAML 文件中声明应用的副本数为2，即设置replicas: 2，Deployment Controller 就会确保应用的副本数一直为2。也就是说，如果当前副本数大于2，Deployment Controller 会删除多余的副本；如果当前副本数小于2，会创建新的副本。

声明式设计是一种设计理念，同时也是一种工作模式，它使得你的系统更加健壮。分布式系统环境可能会出现各种不确定的故障，面对这些组件故障，如果使用声明式 API ，你只需要查看对应组件的 API 服务器状态，再确定需要执行的操作即可。


### 什么是云原生应用？
上面，我介绍了什么是云原生，接下来再介绍下什么是云原生应用。

整体来看，云原生应用是指生而为云的应用，应用程序从设计之初就考虑到了云的环境，可以在云上以最佳姿势运行，充分利用和发挥云平台提供的各种能力。具体来看，云原生应用具有以下三大特点：
- 从应用生命周期管理维度来看，使用 DevOps 和 CI/CD 的方式，进行开发和交付。
- 从应用维度来看，以微服务原则进行划分设计。
- 从系统资源维度来看，采用 Docker + Kubernetes 的方式来部署。

看完上面的介绍，你应该已经对云原生和云原生应用有了一定的理解，接下来我就介绍一种云原生架构实现。因为云原生内容很多，所以这里的介绍只是起到抛砖引玉的作用，让你对云原生架构有初步的理解。至于在具体业务中如何设计云原生架构，你还需要根据业务、团队和技术栈等因素综合考虑。

### 云原生架构包含很多内容，如何学习？
云原生架构中包含了很多概念、技术，那么我们到底如何学习呢？在前面的两讲中，我分别从系统资源层、应用层、应用生命周期管理层介绍了云技术。这 3 个层次基本上构成了整个云计算的技术栈。

今天，我仍然会从这三个层次入手，来对整个云原生架构设计进行相对完整的介绍。每个层次涉及到的技术很多，这一讲我只介绍每一层的核心技术，通过这些核心技术来看每一层的构建方法。

另外，因为应用生命周期管理层涉及到的技术栈非常多，所以今天不会详细讲解每种生命周期管理技术的实现原理，但会介绍它们提供的能力。

除了功能层面的架构设计之外，我们还要考虑部署层面的架构设计。对于云原生架构的部署，通常我们需要关注以下两点：
- 容灾能力：容灾能力是指应用程序遇到故障时的恢复能力。在互联网时代，对应用的容灾能力有比较高的要求。理想情况是系统在出现故障时，能够无缝切换到另外一个可用的实例上，继续提供服务，并做到用户无感知。但在实际开发中，无缝切换在技术上比较难以实现，所以也可以退而求其次，允许系统在一定时间内不可用。通常这个时间需要控制在秒级，例如 5s。容灾能力可以通过负载均衡、健康检查来实现。
- 扩缩容能力：扩缩容能力指的是系统能够根据需要扩缩容，可以手动扩缩容，也可以自动扩缩容。互联网时代对扩缩容能力的要求也比较高，需要实现自动扩缩容。我们可以基于一些自定义指标，例如 CPU 使用率、内存使用率等来自动扩缩容。扩容也意味着能够承载更多的请求，提高系统的吞吐量；缩容，意味着能够节省成本。扩缩容能力的实现，需要借助于负载均衡和监控告警能力。

容灾能力和扩缩容能力都属于高可用能力。也就是说，在部署层面，需要我们的架构具备高可用能力。

接下来，我就重点介绍下系统资源层和应用层的云原生架构设计，并简单介绍下应用生命周期管理层的核心功能构建。在介绍完架构设计之后，我还会介绍下这些层面的高可用架构设计。


### 系统资源层的云原生架构设计
先来看系统资源层面的云原生架构设计。对于一个系统来说，系统资源的架构是需要优先考虑的。在云原生架构中，当前的业界标准是通过 Docker 提供系统资源（例如 CPU、内存等），通过 Kubernetes 来编排 Docker 容器。Docker 和 Kubernetes 的架构，我在43 讲中介绍过，这里我主要介绍下系统资源层面的高可用架构设计。

基于 Docker+Kubernetes 的方案，高可用架构是通过 Kubernetes 高可用架构来实现的。要实现整个 Kubernetes 集群的高可用，我们需要分别实现以下两类高可用：
- Kubernetes 集群的高可用。
- Kubernetes 集群中所部署应用的高可用。

我们来分别看下这两个高可用方案。

#### Kubernetes 集群高可用方案设计
通过43 讲的学习，我们知道 Kubernetes 由 kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager、etcd、kubelet、kube-proxy、container runtime 8 大核心组件组成。

其中，kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager、etcd 通常部署在 master 节点，kubelet、kube-proxy、container runtime 部署在 Node 节点上。实现 Kubernetes 集群的高可用，需要分别实现这 8 大核心组件的高可用。

Kubernetes 集群的高可用架构图如下：

![img](https://static001.geekbang.org/resource/image/76/3f/7667b9f5a88e61487fce2374400d823f.jpg?wh=2248x1466)

上面图片展示的方案中，所有管理节点都部署了 kube-apiserver、kube-controller-manager、kube-scheduler、etcd 等组件。kube-apiserver 均与本地的 etcd 进行通信，etcd 在三个节点间同步数据；而 kube-controller-manager、kube-scheduler 和 cloud-controller-manager，也只与本地的 kube-apiserver 进行通信，或者通过负载均衡访问。

一个 Kubernetes 集群中有多个 Node 节点，当一个 Node 节点故障时，Kubernetes 的调度组件 kube-controller-manager 会将 Pod 调度到其他节点上，并将故障节点的 Pod 在其他可用节点上重建。也就是说，只要集群中有两个以上的节点，当其中一个 Node 故障时，整个集群仍然能够正常提供服务。换句话说，集群的 kubelet、kube-proxy、container runtime 组件可以是单点的，不用实现这些组件的高可用。

接下来，我们来看下 Master 节点各组件是如何实现高可用的。**先来说下 kube-apiserver 组件的高可用方案设计**。因为 kube-apiserver 是一个无状态的服务，所以可以通过部署多个 kube-apiserver 实例，其上挂载负载均衡的方式来实现。其他所有需要访问 kube-apiserver 的组件，都通过负载均衡来访问，以此实现 kube-apiserver 的高可用。

kube-controller-manager、cloud-controller-manager 和 kube-scheduler 因为是有状态的服务，所以它们的高可用能力不能通过负载均衡来实现。kube-controller-manager/kube-scheduler/cloud-controller-manager 通过–leader-elect=true 参数开启分布式锁机制，来进行 leader election。

你可以创建多个 kube-controller-manager/kube-scheduler/cloud-controller-manager 实例，同一时刻只有一个实例能够获取到锁，成为 leader，提供服务。如果当前 leader 故障，其他实例感知到 leader 故障之后会自动抢锁，成为 leader 继续提供服务。通过这种方式，我们实现了 kube-controller-manager/kube-scheduler/cloud-controller-manager 组件的高可用。

当 kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager 故障时，我们期望这些组件能够自动恢复，这时候可以将这些组件以 Static Pod 的方式进行部署，这样当 Pod 故障时，上述实例就能够自动被拉起。


etcd 的高可用方案有下面这 3 种思路：
- 使用独立的 etcd 集群，独立的 etcd 集群自带高可用能力。
- 在每个 Master 节点上，使用 Static Pod 来部署 etcd，多个节点上的 etcd 实例数据相互同步。每个 kube-apiserver 只与本 Master 节点的 etcd 通信。
- 使用 CoreOS 提出的 self-hosted 方案，将 etcd 集群部署在 kubernetes 集群中，通过 kubernetes 集群自身的容灾能力来实现 etcd 的高可用。

这三种思路，需要你根据实际需要进行选择，在实际生产环境中，第二种思路用得最多。到这里，我们就实现了整个 Kubernetes 集群的高可用。接下来，我们来看下 Kubernetes 集群中，应用的高可用是如何实现的。


#### Kubernetes 应用的高可用
Kubernetes 自带了应用高可用能力。在 Kubernetes 中，应用以 Pod 的形式运行。你可以通过 Deployment/StatefulSet 来创建应用，并在 Deployment/StatefulSet 中指定多副本和 Pod 的健康检查方式。当 Pod 健康检查失败时，Deployment/StatefulSet 的控制器（ReplicaSet）会自动销毁故障 Pod，并创建一个新的 Pod，替换故障的 Pod。

你可能会问：当 Pod 故障时，怎么才能避免请求被调度到已故障的 Pod 上，造成请求失败？这里我也详细介绍下。

在 Kubernetes 中，我们可以通过 Kubernetes Service 或者负载均衡来访问这些 Pod。当通过负载均衡来访问 Pod 时，负载均衡后端的 RS（Real Server）实例其实就是 Pod。我们创建了多个 Pod，负载均衡可以自动根据 Pod 的健康状况来进行负载。


接下来，我们主要看下这个问题：**当通过 Kubernetes Service 访问 Pod 时，如何实现高可用？**

高可用原理如下图所示：

![img](https://static001.geekbang.org/resource/image/65/cd/65dab9a3f07d5afed29aa616db14bdcd.jpg?wh=2248x1266)


在 Kubernetes 中，我们可以给每个 Pod 打上标签（Label），标签是一个 key-value 对，例如label: app=Nginx。当我们访问 Service 时，Service 会根据它配置的 Label Selector，匹配具有相同 Label 的 Pod，并将这些 Pod 的 endpoint 地址作为其后端 RS。

举个例子，你可以看看上面的图片：Service 的 Label Selector 是 Labelsapp=Nginx，这样就会选择我们创建的具有label: app=Nginx的 3 个 Pod 实例。这时候，Service 会根据其负载均衡策略，选取一个 Pod 将请求流量转发过去。当其中一个 Pod 故障时，Kubernetes 会自动将故障 Pod 的 endpoint 从 Service 后端对应的 RS 列表中剔除。

由 Deployment 创建的 ReplicaSet，这时候也会发现有一个 Pod 故障，健康的 Pod 实例数变为2，这时候跟其期望的值3不匹配，就会自动创建一个新的健康 Pod，替换掉故障的 Pod。因为新 Pod 满足 Service 的 Label Selector，所以新 Pod 的 endpoint 会被 Kubernetes 自动添加到 Service 对应的 endpoint 列表中。

通过上面这些操作，Service 后端的 RS 中，故障的 Pod IP 被新的、健康的 Pod IP 所替换，通过 Service 访问的后端 Pod 就都是健康的。这样，就通过 Service 实现了应用的高可用。

从上面的原理分析中，我们也可以发现，Service 本质上是一个负载均衡器。

Kubernetes 还提供了滚动更新（RollingUpdate）机制，来确保在发布时服务正常可用。这个机制的大致原理是：在更新时，先创建一个 Pod，再销毁一个 Pod，依次循环，直到所有的 Pod 都更新完成。在更新时，我们还可以控制每次更新的 Pod 数，以及最小可用的 Pod 数。

接下来，我们再来看下应用层的云原生架构设计和高可用设计。

### 应用层的云原生架构设计
在云原生架构中，我们采用微服务架构来构建应用。所以，这里我主要围绕着微服务架构的构建方式来介绍。先和你谈谈我对微服务的理解。

从本质上来说，微服务是一个轻量级的 Web 服务，只不过在微服务场景下，我们通常考虑的不是单个微服务，而是更多地考虑由多个微服务组成的应用。也就是说，一个应用由多个微服务组成，多个微服务就带来了一些单个 Web 服务不会面临的问题，例如部署复杂、排障困难、服务依赖复杂、通信链路长，等等。在微服务场景下，除了编写单个微服务（轻量级的 Web 服务）之外，我们更多是要专注于解决应用微服务化所带来的挑战。所以，在我看来，微服务架构设计包括两个重要内容：


单个微服务的构建方式；解决应用微服务化带来的挑战。


#### 微服务实现
我们可以通过两种方式来构建微服务：
- 采用 Gin、Echo 等轻量级 Web 框架。
- 采用微服务框架，例如 go-chassis、go-micro、go-kit等。

如果要解决应用微服务化带来的挑战，我们需要采用多种技术和手段，每种技术和手段会解决一个或一部分挑战。

综上，在我看来，微服务本质上是一个轻量级的 Web 服务，但又包含一系列的技术和手段，用来解决应用微服务化带来的挑战。微服务的技术栈如下图所示：

![img](https://static001.geekbang.org/resource/image/7a/65/7a860825662bb93f93c51c00efbdeb65.jpg?wh=2248x1158)


不同的技术栈可以由不同的方式来实现，并解决不同的问题：
- 监控告警、日志、CI/CD、分布式调度，可以由 Kubernetes 平台提供的能力来实现。
- 服务网关、权限验证、负载均衡、限流 / 熔断 / 降级，可以由网关来实现，例如 Tyk 网关。
- 进程间通信、REST/RPC 序列化，可以借助 Web 框架来实现，例如 Gin、Go Chassis、gRPC、Sprint Cloud。
- 分布式追踪可以由 Jaeger 来实现。
- 统一配置管理可以由 Apollo 配置中心来实现。
- 消息队列可以由 NSQ、Kafka、RabbitMQ 来实现。

上面的服务注册 / 服务发现，有 3 种实现方式：
- 通过 Kubernetes Service 来进行服务注册 / 服务发现，Kubernetes 自带服务注册 / 服务发现功能。使用此方式，我们不需要额外的开发。
- 通过服务中心来实现服务注册 / 服务发现功能。采用这种方式，需要我们开发并部署服务中心，服务中心通常可以使用 etcd/consul/mgmet 来实现，使用 etcd 的较多。
- 通过网关，来进行服务注册 / 服务发现。这种情况下，可以将服务信息直接上报给网关服务，也可以将服务信息上报到一个服务中心，例如 etcd 中，再由网关从服务中心中获取。

这里要注意，原生的 Kubernetes 集群是不支持监控告警、日志、CI/CD 等功能的。我们在使用 Kubernetes 集群时，通常会使用一个基于 Kubernetes 开发而来的 Kubernetes 平台，例如腾讯云容器服务 TKE。

在 Kubernetes 平台中，通常会基于一些优秀的开源项目，进行二次开发，来实现平台的监控告警、日志、CI/CD 等功能。

- 监控告警：基于 Prometheus 来实现。
- 日志：基于 EFK 日志解决方案来实现。
- CI/CD：可以自己研发，也可以基于优秀的开源项目来实现，例如 drone。

#### 微服务架构设计
上面我介绍了如何实现微服务，这里我再来具体讲讲，上面提到的各个组件 / 功能是如何有机组合在一起，共同构建一个微服务应用的。下面是微服务的架构图：

![img](https://static001.geekbang.org/resource/image/02/yy/020fa7eccc352d03b78b57a1dbfc75yy.jpg?wh=2248x2168)

在上图中，我们将微服务应用层部署在 Kubernetes 集群中，在 Kubernetes 集群之上，可以构建微服务需要的其他功能，例如监控告警、CI/CD、日志、调用链等。这些功能共同完成应用的生命周期管理。

我们在微服务的最上面挂载负载均衡。客户端，例如移动端应用、Web 应用、API 调用等，都通过负载均衡来访问微服务。

微服务在启动时会将自己的 endpoint 信息（通常是ip:port格式）上报到服务中心。微服务也会定时上报自己的心跳到服务中心。在服务中心中，我们可以监控微服务的状态，剔除不健康的微服务，获取微服务之间的访问数据，等等。如果要通过网关调用微服务，或者需要使用网关做负载均衡，那我们还需要网关从服务中心中获取微服务的 endpoint 信息。


#### 微服务高可用架构设计
我们再来看下如何设计微服务应用的高可用能力。

我们可以把所有微服务组件以 Deployment/StatefulSet 的形式部署在 Kubernetes 集群中，副本数至少设置为两个，更新方式为滚动更新，设置服务的监控检查，并通过 Kubernetes Service 或者负载均衡的方式访问服务。这样，我们就可以不用做任何改造，直接使用 Kubernetes 自有的容灾能力，实现微服务架构的高可用。

### 云原生架构鸟瞰图
上面，我介绍了系统资源层和应用层的云原生架构设计，但还不能构成整个云原生架构设计。这里，我通过一张云原生架构鸟瞰图，来整体介绍下云原生架构的设计方案。

![img](https://static001.geekbang.org/resource/image/05/b5/05c7cb8fd6c524242229ab9ea6c9b1b5.jpg?wh=2248x1470)

上图的云原生架构分为 4 层，除了前面提到的系统资源层、应用层、应用生命周期管理层之外，又加了统一接入层。接下来，我来介绍下这些层在云原生架构中的作用。

在最下面的系统资源层，我们除了提供传统的计算资源（物理机、虚拟机）之外，还可以提供容器化的计算资源和高可用的存储服务。其中，容器化的计算资源是基于传统的物理机 / 虚拟机来构建的。

在云原生架构中，我们更应该使用容器化的计算资源，通过 Docker 容器技术来隔离并对外提供计算资源，通过 Kubernetes 来编排容器。Docker + Kubernetes 的组合使用，可以构建出一个非常优秀的系统资源层。这个系统资源层，自带了资源管理、容器调度、自动伸缩、网络通信、服务发现、健康检查等企业应用需要的核心能力。

在云原生时代，这些系统资源除了具有容器化、轻量化的特点之外，还越来越倾向于朝着 Serverless 化的方向去构建：系统资源免申请、免运维，按需计费，具备极致的弹性伸缩能力，并能够缩容到 0。Serverless 化的系统资源，可以使开发者只聚焦在应用层的应用功能开发上，而不用再把时间浪费在系统层的运维工作上。

在系统资源层之上，就可以构建我们的应用层了。云原生架构中，应用的构建方式，基本上都是采用的微服务架构。开发一个微服务应用，我们可以使用微服务框架，也可以不使用。二者的区别是，微服务框架替我们完成了服务治理相关功能，让我们不需要再开发这些功能。

在我看来，这一点有利有弊。好处当然是节省了开发工作量。至于坏处，主要有两方面：一方面，在实现方式和实现思路上，微服务框架所集成的服务治理功能并不一定是最适合我们的方案。另一方面，使用微服务框架还意味着我们的应用会跟微服务框架耦合，不能自由选择服务治理技术和方式。所以，在实际开发中，你应该根据需要，自行选择微服务的构建方式。

一般来说，一个微服务框架中，至少集成了这些服务治理功能：配置中心、调用链追踪、日志系统、监控、服务注册 / 服务发现。

再往上，我们就实现了统一接入层。统一接入层中包含了负载均衡和网关两个组件，其中负载均衡作为服务的唯一入口，供 API、Web 浏览器、手机终端等客户端访问。通过负载均衡，可以使我们的应用在故障时，能够自动切换实例，在负载过高时能够水平扩容。负载均衡下面还对接了网关，网关提供了一些通用能力，例如安全策略、路由策略、流量策略、统计分析、API 管理等能力。

最后，我们还可以构建一系列的应用生命周期管理技术，例如服务编排、配置管理、日志、存储、审计、监控告警、消息队列、分布式链路追踪。这些技术中，一些可以基于 Kubernetes，集成在我们的 Kubernetes 平台中，另一些则可以单独构建，供所有产品接入。

### 公有云版云原生架构
上面我们提到，云原生架构涉及到很多的技术栈。如果公司有能力，可以选择自己开发；如果觉得人力不够、成本太高，也可以使用公有云厂商已经开发好的云原生基础设施。使用云厂商的云原生基础设施，好处很明显：这些基础设施专业、稳定、免开发、免运维。

为了补全云原生架构设计版图，这里我也介绍一个公用云版的云原生架构设计。那么，公有云厂商会提供哪些云原生基础设施呢？这里我介绍下腾讯云提供的云原生解决方案。解决方案全景如下图所示：

![img](https://static001.geekbang.org/resource/image/44/20/4473c11e51fa0976d91202fc7c836020.jpg?wh=2249x1068)

可以看到，**腾讯云提供了全栈的云原生能力**。腾讯云基于底层的云原生能力，提供了一系列的云原生解决方案。这些解决方案，是已经设计好的云原生架构构建方案，可以帮助企业快速落地云原生架构，例如混合云解决方案、AI 解决方案、IoT 解决方案等。


那么，腾讯云底层提供了哪些云原生能力呢？我们一起来看下。在应用层，通过 TSF 微服务平台，我们可以实现微服务的构建，以及微服务的服务治理能力。另外，还提供了更多的应用构建架构，例如：

- Serverless Framework，可以构建 Serverless 应用。
- CloudBase，云原生一体化应用开发平台，可以快速构建小程序、Web、移动应用。
- …

在系统资源层，腾讯云提供了多种计算资源提供形态。例如：通过 TKE，可以创建原生的 Kubernetes 集群；通过 EKS，可以创建 Serverless 化的 Kubernetes 集群；通过TKE-Edge，可以创建能够纳管边缘节点的 Kubernetes 集群。此外，还提供了开源容器服务平台TKEStack，TKEStack 是一个非常优秀的容器云平台，在代码质量、稳定性、平台功能等方面，都在开源的容器云平台中处于龙头地位，也欢迎你 Star。

在应用生命周期管理这一层，提供了云原生的 etcd、Prometheus 服务。此外，还提供了 CLS 日志系统，供你保存并查询应用日志；提供了云监控，供你监控自己的应用程序；提供了容器镜像服务（TCR），用来保存 Docker 镜像；提供了 CODING DevOps 平台，用来支持应用的 CI/CD；提供了调用链跟踪服务（TDW），用来展示微服务的调用链。

在统一接入层，腾讯云提供了功能强大的 API 网关。此外，还提供了多种 Serverless 化的中间件服务，例如消息队列 TDMQ、云原生数据库 TDSQL 等。所有这些云原生基础设施，都有共同的特点，就是免部署、免运维。换句话说，在腾讯云，你可以只专注于使用编程语言编写你的业务逻辑，其他的一切都交给腾讯云来搞定。


### 总结
云原生架构设计，包含了系统资源层、应用层、统一接入层和应用生命周期管理层 4 层。

在系统资源层，可以采用 Docker + Kubernetes 的方式来提供计算资源。我们所有的应用和应用生命周期管理相关的服务，都可以部署在 Kubernetes 集群中，利用 Kubernetes 集群的能力实现服务发现 / 服务注册、弹性伸缩、资源调度等核心能力。

在应用层，可以采用微服务架构，来构建我们的应用。具体构建时，我们可以根据需要，采用类似 Gin 这种轻量级的 Web 框架来构建应用，然后再实现旁路的服务治理功能；也可以采用集成了很多服务治理功能的微服务框架，例如 go-chassis、go-micro 等。

因为我们采用了微服务架构，为了能够将微服务的一些功能，例如：认证授权、限流等功能最大化的复用，我们又提供了统一接入层。可以通过 API 网关、负载均衡、服务网格等技术来构建统一接入层。

在应用生命周期管理这一层，我们可以实现一些云原生的管理平台，例如 DevOps、监控告警、日志、配置中心等，并使我们的应用以云原生化的方式接入这些平台，使用这些平台提供的能力。

最后，我还介绍了腾讯云的云原生基础设施。通过腾讯云提供的云原生能力，你可以专注于使用编程语言编写你的业务逻辑，其他的各种云原生能力，都可以交给云厂商来帮你实现。

## 46 | 如何制作Docker镜像？
要落地云原生架构，其中的一个核心点是通过容器来部署我们的应用。如果要使用容器来部署应用，那么制作应用的 Docker 镜像就是我们绕不开的关键一步。今天，我就来详细介绍下如何制作 Docker 镜像。

在这一讲中，我会先讲解下 Docker 镜像的构建原理和方式，然后介绍 Dockerfile 的指令，以及如何编写 Dockerfile 文件。最后，介绍下编写 Dockerfile 文件时要遵循的一些最佳实践。

### Docker 镜像的构建原理和方式
首先，我们来看下 Docker 镜像构建的原理和方式。我们可以用多种方式来构建一个 Docker 镜像，最常用的有两种：
- 通过docker commit命令，基于一个已存在的容器构建出镜像。
- 编写 Dockerfile 文件，并使用docker build命令来构建镜像。


上面这两种方法中，镜像构建的底层原理是相同的，**都是通过下面 3 个步骤来构建镜像：**
- 基于原镜像，启动一个 Docker 容器。
- 在容器中进行一些操作，例如执行命令、安装文件等。由这些操作产生的文件变更都会被记录在容器的存储层中。
- 将容器存储层的变更 commit 到新的镜像层中，并添加到原镜像上。

下面，我们来具体讲解这两种构建 Docker 镜像的方式。

#### 通过docker commit命令构建镜像
我们可以通过docker commit来构建一个镜像，命令的格式为docker commit [选项] [<仓库名>[:<标签>]]。

下图中，我们通过 4 个步骤构建了 Docker 镜像ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test：

![img](https://static001.geekbang.org/resource/image/23/11/23619b513ff043792c7374acf7781d11.png?wh=1920x344)


具体步骤如下：
- 执行docker ps获取需要构建镜像的容器 ID 48d1dbb89a7f。
- 执行docker pause 48d1dbb89a7f暂停48d1dbb89a7f容器的运行。
- 执行docker commit 48d1dbb89a7f ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test，基于容器 ID 48d1dbb89a7f构建 Docker 镜像。
- 执行docker images ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test，查看镜像是否成功构建。

这种镜像构建方式通常用在下面两个场景中：
- 构建临时的测试镜像；
- 容器被入侵后，使用docker commit，基于被入侵的容器构建镜像，从而保留现场，方便以后追溯。


除了这两种场景，我不建议你使用docker commit来构建生产现网环境的镜像。我这么说的主要原因有两个：
- 使用docker commit构建的镜像包含了编译构建、安装软件，以及程序运行产生的大量无用文件，这会导致镜像体积很大，非常臃肿。
- 使用docker commit构建的镜像会丢失掉所有对该镜像的操作历史，无法还原镜像的构建过程，不利于镜像的维护。

下面，我们再来看看如何使用Dockerfile来构建镜像。

#### 通过Dockerfile来构建镜像
在实际开发中，使用Dockerfile来构建是最常用，也最标准的镜像构建方法。Dockerfile是 Docker 用来构建镜像的文本文件，里面包含了一系列用来构建镜像的指令。

docker build命令会读取Dockerfile的内容，并将Dockerfile的内容发送给 Docker 引擎，最终 Docker 引擎会解析Dockerfile中的每一条指令，构建出需要的镜像。

docker build的命令格式为docker build [OPTIONS] PATH | URL | -。PATH、URL、-指出了构建镜像的上下文（context），context 中包含了构建镜像需要的Dockerfile文件和其他文件。默认情况下，Docker 构建引擎会查找 context 中名为Dockerfile的文件，但你可以通过-f, --file选项，手动指定Dockerfile文件。例如：


```
 $ docker build -f Dockerfile -t ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test .
```
使用 Dockerfile 构建镜像，本质上也是通过镜像创建容器，并在容器中执行相应的指令，然后停止容器，提交存储层的文件变更。和用docker commit构建镜像的方式相比，它有**三个好处：**

- Dockerfile 包含了镜像制作的完整操作流程，其他开发者可以通过 Dockerfile 了解并复现制作过程。
- **Dockerfile 中的每一条指令都会创建新的镜像层，这些镜像可以被 Docker Daemnon 缓存。再次制作镜像时，Docker 会尽量复用缓存的镜像层（using cache），而不是重新逐层构建，这样可以节省时间和磁盘空间。**
- Dockerfile 的操作流程可以通过docker image history [镜像名称]查询，方便开发者查看变更记录。

这里，我们通过一个示例，来详细介绍下通过Dockerfile构建镜像的流程。

首先，我们需要编写一个Dockerfile文件。下面是 iam-apiserver 的Dockerfile文件内容：

```
dockerfile
FROM centos:centos8
LABEL maintainer="<colin404@foxmail.com>"

RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
RUN echo "Asia/Shanghai" > /etc/timezone

WORKDIR /opt/iam
COPY iam-apiserver /opt/iam/bin/

ENTRYPOINT ["/opt/iam/bin/iam-apiserver"]
```
这里选择centos:centos8作为基础镜像，是因为centos:centos8镜像中包含了基本的排障工具，例如vi、cat、curl、mkdir、cp等工具。

接着，执行docker build命令来构建镜像：

```
$ docker build -f Dockerfile -t ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test .
```
执行docker build后的构建流程为：

第一步，docker build会将 context 中的文件打包传给 Docker daemon。如果 context 中有.dockerignore文件，则会从上传列表中删除满足.dockerignore规则的文件。这里有个例外，如果.dockerignore文件中有.dockerignore或者Dockerfile，docker build命令在排除文件时会忽略掉这两个文件。如果指定了镜像的 tag，还会对 repository 和 tag 进行验证。

第二步，docker build命令向 Docker server 发送 HTTP 请求，请求 Docker server 构建镜像，请求中包含了需要的 context 信息。

第三步，Docker server 接收到构建请求之后，会执行以下流程来构建镜像：
1. 创建一个临时目录，并将 context 中的文件解压到该目录下。
2. 读取并解析 Dockerfile，遍历其中的指令，根据命令类型分发到不同的模块去执行。
3. **Docker 构建引擎为每一条指令创建一个临时容器**，在临时容器中执行指令，然后 commit 容器，生成一个新的镜像层。
4. 最后，**将所有指令构建出的镜像层合并**，形成 build 的最后结果。**最后一次 commit 生成的镜像 ID 就是最终的镜像 ID**。

为了提高构建效率，docker build默认会缓存已有的镜像层。如果构建镜像时发现某个镜像层已经被缓存，就会直接使用该缓存镜像，而不用重新构建。如果不希望使用缓存的镜像，可以在执行docker build命令时，指定--no-cache=true参数。

Docker 匹配缓存镜像的规则为：遍历缓存中的基础镜像及其子镜像，**检查这些镜像的构建指令是否和当前指令完全一致**，如果不一样，则说明缓存不匹配。对于ADD、COPY指令，还会根据文件的校验和（checksum）来判断添加到镜像中的文件是否相同，如果不相同，则说明缓存不匹配。

这里要**注意**，缓存匹配检查不会检查容器中的文件。比如，当使用RUN apt-get -y update命令更新了容器中的文件时，缓存策略并不会检查这些文件，来判断缓存是否匹配。

最后，我们可以通过docker history命令来查看镜像的构建历史，如下图所示：

![img](https://static001.geekbang.org/resource/image/f3/06/f32a0e2f90a36995a561747519897806.png?wh=1854x345)


#### 其他制作镜像方式
上面介绍的是两种最常用的镜像构建方式，还有一些其他的镜像创建方式，这里我简单介绍两种。

通过docker save和docker load命令构建

docker save用来将镜像保存为一个 tar 文件，docker load用来将 tar 格式的镜像文件加载到当前机器上，例如：

```
# 在 A 机器上执行，并将 nginx-v1.0.0.tar.gz 复制到 B 机器
$ docker save nginx | gzip > nginx-v1.0.0.tar.gz

# 在 B 机器上执行
$ docker load -i nginx-v1.0.0.tar.gz
```
通过上面的命令，我们就在机器 B 上创建了nginx镜像。


通过docker export和docker import命令构建

我们先通过docker export 保存镜像，再通过docker import 加载镜像，具体命令如下：

```
# 在 A 机器上执行，并将 nginx-v1.0.0.tar.gz 复制到 B 机器
$ docker export nginx > nginx-v1.0.0.tar.gz

# 在 B 机器上执行
$ docker import - nginx:v1.0.0 nginx-v1.0.0.tar.gz
```
通过docker export导出的镜像和通过docker save保存的镜像相比，会丢失掉所有的镜像构建历史。在实际生产环境中，我不建议你通过docker save和docker export这两种方式来创建镜像。我比较推荐的方式是：在 A 机器上将镜像 push 到镜像仓库，在 B 机器上从镜像仓库 pull 该镜像。


### Dockerfile 指令介绍
上面，我介绍了一些与 Docker 镜像构建有关的基础知识。在实际生产环境中，我们标准的做法是通过 Dockerfile 来构建镜像，这就要求你会编写 Dockerfile 文件。接下来，我就详细介绍下如何编写 Dockerfile 文件。

Dockerfile 指令的基本格式如下：


```
# Comment
INSTRUCTION arguments
```
INSTRUCTION是指令，不区分大小写，但我的建议是指令都大写，这样可以与参数进行区分。Dockerfile 中，以 # 开头的行是注释，而在其他位置出现的 # 会被当成参数，例如：

```
# Comment
RUN echo 'hello world # dockerfile'
```
一个 Dockerfile 文件中包含了多条指令，这些指令可以分为 5 类。
- 定义基础镜像的指令：**FROM**；
- 定义镜像维护者的指令：**MAINTAINER**（可选）；
- 定义镜像构建过程的指令：**COPY**、ADD、**RUN**、USER、**WORKDIR**、ARG、**ENV**、VOLUME、**ONBUILD**；
- 定义容器启动时执行命令的指令：**CMD**、**ENTRYPOINT**；
- 其他指令：EXPOSE、HEALTHCHECK、STOPSIGNAL。

其中，加粗的指令是编写 Dockerfile 时经常用到的指令，需要你重点了解下。我把这些常用 Dockerfile 指令的介绍放在了 GitHub 上，你可以看看这个[Dockerfile 指令详解](https://github.com/marmotedu/geekbang-go/blob/master/Dockerfile%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3.md)。

下面是一个 Dockerfile 示例：

```
# 第一行必须指定构建该镜像所基于的容器镜像
FROM centos:centos8

# 维护者信息
MAINTAINER Lingfei Kong <colin404@foxmail.com>

# 镜像的操作指令
RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
RUN echo "Asia/Shanghai" > /etc/timezone
WORKDIR /opt/iam
COPY iam-apiserver /opt/iam/bin/

# 容器启动时执行指令
ENTRYPOINT ["/opt/iam/bin/iam-apiserver"]
```
Docker 会顺序解释并执行 Dockerfile 中的指令，并且第一条指令必须是FROM，FROM 用来指定构建镜像的基础镜像。接下来，一般会指定镜像维护者的信息。后面是镜像操作的指令，最后会通过CMD或者ENTRYPOINT来指定容器启动的命令和参数。

### Dockerfile指令详解

Dockerfile中包含了大量的指令，这些指令完成的功能，使用的格式都不同。这里，我详细介绍下这些指令。

1) `FROM`

格式：`FROM <image>`或`FROM <image>:<tag>`

`FROM`指令的功能是为后面的指令提供基础镜像，因此，Dockerfile必须以`FROM`指令作为第一条非注释指令。我们可以根据需要，选择任何有效的镜像作为基础镜像。

可以在一个Dockerfile文件中，使用多个 `FROM` 指令，来构建多个镜像。每个镜像构建完成之后，Docker会打印出该镜像的ID。如果 `FROM` 指令中没有指定镜像的tag，则默认tag是 `latest` 。如果镜像不存在，则报错退出。

2) `MAINTAINER`

格式：`MAINTAINER <name> <Email>`

用来指定维护该Dockerfile的作者信息。

3) `ENV`

`ENV`指令有两种格式：

* `ENV <key> <value>`
* `ENV <key1>=<value1> <key2>=<value2>`

`ENV`指令用来在镜像创建出来的容器中声明环境变量，被声明的环境变量可被后面的特定指令，例如：`ENV`、`ADD`、`COPY`、`WORKDIR`、`EXPOSE`、`VOLUME`、`USER`使用。其他指令引用格式为：`$variableName`或`${variableName}`。可以使用斜杠 `\` 来转义环境变量，例如：`\$test`或者`\${test}`，这样二者将会被分别转换为`$test`和`${test}`字符串，而不是环境变量所保存的值。这里要注意，`ONBUILD`指令不支持环境替换。

4) `WORKDIR`

格式：`WORKDIR <工作目录路径>`

该指令用于指定当前的工作目录，使用该命令后，接下来每一层的工作目录都会切换到指定的目录（除非重新使用 `WORKDIR` 切换）。

`WORKDIR` 的路径始终使用绝对路径。这可以保证指令的准确和可靠。 同时，使用 `WORKDIR` 来替代`RUN cd ... && do-something` 这样难以维护的指令。

5) `COPY`

格式：`COPY <src> <dest>`

`COPY` 指令复制本机上的 `<src>` 文件或目录到镜像的 `<dest>` 路径下。若`<dest>`或`<src>`以反斜杠`/`结尾则说明其指向的是目录，否则指向文件。

`<src>`可以是多个文件或目录，但必须是上下文根目录中的相对路径。不能使用形如 `COPY ../filename /filename`这样的指令。此外，`<src>`支持使用通配符指向所有匹配通配符的文件或目录，例如，`COPY iam* /opt/`表示添加所有以 `iam` 开头的文件到目录`/opt/`中。

`<dest>`可以是文件或目录，但必须是镜像中的绝对路径或者相对于`WORKDIR`的相对路径。 若`<dest>`是一个文件，则`<src>`的内容会被复制到`<dest>`中；否则`<src>`指向的文件或目录中的内容会被复制到`<dest>`目录中。当`<src>`指定多个源时，`<dest>`必须是目录。如果`<dest>`在镜像中不存在，则会被自动创建。

6) `ADD`

格式：`ADD <src> <dest>`

`ADD`与`COPY`指令具有相似的功能，都支持复制本地文件到镜像的功能。但`ADD`指令还支持其他功能。在 `ADD` 指令中，`<src>`可以是一个网络文件的下载地址， 比如 `ADD http://example.com/iamctl.yaml /`会在镜像中创建文件`/iamctl.yaml`。

`<src>`还可以是一个压缩归档文件，该文件在复制到容器时会被解压提取，例如`ADD iam.tar.xz /`。但是若URL中的文件为归档文件，则不会被解压提取。

在编写Dockerfile时，推荐使用`COPY`，因为`COPY`只支持本地文件，它比 `ADD` 更加透明。

7) `RUN`

`RUN`指令有两种格式：

* `RUN <command>` (shell格式)
* `RUN ["executable", "param1", "param2"]` (exec格式，推荐使用)

`RUN`指令会在前一条命令创建出的镜像的基础上创建一个容器，并在容器中运行命令，在命令结束运行后提交容器为新镜像，新镜像被Dockerfile中的下一条指令使用。

当使用shell格式时，命令通过`/bin/sh -c`运行。当使用exec格式时，命令是直接运行的，即不通过shell来运行命令。这里要注意，exec格式中的参数会以 `JSON` 数组的格式被Docker解析，所以参数必须使用双引号而不是单引号。

因为exec格式不会在shell中执行，所以环境变量不会被替换。比如，执行`RUN ["echo", "$USER"]`指令时，`$USER`不会做变量替换。如果希望运行shell程序，指令可以写成 `RUN ["/bin/bash", "-c", "echo", "$USER"]`。

8) `CMD`

`CMD`指令有3种格式:

* `CMD <command>` (shell格式)
* `CMD ["executable", "param1", "param2"]` (exec格式，推荐使用)
* `CMD ["param1", "param2"]` (为`ENTRYPOINT`指令提供参数)

`CMD`指令提供容器运行时的默认命令或参数，一个Dockerfile中可以有多条`CMD`指令，但只有最后一条`CMD`指令有效。`CMD ["param1", "param2"]`格式用来跟`ENTRYPOINT`指令配合使用，`CMD`指令中的参数会添加到`ENTRYPOINT`指令中。当使用shell和exec格式时，命令在容器中的运行方式与`RUN`指令相同。如果在执行`docker run` 时指定了命令行参数，则会覆盖`CMD`指令中的命令。

9) `ENTRYPOINT`

`ENTRYPOINT`指令有两种格式：

* `ENTRYPOINT <command>` (shell格式)
* `ENTRYPOINT ["executable", "param1", "param2"]` (exec格式，推荐格式)

`ENTRYPOINT`指令和`CMD`指令类似，都可以让容器在每次启动时执行指定的命令，但二者又有不同。`ENTRYPOINT`只能是命令 ，而`CMD`可以是参数，也可以是指令。另外，`docker run`命令行参数可以覆盖`CMD`，但不能覆盖`ENTRYPOINT`。

当使用Shell格式时，`ENTRYPOINT`指令会忽略任何`CMD`指令和`docker run`命令的参数，并且会运行在`bin/sh -c`中。

推荐使用exec格式。使用exec格式时，`docker run`传入的命令行参数会覆盖`CMD`指令的内容并且追加到`ENTRYPOINT`指令的参数中。

一个Dockerfile中可以有多条`ENTRYPOINT`指令，但只有最后一条`ENTRYPOINT`指令有效。

10) `ONBUILD`

格式：`ONBUILD [INSTRUCTION]`

`ONBUILD` 指令后面跟的是其它指令，例如  `RUN` ,  `COPY` 等。这些指令，在当前镜像构建时不会被执行，当以当前镜像为基础镜像，构建下一级镜像时才会被执行。

这里要注意，使用包含`ONBUILD`指令的Dockerfile，构建的镜像应该打上特殊的标签，比如：`python:3.0-onbuild`。另外，在`ONBUILD`指令中使用`ADD`或`COPY`指令时要特别注意。假如新的构建过程的上下文中缺失了被添加的资源，则新的构建过程会失败。我们可以通过给`ONBUILD`镜像添加特殊标签，来提示编写Dockerfile的开发人员要特别注意。

11) `VOLUME`

`VOLUME`指令有两种格式：

* `VOLUMN ["<路径1>", "路径2"...]`
* `VOLUMN <路径>`

为了防止容器内的重要数据因为容器重启而丢失，且避免容器不断变大，应该将容器内的某些目录挂载到宿主机上。在Dockerfile中，我们可以通过 `VOLUME` 指令事先将某些目录挂载为匿名卷，这样在执行`docker run`时，如果没有指定 `-v` 选项，则默认会将`VOLUMN`指定的目录挂载为匿名卷 。

12) `EXPOSE`

格式：`EXPOSE <端口1> [<端口2> ...]`

`EXPOSE`指定了该镜像生成容器时提供服务的端口（默认对外不暴露端口），可以配合`docker run -P`使用，也可以配合`docker run --net=host`使用。

13) `LABEL`

格式：`LABEL <key>=<value> <key>=<value> <key>=<value> ...`

`LABEL` 指令用来给镜像添加一些元数据（metadata）。

14) `USER`

格式：`USER <用户名>[:<用户组>]`

`USER`指令设定一个用户或者用户ID，在执行`RUN`、`CMD`、`ENTRYPOINT`等指令时指定以那个用户得身份去执行。如果容器中的服务不需要以特权身份来运行，则可以使用 `USER` 指令，切换到非root用户，以此来增加安全性。

15) `ARG`

格式：`ARG <参数名>[=<默认值>]`

与`ENV`作用一致，但作用域不相同。通过`ARG`指定的环境变量仅在`docker build`的过程中有效，构建好的镜像内不存在此变量。虽然构建好的镜像内不存在此变量，但是使用`docker history`可以查看到。所以，敏感数据不建议使用`ARG`。

可以在`docker build`时用`--build-arg <参数名>=<值>`来覆盖`ARG`指定的参数值 。

16) `HEALTHCHECK`

`HEALTHCHECK`指令有两种格式：

* `HEALTHCHECK [选项] CMD <命令>`：设置检查容器健康状况的命令
* `HEALTHCHECK NONE`：用来屏蔽掉已有的健康检查指令。

定时检测容器进程是否健康，可以设置检查的时间间隔、超时时间、重试次数、以及用于判断是否健康的指令。其中，`CMD`指定的`<命令>`的返回值决定了该次健康检查是否成功：`0` 成功；`1` 失败；`2` 保留。

`HEALTHCHECK`支持下列指令：

* --interval=<时间间隔>：设置健康检查的时间间隔，默认是 30s。
* --timeout=<超时时长>：设置单次健康检查的超时时间，默认是 30s。
* --retries=<重试次数>：如果健康检查失败，重试多少次，默认是 3 次。如果连续 3 次健康检查都失败，容器的 STATUS 就会显示 unhealthy。

例如：

```
dockerfile
FROM nginx
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/list*
HEALTHCHECK --interval=5s --timeout=3s\
    CMD curl -fs http://localhost/ || exit 1
```
上面的Dockerfile中，使用`curl -fs http://localhost/ || exit 1`作为健康检查命令 ，每`5`秒检查一次容器是否健康，如果健康检查命令超过`3`秒没响应就视为检查失败。

17) `STOPSIGNAL`

格式：`STOPSIGNAL signal`

`STOPSIGNAL`指令指定了容器退出时，发送给容器的系统调用信号。

### Dockerfile 最佳实践
上面我介绍了 Dockerfile 的指令，但在编写 Dockerfile 时，只知道这些指令是不够的，还不能编写一个合格的 Dockerfile。我们还需要遵循一些编写 Dockerfile 的最佳实践。这里，我总结了一份编写 Dockerfile 的最佳实践清单，你可以参考。

1. 建议所有的 Dockerfile 指令大写，这样做可以很好地跟在镜像内执行的指令区分开来。
2. 在选择基础镜像时，尽量选择官方的镜像，并在满足要求的情况下，尽量选择体积小的镜像。**目前，Linux 镜像大小有以下关系：busybox < debian < centos < ubuntu。**最好确保同一个项目中使用一个统一的基础镜像。如无特殊需求，可以选择使用debian:jessie或者alpine。
3. 在构建镜像时，删除不需要的文件，只安装需要的文件，保持镜像干净、轻量。
4. 使用更少的层，把相关的内容放到一个层，并使用换行符进行分割。这样可以进一步减小镜像的体积，也方便查看镜像历史。
5. 不要在 Dockerfile 中修改文件的权限。因为如果修改文件的权限，Docker 在构建时会重新复制一份，这会导致镜像体积越来越大。
6. 给镜像打上标签，标签可以帮助你理解镜像的功能，例如：docker build -t="nginx:3.0-onbuild"。
7. FROM指令应该包含 tag，例如使用FROM debian:jessie，而不是FROM debian。
8. 充分利用缓存。Docker 构建引擎会顺序执行 Dockerfile 中的指令，而且一旦缓存失效，后续命令将不能使用缓存。为了有效地利用缓存，需要尽量将所有的 Dockerfile 文件中相同的部分都放在前面，而将不同的部分放在后面。
9. 优先使用COPY而非ADD指令。和ADD相比，COPY 功能简单，而且也够用。ADD可变的行为会导致该指令的行为不清晰，不利于后期维护和理解。
10. 推荐将CMD和ENTRYPOINT指令结合使用，使用 execl 格式的ENTRYPOINT指令设置固定的默认命令和参数，然后使用CMD指令设置可变的参数。
11. 尽量使用 Dockerfile 共享镜像。通过共享 Dockerfile，可以使开发者明确知道 Docker 镜像的构建过程，并且可以将 Dockerfile 文件加入版本控制，跟踪起来。
12. 使用.dockerignore忽略构建镜像时非必需的文件。忽略无用的文件，可以提高构建速度。
13. 使用多阶段构建。多阶段构建可以大幅减小最终镜像的体积。例如，COPY指令中可能包含一些安装包，安装完成之后这些内容就废弃掉。下面是一个简单的多阶段构建示例：

```
dockerfile
FROM golang:1.11-alpine AS build

# 安装依赖包
RUN go get github.com/golang/mock/mockgen

# 复制源码并执行build，此处当文件有变化会产生新的一层镜像层
COPY . /go/src/iam/
RUN go build -o /bin/iam

# 缩小到一层镜像
FROM busybox
COPY --from=build /bin/iam /bin/iam
ENTRYPOINT ["/bin/iam"]
CMD ["--help"]
```
### 总结
如果你想使用 Docker 容器来部署应用，那么就需要制作 Docker 镜像。今天，我介绍了如何制作 Docker 镜像。


你可以使用这两种方式来构建 Docker 镜像：
- 通过 docker commit 命令，基于一个已存在的容器构建出镜像。
- 通过编写 Dockerfile 文件，并使用 docker build 命令来构建镜像。


这两种方法中，镜像构建的底层原理是相同的：
- 基于原镜像启动一个 Docker 容器。
- 在容器中进行一些操作，例如执行命令、安装文件等，由这些操作产生的文件变更都会被记录在容器的存储层中。
- 将容器存储层的变更 commit 到新的镜像层中，并添加到原镜像上。

此外，我们还可以使用 docker save / docker load 和 docker export / docker import 来复制 Docker 镜像。在实际生产环境中，我们标准的做法是通过 Dockerfile 来构建镜像。使用 Dockerfile 构建镜像，就需要你编写 Dockerfile 文件。Dockerfile 支持多个指令，这些指令可以分为 5 类，对指令的具体介绍你可以再返回复习一遍。

另外，我们在构建 Docker 镜像时，也要遵循一些最佳实践，具体你可以参考我给你总结的最佳实践清单。

## 47 | 如何编写Kubernetes资源定义文件？

在接下来的 48 讲，我会介绍如何基于腾讯云 EKS 来部署 IAM 应用。EKS 其实是一个标准的 Kubernetes 集群，在 Kubernetes 集群中部署应用，需要编写 Kubernetes 资源的 YAML（Yet Another Markup Language）定义文件，例如 Service、Deployment、ConfigMap、Secret、StatefulSet 等。

这些 YAML 定义文件里面有很多配置项需要我们去配置，其中一些也比较难理解。为了你在学习下一讲时更轻松，这一讲我们先学习下如何编写 Kubernetes YAML 文件。

### 为什么选择 YAML 格式来定义 Kubernetes 资源？
首先解释一下，我们为什么使用 YAML 格式来定义 Kubernetes 的各类资源呢？这是因为 YAML 格式和其他格式（例如 XML、JSON 等）相比，不仅能够支持丰富的数据，而且结构清晰、层次分明、表达性极强、易于维护，非常适合拿来供开发者配置和管理 Kubernetes 资源。

其实 Kubernetes 支持 YAML 和 JSON 两种格式，JSON 格式通常用来作为接口之间消息传递的数据格式，YAML 格式则用于资源的配置和管理。YAML 和 JSON 这两种格式是可以相互转换的，你可以通过在线工具json2yaml，来自动转换 YAML 和 JSON 数据格式。

例如，下面是一个 YAML 文件中的内容：

```
yaml
apiVersion: v1
kind: Service
metadata:
  name: iam-apiserver
spec:
  clusterIP: 192.168.0.231
  externalTrafficPolicy: Cluster
  ports:
  - name: https
    nodePort: 30443
    port: 8443
    protocol: TCP
    targetPort: 8443
  selector:
    app: iam-apiserver
  sessionAffinity: None
  type: NodePort
```
它对应的 JSON 格式的文件内容为：
```
json
{
  "apiVersion": "v1",
  "kind": "Service",
  "metadata": {
    "name": "iam-apiserver"
  },
  "spec": {
    "clusterIP": "192.168.0.231",
    "externalTrafficPolicy": "Cluster",
    "ports": [
      {
        "name": "https",
        "nodePort": 30443,
        "port": 8443,
        "protocol": "TCP",
        "targetPort": 8443
      }
    ],
    "selector": {
      "app": "iam-apiserver"
    },
    "sessionAffinity": "None",
    "type": "NodePort"
  }
}
```
我就是通过json2yaml在线工具，来转换 YAML 和 JSON 的，如下图所示：

![img](https://static001.geekbang.org/resource/image/0f/02/0ffac271b296d1cc407941cfc3139702.png?wh=1920x780)

在编写 Kubernetes 资源定义文件的过程中，如果因为 YAML 格式文件中的配置项缩进太深，导致不容易判断配置项的层级，那么，你就可以将其转换成 JSON 格式，通过 JSON 格式来判断配置型的层级。

如果想学习更多关于 YAML 的知识，你可以参考YAML 1.2 (3rd Edition)。这里，可以先看看我整理的 YAML 基本语法：

- 属性和值都是大小写敏感的。
- 使用缩进表示层级关系。
- 禁止使用 Tab 键缩进，只允许使用空格，建议两个空格作为一个层级的缩进。元素左对齐，就说明对齐的两个元素属于同一个级别。
- 使用 # 进行注释，直到行尾。
- key: value格式的定义中，冒号后要有一个空格。
- 短横线表示列表项，使用一个短横线加一个空格；多个项使用同样的缩进级别作为同一列表。
- 使用 --- 表示一个新的 YAML 文件开始。

现在你知道了，Kubernetes 支持 YAML 和 JSON 两种格式，它们是可以相互转换的。但鉴于 YAML 格式的各项优点，我建议你使用 YAML 格式来定义 Kubernetes 的各类资源。

### Kubernetes 资源定义概述
Kubernetes 中有很多内置的资源，常用的资源有 Deployment、StatefulSet、ConfigMap、Service、Secret、Nodes、Pods、Events、Jobs、DaemonSets 等。除此之外，Kubernetes 还有其他一些资源。如果你觉得 Kubernetes 内置的资源满足不了需求，还可以自定义资源。

Kubernetes 的资源清单可以通过执行以下命令来查看：


```
$ kubectl api-resources
NAME                              SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                       v1                                true         Binding
componentstatuses                 cs           v1                                false        ComponentStatus
configmaps                        cm           v1                                true         ConfigMap
endpoints                         ep           v1                                true         Endpoints
events                            ev           v1                                true         Event
```
上述输出中，各列的含义如下。
- NAME：资源名称。
- SHORTNAMES：资源名称简写。
- APIVERSION：资源的 API 版本，也称为 group。
- NAMESPACED：资源是否具有 Namespace 属性。
- KIND：资源类别。

这些资源有一些共同的配置，也有一些特有的配置。这里，我们先来看下这些资源共同的配置。下面这些配置是 Kubernetes 各类资源都具备的：


```
yaml
---
apiVersion: <string> # string类型，指定group的名称，默认为core。可以使用 `kubectl api-versions` 命令，来获取当前kubernetes版本支持的所有group。
kind: <string> # string类型，资源类别。
metadata: <Object> # 资源的元数据。
  name: <string> # string类型，资源名称。
  namespace: <string> # string类型，资源所属的命名空间。
  lables: < map[string]string> # map类型，资源的标签。
  annotations: < map[string]string> # map类型，资源的标注。
  selfLink: <string> # 资源的 REST API路径，格式为：/api/<group>/namespaces/<namespace>/<type>/<name>。例如：/api/v1/namespaces/default/services/iam-apiserver
spec: <Object> # 定义用户期望的资源状态（disired state）。
status: <Object> # 资源当前的状态，以只读的方式显示资源的最近状态。这个字段由kubernetes维护，用户无法定义。
```
你可以通过kubectl explain <object>命令来查看 Object 资源对象介绍，并通过kubectl explain <object1>.<object2>来查看<object1>的子对象<object2>的资源介绍，例如：

```
$ kubectl explain service
$ kubectl explain service.spec
$ kubectl explain service.spec.ports
```
Kubernetes 资源定义 YAML 文件，支持以下数据类型：
- string，表示字符串类型。
- object，表示一个对象，需要嵌套多层字段。
- map[string]string，表示由 key:value 组成的映射。
- [ ]string，表示字串列表。
- []object，表示对象列表。
- boolean，表示布尔类型。
- integer，表示整型。

### 常用的 Kubernetes 资源定义
上面说了，Kubernetes 中有很多资源，其中 Pod、Deployment、Service、ConfigMap 这 4 类是比较常用的资源，我来一个个介绍下。


#### Pod 资源定义
下面是一个 Pod 的 YAML 定义：

```
yaml
apiVersion: v1   # 必须 版本号， 常用v1  apps/v1
kind: Pod   # 必须
metadata:  # 必须，元数据
  name: string  # 必须，名称
  namespace: string # 必须，命名空间，默认上default,生产环境为了安全性建议新建命名空间分类存放
  labels:   # 非必须，标签，列表值
    - name: string
  annotations:  # 非必须，注解，列表值
    - name: string
spec:  # 必须，容器的详细定义
  containers:  #必须，容器列表，
    - name: string　　　#必须，容器1的名称
      image: string    #必须，容器1所用的镜像
      imagePullPolicy: [Always|Never|IfNotPresent]  #非必须，镜像拉取策略，默认是Always
      command: [string]  # 非必须 列表值，如果不指定，则是一镜像打包时使用的启动命令
      args:　[string] # 非必须，启动参数
      workingDir: string # 非必须，容器内的工作目录
      volumeMounts: # 非必须，挂载到容器内的存储卷配置
        - name: string  # 非必须，存储卷名字，需与【@1】处定义的名字一致
          readOnly: boolean #非必须，定义读写模式，默认是读写
      ports: # 非必须，需要暴露的端口
        - name: string  # 非必须 端口名称
          containerPort: int  # 非必须 端口号
          hostPort: int # 非必须 宿主机需要监听的端口号，设置此值时，同一台宿主机不能存在同一端口号的pod， 建议不要设置此值
          proctocol: [tcp|udp]  # 非必须 端口使用的协议，默认是tcp
      env: # 非必须 环境变量
        - name: string # 非必须 ，环境变量名称
          value: string  # 非必须，环境变量键值对
      resources:  # 非必须，资源限制
        limits:  # 非必须，限制的容器使用资源的最大值，超过此值容器会推出
          cpu: string # 非必须，cpu资源，单位是core，从0.1开始
          memory: string 内存限制，单位为MiB,GiB
        requests:  # 非必须，启动时分配的资源
          cpu: string 
          memory: string
      livenessProbe:   # 非必须，容器健康检查的探针探测方式
        exec: # 探测命令
          command: [string] # 探测命令或者脚本
        httpGet: # httpGet方式
          path: string  # 探测路径，例如 http://ip:port/path
          port: number  
          host: string  
          scheme: string
          httpHeaders:
            - name: string
              value: string
          tcpSocket:  # tcpSocket方式，检查端口是否存在
            port: number
          initialDelaySeconds: 0 #容器启动完成多少秒后的再进行首次探测，单位为s
          timeoutSeconds: 0  #探测响应超时的时间,默认是1s,如果失败，则认为容器不健康，会重启该容器
          periodSeconds: 0  # 探测间隔时间，默认是10s
          successThreshold: 0  # 
          failureThreshold: 0
        securityContext:
          privileged: false
        restartPolicy: [Always|Never|OnFailure]  # 容器重启的策略，
        nodeSelector: object  # 指定运行的宿主机
        imagePullSecrets:  # 容器下载时使用的Secrets名称，需要与valumes.secret中定义的一致
          - name: string
        hostNetwork: false
        volumes: ## 挂载的共享存储卷类型
          - name: string  # 非必须，【@1】
          emptyDir: {}
          hostPath:
            path: string
          secret:  # 类型为secret的存储卷，使用内部的secret内的items值作为环境变量
            secrectName: string
            items:
              - key: string
                path: string
            configMap:  ## 类型为configMap的存储卷
              name: string
              items:
                - key: string
                  path: string

```
Pod 是 Kubernetes 中最重要的资源，我们可以通过 Pod YAML 定义来创建一个 Pod，也可以通过 DaemonSet、Deployment、ReplicaSet、StatefulSet、Job、CronJob 来创建 Pod。

#### Deployment 资源定义
Deployment 资源定义 YAML 文件如下：


```
yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels: # 设定资源的标签
    app: iam-apiserver
  name: iam-apiserver
  namespace: default
spec:
  progressDeadlineSeconds: 10 # 指定多少时间内不能完成滚动升级就视为失败，滚动升级自动取消
  replicas: 1 # 声明副本数，建议 >= 2
  revisionHistoryLimit: 5 # 设置保留的历史版本个数，默认是10
  selector: # 选择器
    matchLabels: # 匹配标签
      app: iam-apiserver # 标签格式为key: value对
  strategy: # 指定部署策略
    rollingUpdate:
      maxSurge: 1 # 最大额外可以存在的副本数，可以为百分比，也可以为整数
      maxUnavailable: 1 # 表示在更新过程中能够进入不可用状态的 Pod 的最大值，可以为百分比，也可以为整数
    type: RollingUpdate # 更新策略，包括：重建(Recreate)、RollingUpdate(滚动更新)
  template: # 指定Pod创建模板。注意：以下定义为Pod的资源定义
    metadata: # 指定Pod的元数据
      labels: # 指定Pod的标签
        app: iam-apiserver
    spec:
      affinity:
        podAntiAffinity: # Pod反亲和性，尽量避免同一个应用调度到相同Node
          preferredDuringSchedulingIgnoredDuringExecution: # 软需求
          - podAffinityTerm:
              labelSelector:
                matchExpressions: # 有多个选项，只有同时满足这些条件的节点才能运行 Pod
                - key: app
                  operator: In # 设定标签键与一组值的关系，In、NotIn、Exists、DoesNotExist
                  values:
                  - iam-apiserver
              topologyKey: kubernetes.io/hostname
            weight: 100 # weight 字段值的范围是1-100。
      containers:
      - command: # 指定运行命令
        - /opt/iam/bin/iam-apiserver # 运行参数
        - --config=/etc/iam/iam-apiserver.yaml
        image: ccr.ccs.tencentyun.com/lkccc/iam-apiserver-amd64:v1.0.6 # 镜像名，遵守镜像命名规范
        imagePullPolicy: Always # 镜像拉取策略。IfNotPresent：优先使用本地镜像；Never：使用本地镜像，本地镜像不存在，则报错；Always：默认值，每次都重新拉取镜像
        # lifecycle: # kubernetes支持postStart和preStop事件。当一个容器启动后，Kubernetes将立即发送postStart事件；在容器被终结之前，Kubernetes将发送一个preStop事件
        name: iam-apiserver # 容器名称，与应用名称保持一致
        ports: # 端口设置
        - containerPort: 8443 # 容器暴露的端口
          name: secure # 端口名称
          protocol: TCP # 协议，TCP和UDP
        livenessProbe: # 存活检查，检查容器是否正常，不正常则重启实例
          httpGet: # HTTP请求检查方法
            path: /healthz # 请求路径
            port: 8080 # 检查端口
            scheme: HTTP # 检查协议
          initialDelaySeconds: 5 # 启动延时，容器延时启动健康检查的时间
          periodSeconds: 10 # 间隔时间，进行健康检查的时间间隔
          successThreshold: 1 # 健康阈值，表示后端容器从失败到成功的连续健康检查成功次数
          failureThreshold: 1 # 不健康阈值，表示后端容器从成功到失败的连续健康检查成功次数
          timeoutSeconds: 3 # 响应超时，每次健康检查响应的最大超时时间
        readinessProbe: # 就绪检查，检查容器是否就绪，不就绪则停止转发流量到当前实例
          httpGet: # HTTP请求检查方法
            path: /healthz # 请求路径
            port: 8080 # 检查端口
            scheme: HTTP # 检查协议
          initialDelaySeconds: 5 # 启动延时，容器延时启动健康检查的时间
          periodSeconds: 10 # 间隔时间，进行健康检查的时间间隔
          successThreshold: 1 # 健康阈值，表示后端容器从失败到成功的连续健康检查成功次数
          failureThreshold: 1 # 不健康阈值，表示后端容器从成功到失败的连续健康检查成功次数
          timeoutSeconds: 3 # 响应超时，每次健康检查响应的最大超时时间
        startupProbe: # 启动探针，可以知道应用程序容器什么时候启动了
          failureThreshold: 10
          httpGet:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 3
        resources: # 资源管理
          limits: # limits用于设置容器使用资源的最大上限,避免异常情况下节点资源消耗过多
            cpu: "1" # 设置cpu limit，1核心 = 1000m
            memory: 1Gi # 设置memory limit，1G = 1024Mi
          requests: # requests用于预分配资源,当集群中的节点没有request所要求的资源数量时,容器会创建失败
            cpu: 250m # 设置cpu request
            memory: 500Mi # 设置memory request
        terminationMessagePath: /dev/termination-log # 容器终止时消息保存路径
        terminationMessagePolicy: File # 仅从终止消息文件中检索终止消息
        volumeMounts: # 挂载日志卷
        - mountPath: /etc/iam/iam-apiserver.yaml # 容器内挂载镜像路径
          name: iam # 引用的卷名称
          subPath: iam-apiserver.yaml # 指定所引用的卷内的子路径，而不是其根路径。
        - mountPath: /etc/iam/cert
          name: iam-cert
      dnsPolicy: ClusterFirst
      restartPolicy: Always # 重启策略，Always、OnFailure、Never
      schedulerName: default-scheduler # 指定调度器的名字
      imagePullSecrets: # 在Pod中设置ImagePullSecrets只有提供自己密钥的Pod才能访问私有仓库
        - name: ccr-registry # 镜像仓库的Secrets需要在集群中手动创建
      securityContext: {} # 指定安全上下文
      terminationGracePeriodSeconds: 5 # 优雅关闭时间，这个时间内优雅关闭未结束，k8s 强制 kill
      volumes: # 配置数据卷，类型详见https://kubernetes.io/zh/docs/concepts/storage/volumes
      - configMap: # configMap 类型的数据卷
          defaultMode: 420 #权限设置0~0777，默认0664
          items:
          - key: iam-apiserver.yaml
            path: iam-apiserver.yaml
          name: iam # configmap名称
        name: iam # 设置卷名称，与volumeMounts名称对应
      - configMap:
          defaultMode: 420
          name: iam-cert
        name: iam-cert
```
在部署时，你可以根据需要来配置相应的字段，常见的需要配置的字段为：labels、name、namespace、replicas、command、imagePullPolicy、container.name、livenessProbe、readinessProbe、resources、volumeMounts、volumes、imagePullSecrets等。

另外，在部署应用时，经常需要提供配置文件，供容器内的进程加载使用。最常用的方法是挂载 ConfigMap 到应用容器中。那么，如何挂载 ConfigMap 到容器中呢？

引用 ConfigMap 对象时，你可以在 volume 中通过它的名称来引用。你可以自定义 ConfigMap 中特定条目所要使用的路径。下面的配置就显示了如何将名为 log-config 的 ConfigMap 挂载到名为 configmap-pod 的 Pod 中：

```
yaml
apiVersion: v1
kind: Pod
metadata:
  name: configmap-pod
spec:
  containers:
    - name: test
      image: busybox
      volumeMounts:
        - name: config-vol
          mountPath: /etc/config
  volumes:
    - name: config-vol
      configMap:
        name: log-config
        items:
          - key: log_level
            path: log_level

```
log-config ConfigMap 以卷的形式挂载，并且存储在 log_level 条目中的所有内容都被挂载到 Pod 的/etc/config/log_level 路径下。 请注意，这个路径来源于卷的 mountPath 和 log_level 键对应的path。这里需要注意，在使用 ConfigMap 之前，你首先要创建它。接下来，我们来看下 ConfigMap 定义。


#### ConfigMap 资源定义
下面是一个 ConfigMap YAML 示例：

```
yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config4
data: # 存储配置内容
  db.host: 172.168.10.1 # 存储格式为key: value
  db.port: 3306
```
可以看到，ConfigMap 的 YAML 定义相对简单些。假设我们将上述 YAML 文件保存在了iam-configmap.yaml文件中，我们可以执行以下命令，来创建 ConfigMap：

```
$ kubectl create -f iam-configmap.yaml
```
除此之外，kubectl 命令行工具还提供了 3 种创建 ConfigMap 的方式。我来分别介绍下。

1）通过--from-literal参数创建
创建命令如下：

```
$ kubectl create configmap iam-configmap --from-literal=db.host=172.168.10.1 --from-literal=db.port='3306'
```
2）通过--from-file=<文件>参数创建

创建命令如下：

```
$ echo -n 172.168.10.1 > ./db.host
$ echo -n 3306 > ./db.port
$ kubectl create cm iam-configmap --from-file=./db.host --from-file=./db.port
```
--from-file的值也可以是一个目录。当值是目录时，目录中的文件名为 key，目录的内容为 value。

3）通过--from-env-file参数创建

创建命令如下：

```
$ cat << EOF > env.txt
db.host=172.168.10.1
db.port=3306
EOF
$ kubectl create cm iam-configmap --from-env-file=env.txt
```
#### Service 资源定义
Service 是 Kubernetes 另一个核心资源。通过创建 Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载到后端的各个容器上。Service 资源定义 YAML 文件如下：

```
yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: iam-apiserver
  name: iam-apiserver
  namespace: default
spec:
  clusterIP: 192.168.0.231 # 虚拟服务地址
  externalTrafficPolicy: Cluster # 表示此服务是否希望将外部流量路由到节点本地或集群范围的端点
  ports: # service需要暴露的端口列表
  - name: https #端口名称
    nodePort: 30443 # 当type = NodePort时，指定映射到物理机的端口号
    port: 8443 # 服务监听的端口号
    protocol: TCP # 端口协议，支持TCP和UDP，默认TCP
    targetPort: 8443 # 需要转发到后端Pod的端口号
  selector: # label selector配置，将选择具有label标签的Pod作为其后端RS
    app: iam-apiserver
  sessionAffinity: None # 是否支持session
  type: NodePort # service的类型，指定service的访问方式，默认为clusterIp
```
上面，我介绍了常用的 Kubernetes YAML 的内容。我们在部署应用的时候，是需要手动编写这些文件的。接下来，我就讲解一些在编写过程中常用的编写技巧。

### YAML 文件编写技巧
这里我主要介绍三个技巧。


1）使用在线的工具来自动生成模板 YAML 文件。

YAML 文件很复杂，完全从 0 开始编写一个 YAML 定义文件，工作量大、容易出错，也没必要。我比较推荐的方式是，使用一些工具来自动生成所需的 YAML。

这里我推荐使用k8syaml工具。k8syaml是一个在线的 YAML 生成工具，当前能够生成 Deployment、StatefulSet、DaemonSet 类型的 YAML 文件。k8syaml具有默认值，并且有对各字段详细的说明，可以供我们填参时参考。


2）使用kubectl run命令获取 YAML 模板：

```
$ kubectl run --dry-run=client --image=nginx nginx -o yaml > my-nginx.yaml
$ cat my-nginx.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: nginx
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
```
然后，我们可以基于这个模板，来修改配置，形成最终的 YAML 文件。


3）导出集群中已有的资源描述。

有时候，如果我们想创建一个 Kubernetes 资源，并且发现该资源跟集群中已经创建的资源描述相近或者一致的时候，可以选择导出集群中已经创建资源的 YAML 描述，并基于导出的 YAML 文件进行修改，获得所需的 YAML。例如：

```
$ kubectl get deployment iam-apiserver -o yaml > iam-authz-server.yaml
```
接着，修改iam-authz-server.yaml。通常，我们需要删除 Kubernetes 自动添加的字段，例如kubectl.kubernetes.io/last-applied-configuration、deployment.kubernetes.io/revision、creationTimestamp、generation、resourceVersion、selfLink、uid、status。

这些技巧可以帮助我们更好地编写和使用 Kubernetes YAML。


### 使用 Kubernetes YAML 时的一些推荐工具
接下来，我再介绍一些比较流行的工具，你可以根据自己的需要进行选择。

#### kubeval
kubeval可以用来验证 Kubernetes YAML 是否符合 Kubernetes API 模式。

安装方法如下：

```
$ wget https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz
$ tar xf kubeval-linux-amd64.tar.gz
$ mv kubeval $HOME/bin
```
安装完成后，我们对 Kubernetes YAML 文件进行验证：

```
$ kubeval deployments/iam.invalid.yaml
ERR  - iam/templates/iam-configmap.yaml: Duplicate 'ConfigMap' resource 'iam' in namespace ''
```
根据提示，查看iam.yaml，发现在iam.yaml文件中，我们定义了两个同名的iam ConfigMap：

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: iam
data:
  {}
---
# Source: iam/templates/iam-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: iam
data:
  iam-: ""
  iam-apiserver.yaml: |
    ...
```
可以看到，使用kubeval之类的工具，能让我们在部署的早期，不用访问集群就能发现 YAML 文件的错误。


#### kube-score
kube-score能够对 Kubernetes YAML 进行分析，并根据内置的检查对其评分，这些检查是根据安全建议和最佳实践而选择的，例如：
- 以非 Root 用户启动容器。
- 为 Pods 设置健康检查。
- 定义资源请求和限制。

你可以按照这个方法安装：

```
$ go get github.com/zegl/kube-score/cmd/kube-score
```
然后，我们对 Kubernetes YAML 进行评分：

```
$ kube-score score -o ci deployments/iam.invalid.yaml
[OK] iam-apiserver apps/v1/Deployment
[OK] iam-apiserver apps/v1/Deployment
[OK] iam-apiserver apps/v1/Deployment
[OK] iam-apiserver apps/v1/Deployment
[CRITICAL] iam-apiserver apps/v1/Deployment: The pod does not have a matching NetworkPolicy
[CRITICAL] iam-apiserver apps/v1/Deployment: Container has the same readiness and liveness probe
[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The pod has a container with a writable root filesystem
[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The container is running with a low user ID
[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The container running with a low group ID
[OK] iam-apiserver apps/v1/Deployment
...
```
检查的结果有OK、SKIPPED、WARNING和CRITICAL。CRITICAL是需要你修复的；WARNING是需要你关注的；SKIPPED是因为某些原因略过的检查；OK是验证通过的。如果你想查看详细的错误原因和解决方案，可以使用-o human选项，例如：

```
$ kube-score score -o human deployments/iam.invalid.yaml
```
上述命令会检查 YAML 资源定义文件，如果有不合规的地方会报告级别、类别以及错误详情，如下图所示：

![img](https://static001.geekbang.org/resource/image/04/f6/0498529693c6d15c9d9d45cbyy866cf6.png?wh=1920x827)


当然，除了 kubeval、kube-score 这两个工具，业界还有其他一些 Kubernetes 检查工具，例如config-lint、copper、conftest、polaris等。

这些工具，我推荐你这么来选择：首先，使用 kubeval 工具做最基本的 YAML 文件验证。验证通过之后，我们就可以进行更多的测试。如果你没有特别复杂的 YAML 验证要求，只需要用到一些最常见的检查策略，这时候可以使用 kube-score。如果你有复杂的验证要求，并且希望能够自定义验证策略，则可以考虑使用 copper。当然，polaris、config-lint、copper也值得你去尝试下。

### 总结
今天，我主要讲了如何编写 Kubernetes YAML 文件。

YAML 格式具有丰富的数据表达能力、清晰的结构和层次，因此被用于 Kubernetes 资源的定义文件中。如果你要把应用部署在 Kubernetes 集群中，就要创建多个关联的 K8s 资源，如果要创建 K8s 资源，目前比较多的方式还是编写 YAML 格式的定义文件。

这一讲我介绍了 K8s 中最常用的四种资源（Pod、Deployment、Service、ConfigMap）的 YAML 定义的写法，你可以常来温习。

另外，在编写 YAML 文件时，也有一些技巧。比如，可以通过在线工具k8syaml来自动生成初版的 YAML 文件，再基于此 YAML 文件进行二次修改，从而形成终版。最后，我还给你分享了编写和使用 Kubernetes YAML 时，社区提供的多种工具。比如，kubeval 可以校验 YAML，kube-score 可以给 YAML 文件打分。了解了如何编写 Kubernetes YAML 文件，下一讲的学习相信你会进行得更顺利。


## 48 | 基于腾讯云 EKS 的容器化部署实战


在 45 讲中，我介绍了一种基于 Kubernetes 的云原生架构设计方案。在云原生架构中，我们是通过 Docker + Kubernetes 来部署云原生应用的。那么这一讲，我就手把手教你如何在 Kubernetes 集群中部署好 IAM 应用。因为步骤比较多，所以希望你能跟着我完成每一个操作步骤。相信在实操的过程中，你也会学到更多的知识。

### 准备工作
在部署 IAM 应用之前，我们需要做以下准备工作：开通腾讯云容器服务镜像仓库。安装并配置 Docker。准备一个 Kubernetes 集群。

### 开通腾讯云容器服务镜像仓库
在 Kubernetes 集群中部署 IAM 应用，需要从镜像仓库下载指定的 IAM 镜像，所以首先需要有一个镜像仓库来托管 IAM 的镜像。我们可以选择将 IAM 镜像托管到DockerHub上，这也是 docker 运行时默认获取镜像的地址。

但因为 DockerHub 服务部署在国外，国内访问速度很慢。所以，我建议将 IAM 镜像托管在国内的镜像仓库中。这里我们可以选择腾讯云提供的镜像仓库服务，访问地址为[容器镜像服务个人版](https://cloud.tencent.com/login?s_url=https%3A%2F%2Fconsole.cloud.tencent.com%2Ftke2%2Fregistry)。

如果你已经有腾讯云的镜像仓库，可以忽略腾讯云镜像仓库开通步骤。

在开通腾讯云镜像仓库之前，你需要注册腾讯云账号，并完成实名认证。开通腾讯云镜像仓库的具体步骤如下：

#### 第一步，开通个人版镜像仓库。
登录容器服务控制台，选择左侧导航栏中的【镜像仓库】>【个人版】。根据以下提示，填写相关信息，并单击【开通】进行初始化。如下图所示：

![img](https://static001.geekbang.org/resource/image/1d/8c/1d4bdfe89bc049d224e7002c23a0ea8c.png?wh=1920x569)

用户名：默认是当前用户的账号 ID，是你登录到腾讯云 Docker 镜像仓库的身份，可在 账号信息 页面获取。密码：是你登录到腾讯云 Docker 镜像仓库的凭证。

这里需要你记录用户名及密码，用于推送及拉取镜像。假如我们开通的镜像仓库，用户名为10000099xxxx，密码为iam59!z$。

这里要注意，10000099xxxx要替换成你镜像仓库的用户名。

#### 第二步，登录到腾讯云 Registry（镜像仓库）。
在我们开通完 Registry，就可以登录 Registry 了。可以通过以下命令来登录腾讯云 Registry：

```
$ docker login --username=[username] ccr.ccs.tencentyun.com
```
这里的 username 是腾讯云账号 ID，开通时已注册，可在 账号信息 页面获取。docker 命令会在后面安装。



#### 第三步，新建镜像仓库命名空间。
如果想使用镜像仓库，那么你首先需要创建一个用来创建镜像的命名空间。上一步，我们开通了镜像仓库，就可以在“命名空间”页签新建命名空间了，如下图所示：

![img](https://static001.geekbang.org/resource/image/1e/5a/1e79852fdc5ee1a094bd42efdf21015a.png?wh=1920x522)

上图中，我们创建了一个叫marmotedu的命名空间。这里，镜像仓库服务、命名空间、镜像仓库、标签这几个概念你可能弄不清楚。接下来，我详细介绍下四者的关系，关系如下图所示：

![img](https://static001.geekbang.org/resource/image/ab/3b/abe8358d3ea2851bc32c80fd9519c63b.jpg?wh=2248x1581)

先来看下我们使用镜像仓库的格式：<镜像仓库服务地址>/<命名空间>/<镜像仓库>:<标签>，例如ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:v1.1.0。


如果想使用一个 Docker 镜像，我们首先需要开通一个镜像仓库服务（Registry），镜像仓库服务都会对外提供一个固定的地址供你访问。在 Registry 中，我们（User）可以创建一个或多个命名空间（Namespace），命名空间也可以简单理解为镜像仓库逻辑上的一个分组。接下来，就可以在 Namespace 中创建一个或多个镜像仓库，例如iam-apiserver-amd64、iam-authz-server-amd64、iam-pump-amd64等。针对每一个镜像仓库，又可以创建多个标签（Tag），例如v1.0.1、v1.0.2等。

<镜像仓库>:<标签>又称为镜像。镜像又分为私有镜像和公有镜像，公有镜像可供所有能访问 Registry 的用户下载使用，私有镜像只提供给通过授权的用户使用。


### 安装 Docker
开通完镜像仓库之后，我们还需要安装 Docker，用来构建和测试 Docker 镜像。下面我来讲解下具体的安装步骤。

#### 第一步，安装 Docker 前置条件检查。
需要确保 CentOS 系统启用了centos-extras yum 源，默认情况下已经启用，检查方式如下：

```
$ cat /etc/yum.repos.d/CentOS-Extras.repo
# Qcloud-Extras.repo

[extras]
name=Qcloud-$releasever - Extras
baseurl=http://mirrors.tencentyun.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Qcloud-8
```
如果/etc/yum.repos.d/CentOS-Extras.repo文件存在，且文件中extras部分的enabled配置项值为1，说明已经启用了centos-extras yum 源。如果/etc/yum.repos.d/CentOS-Extras.repo 文件不存在，或者enabled 不为 1，则需要创建/etc/yum.repos.d/CentOS-Extras.repo 文件，并将上述内容复制进去。

#### 第二步，安装 docker。
Docker 官方文档 Install Docker Engine on CentOS提供了 3 种安装方法:
通过 Yum 源安装。通过 RPM 包安装。通过脚本安装。

这里，我们选择最简单的安装方式：通过 Yum 源安装。它具体又分为下面 3 个步骤。

```bash
# 安装 docker。
sudo yum install -y yum-utils # 1. 安装 `yum-utils` 包，该包提供了 `yum-config-manager` 工具
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 2. 安装 `docker-ce.repo` yum 源
sudo yum-config-manager --enable docker-ce-nightly docker-ce-test # 3. 启用 `nightly` 和 `test` yum 源
sudo yum install -y docker-ce docker-ce-cli containerd.io # 4. 安装最新版本的 docker 引擎和 containerd

# 启动 docker。
$ sudo systemctl start docker

# docker 的配置文件是 /etc/docker/daemon.json ，这个配置文件默认是没有的，需要我们手动创建：
$ sudo tee /etc/docker/daemon.json << EOF
{
  "bip": "172.16.0.1/24",
  "registry-mirrors": [],
  "graph": "/data/lib/docker"
}
EOF
```
这里，我来解释下常用的配置参数。
- registry-mirrors：仓库地址，可以根据需要修改为指定的地址。
- graph：镜像、容器的存储路径，默认是 /var/lib/docker。如果你的 / 目录存储空间满足不了需求，需要设置 graph 为更大的目录。
- bip：指定容器的 IP 网段。

配置完成后，需要重启 Docker：

```
$ sudo systemctl restart docker

```
测试 Docker 是否安装成功。

```
$ sudo docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
b8dfde127a29: Pull complete
Digest: sha256:0fe98d7debd9049c50b597ef1f85b7c1e8cc81f59c8d623fcb2250e8bec85b38
Status: Downloaded newer image for hello-world:latest
...
Hello from Docker!
This message shows that your installation appears to be working correctly.
....
```
docker run hello-world命令会下载hello-world镜像，并启动容器，打印安装成功提示信息后退出。这里注意，如果你通过 Yum 源安装失败，可以尝试 Docker 官方文档 [Install Docker Engine on CentOS](https://docs.docker.com/engine/install/centos/)提供的其他方式安装。


#### 第三步，安装后配置。
安装成功后，我们还需要做一些其他配置。主要有两个，**一个是配置 docker，使其可通过non-root用户使用，另一个是配置 docker 开机启动。**

使用non-root用户操作 Docker
我们在 Linux 系统上操作，为了安全，需要以普通用户的身份登录系统并执行操作。所以，我们需要配置 docker，使它可以被non-root用户使用。具体配置方法如下：

```
$ sudo groupadd docker # 1. 创建`docker`用户组
$ sudo usermod -aG docker $USER # 2. 将当前用户添加到`docker`用户组下
$ newgrp docker # 3. 重新加载组成员身份
$ docker run hello-world # 4. 确认能够以普通用户使用docker
```
如果在执行 sudo groupadd docker 时报 groupadd: group 'docker' already exists 错误，说明 docker 组已经存在了，可以忽略这个报错。如果你在将用户添加到 docker 组之前，使用 sudo 运行过 docker 命令，你可能会看到以下错误：

```
WARNING: Error loading config file: /home/user/.docker/config.json -
stat /home/user/.docker/config.json: permission denied
```
这个错误，我们可以通过删除~/.docker/目录来解决，或者通过以下命令更改~/.docker/目录的所有者和权限：

```
$ sudo chown "$USER":"$USER" /home/"$USER"/.docker -R
$ sudo chmod g+rwx "$HOME/.docker" -R
```
配置 docker 开机启动
大部分 Linux 发行版（RHEL、CentOS、Fedora、Debian、Ubuntu 16.04 及更高版本）使用 systemd 来管理服务，包括指定开启时启动的服务。在 Debian 和 Ubuntu 上，Docker 默认配置为开机启动。

在其他系统，我们需要手动配置 Docker 开机启动，配置方式如下（分别需要配置 docker 和 containerd 服务）：要在引导时为其他发行版自动启动 Docker 和 Containerd，你可以使用以下命令：

```
$ sudo systemctl enable docker.service # 设置 docker 开机启动
$ sudo systemctl enable containerd.service # 设置 containerd 开机启动
```
如果要禁止docker、containerd开启启动，可以用这个命令：

```
$ sudo systemctl disable docker.service # 禁止 docker 开机启动
$ sudo systemctl disable containerd.service # 禁止 containerd 开机启动
```
### 安装docker-compose
```
sudo yum install epel-release
sudo yum install python3-pip 
sudo pip3 install --upgrade pip 
sudo pip3 install docker-compose  
#这里会报错：ModuleNotFoundError: No module named 'setuptools_rust'
#解决方法：pip3 install -U pip setuptools
 
 
docker-compose --version
```
### 准备一个 Kubernetes 集群
安装完 Docker 之后，我们还需要一个 Kubernetes 集群，来调度 docker 容器。安装 Kubernetes 集群极其复杂，这里选择一种最简单的方式来准备一个 Kubernetes 集群：购买一个腾讯云弹性集群（EKS）。

如果你想自己搭建 Kubernetes 集群，这里建议你购买 3 台腾讯云 CVM 机器，并参照[follow-me-install-kubernetes-cluster](https://github.com/opsnull/follow-me-install-kubernetes-cluster)教程来一步步搭建 Kubernetes 集群，CVM 机器建议的最小配置如下：

![img](https://static001.geekbang.org/resource/image/88/0b/885d2431e7f2d9bcd02b32d33yye930b.jpg?wh=1920x876)


#### EKS 简介
我先简单介绍一下 EKS 是什么。EKS（Elastic Kubernetes Service）即腾讯云弹性容器服务，是腾讯云容器服务推出的无须用户购买节点即可部署工作负载的服务模式。它完全兼容原生的 Kubernetes，支持使用原生方式创建及管理资源，按照容器真实的资源使用量计费。弹性容器服务 EKS 还扩展支持腾讯云的存储及网络等产品，同时确保用户容器的安全隔离，开箱即用。

#### EKS 费用
那它是如何收费呢？EKS 是全托管的 Serverless Kubernetes 服务，不会收取托管的 Master、etcd 等资源的费用。弹性集群内运行的工作负载采用后付费的按量计费模式，费用根据实际配置的资源量按使用时间计算。也就是说：**Kubernetes 集群本身是免费的，只有运行工作负载，消耗节点资源时收费。**


EKS 有 3 种计费模式：预留券、按量计费、竞价模式，这里我建议选择按量计费。按量计费，支持按秒计费，按小时结算，随时购买随时释放，从专栏学习的角度来说，费用是最低的。EKS 会根据工作负载申请的 CPU、内存数值以及工作负载的运行时间来核算费用，具体定价，你可以参考：[定价|弹性容器服务。](https://buy.cloud.tencent.com/price/eks)

这里我通过例子来说明一下费用问题，IAM 应用会部署 4 个 Deployment，每个 Deployment 一个副本：

- iam-apiserver：IAM REST API 服务，提供用户、密钥、策略资源的 CURD 功能的 API 接口。
- iam-authz-server：IAM 资源授权服务，对外提供资源授权接口。
- iam-pump：IAM 数据清洗服务，从 Redis 中获取授权日志，处理后保存在 MongoDB 中。
- iamctl：IAM 应用的测试服务，登陆 iamctl Pod 可以执行 iamctl 命令和 smoke 测试脚本，完成对 IAM 应用的运维和测试。

上述 4 个 Deployment 中的 Pod 配置均为 0.25 核、512Mi 内存。

这里，我们根据 EKS 的费用计算公式 费用 = 相关计费项配置 × 资源单位时间价格 × 运行时间 计算 IAM 部署一天的费用：

```
总费用 = (4 x 1) x (0.25 x 0.12 + 0.5 x 0.05) x 24 = 4.8 元
```
也就是按最低配置部署 IAM 应用，运行一天的费用是 4.8 元（一瓶水的钱，就能学到如何将 IAM 应用部署在 Kubernetes 平台上，很值！）。你可能想这个计算公式里每个数值都代表什么呢？我来解释一下，其中：

(4 x 1)：Kubernetes Pod 总个数（一共是 4 个 Deployment，每个 Pod 1 个副本）。0.25 x 0.12：连续运行 1 小时的 CPU 配置费用。0.5 x 0.05：连续运行 1 小时的内存配置费用。24：24 小时，也即一天。

这里需要注意，为了帮助你节省费用，上述配置都是最低配置。在实际生产环境中，建议的配置如下：

![img](https://static001.geekbang.org/resource/image/1d/35/1d20c7eeb9dba8f53194969b0da5e835.jpg?wh=1920x718)

因为 iam-pump 组件是有状态的，并且目前没有实现抢占机制，所以副本数需要设置为 1。另外，Intel 按量计费的配置费用见下图：

![img](https://static001.geekbang.org/resource/image/64/59/64a5f89f4cbea95e50691455a06b1e59.png?wh=1372x226)

在这里有个很重要的事情提醒你：学完本节课，销毁这些 Deployment，避免被继续扣费。建议腾讯云账户余额不要超过 50 元。

#### 申请 EKS 集群
了解了 EKS 以及费用相关的问题，接下来我们看看如何申请 EKS 集群。你可以通过以下 5 步来申请 EKS 集群。在正式申请前，请先确保腾讯云账户有大于 10 元的账户余额，否则在创建和使用 EKS 集群的过程中可能会因为费用不足而报错。

创建腾讯云弹性集群
具体步骤如下：首先，登录容器服务控制台，选择左侧导航栏中的【弹性集群】。然后，在页面上方选择需创建弹性集群的地域，并单击【新建】。在“创建弹性集群”页面，根据以下提示设置集群信息。如下图所示：

![img](https://static001.geekbang.org/resource/image/37/8c/3740a98a6140b9c85517bdd27f30268c.png?wh=1920x950)

页面中各选择项的意思，我来给你解释一下：

- 集群名称：创建的弹性集群名称，不超过 60 个字符。
- Kubernetes 版本：弹性集群支持 1.12 以上的多个 Kubernetes 版本选择，建议选择最新的版本。
- 所在地域：建议你根据所在地理位置选择靠近的地域，可降低访问延迟，提高下载速度。
- 集群网络：已创建的弹性集群 VPC 网络，你可以选择私有网络中的子网用于弹性集群的容器网络，详情请见 私有网络（VPC） 。
- 容器网络：为集群内容器分配在容器网络地址范围内的 IP 地址。弹性集群的 Pod 会直接占用 VPC 子网 IP，请尽量选择 IP 数量充足且与其他产品使用无冲突的子网。
- Service CIDR：集群的 ClusterIP Service 默认分配在所选 VPC 子网中，请尽量选择 IP 数量充足且与其他产品使用无冲突的子网。
- 集群描述：创建集群的相关信息，该信息将显示在“集群信息”页面。

设置完成后，单击【完成】即可开始创建，可在“弹性集群”列表页面查看集群的创建进度。等待弹性集群创建完成，创建完成后的弹性集群页面如下图所示：

![img](https://static001.geekbang.org/resource/image/1c/3e/1c533956986531f0245b27864f17dc3e.png?wh=1920x376)

我们创建的弹性集群 ID 为 cls-dc6sdos4。

开启外网访问
如果想访问 EKS 集群，需要先开启 EKS 的外网访问能力，开启方法如下：登录容器服务控制台 -> 选择左侧导航栏中的【弹性集群】 -> 进入 cls-dc6sdos4 集群的详情页中 -> 选择【基本信息】 -> 点击【外网访问】按钮。如下图所示：

![img](https://static001.geekbang.org/resource/image/23/c6/235679797980de87432a0d4b05dd83c6.png?wh=1920x764)

这里要注意，开启外网访问时，为了安全，需要设置允许访问 kube-apiserver 的 IP 段。为了避免不必要的错误，外网访问地址我们设置为0.0.0.0/0  。如下图所示：

![img](https://static001.geekbang.org/resource/image/ea/21/ea627942e5a432401e5959ee90c06221.png?wh=920x441)

注意，只有测试时才可这么设置为 0.0.0.0/0 ，如果是生产环境，建议严格限制可以访问 kube-apiserver 的来源 IP。

安装 kubectl 命令行工具
如果要访问 EKS（标准的 Kubernetes 集群），比较高效的方式是通过 Kubernetes 提供的命令行工具 kubectl 来访问。所以，还需要安装 kubectl 工具。

安装方式如下：
```
$ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
$ mkdir -p $HOME/bin
$ mv kubectl $HOME/bin
$ chmod +x $HOME/bin/kubectl
```
具体可参考安装和设置 kubectl。你可以通过以下命令来配置 kubectl 的 bash 自动补全：

```
$ kubectl completion bash > $HOME/.kube-completion.bash
$ echo 'source $HOME/.kube-completion.bash' >> ~/.bashrc
$ bash
```
下载并安装 kubeconfig
安装完 kubectl 工具之后，需要配置 kubectl 所读取的配置文件。这里注意，在上一步，我们开启了外网访问，开启后 EKS 会生成一个 kubeconfig 配置（ kubeconfig 即为 kubectl 的配置文件）。我们可以从页面下载并安装。在弹性集群的基本信息页面，点击【复制】按钮，复制 kubeconfig 文件内容，如下图所示：

![img](https://static001.geekbang.org/resource/image/bc/bf/bc314604334dd56b7337a905c9b6bfbf.png?wh=1775x731)

复制后，将粘贴板的内容保存在$HOME/.kube/config文件中。需要先执行mkdir -p $HOME/.kube创建.kube目录，再将粘贴版中的内容写到 config 文件中。你可以通过以下命令，来测试 kubectl 工具是否成功安装和配置：

```
$ kubectl get nodes
NAME                    STATUS   ROLES    AGE    VERSION
eklet-subnet-lowt256k   Ready    <none>   2d1h   v2.5.21
```
如果输出了 Kubernetes 的 eklet 节点，并且节点状态为 Ready，说明 Kubernetes 集群运行正常，并且 kubectl 安装和配置正确。

EKS 集群开通集群内服务访问外网能力
因为 IAM 应用中的数据库：MariaDB、Redis、MongoDB 可能需要通过外网访问，所以还需要开通 EKS 中 Pod 访问外网的能力。EKS 支持通过配置 NAT 网关 和 路由表 来实现集群内服务访问外网。具体开启步骤，需要你查看腾讯云官方文档：通过 NAT 网关访问外网。

在开通过程中有以下两点需要你注意：在创建指向 NAT 网关的路由表步骤中，目的端要选择：0.0.0.0/0。在关联子网至路由表步骤中，只关联创建 EKS 集群时选择的子网。

如果你的数据库需要通过外网访问，这里一定要确保 EKS 集群成功开通集群内服务访问外网能力，否则部署 IAM 应用时会因为访问不了数据库而失败。

### 安装 IAM 应用
上面，我们开通了镜像仓库、安装了 Docker 引擎、安装和配置了 Kubernetes 集群，那么接下来，我们就来看下如何将 IAM 应用部署到 Kubernetes 集群中。

假设 IAM 项目仓库根目录路径为 $IAM_ROOT，具体安装步骤如下：

配置scripts/install/environment.sh
scripts/install/environment.sh文件中包含了各类自定义配置。你可能需要配置跟数据库相关的配置（当然，也可以都使用默认值）：
- MariaDB 配置：environment.sh 文件中以MARIADB_开头的变量。
- Redis 配置：environment.sh 文件中以REDIS_开头的变量。
- MongoDB 配置：environment.sh 文件中以MONGO_开头的变量。

其他配置，使用默认值。

创建 IAM 应用的配置文件
```
$ cd ${IAM_ROOT}
$ make gen.defaultconfigs # 生成iam-apiserver、iam-authz-server、iam-pump、iamctl组件的默认配置文件
$ make gen.ca # 生成 CA 证书
```
上述命令会将 IAM 的配置文件存放在这个${IAM_ROOT}/_output/configs/目录下。

创建 IAM 命名空间
我们将 IAM 应用涉及到的各类资源，都创建在iam命名空间中。将 IAM 资源创建在独立的命名空间中，不仅方便维护，还可以有效避免影响其他 Kubernetes 资源。

```
$ kubectl create namespace iam
```
将 IAM 各服务的配置文件，以 ConfigMap 资源的形式保存在 Kubernetes 集群中

```
$ kubectl -n iam create configmap iam --from-file=${IAM_ROOT}/_output/configs/
$ kubectl -n iam get configmap iam
NAME   DATA   AGE
iam    4      13s
```
执行kubectl -n iam get configmap iam命令，可以成功获取创建的iam configmap。如果你觉得每次执行kubectl命令都要指定-n iam选项很繁琐，你可以使用以下命令，将kubectl上下文环境中的命名空间指定为iam。设置后，执行kubectl命令，默认在iam命名空间下执行：

```
$ kubectl config set-context `kubectl config current-context` --namespace=iam
```
将 IAM 各服务使用的证书文件，以 ConfigMap 资源的形式创建在 Kubernetes 集群中


```
$ kubectl -n iam create configmap iam-cert --from-file=${IAM_ROOT}/_output/cert
$ kubectl -n iam get configmap iam-cert
NAME       DATA   AGE
iam-cert   14     12s
```
执行kubectl -n iam get configmap iam-cert命令，可以成功获取创建的iam-cert configmap。

创建镜像仓库访问密钥
在准备阶段，我们开通了腾讯云镜像仓库服务（访问地址为 ccr.ccs.tencentyun.com），并创建了用户10000099xxxx，其密码为iam59!z$。接下来，我们就可以创建 docker-registry secret。Kubernetes 在下载 Docker 镜像时，需要 docker-registry secret 来进行认证。创建命令如下：

```
$ kubectl -n iam create secret docker-registry ccr-registry --docker-server=ccr.ccs.tencentyun.com --docker-username=10000099xxxx --docker-password='iam59!z$'
```
创建 Docker 镜像，并 Push 到镜像仓库
将镜像 Push 到 CCR 镜像仓库，需要确保你已经登录到腾讯云 CCR 镜像仓库，如果没登录，可以执行以下命令来登录：

```
$ docker login --username=[username] ccr.ccs.tencentyun.com
```
执行 make push 命令构建镜像，并将镜像 Push 到 CCR 镜像仓库：

```
$ make push REGISTRY_PREFIX=ccr.ccs.tencentyun.com/marmotedu VERSION=v1.1.0
```
上述命令，会构建 iam-apiserver-amd64、iam-authz-server-amd64、iam-pump-amd64、iamctl-amd64 四个镜像，并将这些镜像 Push 到腾讯云镜像仓库的marmotedu命名空间下。构建的镜像如下：

```
$ docker images|grep marmotedu
ccr.ccs.tencentyun.com/marmotedu/iam-pump-amd64           v1.1.0   e078d340e3fb        10 seconds ago      244MB
ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64      v1.1.0   5e90b67cc949        2 minutes ago       239MB
ccr.ccs.tencentyun.com/marmotedu/iam-authz-server-amd64   v1.1.0   6796b02be68c        2 minutes ago       238MB
ccr.ccs.tencentyun.com/marmotedu/iamctl-amd64             v1.1.0   320a77d525e3        2 minutes ago       235MB
```
修改 ${IAM_ROOT}/deployments/iam.yaml 配置
这里请你注意，如果在上一个步骤中，你构建的镜像 tag 不是 v1.1.0 ，那么你需要修改 ${IAM_ROOT}/deployments/iam.yaml 文件，并将 iam-apiserver-amd64、 iam-authz-server-amd64、 iam-pump-amd64、iamctl-amd64 镜像的 tag 修改成你构建镜像时指定的 tag。


部署 IAM 应用

```
$ kubectl -n iam apply -f ${IAM_ROOT}/deployments/iam.yaml
```
执行上述命令，会在iam命令空间下，创建一系列 Kubernetes 资源，可以使用以下命令，来获取这些资源的状态：

```
$ kubectl -n iam get all
NAME                                    READY   STATUS    RESTARTS   AGE
pod/iam-apiserver-d8dc48596-wkhpl       1/1     Running   0          94m
pod/iam-authz-server-6bc899c747-fbpbk   1/1     Running   0          94m
pod/iam-pump-7dcbfd4f59-2w9vk           1/1     Running   0          94m
pod/iamctl-6fc46b8ccb-gs62l             1/1     Running   1          98m

NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/iam-apiserver      ClusterIP   192.168.0.174   <none>        8443/TCP,8080/TCP,8081/TCP   101m
service/iam-authz-server   ClusterIP   192.168.0.76    <none>        9443/TCP,9090/TCP            101m
service/iam-pump           ClusterIP   192.168.0.155   <none>        7070/TCP                     101m

NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/iam-apiserver      1/1     1            1           101m
deployment.apps/iam-authz-server   1/1     1            1           101m
deployment.apps/iam-pump           1/1     1            1           101m
deployment.apps/iamctl             1/1     1            1           101m

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.apps/iam-apiserver-d8dc48596       1         1         1       101m
replicaset.apps/iam-authz-server-6bc899c747   1         1         1       101m
replicaset.apps/iam-pump-7dcbfd4f59           1         1         1       101m
replicaset.apps/iamctl-6fc46b8ccb             1         1         1       101m
```
我们看到pod/iam-apiserver-d8dc48596-wkhpl、pod/iam-authz-server-6bc899c747-fbpbk、pod/iam-pump-7dcbfd4f59-2w9vk、pod/iamctl-6fc46b8ccb-gs62l 4 个 Pod 都处在Running状态，说明服务都成功启动。

### 测试 IAM 应用
我们在iam命令空间下创建了一个测试 Deployment iamctl。你可以登陆iamctl Deployment 所创建出来的 Pod，执行一些运维操作和冒烟测试。登陆命令如下：

```
$ kubectl -n iam exec -it `kubectl -n iam get pods -l app=iamctl | awk '/iamctl/{print $1}'` -- bash
```
登陆到iamctl-xxxxxxxxxx-xxxxx Pod 中后，就可以执行运维操作和冒烟测试了。

运维操作在 iamctl 容器中，你可以使用 iamctl 工具提供的各类功能，iamctl 以子命令的方式对外提供功能。命令执行效果见下图：

![img](https://static001.geekbang.org/resource/image/44/7e/4460dfd5cd7f7fae5cbb0c64e605367e.png?wh=1920x433)
冒烟测试

```
# cd /opt/iam/scripts/install
# ./test.sh iam::test::smoke
```
如果./test.sh iam::test::smoke命令，打印的输出中，最后一行为congratulations, smoke test passed!字符串，说明 IAM 应用安装成功。如下图所示：

![img](https://static001.geekbang.org/resource/image/b9/2e/b9688e6b0609571a06401da412b63d2e.png?wh=1920x603)


### 销毁 EKS 集群及其资源
好了，到这里，你已经成功在 EKS 集群中部署了 IAM 应用，EKS 的使命也就完成了。接下来，为避免账户被持续扣费，需要删除 EKS 内的资源和集群。

删除 EKS 内创建的 IAM 资源

```
$ kubectl delete namespace iam
```
因为删除 Namespace 会删除 Namespace 下的所有资源，所以上述命令执行时间会久点。

删除 EKS 集群
首先，登录容器服务控制台，选择左侧导航栏中的【弹性集群】。然后，选择创建的 EKS 集群：cls-dc6sdos4，点击最右侧的【删除】按钮，删除 EKS 集群。如下图所示：

![img](https://static001.geekbang.org/resource/image/05/95/05db9d9aca0a2a06e0a9a9faf37c4695.png?wh=1920x455)


### 总结
云原生架构设计中，需要将 IAM 应用部署到 Kubernetes 集群中。所以，首先需要你准备一个 Kubernetes 集群。你可以自己购买腾讯云 CVM 机器搭建 Kubernetes 集群，但这种方式费用高、操作复杂。所以，我建议你直接申请一个 EKS 集群来部署 IAM 应用。EKS 集群是一个标准的 Kubernetes 集群，可以快速申请，并免运维。EKS 集群只收取实际的资源使用费用。在专栏学习过程中，部署 IAM 应用期间产生的资源使用费用其实是很低的，所以推荐使用这种方式来部署 IAM 应用。

有了 Kubernetes 集群，就可以直接通过以下命令来部署整个 IAM 应用：

```
$ kubectl -n iam apply -f ${IAM_ROOT}/deployments/iam.yaml
```
应用部署起来之后，我们可以登陆到iamctl-xxxxxxxxxx-xxxxxPod，并执行以下命令来测试整个 IAM 应用是否被成功部署：

```
# cd /opt/iam/scripts/install
# ./test.sh iam::test::smoke
```
## 49 | 服务编排（上）：Helm服务编排基础知识

我们将应用部署在 Kubernetes 时，可能需要创建多个服务。我就见过一个包含了 40 多个微服务的超大型应用，每个服务又包含了多个 Kubernetes 资源，比如 Service、Deployment、StatefulSet、ConfigMap 等。相同的应用又要部署在不同的环境中，例如测试环境、预发环境、现网环境等，也就是说应用的配置也不同。

对于一个大型的应用，如果基于 YAML 文件一个一个地部署 Kubernetes 资源，是非常繁琐、低效的，而且这些 YAML 文件维护起来极其复杂，还容易出错。那么，有没有一种更加高效的方式？比如，像 Docker 镜像一样，将应用需要的 Kubernetes 资源文件全部打包在一起，通过这个包来整体部署和管理应用，从而降低应用部署和维护的复杂度。

答案是有。我们可以通过 Helm Chart 包来管理这些 Kubernetes 文件，并通过helm命令，基于 Chart 包来创建和管理应用。接下来，我就来介绍下 Helm 的基础知识，并给你演示下如何基于 Helm 部署 IAM 应用。

### Helm 基础知识介绍
Helm 目前是 Kubernetes 服务编排事实上的标准。Helm 提供了多种功能来支持 Kubernetes 的服务编排，例如 helm 命令行工具、Chart 包、Chart 仓库等。下面，我就来详细介绍下。

#### Helm 是什么？
Helm 是 Kubernetes 的包管理器，类似于 Python 的 pip ，centos 的 yum 。Helm 主要用来管理 Chart 包。Helm Chart 包中包含一系列 YAML 格式的 Kubernetes 资源定义文件，以及这些资源的配置，可以通过 Helm Chart 包来整体维护这些资源。

Helm 也提供了一个helm命令行工具，该工具可以基于 Chart 包一键创建应用，在创建应用时，可以自定义 Chart 配置。应用发布者可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本，并发布应用到软件仓库；对于使用者来说，使用 Helm 后不需要编写复杂的应用部署文件，可以非常方便地在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。

Helm 最新的版本是 v3，Helm3 以 Helm2 的核心功能为基础，对 Chart repo、发行版管理、安全性和 library Charts 进行了改进。和 Helm2 比起来，Helm3 最明显的变化是删除了 Tiller（Helm2 是一种 Client-Server 结构，客户端称为 Helm，服务器称为 Tiller）。Helm3 还新增了一些功能，并废弃或重构了 Helm2 的部分功能，与 Helm2 不再兼容。此外，Helm3 还引入了一些新的实验功能，包括 OCI 支持。

Helm3 架构图如下：

![img](https://static001.geekbang.org/resource/image/9b/59/9bb9e2d495d8fbe5eab4d02d407c8059.jpg?wh=1920x1083)

上面的架构图中，核心是 Helm Client（helm命令）和 Helm Chart 包。helm命令可以从Chart Repository中下载 Helm Chart 包，读取kubeconfig文件，并构建 kube-apiserver REST API 接口的 HTTP 请求。通过调用 Kubernetes 提供的 REST API 接口，将 Chart 包中包含的所有以 YAML 格式定义的 Kubernetes 资源，在 Kubernetes 集群中创建。

这些资源以 Release 的形式存在于 Kubernetes 集群中，每个 Release 又包含多个 Kubernetes 资源，例如 Deployment、Pod、Service 等。

#### Helm 中的三大基本概念
要学习和使用 Helm，一定要了解 Helm 中的三大基本概念，Helm 的所有操作基本都是围绕着这些概念来进行的。下面我来介绍下 Helm 的三大基本概念。

- Chart： 代表一个 Helm 包。它包含了在 Kubernetes 集群中运行应用程序、工具或服务所需的所有 YAML 格式的资源定义文件。
- Repository（仓库）： 它是用来存放和共享 Helm Chart 的地方，类似于存放源码的 GitHub 的 Repository，以及存放镜像的 Docker 的 Repository。
- Release：它是运行在 Kubernetes 集群中的 Chart 的实例。一个 Chart 通常可以在同一个集群中安装多次。每一次安装都会创建一个新的 Release。

#### 我们为什么要使用 Helm？
现在你对 Helm 已经有了一定了解，这里我再来详细介绍下为什么要使用 Helm。先来看下传统的应用部署模式：

![img](https://static001.geekbang.org/resource/image/c1/c4/c1f54e347b5db7850b57815abed99ec4.jpg?wh=1920x966)
我们有测试环境、预发环境、现网环境三个环境，每个环境中部署一个应用 A，应用 A 中包含了多个服务，每个服务又包含了自己的配置，不同服务之间的配置有些是共享的，例如配置A。每个服务由一个复杂的 Kubernetes YAML 格式的文件来定义并创建，可以看到如果靠传统的方式，去维护这些 YAML 格式文件，并在不同环境下使用不同的配置去创建应用，是一件非常复杂的工作，并且后期 YAML 文件和 Kubernetes 集群中部署应用的维护都很复杂。随着微服务规模越来越大，会面临以下挑战：

微服务化服务数量急剧增多，给服务管理带来了极大的挑战。服务数量急剧增多，增加了管理难度，对运维部署是一种挑战。服务数量的增多，对服务配置管理也提出了更高的要求。随着服务数量增加，服务依赖关系也变得更加复杂，服务依赖关系的管理难度增大。在环境信息管理方面，在新环境快速部署一个复杂应用变得更加困难。

所以，我们需要一种更好的方式，来维护和管理这些 YAML 文件和 Kubernetes 中部署的应用。Helm 可以帮我们解决上面这些问题。接下来，我们来看下 Helm 是如何解决这些问题的。

在 Helm 中，可以理解为主要包含两类文件：模板文件和配置文件。模板文件通常有多个，配置文件通常有一个。Helm 的模板文件基于text/template模板文件，提供了更加强大的模板渲染能力。Helm 可以将配置文件中的值渲染进模板文件中，最终生成一个可以部署的 Kubernetes YAML 格式的资源定义文件，如下图所示：

![img](https://static001.geekbang.org/resource/image/ff/86/ffcc4eaf4071e19e2e0d317b1c536486.png?wh=1920x936)

上图中，我们将以下配置渲染进了模板中，生成了 Kubernetes YAML 文件：

```
replicas: 2
tag: latest
common:
    username: colin
    password: iam1234
```
所以在 Helm 中，部署一个应用可以简化为Chart模板（多个服务） + Chart配置 -> 应用，如下图所示：

![img](https://static001.geekbang.org/resource/image/bb/6b/bb87b8562102525d4c2yy0b0314ac46b.jpg?wh=1920x995)
Chart 模板一个应用只用编写一次，可以重复使用。在部署时，可以指定不同的配置，从而将应用部署在不同的环境中，或者在同一环境中部署不同配置的应用。

### Helm 基本操作实战
上面，我介绍了 Helm 的一些基础知识，这里我们再来学习下如何使用 Helm 对应用进行生命周期管理。

#### 前置条件
在开始之前，你需要确保你有一个可以使用的 Kubernetes 集群。目前最方便快捷、最经济的方式是申请一个腾讯云 EKS 集群。至于如何申请和访问，你可以参考 48 讲 “准备一个 Kubernetes 集群”部分的教程。这里再提醒下，**用完集群后，记得删除集群资源，免得被持续扣费。**


#### 安装 Helm
Helm 提供了多种安装方式，在能连通外网的情况下，可以通过脚本来安装，安装命令如下：

```
$ mkdir -p $HOME/bin
$ wget https://get.helm.sh/helm-v3.6.3-linux-amd64.tar.gz
$ tar -xvzf helm-v3.6.3-linux-amd64.tar.gz
$ mv linux-amd64/helm $HOME/bin
$ chmod +x $HOME/bin/helm
$ helm version
version.BuildInfo{Version:"v3.6.3", GitCommit:"d506314abfb5d21419df8c7e7e68012379db2354", GitTreeState:"clean", GoVersion:"go1.16.5"}
```
如果执行helm version可以成功打印出 helm 命令的版本号，说明 Helm 安装成功。Helm 各版本安装包地址见 [Helm Releases](https://github.com/helm/helm/releases)。

安装完helm命令后，可以安装helm命令的自动补全脚本。假如你用的 shell 是bash，安装方法如下：

```
$ helm completion bash > $HOME/.helm-completion.bash
$ echo 'source $HOME/.helm-completion.bash' >> ~/.bashrc
$ bash
```
执行 helm comp< TAB >，就会自动补全为helm completion。


### Helm 快速入门
你可以通过以下六个步骤，来快速创建一个 Chart 应用。

#### 第一步，初始化一个 Helm Chart 仓库。
安装完 Helm 之后，就可以使用 helm 命令添加一个 Chart 仓库。类似于用来托管 Docker 镜像的 DockerHub、用来托管代码的 GitHub，Chart 包也有一个托管平台，当前比较流行的 Chart 包托管平台是Artifact Hub。

Artifact Hub 上有很多 Chart 仓库，我们可以添加需要的 Chart 仓库，这里我们添加 BitNami 提供的 Chart 仓库：

```
$ helm repo add bitnami https://charts.bitnami.com/bitnami # 添加 Chart Repository
$ helm repo list # 查看添加的 Repository 列表
```
添加完成后，我们可以通过helm search命令，来查询需要的 Chart 包。helm search支持两种不同的查询方式，这里我来介绍下。
- helm search repo<keyword>：从你使用 helm repo add 添加到本地 Helm 客户端中的仓库里查找。该命令基于本地数据进行搜索，无需连接外网。
- helm search hub<keyword>：从 Artifact Hub 中查找并列出 Helm Charts。 Artifact Hub 中存放了大量的仓库。

Helm 搜索使用模糊字符串匹配算法，所以你可以只输入名字的一部分。下面是一个helm search的示例：

```
$ helm search repo bitnami
NAME                                          CHART VERSION  APP VERSION    DESCRIPTION
bitnami/bitnami-common                        0.0.9          0.0.9          DEPRECATED Chart with custom templates used in ...
bitnami/airflow                               10.2.8         2.1.2          Apache Airflow is a platform to programmaticall...
bitnami/apache                                8.6.1          2.4.48         Chart for Apache HTTP Server
bitnami/argo-cd                               1.0.2          2.0.5          Declarative, GitOps continuous delivery tool fo...
bitnami/aspnet-core                           1.3.14         3.1.18         ASP.NET Core is an open-source framework create...
bitnami/cassandra                             8.0.2          4.0.0          Apache Cassandra is a free and open-source dist...
bitnami/cert-manager                          0.1.15         1.5.1          Cert Manager is a Kubernetes add-on to automate...
# ... and many more
```
第二步，安装一个示例 Chart。

查询到自己需要的 Helm Chart 后，就可以通过helm install命令来安装一个 Chart。helm install支持从多种源进行安装：

- Chart 的 Repository。
- 本地的 Chart Archive，例如helm install foo foo-1.0.0.tgz。
- 一个未打包的 Chart 路径，例如helm install foo path/to/foo。
- 一个完整的 URL，例如helm install foo https://example.com/charts/foo-1.0.0.tgz。

这里，我们选择通过bitnami/mysql Chart 包来安装一个 MySQL 应用。你可以执行 helm show chart bitnami/mysql 命令，来简单了解这个 Chart 的基本信息。 或者，你也可以执行 helm show all bitnami/mysql，获取关于该 Chart 的所有信息。

接下来，就可以使用helm install命令来安装这个 Chart 包了。安装命令如下：

```
$ helm repo update              # Make sure we get the latest list of charts
$ helm install bitnami/mysql --generate-name
NAME: mysql-1629528555
LAST DEPLOYED: Sat Aug 21 14:49:19 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES: ...
```
在上面的例子中，我们通过安装bitnami/mysql这个 Chart，创建了一个mysql-1629528555 Release。--generate-name参数告诉 Helm 自动为这个 Release 命名。在安装过程中，Helm 客户端会打印一些有用的信息，包括哪些资源已经被创建，Release 当前的状态，以及你是否还需要执行额外的配置步骤。例如，从上述例子的输出中，你可以获取到数据库的 Root 密码、登陆方式、更新方式等信息。

安装完之后，你可以使用 helm status 来追踪 Release 的状态。每当你执行 helm install 的时候，都会创建一个新的发布版本。所以一个 Chart 在同一个集群里面可以被安装多次，每一个都可以被独立地管理和升级。

helm install命令会将 templates 渲染成最终的 Kubernetes 能够识别的 YAML 格式，然后安装到 Kubernetes 集群中。helm install 功能非常强大，想了解更多功能，你可以参考这个指南：[使用 Helm](https://helm.sh/zh/docs/intro/using_helm/)。

#### 第三步，安装前自定义 Chart。
上一步中的安装方式只会使用 Chart 的默认配置选项，很多时候我们需要自定义 Chart 来指定我们想要的配置。使用 helm show values 可以查看 Chart 中的可配置选项：

```
$ helm show values bitnami/mysql # 为了方便展示，我删除了 `helm show values`输出中的`#`注释
# ... and many more
architecture: standalone
auth:
  rootPassword: ""
  database: my_database
  username: ""
  password: ""
  replicationUser: replicator
  replicationPassword: ""
  existingSecret: ""
  forcePassword: false
  usePasswordFiles: false
  customPasswordFiles: {}
initdbScripts: {}
# ... and many more
```
然后，你可以使用 YAML 格式的文件，覆盖上述任意配置项，并在安装过程中使用该文件。

```
$ echo '{auth.database: iam, auth.username: iam, auth.password: iam59!z$}' > values.yaml
$ helm install bitnami/mysql -f values.yaml --generate-name
```
上述命令将为 MySQL 创建一个名称为 iam 的默认用户，密码为iam59!z$，并且授予该用户访问新建的 iam 数据库的权限。Chart 中的其他默认配置保持不变。安装过程中，有两种传递配置数据的方式。

-f, --values：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。--set：通过命令行的方式对指定配置项进行覆盖。

如果同时使用两种方式，则 --set 中的值会被合并到 --values 中，但是 --set 中的值优先级更高。在--set中覆盖的内容会被保存在 ConfigMap 中。你可以通过 helm get values <release-name> 来查看指定 Release 中 --set 设置的值，也可以通过运行 helm upgrade 并指定 --reset-values 字段，来清除 --set中设置的值。

**这里我讲解下--set的格式和限制**。--set 选项使用0或多个key-value 对。最简单的用法类似于--set name=value，等价于下面这个 YAML 格式：

```
yaml
name: value
```
多个值之间使用逗号分割，因此--set a=b,c=d 的 YAML 表示是：

```
yaml
a: b
c: d
```
--set还支持更复杂的表达式。例如，--set outer.inner=value 被转换成了：

```
yaml
outer:
  inner: value
```
列表使用花括号{}来表示。例如，--set name={a, b, c} 被转换成了：


```
yaml
name:
  - a
  - b
  - c
```
从 2.5.0 版本开始，我们可以使用数组下标的语法来访问列表中的元素了。例如 --set servers[0].port=80 就变成了：

```
yaml
servers:
  - port: 80

```
多个值也可以通过这种方式来设置。--set servers[0] [0].host=``marmotedu 变成了：


```
yaml
servers:
  - port: 80
    host: marmotedu
```
如果需要在 --set 中使用特殊字符，你可以使用反斜线来进行转义，比如--set name=value1\,value2 就变成了：

```
yaml
name: "value1,value2"
```
如果是深层嵌套的数据结构，可能很难用--set 来表达，更多内容你可以参考 Values 文件。

#### 第四步，查看当前集群安装了哪些 Release。
通过helm list可以查看当前集群、当前 Namespace 下安装的 Release 列表：

```
$ helm list
NAME              NAMESPACE  REVISION  UPDATED                                  STATUS    CHART        APP VERSION
mysql-1629528555  default    1         2021-08-21 14:49:19.101935218 +0800 CST  deployed  mysql-8.8.4  8.0.26
mysql-1629529348  default    1         2021-08-21 15:02:32.079969128 +0800 CST  deployed  mysql-8.8.4  8.0.26
```
可以看到，我们创建了两个 Release，这些 Release 位于default命名空间中。上述命令，也列出了 Release 的更新时间、状态、Chart 的版本等。

#### 第五步，升级 Release，并且在失败时恢复。
部署完应用之后，后续还可能升级应用，可以通过helm upgrade命令来升级应用。升级操作会基于已有的 Release，根据提供的信息进行升级。Helm 在更新时，只会变更有更改的内容。

例如，这里我们升级mysql-1629528555，变更它的 Root 密码：

```
$ helm upgrade mysql-1629528555 bitnami/mysql --set auth.rootPassword='iam59!z$'
```
在上面的例子中，mysql-1629528555 这个 Release 使用相同的 Chart 进行升级，但使用了一个新的rootPassword配置。我们可以使用 helm get values 命令，来看看配置值是否真的生效了：

```
$ helm get values mysql-1629528555
USER-SUPPLIED VALUES:
auth:
  rootPassword: iam59!z$

```
可以看到rootPassword 的新值已经被部署到集群中了。假如发布失败，我们也很容易通过 helm rollback [RELEASE] [REVISION] 命令，回滚到之前的发布版本。

```
$ helm rollback mysql-1629528555 1
```
上面这条命令将我们的mysql-1629528555回滚到了它最初的版本。Release 版本其实是一个增量修订（revision）。 每当发生了一次安装、升级或回滚操作，revision 的值就会加1。第一次 revision 的值永远是1。我们可以使用 helm history [RELEASE] 命令来查看一个特定 Release 的修订版本号：

```
$ helm history mysql-1629528555
REVISION  UPDATED                   STATUS      CHART        APP VERSION  DESCRIPTION
1         Sat Aug 21 14:49:19 2021  superseded  mysql-8.8.4  8.0.26       Install complete
2         Sat Aug 21 15:14:45 2021  deployed    mysql-8.8.4  8.0.26       Upgrade complete
```
你还可以指定一些其他的选项，来自定义 Helm 在安装、升级、回滚期间的行为。这里，我介绍一些常用的参数，供你参考。
- --timeout：一个 Go duration 类型的值，用来表示等待 Kubernetes 命令完成的超时时间，默认值为 5m0s。
- --no-hooks：不运行当前命令的钩子。
- --wait：表示必须要等到所有的 Pods 都处于 ready 状态、PVC 都被绑定、Deployments 处在 ready 状态的 Pods 个数达到最小值（Desired 减去 maxUnavailable），才会标记该 Release 为成功。最长等待时间由 --timeout 值指定。如果达到超时时间，Release 将被标记为 FAILED。


这里需要注意，当 Deployment 的 replicas 被设置为 1，但其滚动升级策略中的maxUnavailable 没有被设置为0时，--wait 将返回就绪，因为已经满足了最小 ready Pod 数。

#### 第六步，卸载 Release。
你可以使用helm uninstall命令卸载一个 Release：


```
$ helm  uninstall mysql-1629528555
```
上述命令会从 Kubernetes 卸载 mysql-1629528555， 它将删除和该版本关联的所有资源（Service、Deployment、Pod、ConfigMap 等），包括该 Release 的所有版本历史。如果你在执行 helm uninstall 的时候提供--keep-history 选项， Helm 将会保存版本历史。 你可以通过helm status命令查看该版本的信息：


```
$ helm status mysql-1629528555
Status: UNINSTALLED
...
```
因为 --keep-history 选项会让 Helm 跟踪你的版本（即使你卸载了它们），所以你可以审计集群历史，甚至使用 helm rollback 回滚版本。

### Helm 命令
上面我介绍了 Helm 的一些命令的用法，如果你想查看 Helm 提供的所有命令，可以执行helm help。或者，你也可以执行helm <subcommand> -h来查看某个子命令的用法，例如：
```
$ helm get -h

This command consists of multiple subcommands which can be used to
get extended information about the release, including:

- The values used to generate the release
- The generated manifest file
- The notes provided by the chart of the release
- The hooks associated with the release

Usage:
  helm get [command]
# ... and many more
```
我整理了一份命令列表，供你参考：

![img](https://static001.geekbang.org/resource/image/c4/bb/c4fa82cf7bf7fc5c98314419b1e0febb.png?wh=1920x4212)

上面这些命令中，有些提供了子命令和命令行参数，具体你可以执行helm <subcommand> -h来查看。

### 总结
今天，我介绍了 Helm 的基础知识，并给你演示了如何基于 Helm 部署 IAM 应用。当一个应用包含了很多微服务时，手动在 Kubernetes 集群中部署、升级、回滚这些微服务是一件非常复杂的工作。这时候，我们就需要一个服务编排方案来编排这些服务，从而提高服务部署和维护的效率。


目前业界提供了多种服务编排方案，其中最流行的是 Helm，Helm 已经成为一个事实上的 Kubernetes 服务编排标准。在 Helm 中，有 Chart、Repository 和 Release 三大基本概念。Chart 代表一个 Helm 包，里面包含了运行 Kubernetes 应用需要的所有资源定义 YAML 文件；Repository 是 Chart 仓库，用来存放和共享 Helm Chart；Release 是运行在 Kubernetes 集群中的 Chart 的实例。

我们可以通过   helm install [NAME] [CHART] [flags] 来安装一个 Chart 包；通过 helm upgrade [RELEASE] [CHART] [flags] 来更新一个 Helm Release；通过 helm uninstall RELEASE_NAME [...] [flags] 来卸载一个 Helm Release。另外，helm 命令行工具还提供了其他的功能，你可以再回顾一遍。

## 50 | 服务编排（下）：基于Helm的服务编排部署实战

上一讲，我介绍了 Helm 的基础知识，并带着你部署了一个简单的应用。掌握 Helm 的基础知识之后，今天我们就来实战下，一起通过 Helm 部署一个 IAM 应用。通过 Helm 部署 IAM 应用，首先需要制作 IAM Chart 包，然后通过 Chart 包来一键部署 IAM 应用。在实际开发中，我们需要将应用部署在不同的环境中，所以我也会给你演示下如何在多环境中部署 IAM 应用。

### 制作 IAM Chart 包
在部署 IAM 应用之前，我们首先需要制作一个 IAM Chart 包。我们假设 IAM 项目源码根目录为${IAM_ROOT}，进入 ${IAM_ROOT}/deployments目录，在该目录下创建 Chart 包。具体创建流程分为四个步骤，下面我来详细介绍下。

第一步，创建一个模板 Chart。Chart 是一个组织在文件目录中的集合，目录名称就是 Chart 名称（没有版本信息）。你可以看看这个 [Chart 开发指南](https://helm.sh/zh/docs/topics/charts/) ，它介绍了如何开发你自己的 Chart。不过，这里你也可以使用 helm create 命令来快速创建一个模板 Chart，并基于该 Chart 进行修改，得到你自己的 Chart。创建命令如下：

```
$ helm create iam
```
helm create iam会在当前目录下生成一个iam目录，里面存放的就是 Chart 文件。Chart 目录结构及文件如下：

```
$ tree -FC iam/
├── charts/                            # [可选]: 该目录中放置当前Chart依赖的其他Chart
├── Chart.yaml                         # YAML文件，用于描述Chart的基本信息，包括名称版本等
├── templates/                         # [可选]: 部署文件模版目录，模版使用的值来自values.yaml和由Tiller提供的值
│   ├── deployment.yaml                # Kubernetes Deployment object
│   ├── _helpers.tpl                   # 用于修改Kubernetes objcet配置的模板
│   ├── hpa.yaml                       # Kubernetes HPA object
│   ├── ingress.yaml                   # Kubernetes Ingress object
│   ├── NOTES.txt                      # [可选]: 放置Chart的使用指南
│   ├── serviceaccount.yaml
│   ├── service.yaml
│   └── tests/                         # 定义了一些测试资源
│       └── test-connection.yaml
└── values.yaml                        # Chart的默认配置文件

```
上面的目录中，有两个比较重要的文件：Chart.yaml 文件templates 目录

下面我来详细介绍下这两个文件。我们先来看 **Chart.yaml 文件**。Chart.yaml 用来描述 Chart 的基本信息，包括名称、版本等，内容如下：

```
yaml
apiVersion: Chart API 版本 （必需）
name: Chart名称 （必需）
version: 语义化版本（必需）
kubeVersion: 兼容Kubernetes版本的语义化版本（可选）
description: 对这个项目的一句话描述（可选）
type: Chart类型 （可选）
keywords:
  - 关于项目的一组关键字（可选）
home: 项目home页面的URL （可选）
sources:
  - 项目源码的URL列表（可选）
dependencies: # chart 必要条件列表 （可选）
  - name: Chart名称 (nginx)
    version: Chart版本 ("1.2.3")
    repository: （可选）仓库URL ("https://example.com/charts") 或别名 ("@repo-name")
    condition: （可选） 解析为布尔值的YAML路径，用于启用/禁用Chart(e.g. subchart1.enabled )
    tags: # （可选）
      - 用于一次启用/禁用 一组Chart的tag
    import-values: # （可选）
      - ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项
    alias: （可选） Chart中使用的别名。当你要多次添加相同的Chart时会很有用
maintainers: # （可选）
  - name: 维护者名字 （每个维护者都需要）
    email: 维护者邮箱 （每个维护者可选）
    url: 维护者URL （每个维护者可选）
icon: 用作icon的SVG或PNG图片URL （可选）
appVersion: 包含的应用版本（可选）。不需要是语义化，建议使用引号
deprecated: 不被推荐的Chart（可选，布尔值）
annotations:
  example: 按名称输入的批注列表 （可选）.
```
我们再来看下**templates 目录这个文件**。templates 目录中包含了应用中各个 Kubernetes 资源的 YAML 格式资源定义模板，例如：

```
yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: { { .Values.pump.name }}
  name: { { .Values.pump.name }}
spec:
  ports:
  - name: http
    protocol: TCP
    { {- toYaml .Values.pump.service.http| nindent 4 }}
  selector:
    app: { { .Values.pump.name }}
  sessionAffinity: None
  type: { { .Values.serviceType }}
```
{ { .Values.pump.name }}会被deployments/iam/values.yaml文件中pump.name的值替换。上面的模版语法扩展了 Go text/template包的语法：

```
yaml
# 这种方式定义的模版，会去除test模版尾部所有的空行
{ {- define "test"}}
模版内容
{ {- end}}

# 去除test模版头部的第一个空行
{ {- template "test" }}
```
下面是用于 YAML 文件前置空格的语法：

```
yaml
# 这种方式定义的模版，会去除test模版头部和尾部所有的空行
{ {- define "test" -}}
模版内容
{ {- end -}}

# 可以在test模版每一行的头部增加4个空格，用于YAML文件的对齐
{ { include "test" | indent 4}}
```
最后，这里有三点需要你注意：
- Chart 名称必须是小写字母和数字，单词之间可以使用横杠-分隔，Chart 名称中不能用大写字母，也不能用下划线，.号也不行。
- 尽可能使用SemVer 2来表示版本号。
- YAML 文件应该按照双空格的形式缩进 (一定不要使用 tab 键)。

第二步，编辑 iam 目录下的 Chart 文件。我们可以基于helm create生成的模板 Chart 来构建自己的 Chart 包。这里我们添加了创建 iam-apiserver、iam-authz-server、iam-pump、iamctl 服务需要的 YAML 格式的 Kubernetes 资源文件模板：
```
$ ls -1 iam/templates/*.yaml
iam/templates/hpa.yaml                                   # Kubernetes HPA模板文件
iam/templates/iam-apiserver-deployment.yaml              # iam-apiserver服务deployment模板文件
iam/templates/iam-apiserver-service.yaml                 # iam-apiserver服务service模板文件
iam/templates/iam-authz-server-deployment.yaml           # iam-authz-server服务deployment模板文件
iam/templates/iam-authz-server-service.yaml              # iam-authz-server服务service模板文件
iam/templates/iamctl-deployment.yaml                     # iamctl服务deployment模板文件
iam/templates/iam-pump-deployment.yaml                   # iam-pump服务deployment模板文件
iam/templates/iam-pump-service.yaml                      # iam-pump服务service模板文件

```
模板的具体内容，你可以查看deployments/iam/templates/。在编辑 Chart 时，我们可以通过 helm lint 验证格式是否正确，例如：

```
$ helm lint iam
==> Linting iam

1 chart(s) linted, 0 chart(s) failed
```
0 chart(s) failed 说明当前 Iam Chart 包是通过校验的。


第三步，修改 Chart 的配置文件，添加自定义配置。我们可以编辑deployments/iam/values.yaml文件，定制自己的配置。具体配置你可以参考deployments/iam/values.yaml。在修改 values.yaml 文件时，你可以参考下面这些最佳实践。


- 变量名称以小写字母开头，单词按驼峰区分，例如chickenNoodleSoup。
- 给所有字符串类型的值加上引号。
- 为了避免整数转换问题，将整型存储为字符串更好，并用 { { int $value }} 在模板中将字符串转回整型。
- values.yaml中定义的每个属性都应该文档化。文档字符串应该以它要描述的属性开头，并至少给出一句描述。例如：

```
yaml
# serverHost is the host name for the webserver
serverHost: example
# serverPort is the HTTP listener port for the webserver
serverPort: 9191
```
这里需要注意，所有的 Helm 内置变量都以大写字母开头，以便与用户定义的 value 进行区分，例如.Release.Name、.Capabilities.KubeVersion。为了安全，values.yaml 中只配置 Kubernetes 资源相关的配置项，例如 Deployment 副本数、Service 端口等。至于 iam-apiserver、iam-authz-server、iam-pump、iamctl 组件的配置文件，我们创建单独的 ConfigMap，并在 Deployment 中引用。

第四步，打包 Chart，并上传到 Chart 仓库中。这是一个可选步骤，可以根据你的实际需要来选择。如果想了解具体操作，你可以查看 [Helm chart 仓库](https://helm.sh/zh/docs/topics/chart_repository)获取更多信息。

最后，IAM 应用的 Chart 包见[deployments/iam](https://github.com/marmotedu/iam/tree/v1.1.0/deployments/iam)。

### IAM Chart 部署
上面，我们制作了 IAM 应用的 Chart 包，接下来我们就使用这个 Chart 包来一键创建 IAM 应用。IAM Chart 部署一共分为 10 个步骤，你可以跟着我一步步操作下。

第一步，配置scripts/install/environment.sh。scripts/install/environment.sh文件中包含了各类自定义配置，你主要配置下面这些跟数据库相关的就可以，其他配置使用默认值。

MariaDB 配置：environment.sh 文件中以MARIADB_开头的变量。Redis 配置：environment.sh 文件中以REDIS_开头的变量。MongoDB 配置：environment.sh 文件中以MONGO_开头的变量。

第二步，创建 IAM 应用的配置文件。

```
$ cd ${IAM_ROOT}
$ make gen.defaultconfigs # 生成iam-apiserver、iam-authz-server、iam-pump、iamctl组件的默认配置文件
$ make gen.ca # 生成 CA 证书
```
上面的命令会将 IAM 的配置文件存放在目录${IAM_ROOT}/_output/configs/下。

第三步，创建 iam 命名空间。我们将 IAM 应用涉及到的各类资源都创建在iam命名空间中。将 IAM 资源创建在独立的命名空间中，不仅方便维护，还可以有效避免影响其他 Kubernetes 资源。

```
$ kubectl create namespace iam
```
第四步，将 IAM 各服务的配置文件，以 ConfigMap 资源的形式保存在 Kubernetes 集群中。

```
$ kubectl -n iam create configmap iam --from-file=${IAM_ROOT}/_output/configs/
$ kubectl -n iam get configmap iam
NAME   DATA   AGE
iam    4      13s
```
第五步，将 IAM 各服务使用的证书文件，以 ConfigMap 资源的形式保存在 Kubernetes 集群中。

```
$ kubectl -n iam create configmap iam-cert --from-file=${IAM_ROOT}/_output/cert
$ kubectl -n iam get configmap iam-cert
NAME       DATA   AGE
iam-cert   14     12s
```
第六步，创建镜像仓库访问密钥。在准备阶段，我们开通了腾讯云镜像仓库服务，并创建了用户10000099``xxxx，密码为iam59!z$。

接下来，我们就可以创建 docker-registry secret 了。Kubernetes 在下载 Docker 镜像时，需要 docker-registry secret 来进行认证。创建命令如下：

```
$ kubectl -n iam create secret docker-registry ccr-registry --docker-server=ccr.ccs.tencentyun.com --docker-username=10000099xxxx --docker-password='iam59!z$'
```
第七步，创建 Docker 镜像，并 Push 到镜像仓库。


```
$ make push REGISTRY_PREFIX=ccr.ccs.tencentyun.com/marmotedu VERSION=v1.1.0
```
第八步，安装 IAM Chart 包。在49 讲里，我介绍了 4 种安装 Chart 包的方法。这里，我们通过未打包的 IAM Chart 路径来安装，安装方法如下：

```
$ cd ${IAM_ROOT}
$ helm -n iam install iam deployments/iam
NAME: iam
LAST DEPLOYED: Sat Aug 21 17:46:56 2021
NAMESPACE: iam
STATUS: deployed
REVISION: 1
TEST SUITE: None
```
执行 helm install 后，Kubernetes 会自动部署应用，等到 IAM 应用的 Pod 都处在 Running 状态时，说明 IAM 应用已经成功安装：

```
$ kubectl -n iam get pods|grep iam
iam-apiserver-cb4ff955-hs827        1/1     Running   0          66s
iam-authz-server-7fccc7db8d-chwnn   1/1     Running   0          66s
iam-pump-78b57b4464-rrlbf           1/1     Running   0          66s
iamctl-59fdc4995-xrzhn              1/1     Running   0          66s
```
第九步，测试 IAM 应用。我们通过helm install在iam命令空间下创建了一个测试 Deployment iamctl。你可以登陆iamctl Deployment 所创建出来的 Pod，执行一些运维操作和冒烟测试。登陆命令如下：

```
$ kubectl -n iam exec -it `kubectl -n iam get pods -l app=iamctl | awk '/iamctl/{print $1}'` -- bash
```
登陆到iamctl-xxxxxxxxxx-xxxxx Pod 中后，你就可以执行运维操作和冒烟测试了。先来看运维操作。iamctl 工具以子命令的方式对外提供功能，你可以使用它提供的各类功能，如下图所示：

![img](https://static001.geekbang.org/resource/image/69/y2/693f608aa571cbfd6e06c8cfdb242yy2.png?wh=1920x337)

再来看冒烟测试：

```
# cd /opt/iam/scripts/install
# ./test.sh iam::test::smoke
```
如果./test.sh iam::test::smoke命令打印的输出中，最后一行为congratulations, smoke test passed!字符串，就说明 IAM 应用安装成功。如下图所示：

![img](https://static001.geekbang.org/resource/image/9d/8c/9dcc557952b3586f7b37b065bf2bd58c.png?wh=1920x314)

第十步，销毁 EKS 集群的资源。

```
$ kubectl delete namespace iam
```
你可以根据需要选择是否删除 EKS 集群，如果不需要了就可以选择删除。


### IAM 应用多环境部署
在实际的项目开发中，我们需要将 IAM 应用部署到不同的环境中，不同环境的配置文件是不同的，那么 IAM 项目是如何进行多环境部署的呢？

IAM 项目在configs目录下创建了多个 Helm values 文件（格式为values-{envName}-env.yaml）：
- values-test-env.yaml，测试环境 Helm values 文件。
- values-pre-env.yaml，预发环境 Helm values 文件。
- values-prod-env.yaml，生产环境 Helm values 文件。

在部署 IAM 应用时，我们在命令行指定-f参数，例如：

```
$ helm -n iam install -f configs/values-test-env.yaml iam deployments/iam # 安装到测试环境。
```
### 总结
这一讲，我们通过 helm create iam 创建了一个模板 Chart，并基于这个模板 Chart 包进行了二次开发，最终创建了 IAM 应用的 Helm Chart 包：[deployments/iam](https://github.com/marmotedu/iam/tree/v1.1.0/deployments/iam)。有了 Helm Chart 包，我们就可以通过 helm -n iam install iam deployments/iam 命令来一键部署好整个 IAM 应用。当 IAM 应用中的所有 Pod 都处在 Running 状态后，说明 IAM 应用被成功部署。

最后，我们可以登录 iamctl 容器，执行 test.sh iam::test::smoke 命令，来对 IAM 应用进行冒烟测试。


## 51 | 基于 GitHub Actions 的 CI 实战

在 Go 项目开发中，我们要频繁地**执行静态代码检查、测试、编译、构建等操作**。如果每一步我们都手动执行，效率低不说，还容易出错。所以，我们通常借助 CI 系统来自动化执行这些操作。

当前业界有很多优秀的 CI 系统可供选择，例如 CircleCI、TravisCI、Jenkins、CODING、GitHub Actions 等。这些系统在设计上大同小异，为了减少你的学习成本，我选择了相对来说容易实践的 GitHub Actions，来给你展示如何通过 CI 来让工作自动化。这一讲，我会先介绍下 GitHub Actions 及其用法，再向你展示一个 CI 示例，最后给你演示下 IAM 是如何构建 CI 任务的。


### GitHub Actions 的基本用法
GitHub Actions 是 GitHub 为托管在 github.com 站点的项目提供的持续集成服务，于 2018 年 10 月推出。GitHub Actions 具有以下功能特性：

- 提供原子的 actions 配置和组合 actions 的 workflow 配置两种能力。
- 全局配置基于YAML 配置，兼容主流 CI/CD 工具配置。
- Actions/Workflows 基于事件触发，包括 Event restrictions、Webhook events、Scheduled events、External events。
- 提供可供运行的托管容器服务，包括 Docker、VM，可运行 Linux、macOS、Windows 主流系统。
- 提供主流语言的支持，包括 Node.js、Python、Java、Ruby、PHP、Go、Rust、.NET。
- 提供实时日志流程，方便调试。
- 提供平台内置的 Actions与第三方提供的 Actions，开箱即用。

### GitHub Actions 的基本概念
在构建持续集成任务时，我们会在任务中心完成各种操作，比如克隆代码、编译代码、运行单元测试、构建和发布镜像等。GitHub 把这些操作称为 Actions。

Actions 在很多项目中是可以共享的，GitHub 允许开发者将这些可共享的 Actions 上传到GitHub 的官方 Actions 市场，开发者在 Actions 市场中可以搜索到他人提交的 Actions。另外，还有一个 awesome actions 的仓库，里面也有不少的 Action 可供开发者使用。如果你需要某个 Action，不必自己写复杂的脚本，直接引用他人写好的 Action 即可。整个持续集成过程，就变成了一个 Actions 的组合。

Action 其实是一个独立的脚本，可以将 Action 存放在 GitHub 代码仓库中，通过<userName>/<repoName>的语法引用 Action。例如，actions/checkout@v2表示https://github.com/actions/checkout这个仓库，tag 是 v2。actions/checkout@v2也代表一个 Action，作用是安装 Go 编译环境。GitHub 官方的 Actions 都放在 github.com/actions 里面。


GitHub Actions 有一些自己的术语，下面我来介绍下。
- workflow（工作流程）：一个  .yml  文件对应一个 workflow，也就是一次持续集成。一个 GitHub 仓库可以包含多个 workflow，只要是在  .github/workflow  目录下的  .yml  文件都会被 GitHub 执行。
- job（任务）：一个 workflow 由一个或多个 job 构成，每个 job 代表一个持续集成任务。
- step（步骤）：每个 job 由多个 step 构成，一步步完成。
- action（动作）：每个 step 可以依次执行一个或多个命令（action）。
- on：一个 workflow 的触发条件，决定了当前的 workflow 在什么时候被执行。

#### workflow 文件介绍
GitHub Actions 配置文件存放在代码仓库的.github/workflows目录下，文件后缀为.yml，支持创建多个文件，文件名可以任意取，比如iam.yml。GitHub 只要发现.github/workflows目录里面有.yml文件，就会自动运行该文件，如果运行过程中存在问题，会以邮件的形式通知到你。

workflow 文件的配置字段非常多，如果你想详细了解，可以查看[官方文档](https://docs.github.com/cn/actions/reference/workflow-syntax-for-github-actions)。这里，我来介绍一些基本的配置字段。

name
name字段是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。

```
name: GitHub Actions Demo
```
on
on字段指定触发 workflow 的条件，通常是某些事件。

```
on: push
```
上面的配置意思是，push事件触发 workflow。on字段也可以是事件的数组，例如:

```
on: [push, pull_request]
```
上面的配置意思是，push事件或pull_request事件都可以触发 workflow。想了解完整的事件列表，你可以查看官方文档。除了代码库事件，GitHub Actions 也支持外部事件触发，或者定时运行。

on.< push|pull_request>.< tags|branches>
指定触发事件时，我们可以限定分支或标签。

```
on:
  push:
    branches:
      - master
```
上面的配置指定，只有master分支发生push事件时，才会触发 workflow。

jobs.< job_id>.name
workflow 文件的主体是jobs字段，表示要执行的一项或多项任务。jobs字段里面，需要写出每一项任务的job_id，具体名称自定义。job_id里面的name字段是任务的说明。

```
jobs:
  my_first_job:
    name: My first job
  my_second_job:
    name: My second job
```
上面的代码中，jobs字段包含两项任务，job_id分别是my_first_job和my_second_job。

jobs.< job_id>.needs
needs字段指定当前任务的依赖关系，即运行顺序。

```
jobs:
  job1:
  job2:
    needs: job1
  job3:
    needs: [job1, job2]
```
上面的代码中，job1必须先于job2完成，而job3等待job1和job2完成后才能运行。因此，这个 workflow 的运行顺序为：job1、job2、job3。

jobs.< job_id>.runs-on
runs-on字段指定运行所需要的虚拟机环境，它是必填字段。目前可用的虚拟机如下：
- ubuntu-latest、ubuntu-18.04 或 ubuntu-16.04。
- windows-latest、windows-2019 或 windows-2016。
- macOS-latest 或 macOS-10.14。

下面的配置指定虚拟机环境为ubuntu-18.04。

```
runs-on: ubuntu-18.04
```
jobs..steps
steps字段指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定下面三个字段。

jobs.< job_id>.steps.name：步骤名称。jobs.< job_id>.steps.run：该步骤运行的命令或者 action。jobs.< job_id>.steps.env：该步骤所需的环境变量。

下面是一个完整的 workflow 文件的范例：

```
name: Greeting from Mona
on: push

jobs:
  my-job:
    name: My Job
    runs-on: ubuntu-latest
    steps:
    - name: Print a greeting
      env:
        MY_VAR: Hello! My name is
        FIRST_NAME: Lingfei
        LAST_NAME: Kong
      run: |
        echo $MY_VAR $FIRST_NAME $LAST_NAME.
```
上面的代码中，steps字段只包括一个步骤。该步骤先注入三个环境变量，然后执行一条 Bash 命令。

uses
uses 可以引用别人已经创建的 actions，就是上面说的 actions 市场中的 actions。引用格式为userName/repoName@verison，例如uses: actions/setup-go@v1。

with
with 指定 actions 的输入参数。每个输入参数都是一个键 / 值对。输入参数被设置为环境变量，该变量的前缀为 INPUT_，并转换为大写。

这里举个例子：我们定义 hello_world 操作所定义的三个输入参数（first_name、middle_name 和 last_name），这些输入变量将被 hello-world 操作作为 INPUT_FIRST_NAME、INPUT_MIDDLE_NAME 和 INPUT_LAST_NAME 环境变量使用。

```
jobs:
  my_first_job:
    steps:
      - name: My first step
        uses: actions/hello_world@master
        with:
          first_name: Lingfei
          middle_name: Go
          last_name: Kong
```
run
run指定执行的命令。可以有多个命令，例如：

id
id是 step 的唯一标识。

### GitHub Actions 的进阶用法
上面，我介绍了 GitHub Actions 的一些基本知识，这里我再介绍下 GitHub Actions 的进阶用法。
#### 为工作流加一个 Badge
在 action 的面板中，点击Create status badge就可以复制 Badge 的 Markdown 内容到 README.md 中。之后，我们就可以直接在 README.md 中看到当前的构建结果：

![img](https://static001.geekbang.org/resource/image/45/af/453a97b0776281873dee5671c53347af.png?wh=1280x765)

#### 使用构建矩阵
如果我们想在多个系统或者多个语言版本上测试构建，就需要设置构建矩阵。例如，我们想在多个操作系统、多个 Go 版本下跑测试，可以使用如下 workflow 配置：

```
name: Go Test

on: [push, pull_request]

jobs:

  helloci-build:
    name: Test with go ${ { matrix.go_version }} on ${ { matrix.os }}
    runs-on: ${ { matrix.os }}

    strategy:
      matrix:
        go_version: [1.15, 1.16]
        os: [ubuntu-latest, macOS-latest]

    steps:

      - name: Set up Go ${ { matrix.go_version }}
        uses: actions/setup-go@v2
        with:
          go-version: ${ { matrix.go_version }}
        id: go
```
上面的 workflow 配置，通过strategy.matrix配置了该工作流程运行的环境矩阵（格式为go_version.os）：ubuntu-latest.1.15、ubuntu-latest.1.16、macOS-latest.1.15、macOS-latest.1.16。也就是说，会在 4 台不同配置的服务器上执行该 workflow。

#### 使用 Secrets
在构建过程中，我们可能需要用到ssh或者token等敏感数据，而我们不希望这些数据直接暴露在仓库中，此时就可以使用secrets。

我们在对应项目中选择Settings-> Secrets，就可以创建secret，如下图所示：

![img](https://static001.geekbang.org/resource/image/c0/d3/c00b11a1709838c1a205ace7976768d3.png?wh=1920x1046)

配置文件中的使用方法如下：

```
name: Go Test
on: [push, pull_request]
jobs:
  helloci-build:
    name: Test with go
    runs-on: [ubuntu-latest]
    environment:
      name: helloci
    steps:
      - name: use secrets
        env:
          super_secret: ${ { secrets.YourSecrets }}
```
secret name 不区分大小写，所以如果新建 secret 的名字是 name，使用时用 secrets.name 或者 secrets.Name 都是可以的。而且，就算此时直接使用 echo 打印 secret , 控制台也只会打印出*来保护 secret。

这里要注意，你的 secret 是属于某一个环境变量的，所以要指明环境的名字：environment.name。上面的 workflow 配置中的secrets.YourSecrets属于helloci环境。
#### 使用 Artifact 保存构建产物
在构建过程中，我们可能需要输出一些构建产物，比如日志文件、测试结果等。这些产物可以使用 Github Actions Artifact 来存储。你可以使用action/upload-artifact 和 download-artifact 进行构建参数的相关操作。

这里我以输出 Jest 测试报告为例来演示下如何保存 Artifact 产物。Jest 测试后的测试产物是 coverage：

```
steps:
      - run: npm ci
      - run: npm test

      - name: Collect Test Coverage File
        uses: actions/upload-artifact@v1.0.0
        with:
          name: coverage-output
          path: coverage
```
执行成功后，我们就能在对应 action 面板看到生成的 Artifact：

![img](https://static001.geekbang.org/resource/image/4c/66/4c4a8d6aec12a5dd1cdc80d238472566.png?wh=1280x208)

### GitHub Actions 实战
上面，我介绍了 GitHub Actions 的用法，接下来我们就来实战下，看下使用 GitHub Actions 的 6 个具体步骤。

第一步，创建一个测试仓库。登陆GitHub 官网，点击 New repository 创建，如下图所示：

![img](https://static001.geekbang.org/resource/image/6d/a0/6d76d02f0418671a32f5346fccf616a0.png?wh=1920x810)

这里，我们创建了一个叫helloci的测试项目。
第二步，将新的仓库 clone 下来，并添加一些文件：


```
$ git clone https://github.com/marmotedu/helloci
```
你可以克隆marmotedu/helloci，并将里面的文件拷贝到你创建的项目仓库中。
第三步，创建 GitHub Actions workflow 配置目录：

```
$ mkdir -p .github/workflows                     
```
第四步，创建 GitHub Actions workflow 配置。在.github/workflows目录下新建helloci.yml文件，内容如下：

```
name: Go Test

on: [push, pull_request]

jobs:

  helloci-build:
    name: Test with go ${ { matrix.go_version }} on ${ { matrix.os }}
    runs-on: ${ { matrix.os }}
    environment:
      name: helloci

    strategy:
      matrix:
        go_version: [1.16]
        os: [ubuntu-latest]

    steps:

      - name: Set up Go ${ { matrix.go_version }}
        uses: actions/setup-go@v2
        with:
          go-version: ${ { matrix.go_version }}
        id: go

      - name: Check out code into the Go module directory
        uses: actions/checkout@v2

      - name: Tidy
        run: |
          go mod tidy

      - name: Build
        run: |
          go build -v -o helloci .

      - name: Collect main.go file
        uses: actions/upload-artifact@v1.0.0
        with:
          name: main-output
          path: main.go

      - name: Publish to Registry
        uses: elgohr/Publish-Docker-GitHub-Action@master
        with:
          name: ccr.ccs.tencentyun.com/marmotedu/helloci:beta  # docker image 的名字
          username: ${ { secrets.DOCKER_USERNAME}} # 用户名
          password: ${ { secrets.DOCKER_PASSWORD }} # 密码
          registry: ccr.ccs.tencentyun.com # 腾讯云Registry
          dockerfile: Dockerfile # 指定 Dockerfile 的位置
          tag_names: true # 是否将 release 的 tag 作为 docker image 的 tag
```
上面的 workflow 文件定义了当 GitHub 仓库有push、pull_request事件发生时，会触发 GitHub Actions 工作流程，流程中定义了一个任务（Job）helloci-build，Job 中包含了多个步骤（Step），每个步骤又包含一些动作（Action）。

上面的 workflow 配置会按顺序执行下面的 6 个步骤。
1. 准备一个 Go 编译环境。
2. 从marmotedu/helloci下载源码。
3. 添加或删除缺失的依赖包。
4. 编译 Go 源码。
5. 上传构建产物。
6. 构建镜像，并将镜像 push 到ccr.ccs.tencentyun.com/marmotedu/helloci:beta。

第五步，在 push 代码之前，我们需要先创建DOCKER_USERNAME和DOCKER_PASSWORD secret。其中，DOCKER_USERNAME保存腾讯云镜像服务（CCR）的用户名，DOCKER_PASSWORD保存 CCR 的密码。我们将这两个 secret 保存在helloci Environments 中，如下图所示：

![img](https://static001.geekbang.org/resource/image/c0/d3/c00b11a1709838c1a205ace7976768d3.png?wh=1920x1046)


第六步，将项目 push 到 GitHub，触发 workflow 工作流：

```
$ git add .
$ git push origin master
```
打开我们的仓库 Actions 标签页，可以发现 GitHub Actions workflow 正在执行：

![img](https://static001.geekbang.org/resource/image/1a/8a/1afb7860d68635c5e3eaba4ff8da208a.png?wh=1920x691)

等 workflow 执行完，点击 Go Test 进入构建详情页面，在详情页面能够看到我们的构建历史：

![img](https://static001.geekbang.org/resource/image/a4/95/a4b83a122379db4f2fe9538afdfb5a95.png?wh=1920x701)

然后，选择其中一个构建记录，查看其运行详情（具体可参考chore: update step name Go Test #10）：

![img](https://static001.geekbang.org/resource/image/48/4f/481f64aabccf30ed61d0a7c85ab30d4f.png?wh=1920x1084)

你可以看到，Go Test工作流程执行了 6 个 Job，每个 Job 执行了下面这些自定义 Step：
1. Set up Go 1.16。
2. Check out code into the Go module directory。
3. Tidy。
4. Build。
5. Collect main.go file。
6. Publish to Registry。

其他步骤是 GitHub Actions 自己添加的步骤：Setup Job、Post Check out code into the Go module directory、Complete job。点击每一个步骤，你都能看到它们的详细输出。

### IAM GitHub Actions 实战
接下来，我们再来看下 IAM 项目的 GitHub Actions 实战。假设 IAM 项目根目录为 ${IAM_ROOT}，它的 workflow 配置文件为：

接下来，我们再来看下 IAM 项目的 GitHub Actions 实战。假设 IAM 项目根目录为 ${IAM_ROOT}，它的 workflow 配置文件为：

```
$ cat ${IAM_ROOT}/.github/workflows/iamci.yaml
name: IamCI

on:
  push:
    branchs:
    - '*'
  pull_request:
    types: [opened, reopened]

jobs:

  iamci:
    name: Test with go ${ { matrix.go_version }} on ${ { matrix.os }}
    runs-on: ${ { matrix.os }}
    environment:
      name: iamci

    strategy:
      matrix:
        go_version: [1.16]
        os: [ubuntu-latest]

    steps:

      - name: Set up Go ${ { matrix.go_version }}
        uses: actions/setup-go@v2
        with:
          go-version: ${ { matrix.go_version }}
        id: go

      - name: Check out code into the Go module directory
        uses: actions/checkout@v2

      - name: Run go modules Tidy
        run: |
          make tidy

      - name: Generate all necessary files, such as error code files
        run: |
          make gen

      - name: Check syntax and styling of go sources
        run: |
          make lint

      - name: Run unit test and get test coverage
        run: |
          make cover

      - name: Build source code for host platform
        run: |
          make build

      - name: Collect Test Coverage File
        uses: actions/upload-artifact@v1.0.0
        with:
          name: main-output
          path: _output/coverage.out

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      - name: Login to DockerHub
        uses: docker/login-action@v1
        with:
          username: ${ { secrets.DOCKERHUB_USERNAME }}
          password: ${ { secrets.DOCKERHUB_TOKEN }}

      - name: Build docker images for host arch and push images to registry
        run: |
          make push
```
上面的 workflow 依次执行了以下步骤：
1. 设置 Go 编译环境。
2. 下载 IAM 项目源码。
3. 添加 / 删除不需要的 Go 包。
4. 生成所有的代码文件。
5. 对 IAM 源码进行静态代码检查。
6. 运行单元测试用例，并计算单元测试覆盖率是否达标。
7. 编译代码。收集构建产物_output/coverage.out。
8. 配置 Docker 构建环境。
9. 登陆 DockerHub。
10. 构建 Docker 镜像，并 push 到 DockerHub。

IamCI workflow 运行历史如下图所示：

![img](https://static001.geekbang.org/resource/image/2b/b0/2b542f9101be0c3a83576fb99bf882b0.png?wh=1920x844)

IamCI workflow 的其中一次工作流程运行结果如下图所示：

![img](https://static001.geekbang.org/resource/image/e9/6a/e9ebf13fdb6e4f41a1b00406e646ec6a.png?wh=1920x887)


### 总结
在 Go 项目开发中，我们需要通过 CI 任务来将需要频繁操作的任务自动化，这不仅可以提高开发效率，还能减少手动操作带来的失误。这一讲，我选择了最易实践的 GitHub Actions，来给你演示如何构建 CI 任务。GitHub Actions 支持通过 push 事件来触发 CI 流程。一个 CI 流程其实就是一个 workflow，workflow 中包含多个任务，这些任务是可以并行执行的。一个任务又包含多个步骤，每一步又由多个动作组成。动作（Action）其实是一个命令 / 脚本，用来完成我们指定的任务，如编译等。因为 GitHub Actions 内容比较多，这一讲只介绍了一些核心的知识，更详细的 GitHub Actions 教程，你可以参考 [官方中文文档](https://docs.github.com/cn/actions)。



## 加餐

## 特别放送 | 给你一份清晰、可直接套用的Go编码规范
我们在上一讲学习了“写出优雅 Go 项目的方法论”，那一讲内容很丰富，是我多年 Go 项目开发的经验沉淀，需要你多花一些时间好好消化吸收。吃完大餐之后，咱们今天来一期特别放送，就是上一讲我提到过的编码规范。这一讲里，为了帮你节省时间和精力，我会给你一份清晰、可直接套用的 Go 编码规范，帮助你编写一个高质量的 Go 应用。这份规范，是我参考了 Go 官方提供的编码规范，以及 Go 社区沉淀的一些比较合理的规范之后，加入自己的理解总结出的，它比很多公司内部的规范更全面，你掌握了，以后在面试大厂的时候，或者在大厂里写代码的时候，都会让人高看你一眼，觉得你 code 很专业。这份编码规范中包含代码风格、命名规范、注释规范、类型、控制结构、函数、GOPATH 设置规范、依赖管理和最佳实践九类规范。如果你觉得这些规范内容太多了，看完一遍也记不住，这完全没关系。你可以多看几遍，也可以在用到时把它翻出来，在实际应用中掌握。这篇特别放送的内容，更多是作为写代码时候的一个参考手册。

### 1. 代码风格
#### 1.1 代码格式
- 代码都必须用 gofmt 进行格式化。
- 运算符和操作数之间要留空格。
- 建议一行代码不超过 120 个字符，超过部分，请采用合适的换行方式换行。
- 但也有些例外场景，例如 import 行、工具自动生成的代码、带 tag 的 struct 字段。
- 文件长度不能超过 800 行。
- 函数长度不能超过 80 行。
- import 规范
  - 代码都必须用 goimports 进行格式化（建议将代码 Go 代码编辑器设置为：保存时运行 goimports）。
    - 不要使用相对路径引入包，例如 import …/util/net 。
    - 包名称与导入路径的最后一个目录名不匹配时，或者多个相同包名冲突时，则必须使用导入别名。

```go
// bad
  "github.com/dgrijalva/jwt-go/v4"

  //good
  jwt "github.com/dgrijalva/jwt-go/v4"
```
  - 导入的包建议进行分组，匿名包的引用使用一个新的分组，并对匿名包引用进行说明。 

```go
  import (
    // go 标准包
    "fmt"

    // 第三方包
      "github.com/jinzhu/gorm"
      "github.com/spf13/cobra"
      "github.com/spf13/viper"

    // 匿名包单独分组，并对匿名包引用进行说明
      // import mysql driver
      _ "github.com/jinzhu/gorm/dialects/mysql"

    // 内部包
      v1 "github.com/marmotedu/api/apiserver/v1"
      metav1 "github.com/marmotedu/apimachinery/pkg/meta/v1"
      "github.com/marmotedu/iam/pkg/cli/genericclioptions"
  )

```
#### 1.2 声明、初始化和定义
当函数中需要使用到多个变量时，可以在函数开始处使用 var 声明。在函数外部声明必须使用 var ，不要采用 := ，容易踩到变量的作用域的问题。

```go
var (
  Width  int
  Height int
)
```
在初始化结构引用时，请使用 &T{}代替 new(T)，以使其与结构体初始化一致。

```go
// bad
sptr := new(T)
sptr.Name = "bar"

// good
sptr := &T{Name: "bar"}
```
struct 声明和初始化格式采用多行，定义如下。

```go
type User struct{
    Username  string
    Email     string
}

user := User{
  Username: "colin",
  Email: "colin404@foxmail.com",
}
```
相似的声明放在一组，同样适用于常量、变量和类型声明。

```go
// bad
import "a"
import "b"

// good
import (
  "a"
  "b"
)
```
尽可能指定容器容量，以便为容器预先分配内存，例如：

```go
v := make(map[int]string, 4)
v := make([]string, 0, 4)
```
在顶层，使用标准 var 关键字。请勿指定类型，除非它与表达式的类型不同。

```go
// bad
var _s string = F()

func F() string { return "A" }

// good
var _s = F()
// 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型
// 还是那种类型

func F() string { return "A" }
```
对于未导出的顶层常量和变量，使用 _ 作为前缀。

```go
// bad
const (
  defaultHost = "127.0.0.1"
  defaultPort = 8080
)

// good
const (
  _defaultHost = "127.0.0.1"
  _defaultPort = 8080
)
```
嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。

```go
// bad
type Client struct {
  version int
  http.Client
}

// good
type Client struct {
  http.Client

  version int
}

```
#### 1.3 错误处理
error作为函数的值返回，必须对error进行处理，或将返回值赋值给明确忽略。对于defer xx.Close()可以不用显式处理。

```go
func load() error {
  // normal code
}

// bad
load()

// good
 _ = load()
```
尽早进行错误处理，并尽早返回，减少嵌套。

```go
// bad
if err != nil {
  // error code
} else {
  // normal code
}

// good
if err != nil {
  // error handling
  return err
}
// normal code
```
如果需要在 if 之外使用函数调用的结果，则应采用下面的方式。

```go
// bad
if v, err := foo(); err != nil {
  // error handling
}

// good
v, err := foo()
if err != nil {
  // error handling
}
```
错误要单独判断，不与其他逻辑组合判断。

```go
// bad
v, err := foo()
if err != nil || v  == nil {
  // error handling
  return err
}

// good
v, err := foo()
if err != nil {
  // error handling
  return err
}

if v == nil {
  // error handling
  return errors.New("invalid value v")
}
```
如果返回值需要初始化，则采用下面的方式。

```go
v, err := f()
if err != nil {
    // error handling
    return // or continue.
}
// use v

```
错误描述建议
- 告诉用户他们可以做什么，而不是告诉他们不能做什么。
- 当声明一个需求时，用 must 而不是 should。例如，must be greater than 0、must match regex ‘[a-z]+’。
- 当声明一个格式不对时，用 must not。例如，must not contain。
- 当声明一个动作时用 may not。例如，may not be specified when otherField is empty、only name may be specified。
- 引用文字字符串值时，请在单引号中指示文字。例如，ust not contain ‘…’。
- 当引用另一个字段名称时，请在反引号中指定该名称。例如，must be greater than request。
- 指定不等时，请使用单词而不是符号。例如，must be less than 256、must be greater than or equal to 0 (不要用 larger than、bigger than、more than、higher than)。
- 指定数字范围时，请尽可能使用包含范围。
- 建议 Go 1.13 以上，error 生成方式为 fmt.Errorf("module xxx: %w", err)。
- 错误描述用小写字母开头，结尾不要加标点符号，例如：

```go
  // bad
  errors.New("Redis connection failed")
  errors.New("redis connection failed.")

  // good
  errors.New("redis connection failed")
```
#### 1.4 panic 处理
- 在业务逻辑处理中禁止使用 panic。
- 在 main 包中，只有当程序完全不可运行时使用 panic，例如无法打开文件、无法连接数据库导致程序无法正常运行。
- 在 main 包中，使用 log.Fatal 来记录错误，这样就可以由 log 来结束程序，或者将 panic 抛出的异常记录到日志文件中，方便排查问题。
- 可导出的接口一定不能有 panic。
- 包内建议采用 error 而不是 panic 来传递错误。

#### 1.5 单元测试
- 单元测试文件名命名规范为 example_test.go。
- 每个重要的可导出函数都要编写测试用例。
- 因为单元测试文件内的函数都是不对外的，所以可导出的结构体、函数等可以不带注释。
- 如果存在 func (b *Bar) Foo ，单测函数可以为 func TestBar_Foo。

#### 1.6 类型断言失败处理
type assertion 的单个返回值针对不正确的类型将产生 panic。请始终使用 “comma ok”的惯用法。

```go
// bad
t := n.(int)

// good
t, ok := n.(int)
if !ok {
  // error handling
}
// normal code
```
### 2. 命名规范
命名规范是代码规范中非常重要的一部分，一个统一的、短小的、精确的命名规范可以大大提高代码的可读性，也可以借此规避一些不必要的 Bug。

#### 2.1 包命名
- 包名必须和目录名一致，尽量采取有意义、简短的包名，不要和标准库冲突。
- 包名全部小写，没有大写或下划线，使用多级目录来划分层级。
- 项目名可以通过中划线来连接多个单词。
- 包名以及包所在的目录名，不要使用复数，例如，是net/url，而不是net/urls。
- 不要用 common、util、shared 或者 lib 这类宽泛的、无意义的包名。
- 包名要简单明了，例如 net、time、log。

#### 2.2 函数命名
- 函数名采用驼峰式，首字母根据访问控制决定使用大写或小写，例如：MixedCaps 或者 mixedCaps。
- 代码生成工具自动生成的代码 (如 xxxx.pb.go) 和为了对相关测试用例进行分组，而采用的下划线 (如 TestMyFunction_WhatIsBeingTested) 排除此规则。
#### 2.3 文件命名
- 文件名要简短有意义。
- **文件名应小写，并使用下划线分割单词**。

#### 2.4 结构体命名
- 采用驼峰命名方式，首字母根据访问控制决定使用大写或小写，例如 MixedCaps 或者 mixedCaps。
- 结构体名不应该是动词，应该是名词，比如 Node、NodeSpec。
- 避免使用 Data、Info 这类无意义的结构体名。
- 结构体的声明和初始化应采用多行，例如：

```go
// User 多行声明
type User struct {
    Name  string
    Email string
}

// 多行初始化
u := User{
    UserName: "colin",
    Email:    "colin404@foxmail.com",
}
```
#### 2.5 接口命名
- 接口命名的规则，基本和结构体命名规则保持一致：
  - 单个函数的接口名以 “er"”作为后缀（例如 Reader，Writer），有时候可能导致蹩脚的英文，但是没关系。
  - 两个函数的接口名以两个函数名命名，例如 ReadWriter。
  - 三个以上函数的接口名，类似于结构体名。

例如：
```go
  // Seeking to an offset before the start of the file is an error.
  // Seeking to any positive offset is legal, but the behavior of subsequent
  // I/O operations on the underlying object is implementation-dependent.
  type Seeker interface {
      Seek(offset int64, whence int) (int64, error)
  }

  // ReadWriter is the interface that groups the basic Read and Write methods.
  type ReadWriter interface {
      Reader
      Writer
  }
```
#### 2.6 变量命名
- 变量名必须遵循驼峰式，首字母根据访问控制决定使用大写或小写。
- 在相对简单（对象数量少、针对性强）的环境中，可以将一些名称由完整单词简写为单个字母，例如：
  - user 可以简写为 u；
  - userID 可以简写 uid。
- 特有名词时，需要遵循以下规则：
  - 如果变量为私有，且特有名词为首个单词，则使用小写，如 apiClient。
  - 其他情况都应当使用该名词原有的写法，如 APIClient、repoID、UserID。

下面列举了一些常见的特有名词。

```go
// A GonicMapper that contains a list of common initialisms taken from golang/lint
var LintGonicMapper = GonicMapper{
    "API":   true,
    "ASCII": true,
    "CPU":   true,
    "CSS":   true,
    "DNS":   true,
    "EOF":   true,
    "GUID":  true,
    "HTML":  true,
    "HTTP":  true,
    "HTTPS": true,
    "ID":    true,
    "IP":    true,
    "JSON":  true,
    "LHS":   true,
    "QPS":   true,
    "RAM":   true,
    "RHS":   true,
    "RPC":   true,
    "SLA":   true,
    "SMTP":  true,
    "SSH":   true,
    "TLS":   true,
    "TTL":   true,
    "UI":    true,
    "UID":   true,
    "UUID":  true,
    "URI":   true,
    "URL":   true,
    "UTF8":  true,
    "VM":    true,
    "XML":   true,
    "XSRF":  true,
    "XSS":   true,
}
```
若变量类型为 bool 类型，则名称应以 Has，Is，Can 或 Allow 开头，例如：

```go
var hasConflict bool
var isExist bool
var canManage bool
var allowGitHook bool
```
局部变量应当尽可能短小，比如使用 buf 指代 buffer，使用 i 指代 index。

代码生成工具自动生成的代码可排除此规则 (如 xxx.pb.go 里面的 Id)

#### 2.7 常量命名
常量名必须遵循驼峰式，首字母根据访问控制决定使用大写或小写。如果是枚举类型的常量，需要先创建相应类型：

```go
// Code defines an error code type.
type Code int

// Internal errors.
const (
    // ErrUnknown - 0: An unknown error occurred.
    ErrUnknown Code = iota
    // ErrFatal - 1: An fatal error occurred.
    ErrFatal
)
```
#### 2.8 Error 的命名
Error 类型应该写成 FooError 的形式。

```go
type ExitError struct {
  // ....
}
```
Error 变量写成 ErrFoo 的形式。
```go
var ErrFormat = errors.New("unknown format")
```
### 3. 注释规范
- 每个可导出的名字都要有注释，该注释对导出的变量、函数、结构体、接口等进行简要介绍。
- 全部使用单行注释，禁止使用多行注释。
- 和代码的规范一样，单行注释不要过长，禁止超过 120 字符，超过的请使用换行展示，尽量保持格式优雅。
- 注释必须是完整的句子，以需要注释的内容作为开头，句点作为结尾，格式为 // 名称 描述. 。例如：

```go
// bad
// logs the flags in the flagset.
func PrintFlags(flags *pflag.FlagSet) {
  // normal code
}

// good
// PrintFlags logs the flags in the flagset.
func PrintFlags(flags *pflag.FlagSet) {
  // normal code
}
```
所有注释掉的代码在提交 code review 前都应该被删除，否则应该说明为什么不删除，并给出后续处理建议。在多段注释之间可以使用空行分隔加以区分，如下所示：

```go
// Package superman implements methods for saving the world.
//
// Experience has shown that a small number of procedures can prove
// helpful when attempting to save the world.
package superman
```
#### 3.1 包注释
每个包都有且仅有一个包级别的注释。包注释统一用 // 进行注释，格式为 // Package 包名 包描述 ，例如：
```go
// Package genericclioptions contains flags which can be added to you command, bound, completed, and produce
// useful helper functions.
package genericclioptions
```
#### 3.2 变量 / 常量注释
每个可导出的变量 / 常量都必须有注释说明，格式为// 变量名 变量描述，例如：

```go
// ErrSigningMethod defines invalid signing method error.
var ErrSigningMethod = errors.New("Invalid signing method")
```
出现大块常量或变量定义时，可在前面注释一个总的说明，然后在每一行常量的前一行或末尾详细注释该常量的定义，例如：

```go
// Code must start with 1xxxxx.    
const (                         
    // ErrSuccess - 200: OK.          
    ErrSuccess int = iota + 100001    
                                                   
    // ErrUnknown - 500: Internal server error.    
    ErrUnknown    

    // ErrBind - 400: Error occurred while binding the request body to the struct.    
    ErrBind    
                                                  
    // ErrValidation - 400: Validation failed.    
    ErrValidation 
)
```
#### 3.3 结构体注释
- 每个需要导出的结构体或者接口都必须有注释说明，格式为 // 结构体名 结构体描述.。
- 结构体内的可导出成员变量名，如果意义不明确，必须要给出注释，放在成员变量的前一行或同一行的末尾。例如：

```go
// User represents a user restful resource. It is also used as gorm model.
type User struct {
    // Standard object's metadata.
    metav1.ObjectMeta `json:"metadata,omitempty"`

    Nickname string `json:"nickname" gorm:"column:nickname"`
    Password string `json:"password" gorm:"column:password"`
    Email    string `json:"email" gorm:"column:email"`
    Phone    string `json:"phone" gorm:"column:phone"`
    IsAdmin  int    `json:"isAdmin,omitempty" gorm:"column:isAdmin"`
}
```
#### 3.4 方法注释
每个需要导出的函数或者方法都必须有注释，格式为// 函数名 函数描述.，例如：

```go
// BeforeUpdate run before update database record.
func (p *Policy) BeforeUpdate() (err error) {
  // normal code
  return nil
}
```
#### 3.5 类型注释
每个需要导出的类型定义和类型别名都必须有注释说明，格式为 // 类型名 类型描述. ，例如：

```go
// Code defines an error code type.
type Code int
```
### 4. 类型
#### 4.1 字符串
空字符串判断。

```go
// bad
if s == "" {
    // normal code
}

// good
if len(s) == 0 {
    // normal code
}
```
[]byte/string 相等比较。

```go
// bad
var s1 []byte
var s2 []byte
...
bytes.Equal(s1, s2) == 0
bytes.Equal(s1, s2) != 0

// good
var s1 []byte
var s2 []byte
...
bytes.Compare(s1, s2) == 0
bytes.Compare(s1, s2) != 0
```
复杂字符串使用 raw 字符串避免字符转义。

```go
// bad
regexp.MustCompile("\\.")

// good
regexp.MustCompile(`\.`)

```
#### 4.2 切片
空 slice 判断。

```go
// bad
if len(slice) = 0 {
    // normal code
}

// good
if slice != nil && len(slice) == 0 {
    // normal code
}
```
上面判断同样适用于 map、channel。
声明 slice。

```go
// bad
s := []string{}
s := make([]string, 0)

// good
var s []string
```
slice 复制。

```go
// bad
var b1, b2 []byte
for i, v := range b1 {
   b2[i] = v
}
for i := range b1 {
   b2[i] = b1[i]
}

// good
copy(b2, b1)
```
slice 新增。

```go
// bad
var a, b []int
for _, v := range a {
    b = append(b, v)
}

// good
var a, b []int
b = append(b, a...)
```
#### 4.3 结构体
struct 初始化。
struct 以多行格式初始化。

```go
type user struct {
  Id   int64
  Name string
}

u1 := user{100, "Colin"}

u2 := user{
    Id:   200,
    Name: "Lex",
}
```
### 5. 控制结构
#### 5.1 if
if 接受初始化语句，约定如下方式建立局部变量。

```go
if err := loadConfig(); err != nil {
  // error handling
  return err
}
```
if 对于 bool 类型的变量，应直接进行真假判断。

```go
var isAllow bool
if isAllow {
  // normal code
}
```
#### 5.2 for
采用短声明建立局部变量。

```go
sum := 0
for i := 0; i < 10; i++ {
    sum += 1
}
```
不要在 for 循环里面使用 defer，defer 只有在函数退出时才会执行。

```go
// bad
for file := range files {
  fd, err := os.Open(file)
  if err != nil {
    return err
  }
  defer fd.Close()
  // normal code
}

// good
for file := range files {
  func() {
    fd, err := os.Open(file)
    if err != nil {
      return err
    }
    defer fd.Close()
    // normal code
  }()
}
```
#### 5.3 range
如果只需要第一项（key），就丢弃第二个。

```go
for key := range keys {
// normal code
}
```
如果只需要第二项，则把第一项置为下划线。

```go
sum := 0
for _, value := range array {
    sum += value
}
```
#### 5.4 switch
必须要有 default。

```go
switch os := runtime.GOOS; os {
    case "linux":
        fmt.Println("Linux.")
    case "darwin":
        fmt.Println("OS X.")
    default:
        fmt.Printf("%s.\n", os)
}
```
#### 5.5 goto
业务代码禁止使用 goto 。
框架或其他底层源码尽量不用。

### 6. 函数
- 传入变量和返回变量以小写字母开头。
- 函数参数个数不能超过 5 个。
- 函数分组与顺序
  - 函数应按粗略的调用顺序排序。
  - 同一文件中的函数应按接收者分组。
- 尽量采用值传递，而非指针传递。
- 传入参数是 map、slice、chan、interface ，不要传递指针。


#### 6.1 函数参数
如果函数返回相同类型的两个或三个参数，或者如果从上下文中不清楚结果的含义，使用命名返回，其他情况不建议使用命名返回，例如：

```go
func coordinate() (x, y float64, err error) {
  // normal code
}
```
传入变量和返回变量都以小写字母开头。尽量用值传递，非指针传递。参数数量均不能超过 5 个。多返回值最多返回三个，超过三个请使用 struct。


#### 6.2 defer
当存在资源创建时，应紧跟 defer 释放资源 (可以大胆使用 defer，defer 在 Go1.14 版本中，性能大幅提升，defer 的性能损耗即使在性能敏感型的业务中，也可以忽略)。

先判断是否错误，再 defer 释放资源，例如：

```go
rep, err := http.Get(url)
if err != nil {
    return err
}

defer resp.Body.Close()
```
#### 6.3 方法的接收器
- 推荐以类名第一个英文首字母的小写作为接收器的命名。
- 接收器的命名在函数超过 20 行的时候不要用单字符。
- 接收器的命名不能采用 me、this、self 这类易混淆名称。

#### 6.4 嵌套
嵌套深度不能超过 4 层。

#### 6.5 变量命名
变量声明尽量放在变量第一次使用的前面，遵循就近原则。

如果魔法数字出现超过两次，则禁止使用，改用一个常量代替，例如：

```go
// PI ...
const Prise = 3.14

func getAppleCost(n float64) float64 {
  return Prise * n
}

func getOrangeCost(n float64) float64 {
  return Prise * n
}
```
### 7.   GOPATH 设置规范
Go 1.11 之后，弱化了 GOPATH 规则，已有代码（很多库肯定是在 1.11 之前建立的）肯定符合这个规则，建议保留 GOPATH 规则，便于维护代码。建议只使用一个 GOPATH，不建议使用多个 GOPATH。如果使用多个 GOPATH，编译生效的 bin 目录是在第一个 GOPATH 下。

### 8. 依赖管理
Go 1.11 以上必须使用 Go Modules。使用 Go Modules 作为依赖管理的项目时，不建议提交 vendor 目录。使用 Go Modules 作为依赖管理的项目时，必须提交 go.sum 文件。

### 9. 最佳实践
尽量少用全局变量，而是通过参数传递，使每个函数都是“无状态”的。这样可以减少耦合，也方便分工和单元测试。在编译时验证接口的符合性，例如：

```go
type LogHandler struct {
  h   http.Handler
  log *zap.Logger
}
var _ http.Handler = LogHandler{}
```
服务器处理请求时，应该创建一个 context，保存该请求的相关信息（如 requestID），并在函数调用链中传递。

#### 9.1 性能
string 表示的是不可变的字符串变量，对 string 的修改是比较重的操作，基本上都需要重新申请内存。所以，如果没有特殊需要，需要修改时多使用 []byte。

优先使用 strconv 而不是 fmt。

#### 9.2 注意事项
append 要小心自动分配内存，append 返回的可能是新分配的地址。

如果要直接修改 map 的 value 值，则 value 只能是指针，否则要覆盖原来的值。

map 在并发中需要加锁。

编译过程无法检查 interface{} 的转换，只能在运行时检查，小心引起 panic。

### 总结
这一讲，我向你介绍了九类常用的编码规范。但今天的最后，我要在这里提醒你一句：规范是人定的，你也可以根据需要，制定符合你项目的规范。这也是我在之前的课程里一直强调的思路。但同时我也建议你采纳这些业界沉淀下来的规范，并通过工具来确保规范的执行。

## 特别放送 | 给你一份Go项目中最常用的Makefile核心语法

在第 14 讲  里，我强调了熟练掌握 Makefile 语法的重要性，还推荐你去学习陈皓老师编写的《跟我一起写 Makefile》 (PDF 重制版)。也许你已经点开了链接，看到那么多 Makefile 语法，是不是有点被“劝退”的感觉？

其实在我看来，虽然 Makefile 有很多语法，但不是所有的语法都需要你熟练掌握，有些语法在 Go 项目中是很少用到的。要编写一个高质量的 Makefile，首先应该掌握一些核心的、最常用的语法知识。这一讲我就来具体介绍下 Go 项目中常用的 Makefile 语法和规则，帮助你快速打好最重要的基础。

Makefile 文件由三个部分组成，分别是 Makefile 规则、Makefile 语法和 Makefile 命令（这些命令可以是 Linux 命令，也可以是可执行的脚本文件）。在这一讲里，我会介绍下 Makefile 规则和 Makefile 语法里的一些核心语法知识。在介绍这些语法知识之前，我们先来看下如何使用 Makefile 脚本。

### Makefile 的使用方法
在实际使用过程中，我们一般是先编写一个 Makefile 文件，指定整个项目的编译规则，然后通过 Linux make 命令来解析该 Makefile 文件，实现项目编译、管理的自动化。默认情况下，make 命令会在当前目录下，按照 GNUmakefile、makefile、Makefile 文件的顺序查找 Makefile 文件，一旦找到，就开始读取这个文件并执行。大多数的 make 都支持“makefile”和“Makefile”这两种文件名，但我建议使用“Makefile”。因为这个文件名第一个字符大写，会很明显，容易辨别。make 也支持 -f 和 --file 参数来指定其他文件名，比如 make -f golang.mk 或者 make --file golang.mk 。

### Makefile 规则介绍
学习 Makefile，最核心的就是学习 Makefile 的规则。规则是 Makefile 中的重要概念，它一般由目标、依赖和命令组成，用来指定源文件编译的先后顺序。Makefile 之所以受欢迎，核心原因就是 Makefile 规则，因为 Makefile 规则可以自动判断是否需要重新编译某个目标，从而确保目标仅在需要时编译。

这一讲我们主要来看 Makefile 规则里的规则语法、伪目标和 order-only 依赖。

#### 规则语法
Makefile 的规则语法，主要包括 target、prerequisites 和 command，示例如下：

```
target ...: prerequisites ...
    command
    ...
    ...
```
target，可以是一个 object file（目标文件），也可以是一个执行文件，还可以是一个标签（label）。target 可使用通配符，当有多个目标时，目标之间用空格分隔。

prerequisites，代表生成该 target 所需要的依赖项。当有多个依赖项时，依赖项之间用空格分隔。

command，代表该 target 要执行的命令（可以是任意的 shell 命令）。
- 在执行 command 之前，默认会先打印出该命令，然后再输出命令的结果；如果不想打印出命令，可在各个 command 前加上@。
- command 可以为多条，也可以分行写，但每行都要以 tab 键开始。另外，如果后一条命令依赖前一条命令，则这两条命令需要写在同一行，并用分号进行分隔。
- 如果要忽略命令的出错，需要在各个 command 之前加上减号-。


**只要 targets 不存在，或 prerequisites 中有一个以上的文件比 targets 文件新，那么 command 所定义的命令就会被执行，从而产生我们需要的文件，或执行我们期望的操作。**

我们直接通过一个例子来理解下 Makefile 的规则吧。第一步，先编写一个 hello.c 文件。

```go
#include <stdio.h>
int main()
{
  printf("Hello World!\n");
  return 0;
}
```
第二步，在当前目录下，编写 Makefile 文件。

```
hello: hello.o
  gcc -o hello hello.o

hello.o: hello.c
  gcc -c hello.c

clean:
  rm hello.o
```
第三步，执行 make，产生可执行文件。

```
$ make
gcc -c hello.c
gcc -o hello hello.o
$ ls
hello  hello.c  hello.o  Makefile
```
上面的示例 Makefile 文件有两个 target，分别是 hello 和 hello.o，每个 target 都指定了构建 command。当执行 make 命令时，发现 hello、hello.o 文件不存在，就会执行 command 命令生成 target。

第四步，不更新任何文件，再次执行 make。

```
$ make
make: 'hello' is up to date.
```
当 target 存在，并且 prerequisites 都不比 target 新时，不会执行对应的 command。
第五步，更新 hello.c，并再次执行 make。

```
$ touch hello.c
$ make
gcc -c hello.c
gcc -o hello hello.o
```
当 target 存在，但 prerequisites 比 target 新时，会重新执行对应的 command。
第六步，清理编译中间文件。Makefile 一般都会有一个 clean 伪目标，用来清理编译中间产物，或者对源码目录做一些定制化的清理：

```
$ make clean
rm hello.o
```
我们可以在规则中使用通配符，make 支持三个通配符：*，? 和~，例如：
```
objects = *.o
print: *.c
    rm *.c
```
### 伪目标
接下来我们介绍下 Makefile 中的伪目标。Makefile 的管理能力基本上都是通过伪目标来实现的。

在上面的 Makefile 示例中，我们定义了一个 clean 目标，这其实是一个伪目标，也就是说我们不会为该目标生成任何文件。因为伪目标不是文件，make 无法生成它的依赖关系，也无法决定是否要执行它。通常情况下，我们需要显式地标识这个目标为伪目标。在 Makefile 中可以使用.PHONY来标识一个目标为伪目标：

```
.PHONY: clean
clean:
    rm hello.o
```
伪目标可以有依赖文件，也可以作为“默认目标”，例如：


```
.PHONY: all
all: lint test build
```
因为伪目标总是会被执行，所以其依赖总是会被决议。通过这种方式，可以达到同时执行所有依赖项的目的。

### order-only 依赖
在上面介绍的规则中，只要 prerequisites 中有任何文件发生改变，就会重新构造 target。但是有时候，我们希望只有**当 prerequisites 中的部分文件改变时，才重新构造 target。**这时，你可以通过 order-only prerequisites 实现。

order-only prerequisites 的形式如下：


```
targets : normal-prerequisites | order-only-prerequisites
    command
    ...
    ...
```
在上面的规则中，只有第一次构造 targets 时，才会使用 order-only-prerequisites。后面即使 order-only-prerequisites 发生改变，也不会重新构造 targets。只有 normal-prerequisites 中的文件发生改变时，才会重新构造 targets。这里，符号“ | ”后面的 prerequisites 就是 order-only-prerequisites。

到这里，我们就介绍了 Makefile 的规则。接下来，我们再来看下 Makefile 中的一些核心语法知识。

### Makefile 语法概览
因为 Makefile 的语法比较多，这一讲只介绍 Makefile 的核心语法，以及 IAM 项目的 Makefile 用到的语法，包括命令、变量、条件语句和函数。因为 Makefile 没有太多复杂的语法，你掌握了这些知识点之后，再在实践中多加运用，融会贯通，就可以写出非常复杂、功能强大的 Makefile 文件了。

#### 命令
Makefile 支持 Linux 命令，调用方式跟在 Linux 系统下调用命令的方式基本一致。默认情况下，make 会把正在执行的命令输出到当前屏幕上。但我们可以通过在命令前加@符号的方式，禁止 make 输出当前正在执行的命令。我们看一个例子。现在有这么一个 Makefile：

```
.PHONY: test
test:
    echo "hello world"
```
执行 make 命令：

```
$ make test
echo "hello world"
hello world
```
可以看到，make 输出了执行的命令。很多时候，我们不需要这样的提示，因为我们更想看的是命令产生的日志，而不是执行的命令。这时就可以在命令行前加@，禁止 make 输出所执行的命令：

```
.PHONY: test
test:
    @echo "hello world"
```
再次执行 make 命令：

```
$ make test
hello world
```
可以看到，make 只是执行了命令，而没有打印命令本身。这样 make 输出就清晰了很多。

这里，我建议在命令前都加@符号，禁止打印命令本身，以保证你的 Makefile 输出易于阅读的、有用的信息。

默认情况下，每条命令执行完 make 就会检查其返回码。如果返回成功（返回码为 0），make 就执行下一条指令；如果返回失败（返回码非 0），make 就会终止当前命令。很多时候，命令出错（比如删除了一个不存在的文件）时，我们并不想终止，这时就可以在命令行前加 - 符号，来让 make 忽略命令的出错，以继续执行下一条命令，比如：

```
clean:
    -rm hello.o
```
#### 变量
变量，可能是 Makefile 中使用最频繁的语法了，Makefile 支持变量赋值、多行变量和环境变量。另外，Makefile 还内置了一些特殊变量和自动化变量。我们先来看下最基本的变量赋值功能。


Makefile 也可以像其他语言一样支持变量。在使用变量时，会像 shell 变量一样原地展开，然后再执行替换后的内容。Makefile 可以通过变量声明来声明一个变量，变量在声明时需要赋予一个初值，比如ROOT_PACKAGE=github.com/marmotedu/iam。引用变量时可以通过$()或者${}方式引用。我的建议是，用$()方式引用变量，例如$(ROOT_PACKAGE)，也建议整个 makefile 的变量引用方式保持一致。


变量会像 bash 变量一样，在使用它的地方展开。比如：

```
go=go
build:
    $(GO) build -v .
```
展开后为：

```
go=go
build:
    go build -v .
```
接下来，我给你介绍下 Makefile 中的 4 种变量赋值方法。

= 最基本的赋值方法。例如：
```
BASE_IMAGE = alpine:3.10
```
使用 = 进行赋值时，要注意下面这样的情况：

```
A = a
B = $(A) b
A = c
```
B 最后的值为 c b，而不是 a b。也就是说，在用变量给变量赋值时，右边变量的取值，取的是最终的变量值。


:=直接赋值，赋予当前位置的值。例如：

```
A = a
B := $(A) b
A = c
```
B 最后的值为 a b。通过 := 的赋值方式，可以避免 = 赋值带来的潜在的不一致。

?= 表示如果该变量没有被赋值，则赋予等号后的值。例如：

```
PLATFORMS ?= linux_amd64 linux_arm64
```
+=表示将等号后面的值添加到前面的变量上。例如：

```
MAKEFLAGS += --no-print-directory
```
Makefile 还支持多行变量。可以通过 define 关键字设置多行变量，变量中允许换行。定义方式为：
```
define 变量名
变量内容
...
endef
```
变量的内容可以包含函数、命令、文字或是其他变量。例如，我们可以定义一个 USAGE_OPTIONS 变量：

```
define USAGE_OPTIONS

Options:
  DEBUG        Whether to generate debug symbols. Default is 0.
  BINS         The binaries to build. Default is all of cmd.
  ...
  V            Set to 1 enable verbose build. Default is 0.
endef
```
Makefile 还支持环境变量。在 Makefile 中，有两种环境变量，分别是 Makefile 预定义的环境变量和自定义的环境变量。其中，自定义的环境变量可以覆盖 Makefile 预定义的环境变量。默认情况下，Makefile 中定义的环境变量只在当前 Makefile 有效，如果想向下层传递（Makefile 中调用另一个 Makefile），需要使用 export 关键字来声明。

下面的例子声明了一个环境变量，并可以在下层 Makefile 中使用：

```
...
export USAGE_OPTIONS
...
```
此外，Makefile 还支持两种内置的变量：特殊变量和自动化变量。特殊变量是 make 提前定义好的，可以在 makefile 中直接引用。特殊变量列表如下：

![img](https://static001.geekbang.org/resource/image/c1/1d/c1cba21aaed2eb0117yyb0470byy641d.png?wh=1052x978)

Makefile 还支持自动化变量。自动化变量可以提高我们编写 Makefile 的效率和质量。在 Makefile 的模式规则中，目标和依赖文件都是一系列的文件，那么我们如何书写一个命令，来完成从不同的依赖文件生成相对应的目标呢？这时就可以用到自动化变量。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，一直到所有符合模式的文件都取完为止。这种自动化变量只应出现在规则的命令中。Makefile 中支持的自动化变量见下表。

![img](https://static001.geekbang.org/resource/image/13/12/13ec33008eaff973c0dd854a795ff712.png?wh=1263x1303)

上面这些自动化变量中，$*是用得最多的。$* 对于构造有关联的文件名是比较有效的。如果目标中没有模式的定义，那么 $* 也就不能被推导出。但是，如果目标文件的后缀是 make 所识别的，那么 $* 就是除了后缀的那一部分。例如：如果目标是 foo.c ，因为.c 是 make 所能识别的后缀名，所以 $* 的值就是 foo。

#### 条件语句
Makefile 也支持条件语句。这里先看一个示例。下面的例子判断变量ROOT_PACKAGE是否为空，如果为空，则输出错误信息，不为空则打印变量值：

```
ifeq ($(ROOT_PACKAGE),)
$(error the variable ROOT_PACKAGE must be set prior to including golang.mk)
else
$(info the value of ROOT_PACKAGE is $(ROOT_PACKAGE))
endif
```
条件语句的语法为：

```
# if ...
<conditional-directive>
<text-if-true>
endif
# if ... else ...
<conditional-directive>
<text-if-true>
else
<text-if-false>
endif
```
例如，判断两个值是否相等：

```
ifeq 条件表达式
...
else
...
endif
```
- ifeq 表示条件语句的开始，并指定一个条件表达式。表达式包含两个参数，参数之间用逗号分隔，并且表达式用圆括号括起来。
- else 表示条件表达式为假的情况。
- endif 表示一个条件语句的结束，任何一个条件表达式都应该以 endif 结束。
- 表示条件关键字，有 4 个关键字：ifeq、ifneq、ifdef、ifndef。


为了加深你的理解，我们分别来看下这 4 个关键字的例子。

ifeq：条件判断，判断是否相等。例如：

```
ifeq (<arg1>, <arg2>)
ifeq '<arg1>' '<arg2>'
ifeq "<arg1>" "<arg2>"
ifeq "<arg1>" '<arg2>'
ifeq '<arg1>' "<arg2>"
```
比较 arg1 和 arg2 的值是否相同，如果相同则为真。也可以用 make 函数 / 变量替代 arg1 或 arg2，例如 ifeq ($(origin ROOT_DIR),undefined) 或 ifeq ($(ROOT_PACKAGE),) 。origin 函数会在之后专门讲函数的一讲中介绍到。

ifneq：条件判断，判断是否不相等。

```
ifneq (<arg1>, <arg2>)
ifneq '<arg1>' '<arg2>'
ifneq "<arg1>" "<arg2>"
ifneq "<arg1>" '<arg2>'
ifneq '<arg1>' "<arg2>"
```
比较 arg1 和 arg2 的值是否不同，如果不同则为真。

ifdef：条件判断，判断变量是否已定义。

```
ifdef <variable-name>
```
如果值非空，则表达式为真，否则为假。也可以是函数的返回值。

ifndef：条件判断，判断变量是否未定义。

```
ifndef <variable-name>
```
如果值为空，则表达式为真，否则为假。也可以是函数的返回值。


#### 函数
Makefile 同样也支持函数，函数语法包括定义语法和调用语法。我们先来看下自定义函数。 make 解释器提供了一系列的函数供 Makefile 调用，这些函数是 Makefile 的预定义函数。我们可以通过 define 关键字来自定义一个函数。自定义函数的语法为：
```
define 函数名
函数体
endef
```
例如，下面这个自定义函数：

```
define Foo
    @echo "my name is $(0)"
    @echo "param is $(1)"
endef
```
define 本质上是定义一个多行变量，可以在 call 的作用下当作函数来使用，在其他位置使用只能作为多行变量来使用，例如：

```
var := $(call Foo)
new := $(Foo)
```
自定义函数是一种过程调用，没有任何的返回值。可以使用自定义函数来定义命令的集合，并应用在规则中。

再来看下预定义函数。 刚才提到，make 编译器也定义了很多函数，这些函数叫作预定义函数，调用语法和变量类似，语法为：

```
$(<function> <arguments>)
```
或者
```
${<function> <arguments>}
```
< function>是函数名，< arguments>是函数参数，参数间用逗号分割。函数的参数也可以是变量。我们来看一个例子：
```
PLATFORM = linux_amd64
GOOS := $(word 1, $(subst _, ,$(PLATFORM)))
```
上面的例子用到了两个函数：word 和 subst。word 函数有两个参数，1 和 subst 函数的输出。subst 函数将 PLATFORM 变量值中的 _ 替换成空格（替换后的 PLATFORM 值为 linux amd64）。word 函数取 linux amd64 字符串中的第一个单词。所以最后 GOOS 的值为 linux。

Makefile 预定义函数能够帮助我们实现很多强大的功能，在编写 Makefile 的过程中，如果有功能需求，可以优先使用这些函数。如果你想使用这些函数，那就需要知道有哪些函数，以及它们实现的功能。常用的函数包括下面这些，你需要先有个印象，以后用到时再来查看。

![img](https://static001.geekbang.org/resource/image/96/5f/96da0853e8225a656d2c0489e544865f.jpg?wh=2248x3692)


### 引入其他 Makefile
除了 Makefile 规则、Makefile 语法之外，Makefile 还有很多特性，比如可以引入其他 Makefile、自动生成依赖关系、文件搜索等等。这里我再介绍一个 IAM 项目的 Makefile 用到的重点特性：引入其他 Makefile。

在 14 讲 中，我们介绍过 Makefile 要结构化、层次化，这一点可以通过**在项目根目录下的 Makefile 中引入其他 Makefile 来实现。**

在 Makefile 中，我们可以通过关键字 include，把别的 makefile 包含进来，类似于 C 语言的#include，被包含的文件会插入在当前的位置。include 用法为include < filename>，示例如下：


```
include scripts/make-rules/common.mk
include scripts/make-rules/golang.mk
```
include 也可以包含通配符include scripts/make-rules/*。make 命令会按下面的顺序查找 makefile 文件：
1. 如果是绝对或相对路径，就直接根据路径 include 进来。
2. 如果 make 执行时，有-I或--include-dir参数，那么 make 就会在这个参数所指定的目录下去找。
3. 如果目录< prefix>/include（一般是/usr/local/bin或/usr/include）存在的话，make 也会去找。

如果有文件没有找到，make 会生成一条警告信息，但不会马上出现致命错误，而是继续载入其他的文件。一旦完成 makefile 的读取，make 会再重试这些没有找到或是不能读取的文件。如果还是不行，make 才会出现一条致命错误信息。如果你想让 make 忽略那些无法读取的文件继续执行，可以在 include 前加一个减号-，如-include <filename>。

### 总结
在这一讲里，为了帮助你编写一个高质量的 Makefile，我重点介绍了 Makefile 规则和 Makefile 语法里的一些核心语法知识。在讲 Makefile 规则时，我们主要学习了规则语法、伪目标和 order-only 依赖。掌握了这些 Makefile 规则，你就掌握了 Makefile 中最核心的内容。在介绍 Makefile 的语法时，我只介绍了 Makefile 的核心语法，以及 IAM 项目的 Makefile 用到的语法，包括命令、变量、条件语句和函数。你可能会觉得这些语法学习起来比较枯燥，但还是那句话，工欲善其事，必先利其器。希望你能熟练掌握 Makefile 的核心语法，为编写高质量的 Makefile 打好基础。

## 特别放送 | Go Modules依赖包管理全讲

在 Go 项目开发中，依赖包管理是一个非常重要的内容，依赖包处理不好，就会导致编译失败。而且 Go 的依赖包管理有一定的复杂度，所以，我们有必要系统学习下 Go 的依赖包管理工具。这一讲，我会首先介绍下 Go 依赖包管理工具的历史，并详细介绍下目前官方推荐的依赖包管理方案 Go Modules。Go Modules 主要包括了 go mod 命令行工具、模块下载机制，以及两个核心文件 go.mod 和 go.sum。另外，Go Modules 也提供了一些环境变量，用来控制 Go Modules 的行为。这一讲，我会分别介绍下这些内容。在正式开始讲解这些内容之前，我们先来对 Go Modules 有个基本的了解。


### Go Modules 简介
Go Modules 是 Go 官方推出的一个 Go 包管理方案，基于 vgo 演进而来，具有下面这几个特性：

- 可以使包的管理更加简单。
- 支持版本管理。
- 允许同一个模块多个版本共存。
- 可以校验依赖包的哈希值，确保包的一致性，增加安全性。
- 内置在几乎所有的 go 命令中，包括go get、go build、go install、go run、go test、go list等命令。
- 具有 Global Caching 特性，不同项目的相同模块版本，只会在服务器上缓存一份。

在 Go1.14 版本以及之后的版本，Go 官方建议在生产环境中使用 Go Modules。因此，以后的 Go 包管理方案会逐渐统一到 Go Modules。与 Go Modules 相关的概念很多，我在这里把它们总结为“6-2-2-1-1”，这一讲后面还会详细介绍每个概念。

- 六个环境变量：GO111MODULE、GOPROXY、GONOPROXY、GOSUMDB、GONOSUMDB、GOPRIVATE。
- 两个概念：Go module proxy 和 Go checksum database。
- 两个主要文件：go.mod 和 go.sum。
- 一个主要管理命令：go mod。
- 一个 build flag。


### Go 包管理的历史
在具体讲解 Go Modules 之前，我们先看一下 Go 包管理的历史。从 Go 推出之后，因为没有一个统一的官方方案，所以出现了很多种 Go 包管理方案，比较混乱，也没有彻底解决 Go 包管理的一些问题。Go 包管理的历史如下图所示：

![img](https://static001.geekbang.org/resource/image/34/e5/348d772b26940f721c6fb907f6833be5.jpg?wh=2248x739)
这张图展示了 Go 依赖包管理工具经历的几个发展阶段，接下来我会按时间顺序重点介绍下其中的五个阶段。

#### Go1.5 版本前：GOPATH
在 Go1.5 版本之前，没有版本控制，所有的依赖包都放在 GOPATH 下。采用这种方式，无法实现包的多版本管理，并且包的位置只能局限在 GOPATH 目录下。如果 A 项目和 B 项目用到了同一个 Go 包的不同版本，这时候只能给每个项目设置一个 GOPATH，将对应版本的包放在各自的 GOPATH 目录下，切换项目目录时也需要切换 GOPATH。这些都增加了开发和实现的复杂度。

#### Go1.5 版本：Vendoring
Go1.5 推出了 vendor 机制，并在 Go1.6 中默认启用。在这个机制中，每个项目的根目录都可以有一个 vendor 目录，里面存放了该项目的 Go 依赖包。在编译 Go 源码时，Go 优先从项目根目录的 vendor 目录查找依赖；如果没有找到，再去 GOPATH 下的 vendor 目录下找；如果还没有找到，就去 GOPATH 下找。这种方式解决了多 GOPATH 的问题，但是随着项目依赖的增多，vendor 目录会越来越大，造成整个项目仓库越来越大。在 vendor 机制下，一个中型项目的 vendor 目录有几百 M 的大小一点也不奇怪。

#### “百花齐放”：多种 Go 依赖包管理工具出现
这个阶段，社区也出现了很多 Go 依赖包管理的工具，这里我介绍三个比较有名的。- Godep：解决包依赖的管理工具，Docker、Kubernetes、CoreOS 等 Go 项目都曾用过 godep 来管理其依赖。
Govendor：它的功能比 Godep 多一些，通过 vendor 目录下的vendor.json文件来记录依赖包的版本。
Glide：相对完善的包管理工具，通过glide.yaml记录依赖信息，通过glide.lock追踪每个包的具体修改。

Govendor、Glide 都是在 Go 支持 vendor 之后推出的工具，Godep 在 Go 支持 vendor 之前也可以使用。Go 支持 vendor 之后，Godep 也改用了 vendor 模式。


#### Go1.9 版本：Dep
对于从 0 构建项目的新用户来说，Glide 功能足够，是个不错的选择。不过，Golang 依赖管理工具混乱的局面最终由官方来终结了：Golang 官方接纳了由社区组织合作开发的 Dep，作为 official experiment。在相当长的一段时间里，Dep 作为标准，成为了事实上的官方包管理工具。因为 Dep 已经成为了 official experiment 的过去时，现在我们就不必再去深究了，让我们直接去了解谁才是未来的 official experiment 吧。


#### Go1.11 版本之后：Go Modules
Go1.11 版本推出了 Go Modules 机制，Go Modules 基于 vgo 演变而来，是 Golang 官方的包管理工具。在 Go1.13 版本，Go 语言将 Go Modules 设置为默认的 Go 管理工具；在 Go1.14 版本，Go 语言官方正式推荐在生产环境使用 Go Modules，并且鼓励所有用户从其他的依赖管理工具迁移过来。至此，Go 终于有了一个稳定的、官方的 Go 包管理工具。到这里，我介绍了 Go 依赖包管理工具的历史，下面再来介绍下 Go Modules 的使用方法。


#### 包（package）和模块（module）
Go 程序被组织到 Go 包中，Go 包是同一目录中一起编译的 Go 源文件的集合。在一个源文件中定义的函数、类型、变量和常量，对于同一包中的所有其他源文件可见。模块是存储在文件树中的 Go 包的集合，并且文件树根目录有 go.mod 文件。go.mod 文件定义了模块的名称及其依赖包，每个依赖包都需要指定导入路径和语义化版本（Semantic Versioning），通过导入路径和语义化版本准确地描述一个依赖。这里要注意，"module" != "package"，模块和包的关系更像是集合和元素的关系，包属于模块，一个模块是零个或者多个包的集合。下面的代码段，引用了一些包：

```go
import (
    // Go 标准包
    "fmt"

    // 第三方包
    "github.com/spf13/pflag"

    // 匿名包
     _ "github.com/jinzhu/gorm/dialects/mysql"

     // 内部包
    "github.com/marmotedu/iam/internal/apiserver"
)
```
这里的fmt、github.com/spf13/pflag和github.com/marmotedu/iam/internal/apiserver都是 Go 包。Go 中有 4 种类型的包，下面我来分别介绍下。
- Go 标准包：在 Go 源码目录下，随 Go 一起发布的包。
- 第三方包：第三方提供的包，比如来自于 github.com 的包。
- 匿名包：只导入而不使用的包。通常情况下，我们只是想使用导入包产生的副作用，即引用包级别的变量、常量、结构体、接口等，以及执行导入包的init()函数。
- 内部包：项目内部的包，位于项目目录下。

下面的目录定义了一个模块：

```
$ ls hello/
go.mod  go.sum  hello.go  hello_test.go  world
```
hello 目录下有一个 go.mod 文件，说明了这是一个模块，该模块包含了 hello 包和一个子包 world。该目录中也包含了一个 go.sum 文件，该文件供 Go 命令在构建时判断依赖包是否合法。这里你先简单了解下，我会在下面讲 go.sum 文件的时候详细介绍。
### Go Modules 命令
Go Modules 的管理命令为go mod，go mod有很多子命令，你可以通过go help mod来获取所有的命令。下面我来具体介绍下这些命令。

- download：下载 go.mod 文件中记录的所有依赖包。
- edit：编辑 go.mod 文件。
- graph：查看现有的依赖结构。
- init：把当前目录初始化为一个新模块。
- tidy：添加丢失的模块，并移除无用的模块。默认情况下，Go 不会移除 go.mod 文件中的无用依赖。当依赖包不再使用了，可以使用go mod tidy命令来清除它。
- vendor：将所有依赖包存到当前目录下的 vendor 目录下。
- verify：检查当前模块的依赖是否已经存储在本地下载的源代码缓存中，以及检查下载后是否有修改。
- why：查看为什么需要依赖某模块。


### Go Modules 开关
如果要使用 Go Modules，在 Go1.14 中仍然需要确保 Go Modules 特性处在打开状态。你可以通过环境变量 GO111MODULE 来打开或者关闭。GO111MODULE 有 3 个值，我来分别介绍下。
- auto：在 Go1.14 版本中是默认值，在$GOPATH/src下，且没有包含 go.mod 时则关闭 Go Modules，其他情况下都开启 Go Modules。
- on：启用 Go Modules，Go1.14 版本推荐打开，未来版本会设为默认值。
- off：关闭 Go Modules，不推荐。

所以，如果要打开 Go Modules，可以设置环境变量export GO111MODULE=on或者export GO111MODULE=auto，建议直接设置export GO111MODULE=on。Go Modules 使用语义化的版本号，我们开发的模块在发布版本打 tag 的时候，要注意遵循语义化的版本要求，不遵循语义化版本规范的版本号都是无法拉取的。


### 模块下载
在执行 go get 等命令时，会自动下载模块。接下来，我会介绍下 go 命令是如何下载模块的。主要有三种下载方式：通过代理下载；指定版本号下载；按最小版本下载。

#### 通过代理来下载模块
默认情况下，Go 命令从 VCS（Version Control System，版本控制系统）直接下载模块，例如 GitHub、Bitbucket、Bazaar、Mercurial 或者 SVN。在 Go 1.13 版本，引入了一个新的环境变量 GOPROXY，用于设置 Go 模块代理（Go module proxy）。模块代理可以使 Go 命令直接从代理服务器下载模块。GOPROXY 默认值为https://proxy.golang.org,direct，代理服务器可以指定多个，中间用逗号隔开，例如GOPROXY=https://proxy.golang.org,https://goproxy.cn,direct。当下载模块时，会优先从指定的代理服务器上下载。如果下载失败，比如代理服务器不可访问，或者 HTTP 返回码为404或410，Go 命令会尝试从下一个代理服务器下载。

direct 是一个特殊指示符，用来指示 Go 回源到模块的源地址 (比如 GitHub 等) 去抓取 ，当值列表中上一个 Go module proxy 返回 404 或 410，Go 会自动尝试列表中的下一个，遇见 direct 时回源，遇见 EOF 时终止，并抛出类似invalid version: unknown revision...的错误。 如果GOPROXY=off，则 Go 命令不会尝试从代理服务器下载模块。引入 Go module proxy 会带来很多好处，比如：

- 国内开发者无法访问像 golang.org、gopkg.in、go.uber.org 这类域名，可以设置 GOPROXY 为国内可以访问的代理服务器，解决依赖包下载失败的问题。
- Go 模块代理会永久缓存和存储所有的依赖，并且这些依赖一经缓存，不可更改，这也意味着我们不需要再维护一个 vendor 目录，也可以避免因为维护 vendor 目录所带来的存储空间占用。
- 因为依赖永久存在于代理服务器，这样即使模块从互联网上被删除，也仍然可以通过代理服务器获取到。
- 一旦将 Go 模块存储在 Go 代理服务器中，就无法覆盖或删除它，这可以保护开发者免受可能注入相同版本恶意代码所带来的攻击。
- 我们不再需要 VCS 工具来下载依赖，因为所有的依赖都是通过 HTTP 的方式从代理服务器下载。
- 因为 Go 代理通过 HTTP 独立提供了源代码（.zip 存档）和 go.mod，所以下载和构建 Go 模块的速度更快。因为可以独立获取 go.mod（而之前必须获取整个仓库），所以解决依赖也更快。
- 当然，开发者也可以设置自己的 Go 模块代理，这样开发者可以对依赖包有更多的控制，并可以预防 VCS 停机所带来的下载失败。

在实际开发中，我们的很多模块可能需要从私有仓库拉取，通过代理服务器访问会报错，这时候我们需要将这些模块添加到环境变量 GONOPROXY 中，这些私有模块的哈希值也不会在 checksum database 中存在，需要将这些模块添加到 GONOSUMDB 中。一般来说，我建议直接设置 GOPRIVATE 环境变量，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值。

GONOPROXY、GONOSUMDB 和 GOPRIVATE 都支持通配符，多个域名用逗号隔开，例如*.example.com,github.com。对于国内的 Go 开发者来说，目前有 3 个常用的 GOPROXY 可供选择，分别是官方、七牛和阿里云。官方的 GOPROXY，国内用户可能访问不到，所以我更推荐使用七牛的goproxy.cn，goproxy.cn是七牛云推出的非营利性项目，它的目标是为中国和世界上其他地方的 Go 开发者提供一个免费、可靠、持续在线，且经过 CDN 加速的模块代理。

#### 指定版本号下载
通常，我们通过go get来下载模块，下载命令格式为go get <package[@version]>，如下表所示：

![img](https://static001.geekbang.org/resource/image/63/92/63fbbf7cf8b67af85aa4e7ce76a99392.jpg?wh=2248x2048)

你可以使用go get -u更新 package 到 latest 版本，也可以使用go get -u=patch只更新小版本，例如从v1.2.4到v1.2.5。

#### 按最小版本下载
一个模块往往会依赖许多其他模块，并且不同的模块也可能会依赖同一个模块的不同版本，如下图所示：

![img](https://static001.geekbang.org/resource/image/00/46/00794e3487e63d9d3302bfe977af6d46.jpg?wh=2248x1212)
在上述依赖中，模块 A 依赖了模块 B 和模块 C，模块 B 依赖了模块 D，模块 C 依赖了模块 D 和模块 F，模块 D 又依赖了模块 E。并且，同模块的不同版本还依赖了对应模块的不同版本。那么 Go Modules 是如何选择版本的呢？Go Modules 会把每个模块的依赖版本清单都整理出来，最终得到一个构建清单，如下图所示：

![img](https://static001.geekbang.org/resource/image/4f/f2/4f83ffe8125d75764c5f8069a73966f2.jpg?wh=2248x1148)

上图中，rough list 和 final list 的区别在于重复引用的模块 D（v1.3、v1.4），最终清单选用了 D 的v1.4版本。这样做的主要原因有两个。第一个是语义化版本的控制。因为模块 D 的v1.3和v1.4版本变更都属于次版本号的变更，而在语义化版本的约束下，v1.4必须要向下兼容v1.3，因此我们要选择高版本的v1.4。第二个是模块导入路径的规范。主版本号不同，模块的导入路径就不一样。所以，如果出现不兼容的情况，主版本号会改变，例如从 v1 变为 v2，模块的导入路径也就改变了，因此不会影响 v1 版本。

### go.mod 和 go.sum 介绍
在 Go Modules 中，go.mod 和 go.sum 是两个非常重要的文件，下面我就来详细介绍这两个文件。

#### go.mod 文件介绍
go.mod 文件是 Go Modules 的核心文件。下面是一个 go.mod 文件示例：

```
module github.com/marmotedu/iam

go 1.14

require (
  github.com/AlekSi/pointer v1.1.0
  github.com/appleboy/gin-jwt/v2 v2.6.3
  github.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535
  github.com/gin-gonic/gin v1.6.3
  github.com/golangci/golangci-lint v1.30.0 // indirect
  github.com/google/uuid v1.0.0
    github.com/blang/semver v3.5.0+incompatible
    golang.org/x/text v0.3.2
)

replace (
    github.com/gin-gonic/gin => /home/colin/gin
    golang.org/x/text v0.3.2 => github.com/golang/text v0.3.2
)

exclude (
    github.com/google/uuid v1.1.0
)
```
**接下来，我会从 go.mod 语句、go.mod 版本号、go.mod 文件修改方法三个方面来介绍 go.mod。**

go.mod 语句

go.mod 文件中包含了 4 个语句，分别是 module、require、replace 和 exclude。下面我来介绍下它们的功能。

- module：用来定义当前项目的模块路径。
- go：用来设置预期的 Go 版本，目前只是起标识作用。
- require：用来设置一个特定的模块版本，格式为<导入包路径> <版本> [// indirect]。
- exclude：用来从使用中排除一个特定的模块版本，如果我们知道模块的某个版本有严重的问题，就可以使用 exclude 将该版本排除掉。
- replace：用来将一个模块版本替换为另外一个模块版本。格式为 $module => $newmodule ，$newmodule可以是本地磁盘的相对路径，例如github.com/gin-gonic/gin => ./gin。也可以是本地磁盘的绝对路径，例如github.com/gin-gonic/gin => /home/lk/gin。还可以是网络路径，例如golang.org/x/text v0.3.2 => github.com/golang/text v0.3.2。

这里需要注意，虽然我们用$newmodule替换了$module，但是在代码中的导入路径仍然为$module。replace 在实际开发中经常用到，下面的场景可能需要用到 replace：
- 在开启 Go Modules 后，缓存的依赖包是只读的，但在日常开发调试中，我们可能需要修改依赖包的代码来进行调试，这时可以将依赖包另存到一个新的位置，并在 go.mod 中替换这个包。
- 如果一些依赖包在 Go 命令运行时无法下载，就可以通过其他途径下载该依赖包，上传到开发构建机，并在 go.mod 中替换为这个包。
- 在项目开发初期，A 项目依赖 B 项目的包，但 B 项目因为种种原因没有 push 到仓库，这时也可以在 go.mod 中把依赖包替换为 B 项目的本地磁盘路径。
- 在国内访问 golang.org/x 的各个包都需要翻墙，可以在 go.mod 中使用 replace，替换成 GitHub 上对应的库，例如golang.org/x/text v0.3.0 => github.com/golang/text v0.3.0。

有一点要注意，exclude 和 replace 只作用于当前主模块，不影响主模块所依赖的其他模块。

go.mod 版本号
go.mod 文件中有很多版本号格式，我知道在平时使用中，有很多开发者对此感到困惑。这里，我来详细说明一下。
- 如果模块具有符合语义化版本格式的 tag，会直接展示 tag 的值，例如 github.com/AlekSi/pointer v1.1.0 。
- 除了 v0 和 v1 外，主版本号必须显试地出现在模块路径的尾部，例如github.com/appleboy/gin-jwt/v2 v2.6.3。
- 对于没有 tag 的模块，Go 命令会选择 master 分支上最新的 commit，并根据 commit 时间和哈希值生成一个符合语义化版本的版本号，例如github.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535。
- 如果模块名字跟版本不符合规范，例如模块的名字为github.com/blang/semver，但是版本为 v3.5.0（正常应该是github.com/blang/semver/v3），go 会在 go.mod 的版本号后加+incompatible表示。
- 如果 go.mod 中的包是间接依赖，则会添加// indirect注释，例如github.com/golangci/golangci-lint v1.30.0 // indirect。

这里要注意，Go Modules 要求模块的版本号格式为v< major>.< minor>.< patch>，如果< major>版本号大于 1，它的版本号还要体现在模块名字中，例如模块github.com/blang/semver版本号增长到v3.x.x，则模块名应为github.com/blang/semver/v3。

这里再详细介绍下出现// indirect的情况。原则上 go.mod 中出现的都是直接依赖，但是下面的两种情况只要出现一种，就会在 go.mod 中添加间接依赖。
- 直接依赖未启用 Go Modules：如果模块 A 依赖模块 B，模块 B 依赖 B1 和 B2，但是 B 没有 go.mod 文件，则 B1 和 B2 会记录到 A 的 go.mod 文件中，并在最后加上// indirect。
- 直接依赖 go.mod 文件中缺失部分依赖：如果模块 A 依赖模块 B，模块 B 依赖 B1 和 B2，B 有 go.mod 文件，但是只有 B1 被记录在 B 的 go.mod 文件中，这时候 B2 会被记录到 A 的 go.mod 文件中，并在最后加上// indirect。


go.mod 文件修改方法
要修改 go.mod 文件，我们可以采用下面这三种方法：

- Go 命令在运行时自动修改。
- 手动编辑 go.mod 文件，编辑之后可以执行go mod edit -fmt格式化 go.mod 文件。
- 执行 go mod 子命令修改。

在实际使用中，我建议你采用第三种修改方法，和其他两种相比不太容易出错。使用方式如下：

```
go mod edit -fmt  # go.mod 格式化
go mod edit -require=golang.org/x/text@v0.3.3  # 添加一个依赖
go mod edit -droprequire=golang.org/x/text # require的反向操作，移除一个依赖
go mod edit -replace=github.com/gin-gonic/gin=/home/colin/gin # 替换模块版本
go mod edit -dropreplace=github.com/gin-gonic/gin # replace的反向操作
go mod edit -exclude=golang.org/x/text@v0.3.1 # 排除一个特定的模块版本
go mod edit -dropexclude=golang.org/x/text@v0.3.1 # exclude的反向操作
```
#### go.sum 文件介绍
Go 会根据 go.mod 文件中记载的依赖包及其版本下载包源码，但是下载的包可能被篡改，缓存在本地的包也可能被篡改。单单一个 go.mod 文件，不能保证包的一致性。为了解决这个潜在的安全问题，Go Modules 引入了 go.sum 文件。

go.sum 文件用来记录每个依赖包的 hash 值，在构建时，如果本地的依赖包 hash 值与go.sum文件中记录的不一致，则会拒绝构建。go.sum 中记录的依赖包是所有的依赖包，包括间接和直接的依赖包。这里提示下，为了避免已缓存的模块被更改，$GOPATH/pkg/mod下缓存的包是只读的，不允许修改。

接下来我从 go.sum 文件内容、go.sum 文件生成、校验三个方面来介绍 go.sum。

go.sum 文件内容
下面是一个 go.sum 文件的内容：
```
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c h1:qgOY6WgZOaTkIIMiVjBQcw93ERBE4m30iBm00nkL0i8=
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=
rsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=
rsc.io/sampler v1.3.0 h1:7uVkIFmeBqHfdjD+gZwtXXI+RODJ2Wc4O7MPEh/QiW4=
rsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=
```
go.sum 文件中，每行记录由模块名、版本、哈希算法和哈希值组成，如< module> < version>[/go.mod] <algorithm>:<hash>。目前，从 Go1.11 到 Go1.14 版本，只有一个算法 SHA-256，用 h1 表示。

正常情况下，每个依赖包会包含两条记录，分别是依赖包所有文件的哈希值和该依赖包 go.mod 的哈希值，例如：


```
rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=
rsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=
```
但是，如果一个依赖包没有 go.mod 文件，就只记录依赖包所有文件的哈希值，也就是只有第一条记录。额外记录 go.mod 的哈希值，主要是为了在计算依赖树时不必下载完整的依赖包版本，只根据 go.mod 即可计算依赖树。

go.sum 文件生成
在 Go Modules 开启时，如果我们的项目需要引入一个新的包，通常会执行go get命令，例如：

```
$ go get rsc.io/quote
```
当执行go get rsc.io/quote命令后，go get命令会先将依赖包下载到$GOPATH/pkg/mod/cache/download，下载的依赖包文件名格式为$version.zip，例如v1.5.2.zip。

下载完成之后，go get会对该 zip 包做哈希运算，并将结果存在$version.ziphash文件中，例如v1.5.2.ziphash。如果在项目根目录下执行go get命令，则go get会同时更新 go.mod 和 go.sum 文件。例如，go.mod 新增一行require rsc.io/quote v1.5.2，go.sum 新增两行：

```
rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=
rsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=
```
校验
在我们执行构建时，go 命令会从本地缓存中查找所有的依赖包，并计算这些依赖包的哈希值，然后与 go.sum 中记录的哈希值进行对比。如果哈希值不一致，则校验失败，停止构建。

校验失败可能是因为本地指定版本的依赖包被修改过，也可能是 go.sum 中记录的哈希值是错误的。但是 Go 命令倾向于相信依赖包被修改过，因为当我们在 go get 依赖包时，包的哈希值会经过校验和数据库（checksum database）进行校验，校验通过才会被加入到 go.sum 文件中。也就是说，go.sum 文件中记录的哈希值是可信的。

校验和数据库可以通过环境变量GOSUMDB指定，GOSUMDB的值是一个 web 服务器，默认值是sum.golang.org。该服务可以用来查询依赖包指定版本的哈希值，保证拉取到的模块版本数据没有经过篡改。

如果设置GOSUMDB为off，或者使用go get的时候启用了-insecure参数，Go 就不会去对下载的依赖包做安全校验，这存在一定的安全隐患，所以我建议你开启校验和数据库。如果对安全性要求很高，同时又访问不了sum.golang.org，你也可以搭建自己的校验和数据库。

值得注意的是，Go checksum database 可以被 Go module proxy 代理，所以当我们设置了GOPROXY后，通常情况下不用再设置GOSUMDB。还要注意的是，go.sum 文件也应该提交到你的 Git 仓库中去。


### 模块下载流程
上面，我介绍了模块下载的整体流程，还介绍了 go.mod 和 go.sum 这两个文件。因为内容比较多，这里用一张图片来做个总结：

![img](https://static001.geekbang.org/resource/image/8b/8d/8b92e53cebd4373f8c41fdbe9328ba8d.jpg?wh=2248x1077)

最后还想介绍下 Go modules 的全局缓存。Go modules 中，相同版本的模块只会缓存一份，其他所有模块公用。目前，所有模块版本数据都缓存在 $GOPATH/pkg/mod 和 $GOPATH/pkg/sum 下，未来有可能移到 $GOCACHE/mod 和 $GOCACHE/sum 下，我认为这可能发生在 GOPATH 被淘汰后。你可以使用 go clean -modcache 清除所有的缓存。

### 总结
Go 依赖包管理是 Go 语言中一个重点的功能。在 Go1.11 版本之前，并没有官方的依赖包管理工具，业界虽然存在多个 Go 依赖包管理方案，但效果都不理想。直到 Go1.11 版本，Go 才推出了官方的依赖包管理工具，Go Modules。这也是我建议你在进行 Go 项目开发时选择的依赖包管理工具。


Go Modules 提供了 go mod 命令，来管理 Go 的依赖包。 go mod 有很多子命令，这些子命令可以完成不同的功能。例如，初始化当前目录为一个新模块，添加丢失的模块，移除无用的模块，等等。

在 Go Modules 中，有两个非常重要的文件：go.mod 和 go.sum。go.mod 文件是 Go Modules 的核心文件，Go 会根据 go.mod 文件中记载的依赖包及其版本下载包源码。go.sum 文件用来记录每个依赖包的 hash 值，在构建时，如果本地的依赖包 hash 值与 go.sum 文件中记录的不一致，就会拒绝构建。

Go 在下载依赖包时，可以通过代理来下载，也可以指定版本号下载。如果不指定版本号，Go Modules 会根据自定义的规则，选择最小版本来下载。


## 特别放送 | IAM排障指南

今天我们更新一期特别放送作为加餐。在部署和使用 IAM 的过程中，难免会出现一些异常 (也称为故障、问题)。这时候，就需要我们能够定位故障，并修复故障。这里，我总结了一些 IAM 的排障方法，以及一些常见故障的解决方法，供你参考。

### 如何排障？
首先，我们需要发现问题，然后定位问题。我们可能需要经过多轮分析排查才能定位到问题的根因，最后去解决问题。排障流程如下图所示：

![img](https://static001.geekbang.org/resource/image/73/0f/7330d836e7c4b5052c79bbd365abdd0f.jpg?wh=2248x535)


如果想排查问题并解决问题，你还需要具备这两个基本能力：**能够理解错误日志的内容；根据错误日志，找出解决方案**。我们举个例子来说吧。有以下错误：

```
[going@dev iam]$ mysql -h127.0.0.1 -uroot -p'iam59!z$'
bash: /usr/bin/mysql: 没有那个文件或目录
[going@dev iam]$
```
对于这个错误，我们首先来理解错误内容：mysql 命令没有找到，说明没有安装 mysql，或者安装 mysql 失败。那么，我们的解决方案就是重新执行 03 讲 中安装 MariaDB 的步骤：

```
$ cd $IAM_ROOT
$ ./scripts/install/mariadb.sh iam::mariadb::install
```
接下来，我会以iam-apiserver服务为例，给你演示下具体如何排障并解决问题。


#### 发现问题
要排障，首先我们需要发现问题。我们通常用下面这几种方式来发现问题。

- 检查服务状态：启动 iam-apiserver 服务后，执行systemctl status iam-apiserver 发现 iam-apiserver 启动失败，即Active的值不为active (running)。
- 功能异常：访问 iam-apiserver 服务，功能异常或者报错，例如接口返回值跟预期不一样等。
- 日志报错：在 iam-apiserver 的日志中发现一些WARN、ERROR、PANIC、FATAL等级别的错误日志。

#### 定位问题
发现问题之后，就需要我们定位出问题的根本原因。我们可以通过下面这三种方式来定位问题。

- 查看日志，它是最简单的排障方式。
- 使用 Go 调试工具 Delve 来定位问题。
- 添加 Debug 日志，从程序入口处跟读代码，在关键位置处打印 Debug 日志，来定位问题。

在定位问题的过程中，我们可以采用“顺藤摸瓜”的思路去排查问题。比如，我们的程序执行流程是：A -> B -> … -> N。其中 A、B、N 都可以理解为一个排查点。所谓的排查点，就是需要在该处定位问题的点，这些点可能是导致问题的根因所在。

在排障过程中，你可以根据最上层的日志报错，找到下一个排查点 B。如果经过定位，发现 B 没有问题，那继续根据程序执行流程，找下一个排查点排查问题。如此反复，直到找到最终的排查点，也就是出问题的根因 N，N 即为 Bug 点。执行流程如下图所示：

![img](https://static001.geekbang.org/resource/image/cc/6d/cc26b83cb2177106695e1a9f7f09ae6d.jpg?wh=2248x931)


下面，我们来具体看看这三种定位问题的方法。

##### 查看日志定位问题
我们首先应该通过日志来定位问题，这是最简单高效的方式。要通过日志来定位问题，你不仅要会看日志，还要能读懂日志，也就是理解日志报错的原因。下面我来具体讲解用这种方法定位问题的步骤。

第一步，确保服务运行正常。你可以通过执行 systemctl status 命令来查看服务的运行状况：

```
$ systemctl status iam-apiserver
● iam-apiserver.service - IAM APIServer
   Loaded: loaded (/etc/systemd/system/iam-apiserver.service; enabled; vendor preset: disabled)
   Active: activating (auto-restart) (Result: exit-code) since Thu 2021-09-09 13:47:56 CST; 2s ago
     Docs: https://github.com/marmotedu/iam/blob/master/init/README.md
  Process: 119463 ExecStart=/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml (code=exited, status=1/FAILURE)
  Process: 119461 ExecStartPre=/usr/bin/mkdir -p /var/log/iam (code=exited, status=0/SUCCESS)
  Process: 119460 ExecStartPre=/usr/bin/mkdir -p /data/iam/iam-apiserver (code=exited, status=0/SUCCESS)
 Main PID: 119463 (code=exited, status=1/FAILURE)
```
可以看到，Active不是active (running)，说明 iam-apiserver 服务没有正常运行。从上面输出中的Process: 119463 ExecStart=/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml (code=exited, status=1/FAILURE)信息中，我们可以获取以下信息：
- iam-apiserver 服务启动命令为/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml。
- /opt/iam/bin/iam-apiserver加载的配置文件为/etc/iam/iam-apiserver.yaml。
- /opt/iam/bin/iam-apiserver命令执行失败，退出码为 1，其进程 ID 为119463。

这里注意，systemctl status会将超过一定长度的行的后半部分用省略号替代，如果想查看完整的信息，可以追加-l参数，也就是systemctl status -l来查看。既然 iam-apiserver 命令启动失败，那我们就需要查看 iam-apiserver 启动时的日志，看看有没有一些报错日志。


接下来，就进入第二步，查看iam-apiserver运行日志。
这里提一句，如果你对 systemd 不了解，也可以趁机恶补一波。你可以参考阮一峰大佬的两篇博客：[Systemd 入门教程：命令篇](https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)和[Systemd 入门教程：实战篇](https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html)。

那么如何查看呢？我们有 3 种查看方式，我在下面按优先级顺序排列了下。你在定位问题和查看日志时，按优先级 3 选 1 即可，1 > 2 > 3。
1. 通过journalctl -u iam-apiserver查看。
2. 通过 iam-apiserver 日志文件查看。
3. 通过 console 查看。

下面我来分别介绍下这三种查看方式。先来看优先级最高的方式，通过journalctl -u iam-apiserver查看。

systemd 提供了自己的日志系统，称为 journal。我们可以使用journalctl命令来读取 journal 日志。journalctl提供了-u选项来查看某个 Unit 的日志，提供了_PID来查看指定进程 ID 的日志。在第一步中，我们知道服务启动失败的进程 ID 为119463。执行以下命令来查看这次启动的日志：

```
$ sudo journalctl _PID=119463
-- Logs begin at Thu 2021-09-09 09:12:25 CST, end at Thu 2021-09-09 14:40:48 CST. --
...
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: 2021-09-09 13:47:56.727        INFO        apiserver        gorm@v1.21.12/gorm.go:202        mysql/mysql.go:75[error] faile>
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: 2021-09-09 13:47:56.727        FATAL        apiserver        apiserver/server.go:139        Failed to get cache instance: g>
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.createAPIServer
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.Run
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.run.func1
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/pkg/app.(*App).runCommand
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).execute
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).ExecuteC
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).Execute
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/pkg/app.(*App).Run
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: main.main
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: runtime.main
Sep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/go/go1.16.2/src/runtime/proc.go:225
lines 10-54/54 (END)

```
从上面的日志中，我们找到了服务启动失败的原因：iam-apiserver启动时，发生了FATAL级别的错误。到这里，你已经初步定位到问题原因了。

我们再来看通过 iam-apiserver 日志文件查看的方式。

作为一个企业级的实战项目，iam-apiserver 的日志当然是会记录到日志文件中的。在第一步中，我们通过systemctl status iam-apiserver输出的信息，知道了 iam-apiserver 启动时加载的配置文件为/etc/iam/iam-apiserver.yaml。所以，我们可以通过 iam-apiserver 的配置文件 iam-apiserver.yaml 中的log.output-paths配置项，查看记录日志文件的位置：

```
log:
    name: apiserver # Logger的名字
    development: true # 是否是开发模式。如果是开发模式，会对DPanicLevel进行堆栈跟踪。
    level: debug # 日志级别，优先级从低到高依次为：debug, info, warn, error, dpanic, panic, fatal。
    format: console # 支持的日志输出格式，目前支持console和json两种。console其实就是text格式。
    enable-color: true # 是否开启颜色输出，true:是，false:否
    disable-caller: false # 是否开启 caller，如果开启会在日志中显示调用日志所在的文件、函数和行号
    disable-stacktrace: false # 是否在panic及以上级别禁止打印堆栈信息
    output-paths: /var/log/iam/iam-apiserver.log,stdout # 支持输出到多个输出，逗号分开。支持输出到标准输出（stdout）和文件。
    error-output-paths: /var/log/iam/iam-apiserver.error.log # zap内部(非业务)错误日志输出路径，多个输出，逗号分开
```
可以看到，iam-apiserver 将日志分别记录到了/var/log/iam/iam-apiserver.log和stdout中。所以，我们可以通过查看/var/log/iam/iam-apiserver.log日志文件，来查看报错信息：

```
$ tail -25 /var/log/iam/iam-apiserver.log
...
2021-09-09 15:42:35.231  INFO  apiserver  server/genericapiserver.go:88  GET    /version --> github.com/marmotedu/iam/internal/pkg/server.(*GenericAPIServer).InstallAPIs.func2 (10 handlers)
2021-09-09 15:42:35.232  INFO  apiserver  gorm@v1.21.12/gorm.go:202  mysql/mysql.go:75[error] failed to initialize database, got error dial tcp 127.0.0.1:3309: connect: connection refused
2021-09-09 15:42:35.232  FATAL  apiserver  apiserver/server.go:139  Failed to get cache instance: got nil cache server
github.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139
github.com/marmotedu/iam/internal/apiserver.createAPIServer
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66
github.com/marmotedu/iam/internal/apiserver.Run
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11
github.com/marmotedu/iam/internal/apiserver.run.func1
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46
github.com/marmotedu/iam/pkg/app.(*App).runCommand
  /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278
github.com/spf13/cobra.(*Command).execute
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856
github.com/spf13/cobra.(*Command).ExecuteC
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974
github.com/spf13/cobra.(*Command).Execute
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902
github.com/marmotedu/iam/pkg/app.(*App).Run
  /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233
main.main
  /home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24
runtime.main
  /home/going/go/go1.16.2/src/runtime/proc.go:225
```
我们再来看最后一种查看方式，通过 console 查看。当然，我们也可以直接通过 console 来看日志，这就需要我们在 Linux 终端前台运行 iam-apiserver（在第一步中，我们已经知道了启动命令）：

```
$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml
...
2021-09-09 15:47:00.660  INFO  apiserver  server/genericapiserver.go:88  GET    /debug/pprof/mutex --> github.com/gin-contrib/pprof.pprofHandler.func1 (10 handlers)
2021-09-09 15:47:00.660  INFO  apiserver  server/genericapiserver.go:88  GET    /debug/pprof/threadcreate --> github.com/gin-contrib/pprof.pprofHandler.func1 (10 handlers)
2021-09-09 15:47:00.660  INFO  apiserver  server/genericapiserver.go:88  GET    /version --> github.com/marmotedu/iam/internal/pkg/server.(*GenericAPIServer).InstallAPIs.func2 (10 handlers)
2021-09-09 15:47:00.661  INFO  apiserver  gorm@v1.21.12/gorm.go:202  mysql/mysql.go:75[error] failed to initialize database, got error dial tcp 127.0.0.1:3309: connect: connection refused
2021-09-09 15:47:00.661  FATAL  apiserver  apiserver/server.go:139  Failed to get cache instance: got nil cache server
github.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139
github.com/marmotedu/iam/internal/apiserver.createAPIServer
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66
github.com/marmotedu/iam/internal/apiserver.Run
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11
github.com/marmotedu/iam/internal/apiserver.run.func1
  /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46
github.com/marmotedu/iam/pkg/app.(*App).runCommand
  /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278
github.com/spf13/cobra.(*Command).execute
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856
github.com/spf13/cobra.(*Command).ExecuteC
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974
github.com/spf13/cobra.(*Command).Execute
  /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902
github.com/marmotedu/iam/pkg/app.(*App).Run
  /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233
main.main
  /home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24
runtime.main
  /home/going/go/go1.16.2/src/runtime/proc.go:225

```
通过上面这 3 种查看方式，我们均能初步定位到服务异常的原因。

##### 使用 Go 调试工具 Delve 来定位问题
查看日志是最简单的排障方式，通过查看日志，我们可能定位出问题的根本原因，这种情况下问题就能得到快速的解决。但有些情况下，我们通过日志并不一定能定位出问题，例如：

- 程序异常，但是没有错误日志。
- 日志有报错，但只能判断问题的面，还不能精准找到问题的根因。

遇到上面这两种情况，我们都需要再进一步地定位问题。这时候，我们可以使用 Delve 调试工具来尝试定位问题。Delve 工具的用法你可以参考 [Delve 使用详解。](https://github.com/marmotedu/geekbang-go/blob/master/Delve%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3.md)


##### 添加 Debug 日志定位问题
如果使用 Delve 工具仍然没有定位出问题，接下来你可以尝试最原始的方法：添加 Debug 日志来定位问题。这种方法具体可以分为两个步骤。


**第一步，在关键代码段添加 Debug 日志。**你需要根据自己对代码的理解来决定关键代码段。如果不确定哪段代码出问题，可以从请求入口处添加 Debug 日志，然后跟着代码流程一步步往下排查，并在需要的地方添加 Debug 日志。

例如，通过排查日志，我们定位到internal/apiserver/server.go:139位置的代码导致程序 FATAL，FATAL 原因是Failed to get cache instance: got nil cache server。cache server是nil，说明cache server没有被初始化。查看cache server初始化函数：

```go
func GetCacheInsOr(store store.Factory) (*Cache, error) {
    if store != nil {
        once.Do(func() {
            cacheServer = &Cache{store}
        })
    }

    if cacheServer == nil {
        return nil, fmt.Errorf("got nil cache server")
    }

    return cacheServer, nil
}
```
我们不难分析出，是store == nil导致cacheServer没有被初始化。再来看下 store 的初始化代码，并加一些 Debug 日志，如下图所示：

![img](https://static001.geekbang.org/resource/image/cc/15/cc50c340e4ff0e5401b3d89430456b15.png?wh=1669x1025)

我们添加完 Debug 代码后，就可以重新编译并运行程序了。这里有个小技巧：可以在错误返回的位置添加 Debug 日志，这样能大概率帮助你定位到出错的位置，例如：

```go
if err != nil {
  log.Debugf("DEBUG POINT - 1: %v", err)
  return err
}
```
**第二步，重新编译源码，并启动**。这里为了调试、看日志方便，我们直接在 Linux 终端的前端运行 iam-apiserver：

```
$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml
```
查看我们添加的 Debug 日志打印的内容，如下图所示：

![img](https://static001.geekbang.org/resource/image/61/03/61f31a4b9e45ed9079470e928f7d3b03.png?wh=1920x265)

从 Debug 日志中，可以看到用来创建 MySQL 实例的端口是错误的，正确的端口应该是3306，而不是3309。MySQL 服务器的端口是在 iam-apiserver.yaml 中配置的。修改 iam-apiserver.yaml 为正确的配置，并启动：

```
$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml

```
再次查看 console 日志，如下图所示：

![img](https://static001.geekbang.org/resource/image/f7/9d/f72b766b7504016259bef04eb03dac9d.png?wh=1920x271)

可以看到问题已经修复，dbIns不为nil，程序正常运行：

```
$ systemctl status iam-apiserver
● iam-apiserver.service - IAM APIServer
   Loaded: loaded (/etc/systemd/system/iam-apiserver.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2021-09-09 20:48:18 CST; 17s ago
     Docs: https://github.com/marmotedu/iam/blob/master/init/README.md
  Process: 255648 ExecStartPre=/usr/bin/mkdir -p /var/log/iam (code=exited, status=0/SUCCESS)
  Process: 255647 ExecStartPre=/usr/bin/mkdir -p /data/iam/iam-apiserver (code=exited, status=0/SUCCESS)
 Main PID: 255650 (iam-apiserver)
    Tasks: 5 (limit: 23724)
   Memory: 7.3M
   CGroup: /system.slice/iam-apiserver.service
           └─255650 /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml
```
在这里，Active为active (running)状态。因为这些 Debug 日志能够协助你定位问题，从侧面说明这些日志是有用的，所以你可以保留这些 Debug 日志调用代码。


##### 解决问题
在定位问题阶段，我们已经找到了问题的原因，接下来就可以根据自己对业务、底层代码实现的掌握和理解，修复这个问题了。至于怎么修复，你需要结合具体情况来判断，并没有统一的流程和方法论，这里就不多介绍了。上面，我介绍了排查问题的思路和方法。接下来，我来向你展示 9 个在部署和使用 IAM 系统时容易遇到的问题，并提供解决方法。这些问题基本上都是由服务器环境引起的。

### IAM 常见故障及解决办法
问题一：安装 neovim，报 No match for argument: neovim 错误。
解决方法是安装 EPEL 源：

```
$ sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm
```
问题二：安装 protoc-gen-go 失败（超时、报错等）。这个故障出现，可能是因为你当前服务器所在的网络环境无法访问github.com，或者访问github.com速度太慢。解决方法是手动编译安装，方法如下：

```
$ git clone --depth 1 https://github.com/golang/protobuf $GOPATH/src/github.com/golang/protobuf
$ cd $GOPATH/src/github.com/golang/protobuf/protoc-gen-go
$ go install -v .
```
问题三：遇到xxx: permission denied这类的错误。出现这种错误，是因为你没有权限执行当前的操作。解决方法是排查自己是否有权限执行当前操作。如果没有权限，需要你切换到有权限的用户，或者放弃执行当前操作。为了说明问题，这里我举一个错误例子，并给出排查思路。例子的错误日志如下：

```
[going@VM-8-9-centos /]$ go get -u github.com/golang/protobuf/protoc-gen-go
go: could not create module cache: mkdir /golang: permission denied
[going@VM-8-9-centos /]$ sudo go get -u github.com/golang/protobuf/protoc-gen-go
sudo: go: command not found
```
上述错误中， 一共报了两个错误，分别是mkdir /golang: permission denied和sudo: go: command not found。我们先来看mkdir /golang: permission denied错误。

通过命令行提示符$可以知道，当前登陆用户是普通用户；通过报错mkdir /golang: permission denied可以知道go get -u github.com/golang/protobuf/protoc-gen-go命令底层执行了mkdir /golang，因为普通用户没有写/ 目录的权限，所以会报权限错误。解决方法是切换到用户的目录下，执行go get -u命令。

我们再来看下sudo: go: command not found错误。sudo命令会将命令执行的环境切换到root用户，root用户显然是没有安装go命令的，所以会导致command not found错误。解决方式是去掉 sudo ，直接执行 $ go get -u xxx 。

问题四：VimIDE 使用过程中，报各类错误。这里的报错原因跟环境有关系，安装 VimIDE 时的系统环境、包的版本等等，都可能会导致使用 VimIDE 报错。因为错误类型太多，没法一一说明，所以我建议你忽略这些错误，其实完全不影响后面的学习。

问题五：访问 iam-authz-server 的/v1/authz接口报{"code":100202,"message":"Signature is invalid"}。这时可能是签发的 Token 有问题，建议重新执行以下 5 个步骤：

重新登陆系统，并获取访问令牌：
```
$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{"username":"admin","password":"Admin@2021"}' http://127.0.0.1:8080/login | jq -r .token`
```
如果没有安装jq命令，可以执行sudo yum -y install jq命令来安装。

创建授权策略：

```
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"policy":{"description":"One policy to rule them all.","subjects":["users:<peter|ken>","users:maria","groups:admins"],"actions":["delete","<create|update>"],"effect":"allow","resources":["resources:articles:<.*>","resources:printer"],"conditions":{"remoteIPAddress":{"type":"CIDRCondition","options":{"cidr":"192.168.0.1/16"}}}}}' http://127.0.0.1:8080/v1/policies
```
创建密钥，并从命令的输出中提取 secretID 和 secretKey：

```
$ curl -s -XPOST -H"Content-Type: application/json" -H"Authorization: Bearer $token" -d'{"metadata":{"name":"authztest"},"expires":0,"description":"admin secret"}' http://127.0.0.1:8080/v1/secrets
{"metadata":{"id":23,"name":"authztest","createdAt":"2021-04-08T07:24:50.071671422+08:00","updatedAt":"2021-04-08T07:24:50.071671422+08:00"},"username":"admin","secretID":"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox","secretKey":"7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8","expires":0,"description":"admin secret"}
```
生成访问 iam-authz-server 的 Token
iamctl 提供了 jwt sigin 命令，你可以根据 secretID 和 secretKey 签发 Token，方便你使用。签发 Token 的具体命令如下：

```
$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey
eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ
```
测试资源授权是否通过：


```
$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{"subject":"users:maria","action":"delete","resource":"resources:articles:ladon-introduction","context":{"remoteIPAddress":"192.168.0.5"}}' http://127.0.0.1:9090/v1/authz
{"allowed":true}
```
问题六：执行iamctl user list报error: {"code":100207,"message":"Permission denied"}。出现这种情况，可能是密码没有配置正确。你可以看下$HOME/.iam/iamctl.yaml配置文件中的用户名和密码配置的是不是 admin，以及 admin 的密码是否是Admin@2021。

问题七：在创建用户时报{"code":100101,"message":"Database error"}错误。出现这种情况，可能是用户名重了，建议换个新的用户名再次创建。


问题八：报No such file or directory、command not found、permission denied错误。遇到这类错误，要根据提示排查和解决问题。

- No such file or directory：确认文件是否存在，不存在的原因是什么。
- command not found：确认命令是否存在，如果不存在，可以重新安装命令。
- permission denied：确认是否有操作权限，如果没有，要切换到有权限的用户或者目录。

问题九：报iam-apiserver.service、/opt/iam/bin/iam-apiserver、/etc/iam/iam-apiserver.yaml文件不存在。我来介绍下这些文件的作用。

- /etc/systemd/system/iam-apiserver.service：iam-apiserver 的 sysmted Unit 文件。
- /opt/iam/bin/iam-apiserver：iam-apiserver 的二进制启动命令。
- /etc/iam/iam-apiserver.yaml：iam-apiserver 的配置文件。

如果某个文件不存在，那就需要你重新安装这些文件。我来分别介绍这三个文件的安装方法。

/etc/systemd/system/iam-apiserver.service安装方法：

```
$ cd $IAM_ROOT
$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-apiserver.service > iam-apiserver.service
$ sudo mv iam-apiserver.service /etc/systemd/system/
```
/opt/iam/bin/iam-apiserver安装方法：

```
$ cd $IAM_ROOT
$ source scripts/install/environment.sh
$ make build BINS=iam-apiserver
$ sudo cp _output/platforms/linux/amd64/iam-apiserver ${IAM_INSTALL_DIR}/bin
```
/etc/iam/iam-apiserver.yaml安装方法：

```
$ cd $IAM_ROOT
$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-apiserver.yaml > iam-apiserver.yaml
$ sudo mv iam-apiserver.yaml ${IAM_CONFIG_DIR}
```
### 总结
这一讲，我以iam-apiserver服务为例，向你介绍了排障的基本流程：发现问题 -> 定位问题 -> 解决问题。你可以通过三种方式来发现问题。

- 检查服务状态：启动 iam-apiserver 服务后，执行systemctl status iam-apiserver 发现 iam-apiserver 启动失败，即Active的值不为active (running)。
- 功能异常：访问 iam-apiserver 服务，功能异常或者报错，例如接口返回值跟预期不一样；接口报错。
- 日志报错：在 iam-apiserver 的日志中发现一些WARN、ERROR、PANIC、FATAL等高级别的错误日志。

发现问题之后，你可以通过查看日志、使用 Go 调试工具 Delve 和添加 Debug 日志这三种方式来定位问题。
- 查看日志：查看日志是最简单的排障方式。
- 使用 Go 调试工具 Delve 来定位问题。
- 添加 Debug 日志：从程序入口处跟读代码，在关键位置处打印 Debug 日志，来定位问题。

找到问题根因之后，就要解决问题。你需要根据自己对业务、底层代码实现的掌握和理解，解决这个问题。最后，我向你展示了 9 个在部署和使用 IAM 系统时容易遇到的问题，并提供了解决方法，希望能给你一些切实的帮助。

## 特别放送 | Go Modules实战

今天我们更新一期特别放送作为加餐。在 特别放送 | Go Modules 依赖包管理全讲中，我介绍了 Go Modules 的知识，里面内容比较多，你可能还不知道具体怎么使用 Go Modules 来为你的项目管理 Go 依赖包。

这一讲，我就通过一个具体的案例，带你一步步学习 Go Modules 的常见用法以及操作方法，具体包含以下内容：

- 准备一个演示项目。
- 配置 Go Modules。
- 初始化 Go 包为 Go 模块。
- Go 包依赖管理。

### 准备一个演示项目
为了演示 Go Modules 的用法，我们首先需要一个 Demo 项目。假设我们有一个 hello 的项目，里面有两个文件，分别是 hello.go 和 hello_test.go，所在目录为/home/lk/workspace/golang/src/github.com/marmotedu/gopractise-demo/modules/hello。

hello.go 文件内容为：

```go
package hello

func Hello() string {
  return "Hello, world."
}
```
hello_test.go 文件内容为：

```go
package hello

import "testing"

func TestHello(t *testing.T) {
  want := "Hello, world."
  if got := Hello(); got != want {
    t.Errorf("Hello() = %q, want %q", got, want)
  }
}
```
这时候，该目录包含了一个 Go 包，但还不是 Go 模块，因为没有 go.mod 件。接下来，我就给你演示下，如何将这个包变成一个 Go 模块，并执行 Go 依赖包的管理操作。这些操作共有 10 个步骤，下面我们来一步步看下。

### 配置 Go Modules
打开 Go Modules
确保 Go 版本>=go1.11，并开启 Go Modules，可以通过设置环境变量export GO111MODULE=on开启。如果你觉得每次都设置比较繁琐，可以将export GO111MODULE=on追加到文件$HOME/.bashrc中，并执行 bash 命令加载到当前 shell 环境中。

设置环境变量
对于国内的开发者来说，需要设置export GOPROXY=https://goproxy.cn,direct，这样一些被墙的包可以通过国内的镜像源安装。如果我们有一些模块存放在私有仓库中，也需要设置 GOPRIVATE 环境变量。


因为 Go Modules 会请求 Go Checksum Database，Checksum Database 国内也可能会访问失败，可以设置export GOSUMDB=off来关闭 Checksum 校验。对于一些模块，如果你希望不通过代理服务器，或者不校验checksum，也可以根据需要设置 GONOPROXY 和 GONOSUMDB。


### 初始化 Go 包为 Go 模块
创建一个新模块

你可以通过go mod init命令，初始化项目为 Go Modules。 init 命令会在当前目录初始化并创建一个新的 go.mod 文件，也代表着创建了一个以项目根目录为根的 Go Modules。如果当前目录已经存在 go.mod 文件，则会初始化失败。

在初始化 Go Modules 时，需要告知go mod init要初始化的模块名，可以指定模块名，例如go mod init github.com/marmotedu/gopractise-demo/modules/hello。也可以不指定模块名，让init自己推导。下面我来介绍下推导规则。


如果有导入路径注释，则使用注释作为模块名，比如：

```
package hello // import "github.com/marmotedu/gopractise-demo/modules/hello"
```
则模块名为github.com/marmotedu/gopractise-demo/modules/hello。

如果没有导入路径注释，并且项目位于 GOPATH 路径下，则模块名为绝对路径去掉$GOPATH/src后的路径名，例如GOPATH=/home/lk/workspace/golang，项目绝对路径为/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/modules/hello，则模块名为github.com/marmotedu/gopractise-demo/modules/hello。

初始化完成之后，会在当前目录生成一个 go.mod 文件：

```
$ cat go.mod
module github.com/marmotedu/gopractise-demo/modules/hello

go 1.14
```
文件内容表明，当前模块的导入路径为github.com/marmotedu/gopractise-demo/modules/hello，使用的 Go 版本是go 1.14。

如果要新增子目录创建新的 package，则 package 的导入路径自动为 模块名/子目录名 ：github.com/marmotedu/gopractise-demo/modules/hello/< sub-package-name>，不需要在子目录中再次执行go mod init。

比如，我们在 hello 目录下又创建了一个 world 包world/world.go，则 world 包的导入路径为github.com/marmotedu/gopractise-demo/modules/hello/world。

### Go 包依赖管理
增加一个依赖
Go Modules 主要是用来对包依赖进行管理的，所以这里我们来给 hello 包增加一个依赖rsc.io/quote：

```go
package hello

import "rsc.io/quote"

func Hello() string {
  return quote.Hello()
}
```
运行go test：

```
$ go test
go: finding module for package rsc.io/quote
go: downloading rsc.io/quote v1.5.2
go: found rsc.io/quote in rsc.io/quote v1.5.2
go: downloading rsc.io/sampler v1.3.0
PASS
ok    github.com/google/addlicense/golang/src/github.com/marmotedu/gopractise-demo/modules/hello  0.003s
```
当 go 命令在解析源码时，遇到需要导入一个模块的情况，就会去 go.mod 文件中查询该模块的版本，如果有指定版本，就导入指定的版本。

如果没有查询到该模块，go 命令会自动根据模块的导入路径安装模块，并将模块和其最新的版本写入 go.mod 文件中。在我们的示例中，go test将模块rsc.io/quote解析为rsc.io/quote v1.5.2，并且同时还下载了rsc.io/quote模块的两个依赖模块：rsc.io/quote和rsc.io/sampler。只有直接依赖才会被记录到 go.mod 文件中。

查看 go.mod 文件：

```
module github.com/marmotedu/gopractise-demo/modules/hello

go 1.14

require rsc.io/quote v1.5.2
```
再次执行go test：

```
$ go test
PASS
ok    github.com/marmotedu/gopractise-demo/modules/hello  0.003s
```
当我们再次执行go test时，不会再下载并记录需要的模块，因为 go.mod 目前是最新的，并且需要的模块已经缓存到了本地的$GOPATH/pkg/mod目录下。可以看到，在当前目录还新生成了一个 go.sum 文件：

```
$ cat go.sum
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c h1:qgOY6WgZOaTkIIMiVjBQcw93ERBE4m30iBm00nkL0i8=
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=
rsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=
rsc.io/sampler v1.3.0 h1:7uVkIFmeBqHfdjD+gZwtXXI+RODJ2Wc4O7MPEh/QiW4=
rsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=
```
go test在执行时，还可以添加-mod选项，比如go test -mod=vendor。-mod有 3 个值，我来分别介绍下。
- readonly：不更新 go.mod，任何可能会导致 go.mod 变更的操作都会失败。通常用来检查 go.mod 文件是否需要更新，例如用在 CI 或者测试场景。
- vendor：从项目顶层目录下的 vendor 中导入包，而不是从模块缓存中导入包，需要确保 vendor 包完整准确。
- mod：从模块缓存中导入包，即使项目根目录下有 vendor 目录。

如果go test执行时没有-mod选项，并且项目根目录存在 vendor 目录，go.mod 中记录的 go 版本大于等于1.14，此时go test执行效果等效于go test -mod=vendor。-mod标志同样适用于 go build、go install、go run、go test、go list、go vet 命令。

查看所有依赖模块
我们可以通过go list -m all命令查看所有依赖模块：

```
$ go list -m all
github.com/marmotedu/gopractise-demo/modules/hello
golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c
rsc.io/quote v1.5.2
rsc.io/sampler v1.3.0
```
可以看出，除了rsc.io/quote v1.5.2外，还间接依赖了其他模块。


更新依赖
通过go list -m all，我们可以看到模块依赖的golang.org/x/text模块版本是v0.0.0，我们可以通过go get命令，将其更新到最新版本，并观察测试是否通过：

```
$ go get golang.org/x/text
go: golang.org/x/text upgrade => v0.3.3
$ go test
PASS
ok    github.com/marmotedu/gopractise-demo/modules/hello  0.003s
```
go test命令执行后输出 PASS 说明升级成功，再次看下go list -m all和 go.mod 文件：
```
$ go list -m all
github.com/marmotedu/gopractise-demo/modules/hello
golang.org/x/text v0.3.3
golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e
rsc.io/quote v1.5.2
rsc.io/sampler v1.3.0
$ cat go.mod
module github.com/marmotedu/gopractise-demo/modules/hello

go 1.14

require (
  golang.org/x/text v0.3.3 // indirect
  rsc.io/quote v1.5.2
)
```
可以看到，golang.org/x/text包被更新到最新的 tag 版本 (v0.3.3)，并且同时更新了 go.mod 文件。// indirect说明golang.org/x/text是间接依赖。现在我们再尝试更新rsc.io/sampler并测试：

```
$ go get rsc.io/sampler
go: rsc.io/sampler upgrade => v1.99.99
go: downloading rsc.io/sampler v1.99.99
$ go test
--- FAIL: TestHello (0.00s)
    hello_test.go:8: Hello() = "99 bottles of beer on the wall, 99 bottles of beer, ...", want "Hello, world."
FAIL
exit status 1
FAIL  github.com/marmotedu/gopractise-demo/modules/hello  0.004s
```
测试失败，说明最新的版本v1.99.99与我们当前的模块不兼容，我们可以列出rsc.io/sampler所有可用的版本，并尝试更新到其他版本：

```
$ go list -m -versions rsc.io/sampler
rsc.io/sampler v1.0.0 v1.2.0 v1.2.1 v1.3.0 v1.3.1 v1.99.99

# 我们尝试选择一个次新的版本v1.3.1
$ go get rsc.io/sampler@v1.3.1
go: downloading rsc.io/sampler v1.3.1
$ go test
PASS
ok    github.com/marmotedu/gopractise-demo/modules/hello  0.004s
```
可以看到，更新到v1.3.1版本，测试是通过的。go get还支持多种参数，如下表所示：

![img](https://static001.geekbang.org/resource/image/2b/f6/2b80e94c1e91bb18dea9c20695b25bf6.jpg?wh=2248x1496)

添加一个新的 major 版本依赖
我们尝试添加一个新的函数func Proverb，该函数通过调用rsc.io/quote/v3的quote.Concurrency函数实现。首先，我们在 hello.go 文件中添加新函数：


```go
package hello

import (
  "rsc.io/quote"
  quoteV3 "rsc.io/quote/v3"
)

func Hello() string {
  return quote.Hello()
}

func Proverb() string {
  return quoteV3.Concurrency()
}
```
在 hello_test.go 中添加该函数的测试用例：

```go
func TestProverb(t *testing.T) {
    want := "Concurrency is not parallelism."
    if got := Proverb(); got != want {
        t.Errorf("Proverb() = %q, want %q", got, want)
    }
}
```
然后执行测试：

```
$ go test
go: finding module for package rsc.io/quote/v3
go: found rsc.io/quote/v3 in rsc.io/quote/v3 v3.1.0
PASS
ok    github.com/marmotedu/gopractise-demo/modules/hello  0.003s
```
测试通过，可以看到当前模块同时依赖了同一个模块的不同版本rsc.io/quote和rsc.io/quote/v3：

```
$ go list -m rsc.io/q...
rsc.io/quote v1.5.2
rsc.io/quote/v3 v3.1.0
```
升级到不兼容的版本
在上一步中，我们使用rsc.io/quote v1版本的Hello()函数。按照语义化版本规则，如果我们想升级major版本，可能面临接口不兼容的问题，需要我们变更代码。我们来看下rsc.io/quote/v3的函数：

```
$ go doc rsc.io/quote/v3
package quote // import "github.com/google/addlicense/golang/pkg/mod/rsc.io/quote/v3@v3.1.0"

Package quote collects pithy sayings.

func Concurrency() string
func GlassV3() string
func GoV3() string
func HelloV3() string
func OptV3() string
```
可以看到，Hello()函数变成了HelloV3()，这就需要我们变更代码做适配。因为我们都统一模块到一个版本了，这时候就不需要再为了避免重名而重命名模块，所以此时 hello.go 内容为：
```go
package hello

import (
  "rsc.io/quote/v3"
)

func Hello() string {
  return quote.HelloV3()
}

func Proverb() string {
  return quote.Concurrency()
}
```
执行go test：

```
$ go test
PASS
ok    github.com/marmotedu/gopractise-demo/modules/hello  0.003s
```
可以看到测试成功。

删除不使用的依赖
在上一步中，我们移除了rsc.io/quote包，但是它仍然存在于go list -m all和 go.mod 中，这时候我们要执行go mod tidy清理不再使用的依赖：

```
$ go mod tidy
[colin@dev hello]$ cat go.mod
module github.com/marmotedu/gopractise-demo/modules/hello

go 1.14

require (
  golang.org/x/text v0.3.3 // indirect
  rsc.io/quote/v3 v3.1.0
  rsc.io/sampler v1.3.1 // indirect
)
```
使用 vendor

如果我们想把所有依赖都保存起来，在 Go 命令执行时不再下载，可以执行go mod vendor，该命令会把当前项目的所有依赖都保存在项目根目录的 vendor 目录下，也会创建vendor/modules.txt文件，来记录包和模块的版本信息：

```
$ go mod vendor
$ ls
go.mod  go.sum  hello.go  hello_test.go  vendor  world
```
到这里，我就讲完了 Go 依赖包管理常用的 10 个操作。


### 总结
这一讲中，我详细介绍了如何使用 Go Modules 来管理依赖，它包括以下 Go Modules 操作：

- 打开 Go Modules；
- 设置环境变量；
- 创建一个新模块；
- 增加一个依赖；
- 查看所有依赖模块；
- 更新依赖；
- 添加一个新的 major 版本依赖；
- 升级到不兼容的版本；
- 删除不使用的依赖。
- 使用 vendor。


## 特别放送 | 分布式作业系统设计和实现


今天这一讲，我们来聊聊如何设计分布式作业系统。在实际的 Go 项目开发中，我们经常会遇到下面这两个功能需求：
- 想定时执行某个任务，例如在每天上午 10:00 清理数据库中的无用数据。
- 轮训数据库表的某个字段，根据字段的状态，进行一些异步的业务逻辑处理。比如，监听到 table_xxx.status = 'pending' 时，执行异步的初始化流程，完成之后设置 table_xxx.status='normal' 。

这两个在 Go 项目开发中非常常见、基础的功能需求，通常可以通过作业系统来实现。IAM 为了解决这种常见的功能需求，也开发了自己的作业系统。今天这一讲，我们就来看下 IAM 是如何实现作业系统的。

### 任务分类
在介绍作业系统之前，这里先来看下任务的分类。理解任务的分类，有助于我们理解作业系统执行的任务类型，进而有助于我们设计作业系统。

在我看来，任务可以分为下面 3 类。
- 定时任务：定时任务会在指定的时间点固定执行。只要到达执行任务的时间点，就会执行任务，而不管上一次任务是否完成。
- 间隔任务：上一次任务执行完，间隔一段时间（如 5 秒、5 分钟），再继续执行下一次任务。
- 间隔性定时任务：间隔任务的变种，从上一次任务开始执行时计时，只要间隔时间一到，便执行下一次任务，而不管上一次任务是否完成。

定时任务好理解，但间隔任务和间隔性定时任务不太好区分，它们的区别是：间隔任务会等待上一次任务执行完，间隔一段时间再执行下一次任务。而间隔性定时任务不会等待上一次任务执行完，只要间隔时间一到，便执行下一次任务。

三者的区别如下图所示：

![img](https://static001.geekbang.org/resource/image/cf/dd/cf323871d6946c31a82de6679c1178dd.jpg?wh=1920x1266)

在实际的项目开发中，我们经常会遇到这 3 类任务的需求。

### 作业系统的常见实现
在开始介绍 IAM 作业系统实现之前，有必要先介绍一下如何执行一个间隔 / 定时任务。只有了解了这些，才能更好地设计 IAM 的作业系统。通常来说，我们可以通过以下 4 种方式，来执行一个间隔 / 定时任务：

- 基于time 包提供的方法（例如time.Sleep、time.Ticker等 ）自己开发执行间隔 / 定时任务的服务。
- 一些 Go 包支持执行间隔 / 定时任务，可以直接使用这些 Go 包来执行间隔 / 定时任务，免去了自己开发作业调度部分的代码，例如github.com/robfig/cron 。
- 借助 Linux 的 crontab 执行定时任务。
- 使用开源的作业系统，并通过作业系统来执行间隔 / 定时任务，例如 distribworks/dkron。

上述 4 种方法，每一种都有自己的优缺点。采用第一种方法的话，因为一切都要从 0 开始实现，开发工作量大、开发效率低。我认为，因为已经有很多优秀的 cron 包可供使用了，没必要自己从 0 开发，可以直接使用这些 cron 包来执行周期 / 定时任务。IAM 项目便采用了这种方法。

接下来，我先介绍下第三种和第四种方法：使用 Linux crontab 和使用开源的 Go 作业系统。然后，我们再来重点看看 IAM 项目采用的第二种方法。

#### Linux crontab
crontab 是 Linux 系统自带的定时执行工具，可以在无需人工干预的情况下运行作业。crontab 通过 crond 进程来提供服务，crond 进程每分钟会定期检查是否有要执行的任务，如果有，则自动执行该任务。crond 进程通过读取 crontab 配置，来判断是否有任务执行，以及何时执行。

crond 进程会在下面这 3 个位置查找 crontab 配置文件。
- /var/spool/cron/：该目录存放用户（包括 root）的 crontab 任务，每个任务以登录名命名，比如 colin 用户创建的 crontab 任务对应的文件就是/var/spool/cron/colin。
- /etc/crontab：该目录存放由系统管理员创建并维护的 crontab 任务。
- /etc/cron.d/：该目录存放任何要执行的 crontab 任务。cron 进程执行时，会自动扫描该目录下的所有文件，按照文件中的时间设定执行后面的命令。

可以看到，如果想执行一个 crontab 任务，就需要确保 crond 运行，并配置 crontab 任务。具体分为以下两步：

第一步，确保 crond 进程正在运行。执行以下命令，查看 crond 进程运行状态：

```
$ systemctl status crond
● crond.service - Command Scheduler
   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)
   Active: active (running) since Wed 2021-11-17 07:11:27 CST; 2 days ago
 Main PID: 9182 (crond)
    Tasks: 1
   Memory: 728.0K
   CGroup: /system.slice/crond.service
           └─9182 /usr/sbin/crond -n
```
Active: active (running)说明 crond 进程正在运行，否则可以执行systemctl start crond启动 crond 进程。


第二步，配置 crontab 任务。可以通过crontab -e来编辑配置文件，例如执行crontab -e后进入 vi 交互界面，并配置以下 crontab 任务：

```
# 每分钟输出时间到文件 /tmp/test.txt
*  *  *  *  * echo `date` >> /tmp/test.txt

# 每隔 2 分钟同步一次互联网时间
*/2 * * * * /usr/bin/ntpstat time.windows.com > /dev/null 2>&1
```
编辑后的配置文件保存在/var/spool/cron/$USER文件中。你可以通过crontab -l或者sudo cat /var/spool/cron/$USER来查看，例如：

```
$ crontab -l
# 每分钟输出时间到文件/tmp/test.txt
*  *  *  *  * echo `date` >> /tmp/test.txt

# 每隔 2 分钟同步一次互联网时间
*/2 * * * * /usr/bin/ntpstat time.windows.com > /dev/null 2>&1
```
如果想删除所有的 crontab 任务，你可以执行crontab -r命令。配置的 crontab 任务需要遵循 crontab 的时间格式，格式如下：

```
.---------------- minute (0 - 59)    
|  .------------- hour (0 - 23)    
|  |  .---------- day of month (1 - 31)    
|  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...    
|  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat    
|  |  |  |  |    
*  *  *  *  * <command to be executed>
```
可以看到，crontab 只能精确到分钟，不能精确到秒。下面是一些常用的 crontab 时间格式，你可以参考，来加深理解：

```
# 每分钟执行一次 <command>            
* * * * * <command> # * 代表所有可能的值

# 每隔一小时执行一次 <command>
* */1 * * * <command> # / 表示频率

# 每小时的 15 和 30 分各执行一次 <command>
15,45 * * * * <command> # , 表示并列

# 在每天上午 8- 11 时中间每小时 15，45 分各执行一次 <command>
15,45 8-11 * * * <command> # - 表示范围

# 每个星期一的上午 8 点到 11 点的第 3 和第 15 分钟执行一次 <command>
3,15 8-11 * * 1 <command>

# 每隔两天的上午 8 点到 11 点的第 3 和第 15 分钟执行一次 <command>
3,15 8-11 */2 * * <command>
```
使用 crontab 执行周期 / 定时任务的优点是不用做任何开发，只需要配置 crontab 任务即可。至于缺点也很明显，主要有下面这几个：
- 不能精确到秒。
- 需要手动编写可执行命令。这些可执行命令跟项目分离，没办法复用项目提供的包、函数等能力。如果想执行跟项目关系紧密的作业，开发起来不方便。
- 单点，如果 crond 进程异常，周期 / 定时任务就没法继续执行。你可能想说：可以在两台机器上配置并执行相同的周期 / 定时任务。但是这样做会有问题，因为两台机器同时执行相同的任务，可能会彼此造成冲突或状态不一致。
- 没办法实现间隔任务和间隔性定时任务。

### 使用开源的作业系统
除了使用 Linux 系统自带的 crontab 之外，我们还可以使用一些业界优秀的开源作业系统。这里，我列出了一些比较受欢迎的 Go 语言开发的作业系统。之所以只选择 Go 语言开发的项目，一方面是想丰富你的 Go 语言生态，另一方面，同种语言也有助于你学习、改造这些项目。

distribworks/dkron。dkron 是一个分布式、启动迅速、带容错机制的定时作业系统，支持 crontab 表达式。它具有下面这些核心特性。
- 易用：可以通过易操作、漂亮的 Web 界面来管理作业。
- 可靠：具备容错机制，一个节点不可用，其他节点可继续执行作业。
- 高可扩展性：能够处理大量的计划作业和数千个节点。

ouqiang/gocron。gocron 是国人开发的轻量级定时任务集中调度和管理系统, 用于替代 Linux-crontab。它具有下面这些核心特性。
- 具有 Web 界面管理定时任务。
- 支持 crontab 时间格式，并精确到秒。
- 支持 shell 命令和 HTTP 请求两种任务格式。
- 具有任务超时机制、任务依赖机制、任务执行失败可重试机制。
- 支持查看任务执行日志，并支持用邮件、Slack、Webhook 等方式通知任务执行结果。

shunfei/cronsun。cronsun 是一个分布式作业系统，单个节点同 crontab 近似。它具有下面这些核心特性。
- 具有 Web 界面，方便对多台服务器上的定时任务进行集中式管理。
- 任务调度时间粒度支持到秒级别。
- 任务执行失败可重试。
- 任务可靠性保障（从 N 个节点里面挑一个可用节点来执行任务）。
- 任务日志查看。
- 任务失败邮件告警（也支持自定义 http 告警接口）。

那么，这么多的开源项目该如何选择呢？这里建议你选择 distribworks/dkron 。原因是 distribworks/dkron  Star 数很多，而且功能齐全易用、文档丰富。当然，在实际开发中，你最好也对其他开源项目进行调研，根据需要选择一个最适合自己的开源项目。

使用这些作业系统的优点是不用开发、功能比 crontab 更强大，有些还是分布式的作业系统，具备容灾能力。但缺点也很明显：
- 这些作业系统支持的任务种类有限，比如一般会支持通过 shell 脚本及发送 HTTP 请求的方式来执行任务。不管哪种方式，实现都跟项目分离，在开发跟项目结合紧密的任务插件时不是很简单、高效。
- 很多时候我们只会使用其中一部分能力，或者仅有一到两个项目会使用到这类系统，但我们还要部署并维护这些作业系统，工作量大，收益小。
- 没办法实现间隔任务。

使用 Linux 的 crontab 和使用开源的 Go 作业系统，这两种方法的缺点都很明显。鉴于这些缺点，IAM 系统选择使用现有的 cron 库封装自己的任务框架，并基于这个框架开发任务。IAM 项目选择了robfig/cron库，原因是 cron 库 Star 数最多，且功能丰富、使用简单。另外 IAM 还使用github.com/go-redsync/redsync实现了基于 Redis 的分布式互斥锁。所以，在开始介绍 IAM 作业系统实现前，我先来简单介绍下如何使用这两个包。


#### github.com/robfig/cron使用介绍
github.com/robfig/cron是一个可以实现类似 Linux crontab 定时任务的 cron 包，但是 cron 包支持到秒。


**cron 包支持的时间格式**
cron 包支持 crontab 格式和固定间隔格式这两种时间格式，下面我来分别介绍下。crontab 格式的时间格式，支持的匹配符跟 crontab 保持一致。时间格式如下：

```
 ┌─────────────second 范围 (0 - 60)
 │ ┌───────────── min (0 - 59)
 │ │ ┌────────────── hour (0 - 23)
 │ │ │ ┌─────────────── day of month (1 - 31)
 │ │ │ │ ┌──────────────── month (1 - 12)
 │ │ │ │ │ ┌───────────────── day of week (0 - 6) (0 to 6 are Sunday to
 │ │ │ │ │ │                  Saturday)
 │ │ │ │ │ │
 │ │ │ │ │ │
 * * * * * *   
```
第二种是固定间隔格式，例如@every <duration>。duration是一个可以被time.ParseDuration解析的字符串，例如@every 1h30m10s表示任务每隔 1 小时 30 分 10 秒会被执行。这里要注意，间隔不考虑任务的运行时间。例如，如果任务需要 3 分钟运行，并且计划每 5 分钟运行一次，则每次运行之间只有 2 分钟的空闲时间。

**cron 包使用示例**
cron 包的使用方法也很简单，下面是一个简单的使用示例：

```go
package main

import (
  "fmt"

  "github.com/robfig/cron/v3"
)

func helloCron() {
  fmt.Println("hello cron")
}

func main() {
  fmt.Println("starting go cron...")

  // 创建一个cron实例
  cron := cron.New(cron.WithSeconds(), cron.WithChain(cron.SkipIfStillRunning(nil), cron.Recover(nil)))

  // 添加一个定时任务
  cron.AddFunc("*  *  *  *  *  *", helloCron)

  // 启动计划任务
  cron.Start()

  // 关闭着计划任务, 但是不能关闭已经在执行中的任务.
  defer cron.Stop()

  select {} // 查询语句，保持程序运行，在这里等同于for{}
}
```
在上面的代码中，通过 cron.New 函数调用创建了一个 cron 实例；接下来通过 cron 实例的 AddFunc 方法，给 cron 实例添加了一个定时任务：每分钟执行一次 helloCron 函数；最后通过 cron 实例的 Start 方法启动定时任务。在程序退出时，还执行了 cron.Stop() 关闭定时任务。


**拦截器**
cron 包还支持安装一些拦截器，这些拦截器可以实现以下功能：

- 从任务的 panic 中恢复（cron.Recover()）。
- 如果上一次任务尚未完成，则延迟下一次任务的执行（cron.DelayIfStillRunning()）。
- 如果上一次任务尚未完成，则跳过下一次任务的执行（cron.SkipIfStillRunning()）。
- 记录每个任务的调用（cron.WithLogger()）。
- 任务完成时通知。

如果想使用这些拦截器，只需要在创建 cron 实例时，传入相应的 Option 即可，例如：

```
cron := cron.New(cron.WithSeconds(), cron.WithChain(cron.SkipIfStillRunning(nil), cron.Recover(nil)))
```
#### github.com/go-redsync/redsync使用介绍
redsync 可以实现基于 Redis 的分布式锁，使用起来也比较简单，我们直接来看一个使用示例：

```go
package main

import (
  goredislib "github.com/go-redis/redis/v8"
  "github.com/go-redsync/redsync/v4"
  "github.com/go-redsync/redsync/v4/redis/goredis/v8"
)

func main() {
  // Create a pool with go-redis (or redigo) which is the pool redisync will
  // use while communicating with Redis. This can also be any pool that
  // implements the `redis.Pool` interface.
  client := goredislib.NewClient(&goredislib.Options{
    Addr: "localhost:6379",
  })
  pool := goredis.NewPool(client) // or, pool := redigo.NewPool(...)

  // Create an instance of redisync to be used to obtain a mutual exclusion
  // lock.
  rs := redsync.New(pool)

  // Obtain a new mutex by using the same name for all instances wanting the
  // same lock.
  mutexname := "my-global-mutex"
  mutex := rs.NewMutex(mutexname)

  // Obtain a lock for our given mutex. After this is successful, no one else
  // can obtain the same lock (the same mutex name) until we unlock it.
  if err := mutex.Lock(); err != nil {
    panic(err)
  }

  // Do your work that requires the lock.

  // Release the lock so other processes or threads can obtain a lock.
  if ok, err := mutex.Unlock(); !ok || err != nil {
    panic("unlock failed")
  }
}
```
上面的代码，创建了一个 redsync.Redsync 实例，并使用 redsync.Redsync 提供的 NewMutex 方法，创建了一个分布式锁实例 mutex。通过 mutex.Lock() 加锁，通过 mutex.Unlock() 释放锁。


### IAM 作业系统特点
在开发 IAM 的作业系统之前，我们需要先梳理好 IAM 要实现的任务。IAM 需要实现以下两个间隔任务：
- 每隔一段时间从 policy_audit 表中清理超过指定天数的授权策略。
- 每隔一段时间禁用超过指定天数没有登录的用户。

结合上面提到的作业系统的缺点，这里将我们需要设计的作业系统的特点总结如下：
- 分布式的作业系统，当有多个实例时，确保同一时刻只有 1 个实例在工作。
- 跟项目契合紧密，能够方便地复用项目提供的包、函数等能力，提高开发效率。
- 能够执行定时任务、间隔任务、间隔性定时任务这 3 种类型的任务。
- 可插件化地加入新的周期 / 定时任务。

### IAM 作业系统实现
介绍完 IAM 作业系统使用到的两个 Go 包和 IAM 作业系统的特点，下面我来正式讲解 IAM 作业系统的实现。

IAM 的作业系统服务名叫 iam-watcher。watcher 是观察者的意思，里面的任务主要是感知一些状态，并执行相应的任务，所以叫 watcher。iam-watcher main 函数位于[cmd/iam-watcher/watcher.go](https://github.com/marmotedu/iam/blob/v1.2.0/cmd/iam-watcher/watcher.go)文件中。应用框架跟 iam-apiserver、iam-authz-server、iam-pump 保持高度一致，这里就不再介绍了。

整个 iam-watcher 服务的核心实现位于internal/watcher/server.go文件中，在 server.go 文件中调用了newWatchJob，创建了一个github.com/robfig/cron.Cron类型的 cron 实例，newWatchJob 代码如下：

```go
func newWatchJob(redisOptions *genericoptions.RedisOptions, watcherOptions *options.WatcherOptions) *watchJob {    
    logger := cronlog.NewLogger(log.SugaredLogger())                                                               

    client := goredislib.NewClient(&goredislib.Options{                     
        Addr:     fmt.Sprintf("%s:%d", redisOptions.Host, redisOptions.Port),    
        Username: redisOptions.Username,                                         
        Password: redisOptions.Password,    
    })                                                                  

    pool := goredis.NewPool(client)                                                                            
    rs := redsync.New(pool)                                                

    cron := cron.New(                                                             
        cron.WithSeconds(),                     
        cron.WithChain(cron.SkipIfStillRunning(logger), cron.Recover(logger)),                                      
    )                                                                             

    return &watchJob{                                             
        Cron:   cron,                                                            
        config: watcherOptions,                                                   
        rs:     rs,                             
    }                                                             
}
```
上述代码创建了以下两种类型的实例。
- github.com/robfig/cron.Cron：基于github.com/robfig/cron包实现的作业系统，可以支持定时任务、间隔任务、间隔性定时任务 3 种类型的任务。
- github.com/go-redsync/redsync.Redsync：基于 Redis 的分布式互斥锁。

这里需要注意，创建 cron 实例时需要增加cron.SkipIfStillRunning() Option，SkipIfStillRunning可以使 cron 任务在上一个任务还没执行完时，跳过下一个任务的执行，以此实现间隔任务的效果。

创建实例后，通过[addWatchers()](https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher.go)来注册 cron 任务。addWatchers 函数代码如下：

```go
func (w *watchJob) addWatchers() *watchJob {                            
    for name, watcher := range watcher.ListWatchers() {
        // log with `{"watcher": "counter"}` key-value to distinguish which watcher the log comes from.
        ctx := context.WithValue(context.Background(), log.KeyWatcherName, name)

        if err := watcher.Init(ctx, w.rs.NewMutex(name, redsync.WithExpiry(2*time.Hour)), w.config); err != nil {
            log.Panicf("construct watcher %s failed: %s", name, err.Error())    
        }                                                              

        _, _ = w.AddJob(watcher.Spec(), watcher)                            
    }           

    return w                                    
}  

```
上述函数会调用watcher.ListWatchers()列出所有的 watcher，并在 for 循环中将这些 watcher 添加到 cron 调度引擎中。watcher 定义如下：

```go
type IWatcher interface {                                               
    Init(ctx context.Context, rs *redsync.Mutex, config interface{}) error
    Spec() string                                                                                      
    cron.Job                                                                    
}

type Job interface {                                                    
    Run()                                                                 
}
```
也就是说，一个 watcher 是实现了以下 3 个方法的结构体：Init()，用来初始化 wacther。Spec()，用来返回 Cron 实例的时间格式，支持 Linux crontab 时间格式和@every 1d类型的时间格式。Run()，用来运行任务。


IAM 实现了两个 watcher：[task](https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/task/watcher.go)：禁用超过X天还没有登录过的用户，X可由 iam-watcher.yaml 配置文件中的watcher.task.max-inactive-days配置项来配置。[clean](https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/clean/watcher.go)：清除policy_audit表中超过X天数后的授权策略，X可由 iam-watcher.yaml 配置文件中的watcher.clean.max-reserve-days配置项来配置。

创建完 cron 实例后，就可以在Run 函数中启动 cron 任务。Run 函数代码如下：


```go
func (s preparedWatcherServer) Run() error {
  stopCh := make(chan struct{})
  s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {
    // wait for running jobs to complete.
    ctx := s.cron.Stop()
    select {
    case <-ctx.Done():
      log.Info("cron jobs stopped.")
    case <-time.After(3 * time.Minute):
      log.Error("context was not done after 3 minutes.")
    }
    stopCh <- struct{}{}

    return nil
  }))

  // start shutdown managers
  if err := s.gs.Start(); err != nil {
    log.Fatalf("start shutdown manager failed: %s", err.Error())
  }

  log.Info("star to run cron jobs.")
  s.cron.Start()

  // blocking here via channel to prevents the process exit.
  <-stopCh

  return nil
}
```
上述代码，通过s.cron.Start()代码调用来启动 cron 实例，执行 cron 任务。

这里需要注意，我们还需要实现优雅关停功能，也就是当程序结束时，等待正在执行的作业都结束后，再终止进程。s.cron.Stop()会返回context.Context类型的变量，用来告知调用者 cron 任务何时结束，以使调用者终止进程。在 cron 任务都执行完毕或者超时 3 分钟后，会往 stopCh 通道中写入一条 message，<-stopCh 会结束阻塞状态，进而退出 iam-watcher 进程。


#### task watcher 实现解读
task watcher 的实现位于internal/watcher/watcher/task/watcher.go文件中，该文件定义了一个taskWatcher结构体：

```go
type taskWatcher struct {    
    ctx             context.Context    
    mutex           *redsync.Mutex    
    maxInactiveDays int          
}
```
taskWatcher实现了IWatcher接口。在程序启动时，通过 init 函数将taskWatcher注册到internal/watcher/watcher/registry.go中定义的全局变量registry中，通过func ListWatchers() map[string]IWatcher函数返回所有注册的 watcher。

这里需要注意，所有的 watcher 在internal/watcher/watcher/all/all.go文件中以匿名包的形式被导入，从而触发 watcher 所在包的 init 函数的执行。init 函数通过调用watcher.Register("clean", &cleanWatcher{})将 watcher 注册到registry变量中。all.go文件中导入匿名包代码如下：

```go
import (                                                           
    _ "github.com/marmotedu/iam/internal/watcher/watcher/clean"    
    _ "github.com/marmotedu/iam/internal/watcher/watcher/task"    
)  
```
这样做的好处是，不需要修改任何 iam-watcher 的框架代码，就可以插件化地注册一个新的 watcher。不改动 iam-watcher 的主体代码，能够使我们以最小的改动添加一个新的 watcher。例如，我们需要新增一个 cleansecret  watcher，只需要执行以下两步即可：
- 在internal/watcher/watcher目录下新建一个cleansecret目录，并实现cleanSecretWatcher。
- 在internal/watcher/watcher/all/all.go文件中以匿名的形式导入github.com/marmotedu/iam/internal/watcher/watcher/cleansecret包。在taskWatcher的Run()方法中，我们通过以下代码，来确保即使有多个 iam-watcher 实例，也只有一个 task watcher 在执行：

```go
    if err := tw.mutex.Lock(); err != nil {               
        log.L(tw.ctx).Info("taskWatcher already run.")    

        return    
    }                 
    defer func() {                                      
        if _, err := tw.mutex.Unlock(); err != nil {    
            log.L(tw.ctx).Errorf("could not release taskWatcher lock. err: %v", err)    

            return    
        }    
    }()
```
我们在taskWatcher的Run()方法中，查询出所有的用户，并对比loginedAt字段中记录的时间和当前时间，来判断是否需要禁止用户。loginedAt字段记录了用户最后一次登录的时间。

通过 task watcher 的实现，可以看到：在 task watcher 中，我们使用了 IAM 项目提供的mysql.GetMySQLFactoryOr函数、log 包，以及 Options 配置，这使我们可以很方便地开发一个跟项目紧密相关的任务。

### 总结
在 Go 项目开发中，我们经常会需要执行一些间隔 / 定时任务，这时我们就需要一个作业系统。我们可以使用 Linux 提供的 crontab 执行定时任务，还可以自己搭建一个作业系统，并在上面执行我们的间隔 / 定时任务。但这些方法都有一些缺点，比如跟项目独立、无法执行间隔任务等。所以，这时候比较好的方式是基于开源的优秀 cron 包，来实现一个作业系统，并基于这个作业系统开发任务插件。

IAM 基于github.com/robfig/cron包和github.com/go-redsync/redsync包，实现了自己的分布式作业系统 iam-watcher。iam-watcher 可以插件化地添加定时任务、间隔任务、间隔性定时任务。至于它的具体实现，你可以跟读 iam-watcher 服务的代码，其 main 函数位于cmd/iam-watcher/watcher.go文件中。



