---
title: "BigData_base_09"
date: 2021-12-06T16:19:58+08:00
lastmod: 2021-12-06
tags: [big_data]
categories: [School courses]
slug: integrate learning
draft: true
---
# 集成学习
基于集成学习的分类方法:
- 集成学习（ensemble learning）
- 从训练数据构建分类器集合
- 综合多个分类器的预测结果来预测新实例的分类预测结果

集成学习的关键问题：
- 强度 （strength）
- 相关性（correlation）
- Tradeoff between strength and correlation

如何生成一个集成分类器？
- 装袋（Bagging）
    - 有放回抽样
    - 为每个自助样本建立分类器
    - 每个样本被抽取的概率是相等的
- 堆叠（Stacking）
    - 基本原理：
        - 异构集成学习方法
        - 组成堆叠法的基础学习器一般互不相同
    - 堆叠法的关键问题
        - 保证不同个体学习数据的独立性
            - 对数据集进行随机划分
        - 保证不同个体的多样性
            - 对不同的数据集采取不同的模型训练
        - 集成策略的选择
            - 将多个模型的输出作为一个模型的输入
    - 随机森林
        - 专门为决策树分类器设计的集成方法
        - 随机森林长出许多分类树 (名字由来)
        - 未修剪的决策树集合
        - 每个基础分类器分类一个“新的”向量
        - 森林选择表决投票最多的分类结果
        - 随机性的两个来源介绍: “装袋”和“随机输入向量”
            - 每棵树都是使用训练数据的bootstrapping样本来生长的
            - 在每个节点上，最佳的分裂是从mtry个变量中选择，而不是所有变量
- 提升（Boosting）
    - 更注重之前错误分类的实例以自适应地改变训练数据分布的迭代过程
        - 最初，所有N个实例都会分配相同的权重
        - 跟装袋不同的是，这些权重会在每一轮提升结束之后发生变化
        - 最终的分类器是基于弱分类器的权重表决的
