---
title: "图神经网络的多元时间序列插补-参考"
date: 2022-05-13T09:33:30+08:00
lastmod: 2022-05-14
tags: [papers]
categories: [Graduation project]
slug: MULTIVARIATE TIME SERIES IMPUTATION BY GRAPH NEURAL NETWORKS
draft: true
---

## 参考

[1]Gabriel Appleby, Linfeng Liu, and Li-Ping Liu. Kriging convolutional networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 3187–3194, 2020.


[2]James Atwood and Don Towsley. Diffusion-convolutional neural networks. In Advances in neural information processing systems, pp. 1993–2001, 2016.


[3]Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271, 2018.

[4]Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.


[5]Lorenzo Beretta and Alessandro Santaniello. Nearest neighbor imputation algorithms: a critical evaluation. BMC medical informatics and decision making, 16(3):197–208, 2016.

[6]Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18–42,2017.

[7]Deng Cai, Xiaofei He, Jiawei Han, and Thomas S Huang. Graph regularized nonnegative matrix factorization for data representation. IEEE transactions on pattern analysis and machine intelligence, 33(8):1548–1560, 2010.

[8]Ling Cai, Krzysztof Janowicz, Gengchen Mai, Bo Yan, and Rui Zhu. Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting. Transactions in GIS, 24(3): 736–755, 2020.

[9]Wei Cao, Dong Wang, Jian Li, Hao Zhou, Yitan Li, and Lei Li. Brits: bidirectional recurrent imputation for time series. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6776–6786, 2018.

[10]Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neural networks for multivariate time series with missing values. Scientific reports, 8(1):1–12,2018


[11]Kyunghyun Cho, Bart Van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ¨ ger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.

[12]Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.

[13]Andrzej Cichocki and Anh-Huy Phan. Fast local algorithms for large scale nonnegative matrix and tensor factorizations. IEICE transactions on fundamentals of electronics, communications and computer sciences, 92(3):708–721, 2009.

[14]Commission for Energy Regulation. CER Smart Metering Project - Electricity Customer Behaviour Trial, 2009-2010 [dataset]. Irish Social Science Data Archive. SN: 0012-00, 2016. URL https: //www.ucd.ie/issda/data/commissionforenergyregulationcer.

[15]Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on ¨ graphs with fast localized spectral filtering. Advances in neural information processing systems, 29:3844–3852, 2016.

[16]James Durbin and Siem Jan Koopman. Time series analysis by state space methods. Oxford university press, 2012.

[17]William Fedus, Ian Goodfellow, and Andrew M Dai. Maskgan: Better text generation via filling in the . In International Conference on Learning Representations, 2018.

[18]Fabrizio Frasca, Emanuele Rossi, Davide Eynard, Benjamin Chamberlain, Michael Bronstein, and Federico Monti. Sign: Scalable inception graph neural networks. In ICML 2020 Workshop on Graph Representation Learning and Beyond, 2020.

[19]Zoubin Ghahramani and Michael Jordan. Supervised learning from incomplete data via an em approach. In J. Cowan, G. Tesauro, and J. Alspector (eds.), Advances in Neural Information Processing Systems, volume 6. Morgan-Kaufmann, 1994. Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International conference on machine learning, pp. 1263–1272. PMLR, 2017.

[20]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014.

[21]Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1. MIT Press, 2016.

[22]Clive WJ Granger. Investigating causal relations by econometric models and cross-spectral methods. Econometrica: journal of the Econometric Society, pp. 424–438, 1969. William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 1025–1035, 2017.

[23]Charles R Harris, K Jarrod Millman, Stefan J van der Walt, Ralf Gommers, Pauli Virtanen, David ´ Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J Smith, et al. Array programming with numpy. Nature, 585(7825):357–362, 2020.

[24]Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. ¨ Neural computation, 9(8): 1735–1780, 1997. Hosagrahar V Jagadish, Johannes Gehrke, Alexandros Labrinidis, Yannis Papakonstantinou, Jignesh M Patel, Raghu Ramakrishnan, and Cyrus Shahabi. Big data and its technical challenges. Communications of the ACM, 57(7):86–94, 2014.

[25]J Kihoro, K Athiany, et al. Imputation of incomplete nonstationary seasonal time series data. Mathematical Theory and Modeling, 3(12):142–154, 2013.

[26]Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. Neural relational inference for interacting systems. In International Conference on Machine Learning, pp. 2688– 2697. PMLR, 2018.

[27]Sanmukh R. Kuppannagari, Yao Fu, Chung Ming Chueng, and Viktor K. Prasanna. Spatio-temporal missing data imputation for smart power grids. In Proceedings of the Twelfth ACM International Conference on Future Energy Systems, e-Energy ’21, pp. 458–465, New York, NY, USA, 2021.

[28]Association for Computing Machinery. ISBN 9781450383332. doi: 10.1145/3447555.3466586. URL https://doi.org/10.1145/3447555.3466586. Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436–444, 2015.

[29]Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. In International Conference on Learning Representations,2018.

### 30
[30]Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations, 2016.

[31]Zachary C Lipton, David Kale, and Randall Wetzel. Directly modeling missing data in sequences with rnns: Improved classification of clinical time series. In Finale Doshi-Velez, Jim Fackler, David Kale, Byron Wallace, and Jenna Wiens (eds.), Proceedings of the 1st Machine Learning for Healthcare Conference, volume 56 of Proceedings of Machine Learning Research, pp. 253– 270, Northeastern University, Boston, MA, USA, 18–19 Aug 2016.

[32]PMLR. Roderick JA Little and Donald B Rubin. Statistical analysis with missing data, volume 793. John Wiley & Sons, 2019.

[33]Weifeng Liu, Puskal P Pokharel, and Jose C Principe. Correntropy: Properties and applications in non-gaussian signal processing. IEEE Transactions on signal processing, 55(11):5286–5298, 2007.

[34]Yukai Liu, Rose Yu, Stephan Zheng, Eric Zhan, and Yisong Yue. Naomi: Non-autoregressive multiresolution sequence imputation. Advances in Neural Information Processing Systems, 32: 11238–11248, 2019.

[35]Yonghong Luo, Xiangrui Cai, Ying Zhang, Jun Xu, and Yuan Xiaojie. Multivariate time series imputation with generative adversarial networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.

[36]Yonghong Luo, Ying Zhang, Xiangrui Cai, and Xiaojie Yuan. E²gan: End-to-end generative adversarial network for multivariate time series imputation. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19, pp. 3094–3100. International Joint Conferences on Artificial Intelligence Organization, 7 2019.

[37]Jiali Mei, Yohann De Castro, Yannig Goude, and Georges Hebrail. Nonnegative matrix factorization ´ for time series recovery from a few temporal aggregates. In International Conference on Machine Learning, pp. 2382–2390. PMLR, 2017.

[38]Xiaoye Miao, Yangyang Wu, Jun Wang, Yunjun Gao, Xudong Mao, and Jianwei Yin. Generative semi-supervised learning for multivariate time series imputation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 8983–8991, 2021.

[39]Fulufhelo V Nelwamondo, Shakir Mohamed, and Tshilidzi Marwala. Missing data: A comparison of neural network and expectation maximization techniques. Current Science, pp. 1514–1521, 2007.

[40]neptune.ai. Neptune: Metadata store for mlops, built for research and production teams that run a lot of experiments, 2021. URL https://neptune.ai. Benjamin Paassen, Daniele Grattarola, Daniele Zambon, Cesare Alippi, and Barbara Eva Hammer. Graph edit networks. In International Conference on Learning Representations, 2020.

[41]Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32: 8026–8037, 2019.

[42]Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier ¨ Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal of machine Learning research, 12:2825–2830, 2011.

[43]Nikhil Rao, Hsiang-Fu Yu, Pradeep Ravikumar, and Inderjit S Dhillon. Collaborative filtering with graph information: Consistency and scalable methods. In NIPS, volume 2, pp. 7. Citeseer, 2015.

[44]Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, and Michael Bronstein. Temporal graph networks for deep learning on dynamic graphs. arXiv preprint arXiv:2006.10637, 2020.

[45]Donald B Rubin. Inference and missing data. Biometrika, 63(3):581–592, 1976. Alex Rubinsteyn and Sergey Feldman. fancyimpute: An imputation library for python. URL https://github.com/iskandr/fancyimpute. Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE transactions on neural networks, 20(1):61–80, 2008.

[46]Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In European semantic web conference, pp. 593–607. Springer, 2018.

[47]Jurgen Schmidhuber. Deep learning in neural networks: An overview. ¨ Neural networks, 61:85–117, 2015.

[48]Youngjoo Seo, Michael Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured sequence ¨ modeling with graph convolutional recurrent networks. In International Conference on Neural Information Processing, pp. 362–373. Springer, 2018.

[49]Chao Shang, Jie Chen, and Jinbo Bi. Discrete graph structure learning for forecasting multiple time series. In International Conference on Learning Representations, 2020.

[50]David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst. The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE signal processing magazine, 30(3):83–98, 2013.

[51]Indro Spinelli, Simone Scardapane, and Aurelio Uncini. Missing data imputation with adversariallytrained graph convolutional networks. Neural Networks, 129:249–260, 2020.

[52]Michael L Stein. Interpolation of spatial data: some theory for kriging. Springer Science & Business Media, 1999. Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein, and Russ B Altman. Missing value estimation methods for dna microarrays. Bioinformatics, 17(6):520–525, 2001.

[53]Guido Van Rossum and Fred L. Drake. Python 3 Reference Manual. CreateSpace, Scotts Valley, CA, 2009. ISBN 1441412697.

[54]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pp. 5998–6008, 2017.

[55]Ian R White, Patrick Royston, and Angela M Wood. Multiple imputation using chained equations: issues and guidance for practice. Statistics in medicine, 30(4):377–399, 2011.

[56]Yuankai Wu, Dingyi Zhuang, Aurelie Labbe, and Lijun Sun. Inductive graph neural networks for spatiotemporal kriging. arXiv preprint arXiv:2006.07527, 2020a.

[57]Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. Graph wavenet for deep spatial-temporal graph modeling. arXiv preprint arXiv:1906.00121, 2019.

[58]Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi Zhang. Connecting the dots: Multivariate time series forecasting with graph neural networks. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 753–763, New York, NY, USA, 2020b. Association for Computing Machinery.

[59]Xiuwen Yi, Yu Zheng, Junbo Zhang, and Tianrui Li. St-mvl: Filling missing values in geo-sensory time series data. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI’16, pp. 2704–2710. AAAI Press, 2016. ISBN 9781577357704.

[60]Jinsung Yoon, James Jordon, and Mihaela Schaar. Gain: Missing data imputation using generative adversarial nets. In International Conference on Machine Learning, pp. 5689–5698. PMLR, 2018a.

[61]Jinsung Yoon, William R Zame, and Mihaela van der Schaar. Estimating missing data in temporal data streams using multi-directional recurrent neural networks. IEEE Transactions on Biomedical Engineering, 66(5):1477–1490, 2018b.

[62]Jiaxuan You, Xiaobai Ma, Daisy Yi Ding, Mykel Kochenderfer, and Jure Leskovec. Handling missing data with graph representation learning. Neural Information Processing Systems (NeurIPS, 2020.

[63]Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. arXiv preprint arXiv:1709.04875, 2017.

[64]Hsiang-Fu Yu, Nikhil Rao, and Inderjit S Dhillon. Temporal regularized matrix factorization for high-dimensional time series prediction. Advances in neural information processing systems, 29: 847–855, 2016.

[65]Daniele Zambon, Daniele Grattarola, Lorenzo Livi, and Cesare Alippi. Autoregressive models for sequences of graphs. In 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1–8. IEEE, 2019.

[66]Jiani Zhang, Xingjian Shi, Junyuan Xie, Hao Ma, Irwin King, and Dit Yan Yeung. Gaan: Gated attention networks for learning on large and spatiotemporal graphs. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, 2018.

[67]Yu Zheng, Licia Capra, Ouri Wolfson, and Hai Yang. Urban computing: concepts, methodologies, and applications. ACM Transactions on Intelligent Systems and Technology (TIST), 5(3):1–55, 2014.

[68]Yu Zheng, Xiuwen Yi, Ming Li, Ruiyuan Li, Zhangqing Shan, Eric Chang, and Tianrui Li. Forecasting fine-grained air quality based on big data. In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, pp. 2267–2276, 2015.

### 中
[1] 加布里埃尔·阿普尔比、刘林峰和刘丽萍。克里金卷积网络。在 AAAI 人工智能会议论文集中，第 34 卷，第 3187-3194 页，2020 年。

[2]詹姆斯·阿特伍德和唐·托斯利。扩散卷积神经网络。在神经信息处理系统的进展中，第 1993-2001 页，2016 年。

[3]Shaojie Bai、J Zico Kolter 和 Vladlen Koltun。用于序列建模的通用卷积和循环网络的经验评估。 arXiv 预印本 arXiv:1803.01271, 2018。

[4]Peter W Battaglia、Jessica B Hamrick、Victor Bapst、Alvaro Sanchez-Gonzalez、Vinicius Zambaldi、Mateusz Malinowski、Andrea Tacchetti、David Raposo、Adam Santoro、Ryan Faulkner 等人。关系归纳偏差、深度学习和图网络。 arXiv 预印本 arXiv:1806.01261, 2018。

[5]洛伦佐·贝雷塔和亚历山德罗·桑塔尼洛。最近邻插补算法：关键评估。 BMC 医学信息学和决策，16(3):197–208, 2016。

[6]迈克尔·M·布朗斯坦、琼·布鲁纳、扬·勒昆、亚瑟·斯拉姆和皮埃尔·范德盖恩斯特。几何深度学习：超越欧几里得数据。 IEEE 信号处理杂志，34(4):18–42,2017。

[7] 邓才、何晓飞、韩家伟、Thomas S Huang。用于数据表示的图形正则化非负矩阵分解。 IEEE 模式分析和机器智能交易，33(8):1548–1560, 2010。

[8] 蔡玲，Krzysztof Janowicz，Gengchen Mai，Bo Yan，Rui Zhu。交通变换器：捕获时间序列的连续性和周期性以进行交通预测。 GIS 交易，24(3): 736–755, 2020。

[9] 曹伟，王东，李健，周浩，李一潭，李磊。英国人：时间序列的双向循环插补。在第 32 届神经信息处理系统国际会议论文集上，第 6776-6786 页，2018 年。

[10]Zhengping Che、Sanjay Purushotham、Kyunghyun Cho、David Sontag 和 Yan Liu。具有缺失值的多元时间序列的递归神经网络。科学报告，8（1）：1-12,2018

[11] Kyunghyun Cho、Bart Van Merrienboer、Caglar Gulcehre、Dzmitry Bahdanau、Fethi Bougares、Hol-ger Schwenk 和 Yoshua Bengio。使用 rnn 编码器-解码器学习短语表示以进行统计机器翻译。 arXiv 预印本 arXiv:1406.1078, 2014。

[12] Junyoung Chung、Caglar Gulcehre、KyungHyun Cho 和 Yoshua Bengio。门控循环神经网络对序列建模的实证评估。 arXiv 预印本 arXiv:1412.3555, 2014。

[13]Andrzej Cichocki 和 Anh-Huy Phan。用于大规模非负矩阵和张量分解的快速局部算法。 IEICE 电子、通信和计算机科学基础交易，92(3):708–721, 2009。

[14]能源监管委员会。 CER 智能计量项目 - 电力客户行为试验，2009-2010 [数据集]。爱尔兰社会科学数据档案。 SN: 0012-00, 2016. URL https://www.ucd.ie/issda/data/commissionforenergyregulationcer。

[15]迈克尔·德弗拉德、泽维尔·布列松和皮埃尔·范德盖恩斯特。图上的卷积神经网络具有快速局部谱滤波。神经信息处理系统的进展，29:3844-3852，2016。

[16]詹姆斯·德宾和西姆·扬·库普曼。通过状态空间方法进行时间序列分析。牛津大学出版社，2012 年。

[17]威廉·费杜斯、伊恩·古德费罗和安德鲁·M·戴。 Maskgan：通过填写更好的文本生成。在 2018 年国际学习代表大会上。

[18]Fabrizio Frasca、Emanuele Rossi、Davide Eynard、Benjamin Chamberlain、Michael Bronstein 和 Federico Monti。标志：可扩展的初始图神经网络。 2020 年 ICML 2020 图形表示学习及超越研讨会。

[19]佐宾·加赫拉马尼和迈克尔·乔丹。通过 em 方法从不完整的数据中进行监督学习。载于 J. Cowan、G. Tesauro 和 J. Alspector (eds.)，《神经信息处理系统进展》，第 6 卷。Morgan-Kaufmann，1994 年。Justin Gilmer、Samuel S Schoenholz、Patrick F Riley、Oriol Vinyals 和 George E达尔。量子化学的神经信息传递。在国际机器学习会议上，第 1263-1272 页。 2017 年，PMLR。

[20]Ian Goodfellow、Jean Pouget-Abadie、Mehdi Mirza、Bing Xu、David Warde-Farley、Sherjil Ozair、Aaron Courville 和 Yoshua Bengio。生成对抗网络。神经信息处理系统的进展，27，2014。

[21]伊恩·古德费罗、约书亚·本吉奥、亚伦·库维尔和约书亚·本吉奥。深度学习，第 1 卷。麻省理工学院出版社，2016 年。

[22]克莱夫·W·J·格兰杰。通过计量经济学模型和交叉光谱法研究因果关系。计量经济学：计量经济学会杂志，第 424-438 页，1969 年。William L Hamilton、Rex Ying 和 Jure Leskovec。大图上的归纳表示学习。在第 31 届神经信息处理系统国际会议论文集上，第 1025-1035 页，2017 年。

[23]查尔斯·R·哈里斯、K·贾罗德·米尔曼、斯特凡·J·范德沃尔特、拉尔夫·戈默斯、保利·维尔塔宁、大卫·库尔纳 peau、Eric Wieser、Julian Taylor、Sebastian Berg、Nathaniel J Smith 等人。使用 numpy 进行数组编程。自然，585（7825）：357–362，2020。

[24]Sepp Hochreiter 和 Jurgen Schmidhuber。长短期记忆。 ¨ 神经计算，9(8): 1735–1780, 1997。Hosagrahar V Jagadish、Johannes Gehrke、Alexandros Labrinidis、Yannis Papakonstantinou、Jignesh M Patel、Raghu Ramakrishnan 和 Cyrus Shahabi。大数据及其技术挑战。 ACM 通讯，57(7):86–94, 2014。

[25]J Kihoro、K Athiany 等人。不完整的非平稳季节性时间序列数据的插补。数学理论与建模，3（12）：142-154，2013。

[26]Thomas Kipf、Ethan Fetaya、Kuan-Chieh Wang、Max Welling 和 Richard Zemel。交互系统的神经关系推理。在机器学习国际会议上，第 2688-2697 页。PMLR，2018。

[27]Sanmukh R. Kuppannagari、Yao Fu、Chung Ming Chueng 和 Viktor K. Prasanna。智能电网时空缺失数据插补。在第十二届 ACM 未来能源系统国际会议论文集中，e-Energy '21，第 458-465 页，美国纽约州纽约市，2021 年。

[28]计算机协会。国际标准书号 9781450383332。doi：10.1145/3447555.3466586。网址 https://doi.org/10.1145/3447555.3466586。 Yann LeCun、Yoshua Bengio 和 Geoffrey Hinton。深度学习。自然，521（7553）：436–444，2015。

[29]李亚光、余蔷薇、赛勒斯·沙哈比、刘艳。扩散卷积递归神经网络：数据驱动的交通预测。在 2018 年国际学习代表大会上。
### 30
[30]李玉嘉、丹尼尔·塔洛、马克·布罗克施密特和理查德·S·泽梅尔。门控图序列神经网络。在国际学习代表大会上，2016。

[31]扎卡里·C·立顿、大卫·凯尔和兰德尔·韦策尔。使用 rnns 直接建模序列中的缺失数据：改进的临床时间序列分类。在 Finale Doshi-Velez、Jim Fackler、David Kale、Byron Wallace 和 Jenna Wiens（编辑），第一届机器学习医疗会议论文集，机器学习研究论文集第 56 卷，第 253-270 页，东北大学，美国马萨诸塞州波士顿，2016 年 8 月 18 日至 19 日。

[32]PMLR。罗德里克 JA 利特尔和唐纳德 B 鲁宾。缺失数据的统计分析，第 793 卷。John Wiley & Sons，2019 年。

[33] 刘伟峰、Puskal P Pokharel 和 Jose C Principe。 Correntropy：非高斯信号处理中的属性和应用。 IEEE 信号处理汇刊，55(11):5286–5298, 2007。

[34] 刘玉凯、于蔷薇、Stephan Zheng、Eric Zhan 和 Yisong Yue。 Naomi：非自回归多分辨率序列插补。神经信息处理系统的进展，32：11238-11248，2019。

[35]罗永红，蔡祥瑞，张颖，徐俊，袁晓杰。具有生成对抗网络的多元时间序列插补。载于 S. Bengio、H. Wallach、H. Larochelle、K. Grauman、N. Cesa-Bianchi 和 R. Garnett（编辑），神经信息处理系统进展，第 31 卷。Curran Associates, Inc.，2018 年。

[36]罗永红，张颖，蔡祥瑞，袁小杰。 E²gan：用于多元时间序列插补的端到端生成对抗网络。在第二十八届国际人工智能联合会议论文集上，IJCAI-19，第 3094-3100 页。国际人工智能组织联合会议，2019 年 7 月。

[37] 梅佳丽、约汉·德·卡斯特罗、雅尼格·古德和乔治·赫伯瑞尔。非负矩阵分解'用于从几个时间聚合中恢复时间序列。在机器学习国际会议上，第 2382-2390 页。 2017 年，PMLR。

[38] 苗小野，吴阳阳，王军，高云军，毛旭东，尹建伟。用于多元时间序列插补的生成式半监督学习。在 AAAI 人工智能会议论文集中，第 35 卷，第 8983-8991 页，2021 年。

[39]Fulufhelo V Nelwamondo、Shakir Mohamed 和 Tshilidzi Marwala。缺失数据：神经网络和期望最大化技术的比较。 《当代科学》，第 1514-1521 页，2007 年。

[40]海王星.ai。 Neptune：用于 mlops 的元数据存储，专为进行大量实验的研究和生产团队打造，2021 年。网址 https://neptune.ai。本杰明·帕森、丹尼尔·格拉塔罗拉、丹尼尔·赞邦、切萨雷·阿利皮和芭芭拉·伊娃·哈默。图形编辑网络。在 2020 年国际学习代表大会上。

[41]Adam Paszke、Sam Gross、Francisco Massa、Adam Lerer、James Bradbury、Gregory Chanan、Trevor Killeen、Zeming Lin、Natalia Gimelshein、Luca Antiga 等。 Pytorch：命令式风格的高性能深度学习库。神经信息处理系统的进展，32：8026-8037，2019。

[42]Fabian Pedregosa、Gael Varoquaux、Alexandre Gramfort、Vincent Michel、Bertrand Thirion、Olivier ¨ Grisel、Mathieu Blondel、Peter Prettenhofer、Ron Weiss、Vincent Dubourg 等。 Scikit-learn：python 中的机器学习。机器学习研究杂志，12:2825–2830，2011。

[43]尼基l Rao、Hsiang-Fu Yu、Pradeep Ravikumar 和 Inderjit S Dhillon。具有图信息的协同过滤：一致性和可扩展方法。在 NIPS，第 2 卷，第 7 页。Citeseer，2015。

[44]伊曼纽尔·罗西、本·张伯伦、法布里齐奥·弗拉斯卡、大卫·艾纳德、费德里科·蒙蒂和迈克尔·布朗斯坦。用于动态图深度学习的时间图网络。 arXiv 预印本 arXiv:2006.10637, 2020。

[45]唐纳德·B·鲁宾。推理和缺失数据。 Biometrika, 63(3):581–592, 1976. Alex Rubinsteyn 和 Sergey Feldman。 fancyimpute：python 的插补库。网址 https://github.com/iskandr/fancyimpute。 Franco Scarselli、Marco Gori、Ah Chung Tsoi、Markus Hagenbuchner 和 Gabriele Monfardini。图神经网络模型。 IEEE 神经网络交易，20(1):61–80, 2008。

[46]Michael Schlichtkrull、Thomas N Kipf、Peter Bloem、Rianne Van Den Berg、Ivan Titov 和 Max Welling。使用图卷积网络对关系数据进行建模。在欧洲语义网络会议上，第 593-607 页。斯普林格，2018。

[47]尤尔根·施米德胡伯。神经网络中的深度学习：概述。 ¨ 神经网络，61:85–117，2015。

[48]Youngjoo Seo、Michael Defferrard、Pierre Vandergheynst 和 Xavier Bresson。结构化序列 - 使用图卷积循环网络建模。在神经信息处理国际会议上，第 362-373 页。斯普林格，2018。

[49] 尚超，陈洁，毕金波。用于预测多个时间序列的离散图结构学习。在 2020 年国际学习代表大会上。

[50]大卫·舒曼、苏尼尔·K·纳朗、帕斯卡·弗罗萨德、安东尼奥·奥尔特加和皮埃尔·范德盖恩斯特。图信号处理的新兴领域：将高维数据分析扩展到网络和其他不规则领域。 IEEE 信号处理杂志，30(3):83–98，2013。

[51]因德罗·斯皮内利、西蒙娜·斯卡达潘和奥雷里奥·安奇尼。对抗训练的图卷积网络缺少数据插补。神经网络，129：249–260，2020。

[52]迈克尔·L·斯坦。空间数据插值：克里金法的一些理论。 Springer Science & Business Media，1999 年。Olga Troyanskaya、Michael Cantor、Gavin Sherlock、Pat Brown、Trevor Hastie、Robert Tibshirani、David Botstein 和 Russ B Altman。 dna 微阵列的缺失值估计方法。生物信息学，17（6）：520–525，2001。

[53]Guido Van Rossum 和 Fred L. Drake。 Python 3 参考手册。 CreateSpace，加利福尼亚州斯科茨谷，2009 年。ISBN 1441412697。

[54]Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、Aidan N Gomez、Łukasz Kaiser 和 Illia Polosukhin。注意力就是你所需要的。在神经信息处理系统的进展中，第 5998-6008 页，2017 年。

[55]伊恩·R·怀特、帕特里克·罗伊斯顿和安吉拉·M·伍德。使用链式方程的多重插补：问题和实践指南。医学统计，30(4):377–399，2011。

[56] 吴元凯、庄丁一、奥蕾莉·拉贝、孙丽君。用于时空克里金法的归纳图神经网络。 arXiv 预印本 arXiv:2006.07527, 2020a。

[57] 吴宗涵、潘诗瑞、龙国栋、姜静、张承启。用于深度时空图建模的图波网。 arXiv 预印本 arXiv:1906.00121, 2019。

[58] 吴宗翰、潘诗瑞、龙国栋、姜静、常晓军、张承启。连接点：使用图神经网络进行多变量时间序列预测。在第 26 届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集中，第 753-763 页，纽约，纽约，美国，2020b。计算机协会。

[59]易修文，于正，张俊波，李天瑞。 St-mvl：填充地理感知时间序列数据中的缺失值。在第二十五届人工智能国际联合会议论文集上，IJCAI'16，第 2704-2710 页。 AAAI 出版社，2016 年。国际标准书号 9781577357704。

[60]Jinsung Yoon、James Jordon 和 Mihaela Schaar。增益：使用生成对抗网络缺失数据插补。在机器学习国际会议上，第 5689-5698 页。 PMLR，2018a。

[61]Jinsung Yoon、William R Zame 和 Mihaela van der Schaar。使用多向递归神经网络估计时间数据流中的缺失数据。 IEEE 生物医学工程汇刊，66(5):1477–1490, 2018b。

[62] 尤嘉轩、马晓白、Daisy Yi Ding、Mykel Kochenderfer 和 Jure Leskovec。使用图表示学习处理缺失数据。神经信息处理系统（NeurIPS，2020。

[63] 于冰，尹浩腾，朱占兴。时空图卷积网络：用于交通预测的深度学习框架。 arXiv 预印本 arXiv:1709.04875, 2017。

[64] Hsiang-Fu Yu、Nikhil Rao 和 Inderjit S Dhillon。用于高维时间序列预测的时间正则化矩阵分解。神经信息处理系统的进展，29：847-855，2016。

[65]Daniele Zambon、Daniele Grattarola、Lorenzo Livi 和 Cesare Alippi。图序列的自回归模型。 2019年国际神经网络联合会议 (IJCNN)，第 1-8 页。 IEEE，2019。

[66]张佳妮、施行健、谢军源、马浩、欧文·金、杨迪特·扬。 Gaan：用于学习大型时空图的门控注意网络。 在 2018 年第 34 届人工智能不确定性会议上，UAI 2018，2018。

[67]于正、莉西亚·卡普拉、欧里·沃尔夫森和海洋。 城市计算：概念、方法和应用。 ACM 智能系统和技术交易 (TIST)，5(3):1-55，2014。

[68] 于正，易修文，李明，李瑞源，张清山，Eric Chang，李天瑞。 基于大数据的细粒度空气质量预测。 在第 21 届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集上，第 2267-2276 页，2015 年。

