# Linear_algebra


# 线性代数

## 开篇词 | 从今天起，学会线性代数
朱维刚 2020-07-27

机器学习本身没有多大难度，因为经过多年的积累后，很多规则已经成型了。对于我们来说真正难的，是机器学习背后的算法所涉及的基础数学原理，包括向量、矩阵等等。我们可以来看下机器学习的整个知识体系。单从数学角度来看，这个覆盖范围非常广，有向量积分、矩阵分解等等，但最最核心的还是线性代数。所以说，不要再问我为什么自己学不会机器学习、人工智能了，因为你没有学好线性代数。

![img](https://static001.geekbang.org/resource/image/29/75/293733525270cdb930e0e1f7d10fee75.png?wh=1920*1079)



不过，你可千万不要觉得，学了线性代数之后，实际应用就只有机器学习。如果这么想，那就太局限了。线性代数是计算机很多领域的基础。比如，如何让 3D 图形显示到二维屏幕上？这是线性代数在图形图像学中的应用。如何提高密码被破译的难度？这个密码学问题，用线性代数中的有限向量空间可以很好地解决。线性代数的应用真的非常广泛。掌握了线性代数这样的基础学科知识，我们其实就相当于有了数学这个利器，为其他领域的实际应用打下了非常好、非常扎实的基础。最简单、最直接的利益——你不仅可以在工作中进行算法调优，还能成为公司创新团队的主力。




### 到底该怎么学线性代数？
既然线性代数是机器学习最底层的知识，如果我们想要在机器学习上有所作为，学会线性代数是必须的。那该怎么学呢？我估计你肯定看过外面很多书或者课程，我也看过。它们无一例外都是直接上来就给你讲机器学习的应用实践，然后里面穿插了一些数学知识，从实践的角度切入。这样编排课程当然没问题，优点是入门容易，但它的缺点也是显而易见的。这样学下来，很多时候，你只知道固定的应用场景，死记硬背几个知识点容易，但是数学知识并不牢固。当遇到实际问题的时候，你除了套公式之外，还是只能干瞪眼，根本没有真正吃透背后的原理。因此，从我自己学习的经验出发，在技术领域里，我更推荐自下而上的学习方式，也就是从底层基础概念开始，一步步循序渐进往上走，一直走到应用实践。当然，这个方式也有缺点，那就是入门的时候困难，可能会遇到很多知识阻碍，很多人都会中途放弃。这些学习经历我都深有体会。所以，我运用了自下而上的方式来进行讲解，同时，讲解每个知识点的时候，我都会加入一些和理论有关的实践讲解。这样就能够帮你由里及表，融会贯通，在搭建起知识体系的同时，可以获得螺旋式上升的学习效果。为了让你能更加系统地学习线性代数，在设计“重学线性代数”这门课时，我还真是下了一番苦功夫。下面就给你详细介绍下这门课的两大模块。

![img](https://static001.geekbang.org/resource/image/a8/aa/a845db49d6524fc3400f2e76c8818caa.png?wh=751*1672)

第一个模块是基础篇，我们主要讲线性代数的理论基础。我会从最简单、也是你最熟悉的线性方程组说起，在这基础上引出向量和矩阵，并通过矩阵来讲“解线性方程组”的不同方法（有直接法，也有实践中用得最多的间接迭代法）。然后，我会在向量和矩阵的基础上讲线性空间，因为在实践中，更多的是对集合的操作，也就是对线性空间的操作。线性空间好比是容器，它包含了向量以及向量的运算。基础篇的最后，我还会为你介绍解析几何，是解析几何使得向量从抽象走向了具象，让向量具有了几何的含义，比如：计算向量的长度、之间的距离和角度，这在机器学习的主成分分析 PCA 中是非常有用的。

第二个模块是应用篇，我会结合线性代数的基础理论，讲解线性代数在计算机科学中的应用。有了之前的基础后，你再来看应用实践就会觉得简单很多。当其中会涉及一些线性代数以外的数学领域时，我也会给予一定的说明。特别地，我要强调一下。在每一讲最后我都特意设计了“线性代数练习场”，带你通过练习来巩固学到的知识点。所以，这个小板块一定要重视起来，期待和你一起在实践中探索。所以从整体来说，“重学线性代数”可以满足你四个层次的需求：

![img](https://static001.geekbang.org/resource/image/b8/57/b867ee13ab166a609f1dd86a168aaa57.png?wh=1920*986)



第一层次：在研究应用领域时，希望能够理解数学公式的意义。第二层次：在阅读线性代数参考书时，希望理解书中的内容。第三层次：能够自己实践、自己计算。第四层次：能够踏入大规模矩阵计算的世界。

好了，到这里，我想说的已经差不多了，不知道你有没有准备好，跟我一起学习了呢？进入 DT 时代后，很多企业都开始着手做数字化转型。站在从业者的角度，有了数字化的基础数据，我相信，终有一天人工智能将定义下一代软件解决方案，这是一个巨大的机会。我希望在这个机会真正到来前，你能和我一起，一步步地、深入浅出地学习线性代数这门数学基础课，成为企业研究机构的创新力量之一。我也非常希望，通过这门课程的学习，你能对线性代数能有一个重新的认识，让线性代数融入到你的工作和生活中，真正改变你的工作和生活，让它成为你的翅膀。

## 基础
## 01 | 导读：如何在机器学习中运用线性代数工具？
在开篇词中，我和你大致讲过我自己的经历，从 2006 年开始到现在 14 年的时间里，我都专注于机器学习领域。对于线性代数在机器学习中的应用，我非常了解。而这也是线性代数最主要的应用场景之一。因此，今天第一节课，我想先和你聊一聊，如何在机器学习中运用线性代数工具，在我们开始自下而上的学习之前，先从上层来看一看。我们都知道，“数据”是机器学习的前提，机器学习的第一步就是要进行数据的收集、预处理和特征提取；而模型就是通过数据来学习的算法；学习则是一个循环过程，一个自动在数据中寻找模式，并不停调优模型参数的过程。那我们就从机器学习的三个核心概念：数据、模型和学习说起。

![img](https://static001.geekbang.org/resource/image/3a/32/3a2a7433d5d13b676abe05041a1bcd32.png?wh=1920*1076)

你看，不论是模型，还是学习，都涉及数据，而数据加上模型和学习，就是数学的一般过程了，也就是：观察、实验、推理和抽象。所以，我认为学好数学，不仅有利于理解复杂的机器学习系统，还能调优算法参数，甚至能帮助你创建新的机器学习解决方案。


### 从机器学习到线性代数
那机器学习和线性代数之间到底有着怎样的关系呢？我想，用一个实际的机器学习算法的例子来解释，你可能更容易搞清楚。接下来，我使用 KNN（K-Nearest Neighbor，K 最近邻分类算法）来让你简单了解一下机器学习，以及它和线性代数之间的关系。之所以选 KNN 分类算法，因为它是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。这个方法的思路是：如果一个样本在特征空间中的 K 个最相似（即特征空间中最邻近）的样本中的大多数属于某一个类别，则该样本也属于这个类别。这里有个前提，KNN 算法中，所选择的“邻居”都是已经正确分类的对象。KNN 分类算法在分类决策上只依据最邻近的一个或者几个样本的类别，来决定待分样本所属的类别。我们通过图来理解的话或许更容易一些。

![img](https://static001.geekbang.org/resource/image/43/aa/439cefee464eb01ed110e70515f94eaa.png?wh=1920*1079)

假设图片中那个绿色圆就要是我们要决策的对象，那么根据 KNN 算法它属于哪一类？是红色三角形还是蓝色四方形？如果 K=3（实线圆），也就是包含离绿色圆最近的 3 个，由于红色三角形所占比例为 2/3，绿色圆就属于红色三角形那个类。但如果 K=5（虚线圆），就是包含离绿色圆最近的 5 个，由于蓝色四方形比例为 3/5，绿色圆就属于蓝色四方形那个类。


### 鸢尾花分类问题中的线性代数
通过前面这个小例子，你应该已经理解了 KNN 算法的概念。那么接下来，我们就试着使用 KNN 在给定鸢尾花特征值的情况下，给鸢尾花做花种分类，带你来实际看一下线性代数在这里起到的作用。特别说明一下，鸢尾花分类问题是一个国际上通用的案例，一般都被作为机器学习入门来使用，所以它的数据集也是公开的。


1. 数据集的收集、加载和分析首先，我们要做的是数据集的收集、加载和分析，你也可以点击[这里](https://www.kaggle.com/notlir/iriscsv)下载原始数据集，来看看原始数据长什么样，下面是获取和加载数据的代码，sklearn 数据集已经包含了样本数据，你可以直接用。

```
import pandas as pd

from sklearn import datasets
iris = datasets.load_iris()

species = [iris.target_names[x] for x in iris.target]

iris = pd.DataFrame(iris['data'], columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'])

iris['Species'] = species
```
从显示的结果，我们能够看出鸢尾花有四个特征：花萼的长、宽和花瓣的长、宽。我们来看下这四个特征的数据类型：

```
iris.dtypes
Sepal_Length    float64
Sepal_Width     float64
Petal_Length    float64
Petal_Width     float64
Species          object
dtype: object
```
这些特征都是数值型，而且标签 Species 表示的是花种，是一个字符串类型的变量。我们继续看一下鸢尾花的分类统计：
```
iris['count'] = 1
iris[['Species', 'count']].groupby('Species').count()
```

![img](https://static001.geekbang.org/resource/image/a7/ce/a7ff740c15de327cfd8c1c9a4b681cce.png?wh=1920*1078)



这里我们直接能够看到，鸢尾花有三个花种，每个种类有 50 个实例，或者说 50 条数据，我们再用图来更直观地显示这三种鸢尾花。



```

%matplotlib inline

def plot_iris(iris, col1, col2):
    import seaborn as sns
    import matplotlib.pyplot as plt

    sns.lmplot(x = col1, y = col2,
               data = iris,
               hue = "Species",
               fit_reg = False)

    plt.xlabel(col1)

    plt.ylabel(col2)

    plt.title('Iris species shown by color')

    plt.show()

plot_iris(iris, 'Petal_Width', 'Sepal_Length')

plot_iris(iris, 'Sepal_Width', 'Sepal_Length')
```

![img](https://static001.geekbang.org/resource/image/c2/93/c216f676f59e00cae4b52481fdf88293.png?wh=1702*1326)

![img](https://static001.geekbang.org/resource/image/a8/0a/a8337b9d13c23ef18e3bd8a4dbb91b0a.png?wh=1726*1324)

蓝、黄、绿，这三种颜色分别代表了三种鸢尾花，显示还是很清楚的。



2. 数据集的准备 接下来的第二步就是数据集的准备了。在训练任何机器学习模型前，数据准备都相当重要，这里也要涉及两步准备。第一步，特征数值标准化。如果我们不做标准化，后果就是大数值特征会主宰模型训练，这会导致更有意义的小数值特征被忽略。这里我们用 Z Score 标准化，使每一类特征平均值为 0，方差为 1.0，我们可以通过代码实现来看下效果。


```
from sklearn.preprocessing import scale

import pandas as pd

num_cols = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']

iris_scaled = scale(iris[num_cols])

iris_scaled = pd.DataFrame(iris_scaled, columns = num_cols)

print(iris_scaled.describe().round(3))
```

![img](https://static001.geekbang.org/resource/image/1f/da/1f7bbea1c93dcdbbcd9c1ba4e32178da.png?wh=1920*1079)

你可以看到，每一列平均值为 0，标准差大约是 1.0。为了分类需要，我们用字典把花种从字符串类型转换成数字表示。

```

levels = {'setosa':0, 'versicolor':1, 'virginica':2}

iris_scaled['Species'] = [levels[x] for x in iris['Species']]

iris_scaled.head()
```

![img](https://static001.geekbang.org/resource/image/bc/5e/bc14b245ab9076d3a8911dyy2da8895e.png?wh=1920*1078)

第二步，把数据集随机分割成样本训练集和评估数据集，训练集用来训练 KNN 模型，评估集用来测试和评估 KNN 的分类结果。

```

from sklearn.model_selection import train_test_split

import numpy as np

np.random.seed(3456)

iris_split = train_test_split(np.asmatrix(iris_scaled), test_size = 75)

iris_train_features = iris_split[0][:, :4]

iris_train_labels = np.ravel(iris_split[0][:, 4])

iris_test_features = iris_split[1][:, :4]

iris_test_labels = np.ravel(iris_split[1][:, 4])

print(iris_train_features.shape)

print(iris_train_labels.shape)

print(iris_test_features.shape)

print(iris_test_labels.shape)
```



通过代码，我们得到了下面这样的结果。

```

(75, 4)
(75,)
(75, 4)
(75,)
```
3. 训练模型 数据准备好后，就是第三步训练模型了。这里我们使用 K=3 来训练 KNN 模型，当然你也可以调整这个参数来进行观察和调优。


```
from sklearn.neighbors import KNeighborsClassifier

KNN_mod = KNeighborsClassifier(n_neighbors = 3)

KNN_mod.fit(iris_train_features, iris_train_labels)
```

4. 模型测试 执行 KNN 训练后，我们来到了最后一步，模型测试，这里我们使用测试集来测试模型。

```
iris_test = pd.DataFrame(iris_test_features, columns = num_cols)

iris_test['predicted'] = KNN_mod.predict(iris_test_features)

iris_test['correct'] = [1 if x == z else 0 for x, z in zip(iris_test['predicted'], iris_test_labels)]

accuracy = 100.0 * float(sum(iris_test['correct'])) / float(iris_test.shape[0])

print(accuracy)
```
```
96.0
```
最终，我们得到的准确率是 96.0，说明了 KNN 的训练模型不错，适用这类场景。我们通过代码把其中的两个分类 setosa 和 versicolor 打印出来看看。

```
levels = {0:'setosa', 1:'versicolor', 2:'virginica'}

iris_test['Species'] = [levels[x] for x in iris_test['predicted']]

markers = {1:'^', 0:'o'}

colors = {'setosa':'blue', 'versicolor':'green',}

def plot_shapes(df, col1,col2,  markers, colors):
    import matplotlib.pyplot as plt
    import seaborn as sns

    ax = plt.figure(figsize=(6, 6)).gca() # define plot axis

    for m in markers: # iterate over marker dictioary keys
        for c in colors: # iterate over color dictionary keys
            df_temp = df[(df['correct'] == m)  & (df['Species'] == c)]
            sns.regplot(x = col1, y = col2,
                        data = df_temp, 
                        fit_reg = False,
                        scatter_kws={'color': colors[c]},
                        marker = markers[m],
                        ax = ax)
    plt.xlabel(col1)
    plt.ylabel(col2)
    plt.title('Iris species by color')
    return 'Done'

plot_shapes(iris_test, 'Petal_Width', 'Sepal_Length', markers, colors)
plot_shapes(iris_test, 'Sepal_Width', 'Sepal_Length', markers, colors)
```

![img](https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png?wh=1100*1168)

![img](https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png?wh=1088*1094)

从显示的效果来说，分类还是挺明显的，熟悉了最基础的机器学习过程后，你可能会问，讲了半天，线性代数到底在哪里呢？关键就在 KNeighborsClassifier 模块上，这个模型算法的实现背后，其实用到了线性代数的核心原理。首先，因为每种鸢尾花都有四个特征：花萼的长、宽和花瓣的长、宽，所以每条数据都是四维向量。接着，量化样本之间的相似度，也就是计算向量之间的距离。而向量之间距离的运算有很多方式，比如：曼哈顿距离、欧式距离、切比雪夫距离、闵可夫斯基距离等等。其中，欧式距离你应该很熟悉了，因为我们初中都学过，在二维平面上计算两点之间的距离公式：

$$
d=\sqrt{\left(x_{1}-x_{2}\right)^{2}+\left(y_{1}-y_{2}\right)^{2}}
$$

扩展到我们实例中的四维向量，也是同样的算法。你看，这就是线性代数在机器学习中的一种应用场景。KNN 是一种监督学习算法，因为在样本集中有分类信息，通过计算距离来衡量样本之间相似度，算法简单，易于理解和实现。还有另一种机器学习算法是无监督学习，底层的数学原理其实也是差不多的，总的思想就是“物以类聚”。现在，你是不是有一种豁然开朗的感觉？终于看到了线性代数原来那么有意义，而且再简单的公式也是美的。


### 本节小结
好了，到这里导读这一讲就结束了，最后我再总结一下前面讲解的内容。这一讲我使用机器学习的监督学习算法 KNN，在给定鸢尾花特征值的情况下，给鸢尾花做花种分类，让你了解机器学习最基本的过程外，能够真正了解其背后的线性代数真相，为你进入后面课程的学习提供一个感性的认知。机器学习中用到的线性代数知识点比比皆是，而且往往软件架构上看上去复杂的事情，在数学上反而很简单，希望你在学习了这门课程后，能够多从数学角度出发去构思解决问题的方案。


## 02 | 基本概念：线性代数研究的到底是什么问题？


线性代数可以运用在很多领域，比如：工程学、计算机科学、经济学、信号处理等等。我们来看一个在经济学中常见的例子：消费矩阵。假设有 n 个行业，比如：化学、食品和石油。制造一单位的某化学品需要 0.2 单位的另一类化学品，0.3 单位的食品，以及 0.4 单位的石油，而制造一单位的某食品和某石油也同样分别需要这三类产品的输入，于是，我们就能构造这样一个消费矩阵：


$$
\left|\begin{array}{l}
\text { 化学输出 } \\
\text { 食吕输出 } \\
\text { 石油输出 }
\end{array}\right|=\left[\begin{array}{lll}
0.2 & 0.3 & 0.4 \\
0.4 & 0.4 & 0.1 \\
0.5 & 0.1 & 0.3
\end{array}\right] \mid \begin{aligned}
&\text { 化学输入 } \\
&\text { 食吕输入 } \\
&\text { 石油输入 }
\end{aligned}
$$

当然，我们也可以用一般的线性方程组 Ax=b 的形式来表达：

$$
\left\{\begin{array}{l}
0.2 x_{1}+0.3 x_{2}+0.4 x_{3}=b_{1} \\
0.4 x_{1}+0.4 x_{2}+0.1 x_{3}=b_{2} \\
0.5 x_{1}+0.1 x_{2}+0.3 x_{3}=b_{3}
\end{array}\right.
$$
从本质上来说，消费矩阵解决的是输入和输出之间的关系。不仅如此，线性代数在现实生活中的运用还有很多，比如，我们可以借用特征值和特征向量，预测若干年后的污水水平；在密码学中，可以使用矩阵及其逆矩阵对需发送的消息加密；在机器学习中，可以使用线性方程组的共轭迭代法来训练神经网络，等等。刚才我分别用矩阵和线性方程组的形式给出了消费矩阵，当然，在实际生活中，你可以灵活选择最有效的方式来解决问题。我们可以看到，线性方程组可以表示成一般形式，也就是你初中学到的 Ax=b 的形式，也可以表示成矩阵形式。矩阵是由向量组合而成的，比如刚才例子中的系数矩阵的每一行都是一个行向量，每一列都是一个列向量。

$$
\left[\begin{array}{lll}
0.2 & 0.3 & 0.4 \\
0.4 & 0.4 & 0.1 \\
0.5 & 0.1 & 0.3
\end{array}\right]
$$


从这里我们能看出，向量其实就会是线性代数最基础的核心。数学对抽象思维要求很高，简单来说，抽象思维就是抽取同类事物的共性。所以，在进入具体的线性方程组的主题前，我要先从数学抽象的角度说一说代数和线性代数，这也是深入理解后面内容的前提。


### 代数和线性代数的基本概念
那什么是代数呢？百度百科的解释是这样的：

代数是研究数、数量、关系、结构与代数方程（组）的通用解法及其性质的数学分支。

但我觉得这个解释其实没有说出代数这个概念的重点。我的理解是这样的：代数是构造一系列对象和一系列操作这些对象的规则。所以你看，代数这个概念的核心就两点，对象和操作对象的规则，这样就很好理解了吧？那有了代数的定义，线性代数就很好定义了。我们类比来看，线性代数其实就是向量，以及操作这些向量的规则。这里，向量映射到对象，向量的规则映射到对象的规则，因此线性代数是代数的具像化表达。

![img](https://static001.geekbang.org/resource/image/b5/64/b51a25b2810340472a4yy5701a057764.png?wh=2622*1024)


### 向量的基本概念
那什么是向量呢？从样子来看，向量其实就是由字母加上它上面的箭头来表示的，比如我们一版会写成 x。我估计你在高中或大学里已经接触过“几何向量”。那么，下面我用更抽象的数学观点来给你解释一下。向量，也叫欧几里得向量（Euclidean Vector），其实就是能够互相相加、被标量乘的特殊对象。而标量也叫“无向量”，它只有数值大小，没有方向。怎么理解呢？我们来看一些向量的例子，通过这些例子来深入理解向量的概念。几何向量是有向线段，在二维空间（也就是平面）中，两个几何向量能够相加，比如，向量 x 加上向量 y 等于向量 z，x+y​=z ，x 向量也能被一个标量乘。再比如，标量 λ 乘向量 x 结果也是向量，λx,λ∈R。几何向量通过大小和方向来简化向量的表达，所以，一般数学课程一开始都会拿几何向量来进行举例。

![img](https://static001.geekbang.org/resource/image/bb/5c/bbc1e0e2cd7eac341f91cd0e40b5f35c.png?wh=2620*1142)

多项式其实也是向量。两个多项式能够相加，它也能够被标量乘，结果也是多项式。矩阵的一行或一列也是向量。就比如下面这样形式的向量。

$$
x \in R^{3}: x=\left[\begin{array}{l}
1 \\
2 \\
3
\end{array}\right]
$$

两个向量能够相加，它也能够被标量乘，结果也是向量。它和现代大部分的编程语言中的数组一致，而且数组的运算简化了向量操作的算法实施。矢量图、音频信号也是向量。它们都能被一系列数字表示，比如，在音频信号处理中，常用到数据增强的方法，通过向量的操作就能到达目标。看了这些向量例子，不知道你现在有点感觉了吗？其实，线性代数的本质就是寻找向量之间的相似性，比如在做分类时，我们常常需要估算不同样本之间的相似性度量（Similarity Measurement），这时通常采用的方法就是计算样本间的“距离”（Distance）。

可以看出来，向量非常重要，我们后面很多内容都是从向量延伸而来的，比如矩阵和求解线性方程组。下面我用一张图来表达和向量有关的所有概念，也就是线性代数所有的核心内容，其中大部分内容你都会学到，希望通过这个图，你对线性代数有个大概的认知。相信学习完所有课程后，你再回过头来看时，肯定会有一些新的认知。

![img](https://static001.geekbang.org/resource/image/27/a6/271d9b2f46af71fc70b55863556a0ba6.png?wh=2622*1472)

从图中最左侧这一列，我们可以看出，向量组合成矩阵，矩阵可以表示成线性方程组，而线性方程组可以通过高斯消元法求解，也可以求逆矩阵。同时，向量又可以组合成向量空间，向量空间和矩阵都可以做线性映射或者线性变换，线性映射在实践中可以用在解析几何和分类问题中。而且，向量和线性独立是强相关的，也就是说，线性独立指的是向量的线性独立，而线性独立又可以引出能够生成整个空间的基（Basis），基在实践中可以用在分类和降维中。这里，我再额外提一个非常重要的、在数学中经常用到的概念——封闭性，或者俗称闭包（Closure）。封闭性的定义是，如果我们要对某个集合的成员进行一种运算，生成的仍然是这个集合的成员，那这个集合就可以称为在这个运算下闭合。我为什么要提这个概念呢？这是因为，向量的线性运算是封闭的，也就是说向量的加法、数乘结果仍属于向量空间，即向量的任意线性组合仍属于向量空间。


### 线性方程组的应用
……

### 线性方程组的几何表达
……
### 小结

![img](https://static001.geekbang.org/resource/image/b3/b7/b3685e09f961f3c7e51702bbd56d7cb7.png?wh=1200*1021)


## 03 | 矩阵：为什么说矩阵是线性方程组的另一种表达？

在开始学习之前，我想先问你个问题，你觉得，学习矩阵有什么用呢？你可以先自己想一想。之后我们讲任何一个知识的时候，你都可以从这个角度出发，自己先思考一下，这样有助于你对所学内容理解得更深刻。对于刚才那个问题，我的答案很简单，就一句话，从我们程序员的角度去理解的话，矩阵可以极大地提高计算机的运算效率。怎么说呢？我给你举一个例子。在机器学习中（特别是深度学习，或者更具体一点，神经网络），并行计算是非常昂贵的。

![img](https://static001.geekbang.org/resource/image/a6/0d/a66474802f395e8e1a78147c7949150d.png?wh=1200*661)

上图是一个典型的神经网络架构，在这时候，矩阵就能发挥用武之地了，计算 H 隐藏层输出的公式是：H=f(W.x+b)，其中 W 是权重矩阵，f 是激活函数，b 是偏差，x 是输入层矩阵。而这个计算过程就叫做向量化（Vectorization），这也是 GPU 在深度学习中非常重要的原因，因为 GPU 非常擅长做类似矩阵乘之类的运算。

不过，矩阵也不仅仅局限于神经网络的应用，同时它也可以用在计算机图形图像的应用中，比如，三维物体从取景到屏幕的显示，就需要经历一系列的空间变换，才能生成二维图像显示在显示器上。在这个计算过程中，我们都需要用到矩阵。矩阵是非常实用的，但它正式作为数学中的研究对象出现，其实是在行列式的研究发展起来之后。英国数学家 Arthur Cayley 被公认为矩阵论的创立人，他提出的矩阵概念可能来自于行列式。但我相信另一种说法，提出矩阵是为了更简单地表达线性方程组，也就是说，矩阵是线性方程组的另一种表达。


只有相邻阶数匹配的矩阵才能相乘，例如，一个 n×k 矩阵 A 和一个 k×m 矩阵 B 相乘，最后得出 n×m 矩阵 C，而这里的 k 就是相邻阶数。


## 04 | 解线性方程组：为什么用矩阵求解的效率这么高？

![img](https://static001.geekbang.org/resource/image/24/8b/24dbdb71282f2685353b63bd4ec8ee8b.png?wh=1200*948)

## 05 | 线性空间：如何通过向量的结构化空间在机器学习中做降维处理？

## 06 | 线性无关：如何理解向量在N维空间的几何意义？

## 07 | 基和秩：为什么说它表达了向量空间中“有用”的向量个数？

## 08 | 线性映射：如何从坐标系角度理解两个向量空间之间的函数？

## 09 | 仿射空间：如何在图形的平移操作中大显身手？


## 10 | 解析几何：为什么说它是向量从抽象到具象的表达？


## 应用篇

## 11 | 如何运用线性代数方法解决图论问题？

## 12 | 如何通过矩阵转换让3D图形显示到二维屏幕上？

## 13 | 如何通过有限向量空间加持的希尔密码，提高密码被破译的难度？

## 14 | 如何在深度学习中运用数值代数的迭代法做训练？

## 15 | 如何从计算机的角度来理解线性代数？



