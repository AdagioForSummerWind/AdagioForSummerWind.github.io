# Middleware


# 中间件核心技术与实战


## 开篇词｜为什么中间件对分布式架构体系来说这么重要？

你好，我是丁威。一名奋战在 IT 一线十多年的技术老兵，现任中通快递技术平台部资深架构师，也是 Apache RocketMQ 社区的首席布道师，《RocketMQ 技术内幕》一书的作者。不知道你有没有发现这样一个现状，深度实践分布式架构体系还得看大厂，他们所提供的高并发、大数据等应用场景更是众多研发工程师的练兵地，给出的薪资、待遇、发展潜力也远超小平台。但说句现实点的，绝大多数 Java 从业人员其实都在干着 CRUD 的工作，并没有机会去实践高并发。一边是大厂牛人岗位的稀缺，一边是研发工程师的晋升无门，怎么打破这个死循环，自开一扇窗呢？结合我自己的经历，加上这些年我对研发工程师的职场发展的思考，我觉得中间件这个细分赛道或许可以奋力一搏。甚至可以说，学习它已经是进入大厂的必备条件了。

### 第一阶段：高效工作
对于刚开始接触系统架构的人来说，熟练掌握中间件是高效工作的前提。因为中间件是互联网分布式架构设计必不可少的部分，几乎每一个分布式系统都有一种乃至几种中间件在系统中发挥作用。中间件的这种持续发展和系统的内部结构有关。可以结合你们公司的业务想一下，为了追求高并发、高性能、高可用性还有扩展性，是不是在对软件架构进行部署时，通常会采用分层架构思想，将系统架构分为接入层、基础层、服务层、数据存储层和运行环境，而每一层需要解决的问题各不相同。就像这样一个系统架构模型。

![img](https://static001.geekbang.org/resource/image/4f/5b/4f88b15ac109b8f732039bc35f2c5a5b.jpg?wh=1779x1572)

但单凭这个架构并不能解决所有问题。试想一下，如果一家公司每做一个项目都要自己去实现一套事务管理、一套定时任务调度框架，那么他们的业务交付效率一定会很低。这不但会给开发编码带来极大的技术挑战，同时系统也需要面临高并发、大流量的冲击。在这么多未知的挑战和不可控的因素当中，要想交付一套稳定的系统可以说是困难重重。好在随着分布式架构体系的不断演变，越来越多的优秀中间件应运而生。我们无需再重复造轮子，可以直接在项目中使用这些优秀的中间件，把更多精力放在业务功能的开发上，在提高交付效率的同时也使得系统更加稳定，一举多得。中间件的种类非常多，不可能尽数列举。但我把各个领域主流的中间件汇总在一起，做了一张思维导图，供你随时查看：

![img](https://static001.geekbang.org/resource/image/cy/a1/cyy3f5a28cd124e5d8a300d0d67770a1.jpg?wh=1920x2312)



那随着中间件的逐渐增多，必然会出现一个现象：各个项目基本都会用到一个或多个中间件。为了更加出色地完成工作，掌握这些中间件的使用方法、设计理念，了解它们的设计缺陷就成了我们的必修课。

### 第二阶段：突破高并发
入行一段时间之后，认识高并发、突破高并发就成了我们每个人都要面对的问题。中间件和高并发密切相关，这是因为每一款优秀的中间件几乎都是由各个行业中的头部企业贡献的。中间件的诞生几乎无一例外都是为了解决特定业务领域的技术挑战，需要满足高并发、高性能、高可用三大功能。也就是说，每一款中间件的设计理念、代码编码都会遵循高并发领域的一些常见理论。例如，我们非常熟悉的消息中间件 Apache RocketMQ，它承载了阿里“双十一”巨大的流量，那它具体是如何应对这一场景的？又采用了什么“牛逼”的技术架构？尽管我们暂时没有机会参与阿里双十一这样的大流量场景，没法从第一现场了解这些问题，但我们可以通过深入学习和研究 Apache Apache 项目去体会高并发编程的魅力，让 Apache RocketMQ 中的编程技巧成为我们的“经验”。这样一来，我们不就可以用最低成本轻松拿下高并发场景了吗？再说回职场晋升，我相信你也和我一样，在准备面试时总会先背诵一下“零拷贝”相关的理论知识，因为它是一个非常高频的面试题。但你知道怎么在项目中实际运用零拷贝技术来提升系统的性能吗？

听到这个问题是不是没了思路？其实，RocketMQ 作为一款文件存储领域非常知名的消息中间件，就运用了“零拷贝”技术，这部分内容也会在我的专栏中体现。我们要做的只是翻阅对应的源码，进行相应的练习和总结，就可以真正掌握“零拷贝”了。讲到这里你应该也发现了，中间件是我们突破高并发的利器。它能够最大程度弥补我们缺少的高并发场景实战经验，为我们提供最优秀的项目实践机会。


### 第三阶段：防患于未然
那是不是只要能够熟练使用这些技术、框架就够了呢？我认为，中间件的学习进程到这里还远没有结束。由于中间件在分布式互联网架构体系中占据着非常重要的位置，因此，很多故障都和中间件的使用不当有关。只有深入中间件的底层设计原理，读懂源码，才能将很多问题扼杀在摇篮中。相反，如果故障已经发生了，哪怕你的故障排查能力和处理能力再强，一旦出了问题，就会对业务造成重大影响或者给公司带来资金损失，这些都是无法挽回的。为了尽可能避免这类问题，很多公司都设置了故障追责机制。例如，阿里巴巴就有“325”，意思是，如果你的系统出现了一次比较大的故障，那么绩效得分为 325，全年绩效为 0。这样的问题我想是大家都不愿意看到的。不过，只要我们加强对中间件工作机制的了解，提前发现系统的“病灶”，及时规避掉风险，就能防止公司和个人面临不可估量的损失。


### 课程设计
总结一下，学好中间件可以提高我们的工作效率、突破高并发瓶颈，还能防患于未然，极大地减少公司和个人的损失。如果你对这些问题感兴趣，那我的专栏就是为你打造的。《中间件核心技术与实战》共分为六个模块。

![img](https://static001.geekbang.org/resource/image/e7/00/e792fd3c26f449yy26e32d5e2208dc00.jpg?wh=1920x604)



在全局认知篇，我会介绍中间件在互联网分布式架构体系中的整体面貌，并重点对数据库、缓存等中间件的发展和选型依据做详细的介绍，帮助你更快掌握技术架构的发展方向，合理选择中间件。在基础篇，我会系统讲解中间件必备的基础知识，主要包括 Java 常用数据结构、并发编程与网络编程。通过图解的方式，你可以更好地吸收这些原理，不再像背诵八股文一样学习理论知识，而是通过技术背后的设计理念，做到一通百通。实战篇是我们全专栏最核心的内容，它分为微服务体系 Dubbo、消息中间件和定时调度任务三个部分。我会按照设计理念、选型标准、实战演练的顺序展开。带你从理论到实践，解决实际生产中遇到的问题。最后是综合案例篇，我给你提供了一个全链路压测的落地项目，方便你全方位地串起各个主流中间件，完成对中间件的综合应用。学完这个专栏，你应该能够对中间件的主要分类有更宏观地了解，掌握微服务、消息中间件、定时调度框架的设计场景，灵活应对高并发场景。

### 写在最后
最后我想说，中间件是分布式架构绕不开的话题，对于主流的中间件，你可能早就听说或者使用过，但是，中间件始终在发展和迭代，为了适应未来的变化、从容应对庞大的数据量，我们应该走得更深、更扎实一些，打造自己难以被撼动的职场竞争力。回想我自己 10 余年的奋斗经历，正是不断的学习让我实现了职位和技能的突破。在我职业生涯的前几年，因为没有良好的教育背景，又长期在传统行业从事电子政务相关系统的开发，我无缘接触高并发，成为了一名“CRUD 工程师”。好在，2017 年我迎来了自己职业生涯的转折点。这一年，RocketMQ 正式成为 Apache 顶级开源项目，通过研读 RocketMQ 的架构设计、编程技巧，我彻底突破了高并发门槛，找到了向大厂晋升的那扇窗。在这期间，我也总结出了一套学习中间件的基本方法论，学完这些内容，如果你对其他类型的中间件也很感兴趣，可以用这个方法持续深挖，更高效、透彻地掌握其他类型的中间件。


了解这款中间件的使用场景、能解决什么痛点问题。阅读官方架构设计文档，从整体上把握这款中间件的架构、设计理念、工作机制。阅读官方用户手册文档，初步了解如何使用这款中间件。搭建自己的开发调试环境，运行官方 Demo 示例，进一步掌握这款中间件的使用方法。结合中间件的架构设计文档、亮点技术追溯源码，掌握落地细节并举一反三，结合使用场景进行理解。这是彻底掌握中间件的关键。


## 全局认知

## 01｜中间件生态（上）：有哪些类型的中间件？


最近十年是互联网磅礴发展的十年，IT 系统从单体应用逐渐向分布式架构演变，高并发、高可用、高性能、分布式等话题变得异常火热，中间件也在这一时期如雨后春笋般涌现出来，那到底什么是中间件呢？存在哪些类型的中间件呢？同一类型的中间件，我们该怎么选择？接下来的两节课，我们就来聊聊这些问题。中间件的种类很多，我们无法把所有类型和产品列出来逐一讲解。但是每个类别的中间件在设计原理、使用上有很多共同的考量标准，只要了解了最重要、最主流的几种中间件，我们就可以方便地进行知识迁移，举一反三了，然后学习其他中间件将变得非常简单。所以呢，你可以把这两节课看作是提纲挈领的知识清单。下面我们讲到的中间件你不一定都能够用上，但在需要的时候，可以帮你从更加高屋建瓴的角度迅速决策。

### 什么是中间件？
先来说说什么是中间件，我认为中间件是游离于业务需求之外，专门为了处理项目中涉及高可用、高性能、高并发等技术需求而引入的一个个技术组件。它的一个重要作用就是能够实现业务代码与技术功能之间解耦合。这么说是不是还有点抽象？在这里定义里，我提到了业务需求和技术需求，关于这两个词我需要再解释一下。业务需求，笼统地说就是特定用户的特定诉求。以我们快递行业为例：人与人之间需要跨城市传递物品，逢年过节我们需要给远方的亲人寄礼物，这就是所谓的业务需求。技术需求，就是随着业务的不断扩展，形成规模效应后带来的使用上的需求。例如上面提到的寄件服务，原先只需要服务 1 万个客户，用户体验非常好，但现在需要服务几个亿的用户，用户在使用的过程中就会出现卡顿、系统异常等问题，因此产生可用性、稳定性方面的技术诉求。为了解决各式各样的业务和技术诉求，代码量会越来越多。如果我们任凭业务代码与技术类代码没有秩序地纠缠在一起，系统会变得越来越不可维护，运营成本也会成指数级增加，故障频发，最终直接导致项目建设失败。

怎么解决这个问题呢？计算机领域有一个非常经典的分层架构思想，还有这样一句话“计算机领域任何一个问题都可以通过分层来解决，如果不行，那就再增加一层。”要想让系统做得越来越好，我们通常会基于分层的架构思想引入一个中间层，专门来解决可用性、稳定性、高性能方面的技术类诉求，这个中间层就是中间件，这也正是“中间件”这个词的来源。


### 中间件生态漫谈
明白了中间件的内涵，我们再来看看市面上有哪些中间件。我在开篇词中已经提到过了，中间件的种类繁多，我整理了一版分布式架构体系中常见的中间件，你可以先打开图片仔细看一看。

![img](https://static001.geekbang.org/resource/image/38/47/3817898c73b8a28acc23851457d42a47.jpg?wh=1920x2205)



结合我 10 多年的从业经验，特别是对互联网主流分布式架构体系的研读，我发现微服务中间件、消息中间件、定时调度的使用频率极高，在解决分布式架构相关问题中是排头兵，具有无可比拟的普适性。这三者的设计理念和案例能对分布式、高可用和高并发等理念实现全覆盖。所以，在专栏的第三章到第五章，我会深度剖析微服务、消息中间件和定时调度这三个方向，结合生产级经典案例深入剖析它们的架构设计理念，带你扎实地掌握分布式架构设计相关的基本技能。



微服务
具体而言，作为软件架构从单体应用向分布式演进出现的第一个新名词，微服务涉及分布式领域中服务注册、服务动态发现、RPC 调用、负载均衡、服务聚合等核心技术，而 Dubbo 在微服务领域是当仁不让的王者。所以在微服务这一部分，我们会以 Dubbo 为例进行实战演练。

消息中间件
随着微服务的蓬勃发展，系统的复杂度越来越高，加上互联网秒杀、双十一、618 等各种大促活动层出不穷，我们急切需要对系统解耦和应对突发流量的解决办法，这时候消息中间件应运而生了，它同样成为我们架构设计工作中最常用的工具包。常用的消息中间件包括 RocketMQ、Kafka，它们在适用性上有所不同，如何保障消息中间件的稳定性是一大挑战。

定时调度
而定时调度呢？我们既可以认为它是个技术需求，也可以认为它是一个业务类需求，通过研读 ElasticJob、XXL-Job 等定时调度框架，可以很好地提升我们对业务需求的架构设计能力。

这三部分我们会在后面的模块中重点展开，所以这一模块不做深入讲解。接下来，为了让你对主流中间件有一个更全面的认知，我会分两节课对另外的几类中间件（数据库、缓存、搜索、日志等）进行简要阐述，以补全你的中间件知识图谱，帮助你更加有底气、有效率地进行决策。这节课，我们先来看看数据库中间件。

### 数据库中间件
数据库中间件应该是我们接触得最早也是最为常见的中间件，在引入数据库中间件之前，由于单体应用向分布式架构演进的过程中单表日数据急速增长，单个数据库的节点很容易成为系统瓶颈，无法提供稳定的服务。因此，为了解决可用性问题，在技术架构领域通常有如下两种解决方案：**读写分离；分库分表**。我们先分别解析下这两个方案。最后再来看一看，引入数据库中间件给技术带来的简化。


#### 读写分离
这是我在没有接触中间件之前，在一个项目中使用过的方案：

![img](https://static001.geekbang.org/resource/image/00/74/006b469830c171f554903cb2384e1874.jpg?wh=1620x512)

这个方案的实现要点有三个。第一，在编写业务接口时，要通过在接口上添加注解来指示运行时应该使用的数据源。例如，@SlaveofDB 表示使用 Slave 数据库，@MasterOfDB 表示使用主库。第二，当用户发起请求时，要先经过一个拦截器获取用户请求的具体接口，然后使用反射机制获取该方法上的注解。举个例子，如果存在 @SlaveofDB，则往线程上下文环境中存储一个名为 dbType 的变量，赋值为 slave，表示走从库；如果存在 @MasterOfDB，则存储为 master，表示走主库。第三，在 Dao 层采用 Spring 提供的路由选择机制，继承自 AbastractRoutingDataSource。应用程序启动时自动注入两个数据源 (master-slave)，采用 key-value 键值对的方式存储。在真正需要获取链接时，根据上下文环境中存储的数据库类型，从内部持有的 dataSourceMap 中获取对应的数据源，从而实现数据库层面的读写分离。

总结一下，读写分离的思路就是通过降低写入节点的负载，将耗时的查询类请求转发到从节点，从而有效提升写入的性能。但是，当业务量不断增加，单个数据库节点已无法再满足业务需求时，我们就要对数据进行切片，分库分表的技术思想就应运而生了。


#### 分库分表
分库分表是负载均衡在数据库领域的应用，主要的原理你可以参考下面这张图。

![img](https://static001.geekbang.org/resource/image/26/42/2644e659d2e832d1b4af841de8b20e42.jpg?wh=1920x766)

简单说明一下。分库分表主要是通过引入多个写入节点来缓解数据压力的。因此，在接受写入请求后，负载均衡算法会将数据路由到其中一个节点上，多个节点共同分担数据写入请求，降低单个节点的压力，提升扩展性，解决单节点的性能瓶颈。不过，要实现数据库层面的分库分表还是存在一定技术难度的。因为分库分表和读写分离一样，最终要解决的都是如何选择数据源的问题。所以在分库分表方案中，首先我们要有两个算法。

一个分库字段和分库算法，即在进行数据查询、数据写入时，根据分库字段的值算出要路由到哪个数据库实例上；一个分表字段和分表算法，即在进行数据查询、数据写入时，根据分表字段的值算出要路由到哪个表上。

不管是上面的分库、还是分表都需要解决一个非常关键的问题：SQL 解析。你可以看下面这张图。

![img](https://static001.geekbang.org/resource/image/ca/dc/cab6b8d6fdb060d1e38a978ae594c0dc.jpg?wh=1920x828)

如果订单库的分库字段设置为 order_no，要想正确执行这条 SQL 语句，我们首先要解析这条 SQL 语句，提取 order_no 的字段值，再根据分库算法 (负载均衡算法) 计算应该发送到哪一个具体的库上执行。SQL 语句语法非常复杂，要实现一套高性能的 SQL 解析引擎绝非易事，如果按照上面我提供的解决方案，将会带来几个明显的弊端。

技术需求会污染业务代码，维护成本高
在业务控制器中需要使用注解来声明读写分离按相关的规则进行，随着业务控制的不断增加、或者读写分离规则的变化，我们需要对系统所有注解进行修改，但业务逻辑其实并没有改变。这就造成两者之间相互影响，后期维护成本较高。

技术实现难度较大，极大增加开发成本
由于 SQL 语句的格式太复杂、太灵活，如果不是数据库专业人才，很难全面掌握 SQL 语法。在这样的情况下，你写出的 SQL 解析引擎很难覆盖所有的场景，容易出现遗漏最终导致故障的发生；这也给产品的性能带来极大挑战。那怎么办呢？其实，我们完全可以使用业界大神的开源作品来解决问题，这就要说到数据库中间件了。


### 引进数据库中间件
技术类诉求往往是相通的，极具普适性，为了解决上面的通病，根据分层的架构理念，我们通常会引入一个中间层，专门解决数据库方面的技术类需求。


MyCat 和 ShardingJDBC/ShardingSphere 是目前市面最主流的两个数据库中间件，二者各有优势。

#### MyCat 服务端代理模式
先来看下 MyCat 代理数据库。它的工作模式可以用下面这张图概括：

![img](https://static001.geekbang.org/resource/image/ca/23/caef85cbfdc84600b45a1d4ff3d1e723.jpg?wh=1920x766)

面对应用程序，MyCat 会伪装成一个数据库服务器 (例如 MySQL 服务端)。它会根据各个数据库的通信协议，从二进制请求中根据协议进行解码，然后提取 SQL，并根据配置的分库分表、读写分离规则计算出需要发送到哪个物理数据库。随后，面对真实的数据库资源，MyCat 会伪装成一个数据库客户端。它会根据通信协议将 SQL 语句封装成二进制流，发送请求到真实的物理资源，真实的物理数据库收到请求后解析请求并进行对应的处理，再将结果层层返回到应用程序。这种架构的优势是它对业务代码无任何侵入性，应用程序只需要修改项目中数据库的连接配置就可以了，而且使用简单，易于推广。同时它也有劣势：

存在性能损耗
数据库中间件需要对应用程序发送过来的请求进行解码并计算路由，随后它还要再次对请求进行编码并转发到真实的数据库，这就增加了性能开销。

高度中心化，数据库中间件容易成为性能瓶颈
数据库中间件需要处理所有的数据库请求，返回结果都需要在数据库中进行聚合，虽然减少了后端数据库的压力，但中间件本身很容易成为系统的瓶颈，扩展能力受到一定制约。

代理层实现复杂，普适性差
数据库中间件本身的实现比较复杂，需要适配市面上各主流数据库，例如 MySQL、Oracle 等，通用性大打折扣。


#### ShardingJDBC 客户端代理模式
下面我们再来看下 ShardingJDBC 客户端代理数据库。ShardingJDBC 的工作模式如下图所示：

![img](https://static001.geekbang.org/resource/image/4c/dd/4c2e6916f7df062aa145063586b1e3dd.jpg?wh=1920x1261)

ShardingJDBC 主要实现的是 JDBC 协议。实现 JDBC 协议，其实主要是面向 java.sql.Datasource、Connection、ResultSet 等对象编程。它通常以客户端 Jar 包的方式嵌入到业务系统中，ShardingjJDBC 根据分库分表的配置信息，初始化一个 ShardingJdbcDatasource 对象，随后解析 SQL 语句来提取分库、分表字段值，再根据配置的路由规则选择正确的后端真实数据库，最后，ShardingJDBC 用各种类型数据库的驱动包将 SQL 发送到真实的物理数据库上。我们同样来分析一下这个方案的优缺点。主要的优势有如下几点：

无性能损耗
ShardingJDBC 使用的是基于客户端的代理模式，不需要对 SQL 进行编码解码等操作，只要根据 SQL 语句进行路由选择就可以了，没有太多性能损耗。

无单点故障、扩展性强
ShardingJDBC 以 Jar 包的形式存在于项目中，其分布式特性随着应用的增加而增加，扩展性极强。

JDBC 协议是应用程序与关系型数据库
交互的业界通用标准，市面上所有关系型数据库都天然支持 JDBC，故不存在兼容性问题。


当然缺点也很明显，对于分库分表，它没有一个统一的视图，运维类成本较高。举个例子，如果订单表被分成了 1024 个表，这时候如果你想根据订单编号去查询数据，必须人为计算出这条数据存在于哪个库的哪个表中，然后再去对应的库上执行 SQL 语句。为了解决 ShardingJDBC 存在的问题，官方提供了 ShardingSphere，其工作机制基于代理模式，与 MyCat 的设计理念一致，作为数据库的代理层，提供统一的数据聚合层，可以有效弥补 ShardingJDBC 在运维层面的缺陷，**因此项目通常采用 ShardingDBC 的编程方式，然后再搭建一套 ShardingSphere 供数据查询。**

在没有 ShardingSphere 之前，使用 MyCat 也有一定优势。MyCat 对业务代码无侵入性，接入成本也比较低。但 ShardingSphere 弥补了 ShardingJDBC 对运维的不友好，而且它的性能损耗低、扩展性强、支持各类主流数据库，可以说相比 MyCat 已经占有明显的优势了。所以如果要在实践生产中选择数据库中间件，我更加推荐 ShardingJDBC。

除了上面的原因，从资源利用率和社区活跃度的角度讲，首先，MyCat 的“前身”是阿里开源的 Cobar，是数据库中间件的开山鼻祖，技术架构稍显古老，而 ShardingJDBC 在设计之初就可以规避 MyCat 的固有缺陷，摒弃服务端代理模式。代理模式需要额外的机器搭建 MyCat 进程，引入了新的进程，势必需要增加硬件资源的投入。其次，ShardingJDBC 目前已经是 Apache 的顶级项目，它的社区活跃度也是 MyCat 无法比拟的。一个开源项目社区越活跃，寻求帮助后问题得到解决的概率就会越大，越多人使用，系统中存在的 Bug 也更容易被发现、被修复，这就使得中间件本身的稳定性更有保障。

![img](https://static001.geekbang.org/resource/image/f4/38/f48ea3374ac767fffc685270df18ac38.jpg?wh=1920x988)


### 总结
好了，这节课就讲到这里，我们来做个小结。通过刚才的学习，我们知道了中间件的概念，它是为了解决系统中的技术需求，将技术需求与业务需求进行解耦，让我们专注于业务代码开发的一个个技术组件。中间件的存在，就是为了解决高并发、高可用性、高性能等各领域的技术难题。在项目中，合理引用中间件能极大提升我们系统的稳定性、可用性，但同时也会提升系统维护的复杂度，对我们的技术能力提出了更高的要求，我们必须要熟练掌握项目中引用的各种中间件，深入理解其工作原理、实现细节，提高对中间件的驾驭能力，否则一旦运用不当，很可能给系统带来灾难性的故障。为了让你对中间件有一个更加宏观的认识，我给你列举了市面最为常用的中间件。虽然现在新的中间件层出不穷，但在我看来，大都不超过我列的这几类。这节课我们重点讲了两个主流的数据库中间件，下节课，我们再来解读缓存、全文索引、分布式日志这几类中间件。


## 02｜中间件生态（下）：同类型的中间件如何进行选型？

### 缓存中间件
纵观整个计算机系统的发展历程，不难得出这样一个结论：缓存是性能优化的一大利器。我们先一起来看一个用户中心查询用户信息的基本流程：

![img](https://static001.geekbang.org/resource/image/cd/ee/cd306db0699d3242eae6309608e1cdee.jpg?wh=1334x500)

这时候，如果查找用户信息这个 API 的调用频率增加，并且在整个业务流程中，同一个用户的信息会多次被调用，那么我们可以引入缓存机制来提升性能：

![img](https://static001.geekbang.org/resource/image/d3/42/d316a9dda96b36744c592736541b3a42.jpg?wh=1343x648)



也就是说，在 UserService 中引入一个 LinkedHashMap 结构的内存容器，用它存储已经查询到的数据。如果新的查询请求能命中缓存，那么我们就不需要再查询数据库了，这就降低了数据库的压力，将网络 IO、磁盘 IO 转变为了直接访问内存，性能自然而然也提升了。但上面这个方案实在算不上一个优秀的方案，因为它考虑得非常不全面，存在下面这几个明显的缺陷：内存容量有限、容易引发内存溢出，缓存在节点之间不一致，数据量非常庞大。上面每一个问题都会带来巨大的影响，如果我们每做一个业务系统，都需要花这么多精力去解决这些技术问题，那这个成本也是不可估量的。为了解决与缓存相关的技术诉求，市面上也涌现出了一些非常优秀的中间件。缓存中间件经历了从本地缓存到分布式缓存的演变历程，我们先来看本地缓存中间件。


### 本地缓存中间件
本地缓存与应用属于同一个进程，主要的优势是没有网络访问开销，**其中 Ehcache、Guava Cache 与 Caffeine 是 Java 领域当下比较知名的本地缓存框架。**由于 Ehcache 比较耗磁盘空间，并且在进程宕机后容易造成缓存数据结构破坏，只能通过重建索引的方式进行修复，所以目前我们主要使用 Guava Cache 和 Caffeine，他们之间并没有明显的优劣势。尽管内部实现细节不同，但本地缓存中间件基本都需要包含下面三个功能。

支持大容量。它们基本都会采取内存 + 磁盘两级存储模型，其中内存存放热数据，磁盘存放全量数据。

过期 / 淘汰机制。评估缓存对性能提升程度的一个重要依据就是缓存的命中率。如果用户每次访问都无法命中缓存，相当于缓存没有起到效果，存储的数据都是“无用”的数据，只会带来存储空间的浪费。所以，必须引入缓存过期机制，删除不常用的数据。

基本的数据统计功能。监控数据的主要目的是检测当前缓存的工作状态是否健康，需要检测的内容包括缓存命中率、内存空间使用情况、磁盘空间使用情况等。


总的来说，本地缓存对单体应用非常友好，但对分布式应用就会显得有点浪费资源，为什么这么说呢？你可以先看看下面这张图。

![img](https://static001.geekbang.org/resource/image/04/f9/04c18e500f1ba16c0061b390633ddff9.jpg?wh=765x380)

在这张图中，当连续两次查询用户 ID 为 1 的用户信息时，受到负载均衡组件的影响，其中一个请求会转发到 192.168.3.100，另外一个请求会转发到 192.168.3.101。这样，同一个用户的信息会在两台机器上分别缓存一份数据。而且，如果数据发生变化，也需要通知多台机器同时刷新缓存，这就造成了资源浪费。因此，本地缓存更适合存储一些变化频率极低，数据量较小的场景，诸如基础数据、配置了类型的数据缓存等。


### 分布式缓存中间件
本地缓存属于单进程管理的范畴，存在单点故障与资源瓶颈，无法应对数据的持续增长。为了适应分布式架构的特点，市面上也出现了一批基于内存存储的分布式存储框架。由于分布式缓存与应用进程分属不同的进程，存在网络访问开销，所以几乎各个缓存中间件都是基于内存存储的系统，它们的存储容量受限于机器内存容量。为了解决存储方面的瓶颈，各个分布式缓存中间件都支持集群部署。分布式缓存中间件中比较出名的非 Redis 与 Memcached 莫属。我们以 Redis 为例，来看一下经典的分布式缓存部署架构：

![img](https://static001.geekbang.org/resource/image/66/34/66d4c70c2e797393e3d26121dcd43334.jpg?wh=1245x434)

从这张图中，我们可以提取出下面几个要点。首先，客户端通常会使用一致性哈希算法进行负载均衡，主要是为了提高节点扩容、缩容时的缓存命中率。第二，Redis 采用主从同步模式，这可以提升数据的存储可靠性。如果是像 Memcache 这种不能持久化的中间件，进程一旦退出，存储在内存中的数据将会丢失，就要重新从数据库加载数据，这会让大量流量在短时间内穿透到数据库，造成数据库层面不稳定。第三，单台 Redis 受限于机器内存的容量限制，通常会采用集群部署，即每一个节点存储部分数据。第四，为了提升 Redis 的 master-slave 高可用性能，降低由于 master 节点宕机导致的集群写入节点数量减少问题，通常会引入哨兵集群，使 master-slave 主从自动切换，进一步提升缓存中间件的高可用性。

那么，同为分布式缓存中间件，Redis 和 Memcached 又有什么区别与联系呢？二者的共同点是，它们都是基于内存访问的高性能缓存存储系统，具有高并发、低延迟特性。但它们的不同点也很多，我总结为了以下四点。

数据类型：Redis 支持丰富的数据类型，不仅支持 key-value 的存储结构，还支持 List、Set 等复杂数据结构，而 Memcache 只支持简单的数据类型。数据持久化：Redis 支持基于 AOF、快照两种数据持久机制，持久化带来的好处便是进程重启后数据不会丢失，能有效防止缓存被击穿的风险；Memcache 不支持数据持久化。分布式存储：Redis 自身支持 master-slave、Cluster 两种分布式存储架构，而 Memcache 自身并不支持集群部署，需要使用一致性哈希算法来构建集群。线程模型：Redis 命令执行采用单线程，故 Redis 不适合大 Value 值的存储，但借助 Redis 单线程模型可以非常方便地实现分布式锁等功能；Memcache 基于多线程运行模型，可以充分利用多核 CPU 的并发优势，提升资源的利用率。

讲了这么多，要一下记住可能有点难度，我给你画了两张图，总结了刚才不同中间件的差异、适用场景，你可以保存下来随时回顾：

![img](https://static001.geekbang.org/resource/image/2a/c6/2a4ca67a58b46b0567c2913c94937dc6.jpg?wh=1920x732)

![img](https://static001.geekbang.org/resource/image/10/c7/10f9f71ef95a17e197ce2fd8a85380c7.jpg?wh=1920x1080)

一句话总结，缓存框架是不断在演进的，在项目中引入缓存相关的中间件技术绝对是一个明智之举。在数据量较少，并且变更不频繁时，我建议你采用本地缓存，其他情况建议使用分布式缓存。那如何在 Redis 与 Memcache 中进行选型呢？虽然技术选型我们需要结合业务场景来看，但从上述功能的对比来看，Redis 基本在各个对比项中对 Memcache 呈“压制”态势，所以多数情况下，我建议你使用 Redis。


### 全文索引中间件
Elasticsearch 是一个基于 Apache Lucene 的开源且支持全文搜索的搜索引擎。Lucene 被公认为迄今为止性能最强、功能最齐全的搜索引擎库。但 Lucene 只是一个类库，只提供单机版本的搜索功能，无法与分布式计算、分布式存储等协调展开工作。为了适应分布式的架构体系，Elasticsearch 应运而生。Elasticsearch 提供了强大的分布式文件存储能力、分布式实时分析搜索能力、实时全文搜索能力、强大的集群扩展能力，PB 级别的结构化和非结构化数据处理能力。Elasticsearch 在分布式架构中有两个最常见的应用场景，一个是宽表、解决跨库 Join，另一个就是全文搜索。接下来我们分别展开介绍。

在数据库领域，如果一个表的数据量庞大，我们通常会引入分库分表技术以提高可用性。但这会带来一个新的问题，就是数据关联、报表等查询会变得无比复杂，性能也无法得到保障。我们以订单场景为例。在一个订单中通常会包含多个商品，一个非常经典的设计策略是会创建 t_order 与 t_order_item 表，其中 t_order_item 是 torder 的子表。但如果我们使用了分库分表技术，关联查询将变得非常复杂：

![img](https://static001.geekbang.org/resource/image/5b/66/5bb32be84d742f2ba66090c8f8cc3466.jpg?wh=1485x802)



看一下上面这张图片，想象一下，如果应用程序发送一条 Join 语句给数据库，会发生什么事情呢？由于订单编号为 1 的订单信息存储在 order_db_00 中，但与这条订单关联的订单字表却存储在 order_db_01 中，而 Join 操作需要的笛卡尔积操作存在于不同的数据库实例中，所以我们就要将多个数据库中的数据统一加载到内存中。这就需要创建众多对象，如果需要加载的数据庞大，无疑会导致内存竞争，垃圾回收加剧，性能将直线下降。我相信你一定能想到这个问题的解法：用 ER 分库思想，让具有关联性的表使用字段相同的分片算法。例如上面的示例，我们可以将 t_order、t_order_item 两个表的分库字段都设置为订单 ID，这样一来，同一订单 id 的父子数据都在同一个数据库实例中，就避免了跨库 Join，可以让性能得到很大提升。但真实的应用场景比这个要复杂很多，面对的用户不同，他们的诉求也不一样。

我们还是说回订单系统。

从买家的角度出发，我们希望同一个买家的订单数据（父子关联表）能够采用同样的分库策略，以此保证同一个买家的订单关联数据存储在同一个库中，这样买家在查询订单时不必跨库。但是如果采用这种策略，从商家的角度出发就会发现，商家在查询商家订单信息、商家日订单报表、月订单报表时要查询多个数据库，甚至可能产生跨库 Join 的风险。这无疑会降低性能，严重时会使整个数据库变得不可用。

用一句话概述就是，分库分表在面对多维度查询时将变得力不从心，那该如何解决呢？我们通常会引入数据异构 + 宽表的设计方案：

![img](https://static001.geekbang.org/resource/image/d4/1e/d43d2dfa8e45f6034f776ddfc1541d1e.jpg?wh=1437x722)



我们需要引入 Canal 数据同步工具，订阅 MySQL 的 Binglog，将增量数据同步到 Elasticsearch 中，实现数据访问层面的读写分离。ElasticSearch 另外一个场景就是全文搜索。我们以电商场景为例，用户在购买商品之前通常需要输入一些关键字搜索出符合自己期望的数据，例如商品表的表结构如下图所示：

![img](https://static001.geekbang.org/resource/image/dc/3e/dca81672ebc1667aa25031588599663e.jpg?wh=505x260)



如果我们要查询关键字为“苹果电脑”，基于关系型数据库，我们通常会写出这样的 SQL 语句：


```
select * from goods a where a.goods_decribe like '%苹果电脑%'；
```

运行上述代码，如果商品数量少那倒没关系，但如果是淘宝、天猫、京东等一线电商平台，需要存储海量商品信息，在商品库中运行上述 SQL，对数据库来说就是一个“噩梦”，因为上述语句并不会走索引，容易很快耗尽数据库链接而导致系统不可用。这个时候，使用 Elasticsearch 就是一个非常明智的选择。因为 Elasticsearch 的底层是 Lucene，可以对需要查找的字段建立索引，中间还会进行分词处理，进行更智能的匹配。由于 Elasticsearch 底层会为字段建立倒排索引，根据关键字查询可以轻松命中缓存，从而能极大提升访问性能，实现低延迟访问。


### 分布式日志中间件
随着微服务的兴起、业务量的增长，每一个服务在生产环境都会部署多台机器。例如，在我们公司，光是订单中心的“创建订单”服务就部署了四十多台机器。当遇到生产问题时，如果我们想要查看服务器日志，就会异常困难，因为我们根本不知道发生错误的请求具体在哪台机器上。在机器数量较少（10 台机器以内）的时候，通常我们可以使用 Ansibe 同时向所有需要采集的服务端执行日志检索命令，其工作示意图如下：

![img](https://static001.geekbang.org/resource/image/2a/3c/2acac65bccde5025756256897e86183c.jpg?wh=1191x542)

这种方式对于用户来说就像是操作单机模式一样，但是它的缺陷也是显而易见的。基于 Ansibe 这种命令行等批量运维工具，需要保存目标机器的用户名与密码，安全性会受到影响。如果要管理的目标机器有成百上千台，这种方式的系统开销会很大，搜索的响应时间很长，几乎是不太可能顺畅使用的。

为了进一步解决这个问题，我们通常需要采集每台服务器的日志，并将它存储在一个集中的地方，再提供一个可视化界面供用户查询。那么问题来了，市面上有这样的中间件吗？我的回答是，必须得有，它就是大名鼎鼎的 ELK。我们可以先看下这张 ELK 的工作架构图：

![img](https://static001.geekbang.org/resource/image/75/be/75b0b2c7cf67dc907a38ccdec91008be.jpg?wh=1920x1166)

我们需要在需要进行日志采集的机器上安装一个 filebeat 工具，用来采集服务器的日志，并将它们存储到消息中间件中。然后，在需要采集的机器中安装 Logstash 进程，通过 Logstash 将日志数据存储到 Elasticsearch 服务器，用户可以通过 Kibana 查询存储在 Elasticsearch 中的日志数据，这样，我们就可以有针对性地查询所需要的日志了。

### 总结
好了，这节课就讲到这里。这节课，我们重点介绍了缓存、全文索引、分布式日志三类中间件。缓存是性能优化的一柄利器，我们重点阐述了缓存技术从本地缓存到分布式缓存的演进之路，各种技术引入的背景以及解决方案，你可以根据自身情况，选择适合自己的缓存中间件。另外，搜索相关技术也是应用系统必不可少的一环。随着微服务技术和数据库分库分表技术的兴起，数据写入效率大大提高，但与此同时，数据查询也面临更大的挑战，而基于 Elasticsearch 的数据异构架构方式能非常方便地解决数据查询的性能问题。在分布式环境下，传统的应用日志查询方式也变得越来越难使用，ELK 日志技术则为日志搜索带来了新气象，是分布式日志中间件的不二之选。


## 基础
## 03 | 数组与链表：存储设计的基石有哪些？


从这节课开始，我们就要进行基础篇的学习了。想要熟练使用中间件解决各种各样的问题，首先需要掌握中间件的基础知识。我认为，中间件主要包括如下三方面的基础：数据结构、JUC 和 Netty，接下来的两节课，我们先讲数据结构。数据结构主要解决的是数据的存储方式问题，是程序设计的基座。按照重要性和复杂程度，我选取了数组和链表、键值对 (HashMap)、红黑树、LinkedHashMap 和 PriorityQueue 几种数据结构重点解析。其中，数组与链表是最底层的两种结构，是后续所有数据结构的基础。我会带你分析每种结构的存储结构、新增元素和搜索元素的方式、扩容机制等，让你迅速抓住数据结构底层的特性。当然，我还会结合一些工业级实践，带你深入理解这些容器背后蕴含的设计理念。说明一下，数据结构其实并不区分语言，但为了方便阐述，这节课我主要基于 Java 语言进行讲解。


### 数组
我们先来看下数组。数组是用于储存多个相同类型数据的集合，它具有顺序性，并且也要求内存空间必须连续。高级编程语言基本都会提供数组的实现。为了更直观地了解数组的内存布局，我们假设从操作系统申请了 128 字节的内存空间，它的数据结构可以参考下面这张图：

![img](https://static001.geekbang.org/resource/image/09/57/09c4065e6081fc190a87662c0101b357.jpg?wh=1920x505)

结合这张图我们可以看到，在 Java 中，数组通常包含下面几个部分。引用：每一个变量都会在栈中存储数组的引用，我们可以通过引用对数组进行操作，对应上图的 array1、array2。容量：数组在创建时需要指定容量，一旦创建，无法修改，也就是说，数组并不能自动扩容。下标：数组可以通过下标对数组中的元素进行随机访问，例如 array1[0]表示访问数组中的第一个元素，下标从 0 开始，其最大值为容量减一。

在后面的讲解中，你能看到很多数据结构都是基于数组而构建的。那么数组有哪些特性呢？这里我想介绍两个我认为最重要的点：内存连续性和随机访问效率高。我们先来看下内存连续性。



内存连续性的意思是，数组在向操作系统申请内存时，申请的必须是连续的内存空间。我们还是继续用上面这个例子做说明。我们已经创建了 array1、array2 两个数组，如果想要再申请一个拥有五个 int 元素的数组，能把这五个元素拆开，分别放在数组 1 的前面和后面吗？你可以看看下面这张示意图。



![img](https://static001.geekbang.org/resource/image/2e/bc/2e13df9e8ea3526801415096d62c72bc.jpg?wh=1920x589)



答案当然是不可以。虽然当前内存中剩余可用空间为 32 个字节，乍一看上去有充足的内存。但是，因为不存在连续的 20 字节的空间，所以不能直接创建 array3。当我们想要创建 20 字节长度的 array3 时，在 Java 中会触发一次内存回收，如果垃圾回收器支持整理特性，那么垃圾回收器对内存进行回收后，我们就可以得到一个新的布局：

![img](https://static001.geekbang.org/resource/image/f2/b8/f2caf59b16797abb34fd61d2c5dedfb8.jpg?wh=1920x463)



经过内存整理后就能创建数组 3 了。也就是说，如果内存管理不当，确实容易产生内存碎片，从而影响性能。那我们为什么要把内存设计为连续的呢？换句话说，连续内存有什么好处呢？这就不得不提到数组一个无可比拟的优势了：数组的随机访问性能极好。连续内存确保了地址空间的连续性，寻址非常简单高效。举个例子，我们创建一个存放 int 数据类型的数组，代码如下：

```
int[] array1 = new int[10];

```
然后我们看下 JVM 中的布局：

![img](https://static001.geekbang.org/resource/image/7b/d1/7b5a75b843b04f09349ea95d1077d0d1.jpg?wh=1920x722)

可以看到，首先内存管理器在栈空间会分配一段空间，用它存储数组在物理内存的起始地址，这个起始地址我们用 baseOffset 表示。如果是 64 位操作系统，默认一个变量使用 8 字节，如果采用了指针压缩技术，可以减少到 4 字节。**数组能够高效地随机访问数组中的元素，主要原因是它能够根据下标快速计算出真实的物理地址，寻找算法为“baseOffset + index * size”**。其中,size 为数组中单个元素的长度，是一个常量。在上面这个数组中，存储的元素是 int 类型的数据，所以 size 为 4。因此，我们根据数组下标就可以迅速找到对应位置存储的数据。数组这种高效的访问机制在中间件领域有着非常广泛的应用，大名鼎鼎的消息中间件 RocketMQ 在它的文件设计中就灵活运用了这个特性。RocketMQ 为了追求消息写入时极致的顺序写，会把所有主题的消息全部顺序写入到 commitlog 文件中。也就是说，commitlog 文件中混杂着各个主题的消息，但消息消费时，需要根据主题、队列、消费位置向消息服务器拉取消息。如果想从 commitlog 文件中读取消息，则需要遍历 commitlog 文件中的所有消息，检索性能非常低下。一开始，为了提高检索效率，RocketMQ 引入了 ConsumeQueue 文件，可以理解为 commitlog 文件按照主题创建索引。

为了在消费端支持消息按 tag 进行消息过滤，索引数据中需要包含消息的 tag 信息，它的数据类型是 String，索引文件遵循{topic}/{queueId}，也就是按照主题、队列两级目录存储。单个索引文件的存储结构设计如下图所示：

![img](https://static001.geekbang.org/resource/image/37/cc/37d00ef801366678bdd99e5966f74ecc.jpg?wh=1920x568)



索引文件中，每一条消息都包含偏移量、消息长度和 tag 内容 3 个字段。commitlog 偏移量  可以根据该值快速从 commitlog 文件中找到消息，这也是索引文件的意义。消息长度  消息的长度，知道它可以方便我们快速提取一条完整的消息。tag 内容  由于消息的 tag 是由用户定义的，例如 tagA、createorder 等，它的长度可变。在文件存储领域，一般存储可变长的数据，通常会采用“长度字段 + 具体内容”的存储方式。其中用来存储内容的长度使用固定长度，它是用来记录后边内容的长度。

回到消息消费这个需求，我们根据主题、消费组，消息位置 (队列中存储的第 N 条消息)，能否快速找到消息呢？例如输入 topic:order_topic、queueId:0,offset:2，能不能马上找到第 N 条消息？答案是可以找到，但不那么高效。原因是，我们根据 topic、queueid，能非常高效地找到对应的索引文件。我们只需要找到对应的 topic 文件夹，然后在它的子目录中找到对应的队列 id 文件夹就可以了。但要想从索引文件中找到具体条目，我们还是必须遍历索引文件中的每一个条目，直到到达 offset 的条目，才能取出对应的 commitlog 偏移量。

那是否有更高效的索引方式呢？当然有，我们可以将每一个条目设计成固定长度，然后按照数组下标的方式进行检索。为了实现每一个条目定长，我们在这里不存储 tag 的原始字符串，而是存储原始字符串的 hashCode，这样就可以确保定长了。你可以看看下面这张设计图：

![img](https://static001.geekbang.org/resource/image/6d/3b/6ddd2f39e7a4261caeef32248b29893b.jpg?wh=1920x487)



基于这种设计，如果给定一个 offset，我们再想快速提取一条索引就变得非常简单了。首先，根据 offset * 20(每一个条目的长度)，定位到需要查找条目的起始位置，用 startOffset 表示。然后，从 startOffset 位置开始读取 20 个字节的长度，就可以得到物理偏移量、消息长度和 tag 的 hashCode 了。接着，我们可以通过 hashCode 进行第一次过滤，如果遇到 hash 冲突，就让客户端再根据消息的 tag 字符串精确过滤一遍。这种方式，显然借鉴了数组高效访问数据的设计理念，是数组实现理念在文件存储过程中的经典运用。总之，正是由于数组具有内存连续性，具有随机访问的特性，它在存储设计领域的应用才非常广泛，我们后面介绍的 HashMap 也引入了数组。

### ArrayList
不过，数组从严格意义上来说是面向过程编程中的产物，而 Java 是一门面向对象编程的语言，所以，直接使用数组容易破坏面向对象的编程范式，故面向对象编程语言都会对数组进行更高级别的抽象，在 Java 中对应的就是 ArrayList。我会从数据存储结构、扩容机制、数据访问特性三个方面和你一起来探究一下 ArrayList。首先我们来看一下 ArrayList 的底层存储结构，你可以先看下这个示意图：

![img](https://static001.geekbang.org/resource/image/ef/a2/efc6558677927715d84a4af456d117a2.jpg?wh=1920x357)

从图中可以看出，ArrayList 的底层数据直接使用了数组，是对数组的抽象。ArrayList 相比数组，增加了一个特性，它支持自动扩容。其扩容机制如下图所示：

![img](https://static001.geekbang.org/resource/image/65/46/65ba6fb1d476ed9c21e1e95485850f46.jpg?wh=1920x605)



扩容的实现有三个要点。扩容后的容量 = 原容量 +（原容量）/ 2，以 1.5 倍进行扩容。内部要创建一个新的数组，数组长度为扩容后的新长度。需要将原数组中的内容拷贝到新的数组，即扩容过程中存在内存复制等较重的操作。



注意，只在当前无剩余空间时才会触发扩容。在实际的使用过程中，我们要尽量做好容量评估，减少扩容的发生。因为扩容的成本还是比较高的，存储的数据越多，扩容的成本越高。接下来，我们来看一下 ArrayList 的数据访问特性。

顺序添加元素的效率高   ArrayList 顺序添加元素，如果不需要扩容，直接将新的数据添加到 elementData[size]位置，然后 size 加一即可（其中，size 表示当前数组中存储的元素个数）。ArrayList 添加元素的时间复杂度为 O(1)，也就是说它不会随着存储数据的大小而改变，是非常高效的存储方式。

中间位置插入 / 删除元素的效率低

![img](https://static001.geekbang.org/resource/image/e7/b8/e74e9012db10cd7dc524831c697f5cb8.jpg?wh=1205x858)

在插入元素时，我们将需要插入数据的下标用 index 表示，将 index 之后的依次向后移动 (复制到 index + 1)，然后将新数据存储在下标 index 的位置。删除操作与插入类似，只是一个数据是往后移，而删除动作是往前移。ArrayList 在中间位置进行删除的时间复杂度为 O(n)，这是一个比较低效的操作。

随机访问性能高   由于 ArrayList 的底层就是数组，因此它拥有高效的随机访问数据特性。




### LinkedList
除了 ArrayList，在数据结构中，还有一种也很经典的数据结构：链表。LinkedList 就是链表的具体实现。我们先来看一下 LinkedList 的底层存储结构，最后再对比一下它和 ArrayList 的差异。

![img](https://static001.geekbang.org/resource/image/9f/73/9fb78d978bf28813c88aa381cfb93973.jpg?wh=1920x723)

从上面这张图你可以看到，一个 LinkedList 对象在内存中通常由两部分组成：LinkedList 对象和由 Node 节点组成的链条。一个 LinkedList 对象在内存中主要包含 3 个字段。

int size：链表中当前存在的 Node 节点数，主要用来判断是否为空、判断随机访问位点是否存在；Node first：指向链表的头节点；Node last：指向链表的尾节点。

再来说说由 Node 节点组成的链条。Node 节点用于存储真实的数据，并维护两个指针。分别解释一下。

E item：拥有存储用户数据；Node prev：前驱节点，指向当前节点的前一个指针；Node last：后继节点，指向当前节点的下一个节点。由这两部分构成的链表具有一个非常典型的特征：内存的申请无须连续性。这就减少了内存申请的限制。

接下来我们来看看如何操作链表。对于链表的操作主要有两类，一类是在链表前后添加或删除节点，一类是在链表中间添加或删除数据。当你想要在链表前后添加或删除节点时，因为我们在 LinkedList 对象中持有链表的头尾指针，可以非常快地定位到头部或尾部节点。也就是说，这时如果我们想要增删数据，都只需要更新相关的前驱或后继节点就可以了，具体操作如下图所示：

![img](https://static001.geekbang.org/resource/image/71/a2/71723714cf880891a0b7a49440bf42a2.jpg?wh=1920x530)



举个例子，如果我们向尾部节点添加节点，它的代码是这样的：

```
Node oldLastNode = list.last; //添加数据之前原先的尾部节点
Node newNode = new Node();
newNode.item = 4;//设置用户的值
oldLastNode.next = newNode; // 将原先尾部节点的next指针更新为新添加的节点
newNode.prev = oldLastNode; // 新添加的节点的prev指向源尾部节点，通过这两步，使新加入的节点添加到链表中
list.last = newNode; // 更新LinkedList的尾部节点为新添加节点
```


在链表的尾部、头部添加和删除数据，时间复杂度都是 O(1)，比 ArrayList 在尾部添加节点效率要高。因为当 ArrayList 需要扩容时，会触发数据的大量复制，而 LinkedList 是一个无界队列，不存在扩容问题。如果要在链表的中间添加或删除数据，我们首先需要遍历链表，找到操作节点。因为链表是非连续内存，无法像数组那样直接根据下标快速定位到内存地址。例如，在下标 index 为 1 的后面插入新的数据，它的操作示例图如下：

![img](https://static001.geekbang.org/resource/image/bd/92/bd79fd4b138507339412e3d325f53d92.jpg?wh=1920x1763)

我们从上往下看。插入新节点的第一步是需要从头节点开始遍历，找到下标为 i=1 的节点，然后在该节点的后面插入节点，最后执行插入节点的逻辑。插入节点的具体实现主要是为了维护链表中相关操作节点的前驱与后继节点。遍历链表、查询操作节点的时间复杂度为 O(n)，然后基于操作节点进行插入与删除动作的时间复杂度为 O(1)。关于链表的知识点就讲到这里。由于链表与数组是数据结构中两种最基本的存储结构，为了让你更直观地了解二者的差异，我也给你画了一个表格，对两种数据结构做了对比：

![img](https://static001.geekbang.org/resource/image/26/32/267cd926d583043d2b1909byy2d37132.jpg?wh=1920x1028)


### HashMap
无论是链表还是数组都是一维的，在现实世界中有一种关系也非常普遍：关联关系。关联关系在计算机领域主要是用键值对来实现，HashMap 就是基于哈希表 Map 接口的具体实现。JDK1.8 版本之前，HashMap 的底层存储结构如下图所示：

![img](https://static001.geekbang.org/resource/image/7a/c8/7a0bdacf9de99f5ef3d064caa7f6ffc8.jpg?wh=1920x906)



HashMap 的存储结构主体是哈希槽与链表的组合，类似一个抽屉。我们向 HashMap 中添加一个键值对，用这个例子对 HashMap 的存储结构做进一步说明。HashMap 内部持有一个 Map.Entry[]的数组，俗称哈希槽。当我们往 HashMap 中添加一个键值对时，HashMap 会根据 Key 的 hashCode 与槽的总数进行取模，得出槽的位置 (也就是数组的下标)，然后判断槽中是否已经存储了数据。如果未存储数据，则直接将待添加的键值对存入指定的槽；如果槽中存在数据，那就将新的数据加入槽对应的链表中，解决诸如哈希冲突的问题。在 HashMap 中，单个键值对用一个 Map.Entry 结构表示，具体字段信息如下。



K key：存储的 Key，后续可以用该 Key 进行查找V value：存储的 Value；int hash：Key 的哈希值；Ma.Entry ：next 链表。



到这里，你可以停下来思考一下，当哈希槽中已经存在数据时，新加入的元素是存储在链表的头部还是尾部呢？答案是放在头部。代码如下：


```

//假设新放入的槽位下标用 index 表示,哈希槽用 hashArray 表示
Map.Entry newEntry = new Map.Entry(key,value);
newEntry.next = hashArray[index];
hashArray[index] = newEntry;

```



我们将新增加的元素放到链表的头部，也就是直接放在哈希槽中，然后用 next 指向原先存在于哈希槽中的元素。

![img](https://static001.geekbang.org/resource/image/0b/c5/0b29590ca607556yyc816ff867313ac5.jpg?wh=1920x1041)

这种方式的妙处在于，只涉及两个指针的修改。如果我们把新增加的元素放入链表的头部，链表的复杂度为 O(1)。相反，如果我们把新元素放到链表的尾部，那就需要遍历整条链表，写入复杂度会有所提高，随着哈希表中存储的数据越来越多，那么新增数据的性能将随着链表长度的增加而逐步降低。



介绍完添加元素，我们来看一下元素的查找流程，也就是如何根据 Key 查找到指定的键值对。首先，计算 Key 的 hashCode，然后与哈希槽总数进行取模，得到对应哈希槽下标。然后，访问哈希槽中对应位置的数据。如果数据为空，则返回“未找到元素”。如果哈希槽对应位置的数据不为空，那我们就要判断 Key 值是否匹配了。如果匹配，则返回当前数据；如果不匹配，则需要遍历哈希槽，如果遍历到链表尾部还没有匹配到任何元素，则返回“未找到元素”。说到这里，我们不难得出这样一个结论：如果没有发生哈希槽冲突，也就是说如果根据 Key 可以直接命中哈希槽中的元素，数据读取访问性能非常高。但如果需要从链表中查找数据，则性能下降非常明显，时间复杂度将从 O(1) 提升到 O(n)，这对查找来说就是一个“噩梦”。

一旦出现这种情况，HashMap 的结构会变成下面这个样子：

![img](https://static001.geekbang.org/resource/image/ae/80/ae0cc399328f69c6af771efc396bec80.jpg?wh=1920x624)



怎么解决这个问题呢？JDK 的设计者们给出了两种优化策略。第一种，对 Hash 槽进行扩容，让数据尽可能分布到哈希槽上，但不能解决因为哈希冲突导致的链表变长的问题。第二种，当链表达到指定长度后，将链表结构转换为红黑树，提升检索性能 (JDK8 开始引入)。



我们先来通过源码深入探究一下 HashMap 的扩容机制。HashMap 的扩容机制由 resize 方法实现，该方法主要分成两个部分，上半部分处理初始化或扩容容量计算，下半部分处理扩容后的数据复制 (重新布局)。上半部分的具体源码如下：
```
    /**
     * Initializes or doubles table size.  If null, allocates in
     * accord with initial capacity target held in field threshold.
     * Otherwise, because we are using power-of-two expansion, the
     * elements from each bin must either stay at same index, or move
     * with a power of two offset in the new table.
     *
     * @return the table
     */
    final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table;
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
        if (oldCap > 0) {
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr << 1; // double threshold
        }
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab;
      //此处省略数据复制相关代码
    }
```
为了方便你对代码进行理解，我画了一个与之对应的流程图：

![img](https://static001.geekbang.org/resource/image/31/47/312f3caa99e8563c26b21038d2222347.jpg?wh=1920x1259)

总结一下扩容的要点。HashMap 的容量并无限制，但超过 2 的 30 次幂后不再扩容哈希槽。哈希槽是按倍数扩容的。HashMap 在不指定容量时，默认初始容量为 16。



HashMap 并不是在无容量可用的时候才扩容。它会先设置一个扩容临界值，当 HashMap 中的存储的数据量达到设置的阔值时就触发扩容，这个阔值用 threshold 表示。我们还引入了一个变量 loadFactor 来计算阔值，阔值 = 容量 *loadFactor。其中，loadFactor 表示加载因子，默认为 0.75。加载因子的引入与 HashMap 哈希槽的存储结构与存储算法有关。HashMap 在出现哈希冲突时，会引入一个链表，形成“数组 + 链表”的存储结构。这带来的效果就是，如果 HashMap 有 32 个哈希槽，当前存储的数据也刚好有 32 个，这些数据却不一定全会落在哈希槽中，因为可能存在 hash 值一样但是不同 Key 的数据，这时，数据就会进入到链表中。



前面我们也提到过，数据放入链表就容易引起查找性能的下降，所以，**HashMap 的设计者为了将数据尽可能地存储到哈希槽中，会提前进行扩容，用更多的空间换来检索性能的提高**。我们再来看一下扩容的下半部分代码。我们先来看下这段代码：

```java
@SuppressWarnings({"rawtypes","unchecked"})
Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
table = newTab;
if (oldTab != null) {
    for (int j = 0; j < oldCap; ++j) {
        Node<K,V> e;
        if ((e = oldTab[j]) != null) {
            oldTab[j] = null;
            if (e.next == null)
                newTab[e.hash & (newCap - 1)] = e;
            else if (e instanceof TreeNode)
                ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
            else { // preserve order
                Node<K,V> loHead = null, loTail = null;
                Node<K,V> hiHead = null, hiTail = null;
                Node<K,V> next;
                do {
                    next = e.next;
                    if ((e.hash & oldCap) == 0) {
                        if (loTail == null)
                            loHead = e;
                        else
                            loTail.next = e;
                        loTail = e;
                    }
                    else {
                        if (hiTail == null)
                            hiHead = e;
                        else
                            hiTail.next = e;
                        hiTail = e;
                    }
                } while ((e = next) != null);
                if (loTail != null) {
                    loTail.next = null;
                    newTab[j] = loHead;
                }
                if (hiTail != null) {
                    hiTail.next = null;
                    newTab[j + oldCap] = hiHead;
                }
            }
        }
    }
}

```
这段代码不难理解，就是按照扩容后的容量创建一个新的哈希槽数组，遍历原先的哈希槽 (数组)，然后将数据重新放入到新的哈希槽中，为了保证链表中数据的顺序性，在扩容时采用尾插法。除了扩容，JDK8 之后的版本还有另外一种提升检索能力的措施，那就是在链表长度超过 8 时，将链表演变为红黑树。这时的时间复杂度为 O(2lgN)，可以有效提升效率。关于红黑树，我会在下节课详细介绍。

### 总结
这节课，我们介绍了数组、ArrayList、LinkedList、HashMap 这几种数据结构。数组，由于其内存的连续性，可以通过下标的方式高效随机地访问数组中的元素。数组与链表可以说是数据结构中两种最基本的数据结构，这节课，我们详细对比了两种数据结构的存储特性。

![img](https://static001.geekbang.org/resource/image/26/32/267cd926d583043d2b1909byy2d37132.jpg?wh=1920x1028)

哈希表是我们使用得最多的数据结构，它的底层的设计也很具技巧性。哈希表充分考虑到数组与链表的优劣，扬长避短，HashMap 就是这两者的组合体。为了解决链表检索性能低下的问题，HashMap 内部又引入了扩容与链表树化两种方式进行性能提升，提高了使用的便利性，降低了使用门槛。


## 04 | 红黑树：图解红黑树的构造过程与应用场景

这节课，我们继续 Java 中常用数据结构的讲解。我会重点介绍 TreeMap、LinkedHashMap 和  PriorityQueue 这三种数据结构。


### TreeMap
先来看 TreeMap。TreeMap 的底层数据结构是一棵红黑树，这是一种比较复杂但也非常重要的数据结构。它是由树这种基础的数据结构演化而来的。我们知道，在计算机领域，树指的就是具有树状结构的数据的集合。把它叫做“树”，是因为它看起来像一棵自上而下倒挂的树。一棵树通常有下面几个特点：

每个节点都只有有限个子节点或无子节点；没有父节点的节点称为根节点；每一个非根节点有且只有一个父节点；除了根节点外，每个子节点可以分为多个不相交的子树；树里面没有环路（cycle）。

如果一棵树的每个节点最多有两个子树，那它就是一棵二叉树。二叉树是“树”的一个重要分支，我们可以通过文稿中这张图来直观感受一下：

![img](https://static001.geekbang.org/resource/image/db/95/dbba4e3eee0647c17e70816eee942a95.jpg?wh=1920x719)

但是如果数据按照这样的结构存储，想要新增或者查找数据就需要沿着根节点去遍历所有的节点，这时的效率为 O(n)，可以看出性能非常低下。作为数据结构的设计者，肯定不能让这样的事情发生。这时候，我们就需要对数据进行排序了，也就是使用所谓的二叉排序树（二叉查找树）。它有下面几个特点：

若任意节点的左子树不为空，则左子树上所有节点的值均小于它的根节点的值；若任意节点的右子树不为空，则右子树上所有节点的值均大于它的根节点的值；没有键值相等的节点。

如果上图这棵二叉树变成一棵二叉排序树，可能长成下面这个样子：

![img](https://static001.geekbang.org/resource/image/f9/4f/f9296accdc782637396dfab5c6d7b54f.jpg?wh=1920x701)

基于排序后的数据存储结构，我们来尝试一下查找数字 30：从根节点 37 开始查找，判断出 37 比 30 大，然后尝试从 37 的左子树继续查找；37 的左子节点为 26，判断出 26 比 30 小，所以需要从 26 的右子树继续查找；26 的右子节点为 32，由于 32 比 30 大，所以从 32 的左子树继续查找；32 的左子节点为 30，命中，结束。

你应该已经发现了，每次查找，都可以排除掉一半的数据。我们可以将它类比作二分查找算法，其时间复杂度为 O(logN)，也就是对数级。所以说，二叉排序树是一种比较高效的查找算法。不过，二叉排序树也有缺陷。一个最主要的问题就是，在查找之前我们需要按照二叉排序树的存储特点来构建它。我们还是用上面这个例子，将节点按照从小到大的顺序构建二叉排序树，构建过程如下图所示：

![img](https://static001.geekbang.org/resource/image/ff/03/ff3e0419b56cc82e9byycdyy11d59203.jpg?wh=1920x1042)

根据排序二叉树的构建规则，如果数据本身是顺序的，那么二叉排序树会退化成单链表，时间复杂度飙升到 O(n)，我们显然不能接受这种情况。对比这两棵二叉排序树，第一棵左右子树比较对称，两边基本能保持平衡，但第二棵严重地向右边倾斜，这会导致每遍历新的一层，都无法有效过滤一半的数据，也就意味着性能的下降。那有没有一种办法能够自动调整二叉排序树的平衡呢？这就是红黑树要解决的问题了。

红黑树是一种每个节点都带有颜色属性（红色或黑色）的二叉查找树，它可以实现树的自平衡，查找、插入和删除节点的时间复杂度都为 O(logn)。除了要具备二叉排序树的特征外，红黑树还必须具备下面五个特性。

性质 1：节点是红色或黑色。性质 2：根是黑色。性质 3：所有叶子都是黑色（叶子是 NIL 节点）。性质 4：每个红色节点必须有两个黑色的子节点。也就是说，从每个叶子到根的所有路径上不能有两个连续的红色节点。性质 5：从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。

由于插入、删除节点都有可能破坏红黑树的这些特性，所以我们需要进行一些操作，也就是通过树的旋转让它重新满足这些特点。树的旋转又分为右旋和左旋两种：右旋指的是旋转后需要改变支点节点的右子树，左旋指的是旋转后需要改变支点节点的左节点。 这个通过旋转重新满足特性的过程就是自平衡。树越平衡，数据的查找效率越高。

为了让你直观地看到“红黑树的魅力”，我们还是沿用上面的例子，将节点按照从小到大的顺序依次插入到一棵红黑树中，最终产生的红黑树为如下图所示：

![img](https://static001.geekbang.org/resource/image/14/dc/14f92ece5408bacf210ea002fb0b9ddc.jpg?wh=1920x913)



这是一棵地地道道的二叉排序树。但是我们刚才说，在查找元素时，时间复杂度从 O(n) 飙升到了 O(logN)，这棵树是如何做到节点顺序插入时没有退化成链表的呢？我们一起来看下红黑树的构建过程。提前说明一下，由于从小到大排序是一种特殊情况，不能覆盖建构红黑树的多种情况，所以为了更好地说明红黑树的工作机制，我们把节点的插入顺序变更为 50、37、70、35、25、30、26、80、90、100、20、18、32、75、85。

1. 按照这个顺序，首先我们连续插入节点 50、节点 37、节点 70，其初始状态如下图所示：

![img](https://static001.geekbang.org/resource/image/2d/56/2db415ef66db6049913f711abf362856.jpg?wh=1295x440)

2. 然后，继续插入节点 35：

![img](https://static001.geekbang.org/resource/image/52/5b/526ba3c42231056f4dfc454f6545b75b.jpg?wh=1920x675)

这个时候，新插入的节点 0035 的父节点 (00037) 和叔叔节点 (0070) 都是红色，所以我们需要将 0035 的祖父节点的颜色传递到它的两个子节点，这样也就到了图里的第二个状态。由于根节点的颜色为红色，不符合红黑树的特点，我们再将根节点的颜色变更为黑色。

3. 继续插入节点 25：

![img](https://static001.geekbang.org/resource/image/43/26/43db0d4bd05635546yyae7bf82ae3f26.jpg?wh=1920x694)

可以看到，初始状态的当前节点、父节点和祖先节点的形状为一条斜线。这时红色节点 0025 与 0035 都是红色，违背了红黑树的性质 4，这种情况可以使用右旋来解决，具体操作是：让当前节点 (0025) 的祖先节点 (0037) 下沉，作为当前节点的父节点 (0035) 的右子节点。同时，当前父节点（0025）的祖先节点（0050）的左节点指向当前节点的父节点，这样，0050 的左节点就直接指向了 0035。本轮操作后变成图里的第二个状态。旋转之后 0035 节点的右子树路径多了一个黑色的节点 0037，为了符合红黑树的特性，我们需要将 0037 父节点的颜色进行翻转，变成图里的第三个状态。

总结一下，右旋的第一个触发条件：当前节点与父亲节点为红色，并且都是左节点。

4. 继续插入节点 30：

![img](https://static001.geekbang.org/resource/image/c2/df/c2af916e139f79byybd32b4a986dd6df.jpg?wh=1920x747)

当前节点 (0030)、父节点 (0025) 和叔叔节点 (0037) 都为红色，所以可以将当前节点的祖先 (0035) 的状态传递给子节点，变成上图第二个状态。

5. 继续插入节点 26：

![img](https://static001.geekbang.org/resource/image/6d/1d/6d37157133004d3a7e425de24f22911d.jpg?wh=1920x592)



可以看到，现在的状态是，当前节点 (0026) 和父节点 (0030) 为红色，当前节点为左子树，父节点为右子树，并且叔叔节点并不为红色（组成一个大于号）。这时候我们也需要右旋，以当前节点为支点，将其父节点作为当前节点的右节点，当前节点重新充当其祖父节点的右节点，状态从图一转为图二。

**这是右旋的第二个触发条件：当前节点、父节点、祖父节点的形状为大于号，而且当前节点的父节点为支点。**

状态变为图二之后，当前节点 (0030) 与父节点 (0026) 都是红色，并且都是右节点，所以应该执行一次左旋。以父节点 0026 为支点，将当前节点（0030）的祖父节点（0025）变为父节点（0026）的左子节点，经过这个动作后，状态从图二转为图三。左旋之后，黑色节点 0025 变成了节点 0026 的左子树，左子树的黑色节点数量变多，所以我们需要将黑色传递到父节点，也就是要把节点 0025 变为红色，0026 变为黑色，变成图中的第四个状态。

6. 我们接着插入节点 80，此时不会改变红黑色特性，再插入节点 90：



![img](https://static001.geekbang.org/resource/image/f0/80/f0895de57fc10a343fcb8792a3539680.jpg?wh=1920x535)



由于当前节点与父节点都是红色，并且都是右节点，需要执行左旋。其实，到底什么时候需要左旋，什么时候需要右旋你没有必要死记硬背。因为左旋、右旋的最终目的是要满足树的平衡，也就是降低树的层级。只要确保旋转后的最终效果满足二叉排序树的定义（根节点比左子树大，比右子数小）就可以了。

7. 继续插入节点 100、20：

![img](https://static001.geekbang.org/resource/image/db/27/dbb189eafbf50c0d94955ce455764727.jpg?wh=1920x1032)



到这里我们就需要说明一下了。这一步和步骤 2 一样，当前节点、父节点和叔叔节点都是红色，只需要将当前节点的祖父节点的颜色传递到祖父节点的两个子节点就可以了，这就到了图中的第二个状态。但这个时候，0026 和它的父节点 0035 同为红色，并且叔叔节点也是红色，我们需要再像上面一样传递颜色，调整后变成图里的第三个状态。最后，由于根节点是红色，我们需要将根节点转为黑色。这里重点强调的是，无论是左旋、右旋还是变色，都需要再次向上递归进行验证。

8. 继续插入 18、32、75、85 等节点：

![img](https://static001.geekbang.org/resource/image/28/9b/28011fc0405a3e9aefc82e0fa0c5639b.jpg?wh=1920x757)



到这一步基本没有什么新的知识点了，按照我们前面所讲过的方法进行调整，就可以得到上面这棵红黑树了。红黑树的构建过程就介绍到这里。红黑树的主要过程就是通过为节点引入颜色、左旋、右旋、变色等手段实现树的平衡，保证查询功能高效有序进行。聊完数据结构，我们再来看看它的应用。其实，TreeMap 在中间件开发领域的运用非常广泛，其中最出名的估计要属使用 TreeMap 实现一致性哈希算法了。下面是一致性哈希算法的示意图：

![img](https://static001.geekbang.org/resource/image/bc/fe/bc31cb6cbc80a69f63639f9a96fa58fe.jpg?wh=1623x1209)

其中，Node1、Node2、Node3 是真实存储的有效数据，每一个节点需要存储一些关联信息，很适合 key-value 的存储形式。一致性哈希算法的查询规则是：查询第一个大于目标哈希值的节点。例如，如果输入 key1，key2，需要命中 Node2，如果输入 key3，则需要命中 Node3。这种情况其实就是需要将数据按照 key 进行排序，而 TreeMap 中的数据本身就是顺序的，所以非常适合这个场景。

在 RocketMQ 中，就使用了一致性哈希算法来实现消费组队列的负载均衡。

![img](https://static001.geekbang.org/resource/image/13/b6/134d19568880d1033ab0622329dfbfb6.png?wh=729x221)

TreeMap 的 TailMap 是返回大于等于 key 的子树，然后调用子树的 firstKey 获取 TreeMap 中最小的元素，符合一致性哈希算法的命中规则。又因为 TreeMap 是一棵排序树，所以得到最小、最大值会非常容易。在 TreeMap 中实现 firstkey 方法时，内部会先获取 TreeMap 中的键值对，也就是 Entry 对象：

![img](https://static001.geekbang.org/resource/image/56/32/567afede5fce939998065532aef63732.png?wh=645x216)

然后从根节点开始遍历，查找到节点的左子树，再一直遍历到树的最后一个左节点，时间复杂度为 O(logN)。

### LinkedHashMap
红黑树就介绍到这里了，接下来我们再来看一个与 LRU 相关的数据结构 LinkedHashMap。LinkedHashMap 是 LinkedList 和 HashMap 的结合体，它内部的存储结构可以简单表示为下面这样：

![img](https://static001.geekbang.org/resource/image/33/93/33c1401cbf092cbfabd7f1dc38acd793.jpg?wh=1920x1483)



LinkedHashMap 内部存储的 Entry 在 HashMap 的基础上增加了两个指针：before 和 after。这两个节点可以对插入的节点进行链接，以此来维护顺序性。同时，链表结构为了方便插入，也会持有“头尾节点”这两个指针。那引入链表有什么好处呢？



我认为大概有下面两个优点。一个是降低了遍历实现的复杂度。我们对比一下，HashMap 的遍历是首先遍历哈希槽，然后遍历链表；但 LinkedHashMap 则可以基于头节点遍历，复杂度明显降低。引入链表的第二个优点则是提供了顺序性。接下来，我们就来看看 LinkedHashMap 的顺序性和使用场景。

LinkedHashMap 提供了两种顺序性机制：按节点插入顺序，是 LinkedHashMap 的默认行为；按节点的访问性顺序，最新访问的节点将被放到链表的末尾。

它的使用场景也很常见，有一种知名的淘汰算法叫 LRU。顾名思义，LRU 就是要淘汰最近没有使用的数据。在 Java 领域，实现 LRU 的首选就是 LinkedHashMap，因为 LinkedHashMap 能够按访问性排序。在 LinkedHashMap 中，如果顺行性机制选择“按访问顺序”，那么当元素被访问时，元素会默认被放到链表的尾部，并且在向 LinkedHashMap 添加元素时会调用 afterNodeInsertion 方法。这个方法的具体实现代码如下：

![img](https://static001.geekbang.org/resource/image/2d/53/2d077d7a97e7c70f9c195fd011be7853.png?wh=650x169)

从代码中可以看出，如果 removeEldestEntry 函数返回 true，则会删除 LinkedHashMap 中的第一个元素，这样就淘汰了旧的数据，实现了 LRU 的效果。removeEledestEntry 方法的代码如下：

![img](https://static001.geekbang.org/resource/image/66/4c/665831dd1b1785af1c1740830fa3994c.png?wh=529x70)



可以看到，默认返回的是 false，表示 LinkedHashMap 并不会启用节点的淘汰机制。为了实现 LRU 算法，我们需要继承 LinkedHashMap 并重写该方法，具体实现代码如下：

```java
package net.codingw.datastruct;
import java.util.LinkedHashMap;
import java.util.Map;
public class LRUCache<K,V> extends LinkedHashMap<K,V> {
    private int maxCapacity;
    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
        //如果超过了最大容量，则启动剔除机制
        return size() >= maxCapacity;
    }
    public void setMaxCapacity(int maxCapacity) {
        this.maxCapacity = maxCapacity;
    }
}
```

LinkedHashMap 就介绍到这里了，我们再来看一种特殊的队列——优先级队列，它是实现定时调度的核心数据结构。


### PriorityQueue
我们知道，普通队列都是先进先出的，但优先级队列不同，它可以为元素设置优先级，优先级高的元素完全可以后进先出。我们先来看一下 PriorityQueue 的类图：

![img](https://static001.geekbang.org/resource/image/34/54/3427653c4cf7df7cf84aae443aba1d54.jpg?wh=1100x518)



优先级队列的底层结构是数组，可是怎么在数组的基础上排列优先级呢？原来，PriorityQueue 的底层是基于最小堆实现的堆排序。所谓最小堆指的是一棵经过排序的完全二叉树，根结点的键值是所有堆结点键值中最小者。无论是最大堆还是最小堆，都只固定根节点与子节点的关系，两个子节点之间的关系并不做强制要求。我们采用数组作为最小堆的底层数据结构，将最小堆用一棵二叉树来表示，这时的数据是按照从上到下、从左到右的方式依次存储在数组中的：

![img](https://static001.geekbang.org/resource/image/b3/8d/b3d543f95051844ff50d909c2b1ebf8d.jpg?wh=1920x1141)



这种存储方式有两个特点：假设一个节点在数组中的下标为 n，则它的左子节点的下标为 2n+1，它的右子节点的下标为 2n+2；假设一个节点在数组中的下标为 n，那么它的父节点下标为 (n -1) >>> 1。

有些最小堆的存储方式是将数组的第一个元素空出来，把根节点存储在下标为 1 的位置。如果基于这种方式，存储有下面两个特点：假设一个节点在数组中的下标为 n，则它的左子节点的下标为 2n，它的右子节点的下标为 2n+1；假设一个节点在数组中的下标为 n，则它的父节点下标为 (n) >>> 1。

但在实践场景中，数据不可能按顺序插入，既然如此，要实现优先级队列，该怎么对这棵树进行排序呢？PriorityQueue 队列的实现中采用了堆排序。我们还是用图解的方式来看一下构建规则。首先我们连续插入节点 500，600，700，800，其内部结构如下图所示：



![img](https://static001.geekbang.org/resource/image/21/71/21d49d0212b7686bdac290e5b565c171.jpg?wh=1179x358)



由于首先插入了根节点为 500，后续 600，700 比根节点都小，所以 600 和 700 可以直接成为根节点的左右子树。继续插入 800，由于比根节点大，同时比 600 大，则直接放入到 600 的子节点即可。继续插入 490，插入过程如下图所示：

![img](https://static001.geekbang.org/resource/image/e3/22/e3604ea102ba4a7416cc6688a5494c22.jpg?wh=1920x807)

解释一下。我们首先将新元素插入到数组的最后，下标为 n=5，队列是图中的第一个状态。根据公式 n >>> 1 ，可以算出它的父节点的下标为 2，比较两者的大小，如果新插入的节点比父节点少，那么交换两者的值，变化到图中的第二个状态。这时候，我们再通过公式 n>>>1 算出父节点的下标为 1，比较两者的值，发现子节点的值比父节点的值低，则继续交换两者的值，成为图中的第三个状态。要实现上面的步骤，我们相应的代码是：

```java
private void siftUp(int k, E x) {
    if (comparator != null)
        siftUpUsingComparator(k, x);
    else
        siftUpComparable(k, x);
}
@SuppressWarnings("unchecked")
private void siftUpComparable(int k, E x) {
    Comparable<? super E> key = (Comparable<? super E>) x;
    while (k > 0) {
        int parent = (k - 1) >>> 1;
        Object e = queue[parent];
        if (key.compareTo((E) e) >= 0)
            break;
        queue[k] = e;
        k = parent;
    }
    queue[k] = key;
}
```

在这段代码里，我们首先使用 while(k>0) 实现递归，因为最小堆是将新插入的节点放在叶子结点，然后不断与其父节点进行比较，直到到达根节点。然后，我们要根据当前节点的序号，计算其父节点的序号 (这里的算法与图解方式不一样，是因为 PriorityQueue 是将根节点的下标定为 0)，然后比较大小：

如果当前节点比父节点的值大，则跳出循环，符合最小堆的要求；如果当前节点比父节点的值小，则交换两者的值，将 k 的值赋值为父节点 (k = parent)，然后继续向上递归做判断。


构建好堆之后，我们再来看看怎么从堆中获取数据。要注意的是，访问数据只能从堆的根节点开发方法，具体做法就是删除根节点，并将根节点的值返回。我们先尝试删除根节点 490：

![img](https://static001.geekbang.org/resource/image/75/17/75bbe9ea5cde7333cb00a50216a09e17.jpg?wh=1920x1187)

删除根节点和删除其他任何节点的算法是一样的：首先，我们将待删除的位置的值清除，状态为图一。然后，将数组最后的元素移动到待删除位置，我们用下标 n 表示。删除根节点，n 为 0，状态转为图二。接下来，根据下标算法分别算出其子节点的下标为 2n、2n+1，从左右节点中挑选最小值，如图三。用父节点的值与左右子节点中最小的值进行对比，如图四。如果父节点比最小子节点大，则交换两者的值，如图五。我们要一直往下递归，直到节点没有子节点，或者没有父节点比子节点小为止。

结合这张图，我们同样来看一下 PriorityQueue 中删除元素的代码：

```java
private void siftDown(int k, E x) {
    if (comparator != null)
        siftDownUsingComparator(k, x);
    else
        siftDownComparable(k, x);
}
@SuppressWarnings("unchecked")
private void siftDownComparable(int k, E x) {
    Comparable<? super E> key = (Comparable<? super E>)x;
    int half = size >>> 1;        // loop while a non-leaf
    while (k < half) {
        int child = (k << 1) + 1; // assume left child is least
        Object c = queue[child];
        int right = child + 1;
        if (right < size &&
            ((Comparable<? super E>) c).compareTo((E) queue[right]) > 0)
            c = queue[child = right];
        if (key.compareTo((E) c) <= 0)
            break;
        queue[k] = c;
        k = child;
    }
    queue[k] = key;
}
```
可以看到，在这段代码中，我们设定 half 为 size 的一半，如果下标大于 half，则下标对应的位置不会再有子节点，可以跳出循环。代码的第 12 行是计算左右节点下标的公式，我们可以按照公式算出左右节点的下标，并比较两者的大小，挑选更小的值与父节点进行对比。最后，我们再来看一下优先级队列的应用场景。其实，JUC 中的定时调度线程池 ScheduledExecutorService 的底层就使用了优先级队列。定时任务调度线程池的基本实现原理是：


在将调度任务提交到线程池之前，首先计算出下一次需要执行的时间戳，通过时间戳来计算优先级，将其存入最小堆中，这样就确保了最先需要执行的调度任务位于最小堆的顶部 (也就是根节点)。然后开一个定时任务，拿队列中第一个元素和当前时间进行比较：如果下一次执行时间大于等于当前时间，则将队列中第一个元素 (调度任务) 从队列中移除，投入线程池中执行。如果下一次执行时间小于当前时间，则不处理，因为队列中最小的待执行任务都还没有到执行时间，其他任务一定也是这样。

可以看到，定时调度场景的关键是找到第一个需要触发的任务，类似 SQL 中的 min 语义，重在优先二字，而优先级队列的实现原理同样注重优先。理念上的契合让定时任务调度和优先级队列经常绑定在一起出现。


### 总结
好了，这节课就讲到这里。内容比较多，但是把脉络拎出来，其实我们主要讲了三种数据结构。其中，树是数据结构中比较难但同时也非常常见的一种数据结构。我们从二叉排序树的优劣势出发，引出了红黑树，并用图解的方式详细介绍了红黑树的构建过程，介绍了红黑树的左旋、右旋、变色方法，还列举了红黑树的经典应用场景。紧接着我们介绍了 LinkedHashMap，它是链表与 HashMap 的结合体。LinkedHashMap 既拥有 HashMap 快速的检索能力，还引入了节点顺序性，可以基于它实现 LRU 缓存淘汰算法。最后，我们还通过图解认识了优先级队列，看到了用数组存储树的高阶用法，以及堆排序的工作机制和应用场景。希望你能够借这个机会再巩固一下自己的基础知识，有所收获。同时，我也建议你在学完这些数据结构基本原理之后，有针对性地阅读一下源码，提炼出自己的学习方法。

## 基本围绕着java介绍的
……





















































