<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Algorithm_business - 绿叶律动</title><meta name="Description" content="绿叶律动"><meta property="og:title" content="Algorithm_business" />
<meta property="og:description" content="业务开发算法50讲 黄清昊2021-12 开篇词｜真实世界的算法，和你想的不一样 许多同学在工作中没什么机会和需求要手写一些基础的数据结构，只是偶" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jefofrank.xyz/algorithm_business/" /><meta property="og:image" content="https://jefofrank.xyz/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-16T13:57:52+08:00" />
<meta property="article:modified_time" content="2022-10-08T19:55:40+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jefofrank.xyz/logo.png"/>

<meta name="twitter:title" content="Algorithm_business"/>
<meta name="twitter:description" content="业务开发算法50讲 黄清昊2021-12 开篇词｜真实世界的算法，和你想的不一样 许多同学在工作中没什么机会和需求要手写一些基础的数据结构，只是偶"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://jefofrank.xyz/algorithm_business/" /><link rel="prev" href="https://jefofrank.xyz/vim/" /><link rel="next" href="https://jefofrank.xyz/algorithm_facialmeridians/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Algorithm_business",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/jefofrank.xyz\/algorithm_business\/"
        },"image": ["https:\/\/jefofrank.xyz\/images\/Apple-Devices-Preview.png"],"genre": "posts","wordcount":  74988 ,
        "url": "https:\/\/jefofrank.xyz\/algorithm_business\/","datePublished": "2022-07-16T13:57:52+08:00","dateModified": "2022-10-08T19:55:40+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "Jefo","logo": "https:\/\/jefofrank.xyz\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Jefo"
            },"description": ""
    }
    </script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-193031966-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-193031966-2');
</script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="绿叶律动"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span><span id="id-1" class="typeit"></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> All posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="https://github.com/jf-011101" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="直接搜索更方便^-^" id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="绿叶律动"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span><span id="id-2" class="typeit"></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="直接搜索更方便^-^" id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">All posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="https://github.com/jf-011101" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Algorithm_business</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/jf-011101" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>Jefo</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-07-16 13:57:52">2022-07-16 13:57:52</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 74988 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 150 分钟&nbsp;<span id="busuanzi_container_page_pv">
                    <i class="far fa-eye fa-fw"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;次阅读量</span>
                </span>
            </div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#开篇词真实世界的算法和你想的不一样">开篇词｜真实世界的算法，和你想的不一样</a></li>
    <li><a href="#先导篇诶这个-git-diff-好像不是很直观">先导篇｜诶，这个 git diff 好像不是很直观？</a>
      <ul>
        <li><a href="#文本差分是什么">文本差分是什么</a>
          <ul>
            <li><a href="#评价指标-1">评价指标 1</a></li>
            <li><a href="#评价指标-2">评价指标 2</a></li>
          </ul>
        </li>
        <li><a href="#myers-diff-algorithm-模型抽象">Myers Diff Algorithm 模型抽象</a>
          <ul>
            <li><a href="#如何抽象---转化为图搜索问题">如何抽象 - 转化为图搜索问题</a></li>
            <li><a href="#如何解决图搜索问题">如何解决图搜索问题</a></li>
            <li><a href="#代码实现">代码实现</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
      </ul>
    </li>
    <li><a href="#04栈函数调用的秘密究竟是什么">04｜栈：函数调用的秘密究竟是什么？</a></li>
    <li><a href="#06treemap红黑树真的有那么难吗">06｜TreeMap：红黑树真的有那么难吗？</a>
      <ul>
        <li><a href="#2-3-树">2-3 树</a></li>
        <li><a href="#红黑树">红黑树</a></li>
        <li><a href="#旋转操作的实现">旋转操作的实现</a>
          <ul>
            <li><a href="#2-节点插入">2 节点插入</a></li>
            <li><a href="#3-节点插入">3 节点插入</a></li>
          </ul>
        </li>
        <li><a href="#操作红黑树的复杂度">操作红黑树的复杂度</a></li>
      </ul>
    </li>
    <li><a href="#07堆如何实现一个高效的优先队列">07｜堆：如何实现一个高效的优先队列？</a>
      <ul>
        <li><a href="#二叉堆">二叉堆</a></li>
      </ul>
    </li>
    <li><a href="#基础算法篇">基础算法篇</a></li>
    <li><a href="#08外部排序如何为tb级数据排序">08｜外部排序：如何为TB级数据排序？</a>
      <ul>
        <li><a href="#tb-级数据排序">TB 级数据排序</a></li>
        <li><a href="#外部排序">外部排序</a>
          <ul>
            <li><a href="#运行时间">运行时间</a></li>
          </ul>
        </li>
        <li><a href="#如何降低归并层数">如何降低归并层数</a></li>
        <li><a href="#败者树">败者树</a></li>
        <li><a href="#时间复杂度">时间复杂度</a></li>
        <li><a href="#总结-1">总结</a></li>
      </ul>
    </li>
    <li><a href="#10搜索算法-一起来写一个简单的爬虫">10｜搜索算法： 一起来写一个简单的爬虫？</a>
      <ul>
        <li><a href="#bfs-和-dfs">BFS 和 DFS</a></li>
        <li><a href="#bfs实现">BFS实现</a></li>
        <li><a href="#dfs实现">DFS实现</a></li>
        <li><a href="#总结-2">总结</a></li>
      </ul>
    </li>
    <li><a href="#11字符串匹配如何实现最快的grep工具">11｜字符串匹配：如何实现最快的grep工具</a>
      <ul>
        <li><a href="#总结-3">总结</a></li>
      </ul>
    </li>
    <li><a href="#13哈夫曼树http20是如何更快传输协议头的">13｜哈夫曼树：HTTP2.0是如何更快传输协议头的？</a>
      <ul>
        <li><a href="#压缩技术">压缩技术</a></li>
        <li><a href="#引入-hpack-的价值">引入 HPACK 的价值</a></li>
        <li><a href="#hpack-的压缩效果">HPACK 的压缩效果</a>
          <ul>
            <li><a href="#1hpack-中的静态表">1.HPACK 中的静态表</a></li>
            <li><a href="#2hpack-中的动态表">2.HPACK 中的动态表</a></li>
          </ul>
        </li>
        <li><a href="#3hpack-中的哈夫曼编码">3.HPACK 中的哈夫曼编码</a>
          <ul>
            <li><a href="#哈夫曼编码">哈夫曼编码</a></li>
            <li><a href="#贪心的哈夫曼树">贪心的哈夫曼树</a></li>
            <li><a href="#哈夫曼树实现">哈夫曼树实现</a></li>
          </ul>
        </li>
        <li><a href="#总结-4">总结</a></li>
      </ul>
    </li>
    <li><a href="#操作系统">操作系统</a></li>
    <li><a href="#14调度算法操作系统中的进程是如何调度的">14｜调度算法：操作系统中的进程是如何调度的？</a>
      <ul>
        <li><a href="#进程是什么">进程是什么？</a></li>
        <li><a href="#进程状态">进程状态</a></li>
        <li><a href="#调度算法">调度算法</a></li>
        <li><a href="#linux-的进程">Linux 的进程</a></li>
        <li><a href="#round-robin-算法">Round-Robin 算法</a></li>
        <li><a href="#普通进程调度">普通进程调度</a>
          <ul>
            <li><a href="#fcfs">FCFS</a></li>
            <li><a href="#sjf">SJF</a></li>
            <li><a href="#srtf">SRTF</a></li>
          </ul>
        </li>
        <li><a href="#总结-5">总结</a></li>
      </ul>
    </li>
    <li><a href="#15lru在虚拟内存中页面是如何置换的">15｜LRU：在虚拟内存中页面是如何置换的？</a>
      <ul>
        <li><a href="#操作系统的缓存淘汰">操作系统的缓存淘汰</a></li>
        <li><a href="#置换策略">置换策略</a></li>
        <li><a href="#时间局限性与页面置换算法">时间局限性与页面置换算法</a></li>
        <li><a href="#随机页面置换算法">随机页面置换算法</a></li>
        <li><a href="#最优页面置换算法">最优页面置换算法</a></li>
        <li><a href="#fifo-算法">FIFO 算法</a></li>
        <li><a href="#lru-算法">LRU 算法</a></li>
        <li><a href="#实现思路">实现思路</a></li>
        <li><a href="#数据结构选择">数据结构选择</a></li>
        <li><a href="#代码实现-1">代码实现</a></li>
        <li><a href="#总结-6">总结</a></li>
      </ul>
    </li>
    <li><a href="#16日志型文件系统写入文件的时候断电了会发生什么">16｜日志型文件系统：写入文件的时候断电了会发生什么？</a>
      <ul>
        <li><a href="#崩溃一致性">崩溃一致性</a></li>
        <li><a href="#引入元数据的问题">引入元数据的问题</a></li>
        <li><a href="#如何解决">如何解决</a>
          <ul>
            <li><a href="#解决方案-1fsck">解决方案 1：FSCK</a></li>
            <li><a href="#解决方案-2journaling">解决方案 2：Journaling</a></li>
          </ul>
        </li>
        <li><a href="#总结-7">总结</a></li>
      </ul>
    </li>
    <li><a href="#计算机网络">计算机网络</a></li>
    <li><a href="#17选路算法dijkstra是如何解决最短路问题的">17｜选路算法：Dijkstra是如何解决最短路问题的？</a>
      <ul>
        <li><a href="#路由">路由</a></li>
        <li><a href="#路由表">路由表</a></li>
        <li><a href="#dijkstra-算法">Dijkstra 算法</a></li>
        <li><a href="#思路">思路</a></li>
        <li><a href="#代码">代码</a></li>
        <li><a href="#总结-8">总结</a></li>
      </ul>
    </li>
    <li><a href="#18选路算法链路状态算法是如何分发全局信息的">18｜选路算法：链路状态算法是如何分发全局信息的</a>
      <ul>
        <li><a href="#网络路由问题">网络路由问题</a></li>
        <li><a href="#发现节点">发现节点</a></li>
        <li><a href="#测量链路成本">测量链路成本</a></li>
        <li><a href="#封装链路状态包">封装链路状态包</a></li>
        <li><a href="#发送链路状态包">发送链路状态包</a></li>
        <li><a href="#计算路由">计算路由</a></li>
        <li><a href="#链路状态的动态性">链路状态的动态性</a></li>
        <li><a href="#总结-9">总结</a></li>
      </ul>
    </li>
    <li><a href="#19选路算法距离矢量算法为什么会产生无穷计算问题">19｜选路算法：距离矢量算法为什么会产生无穷计算问题？</a>
      <ul>
        <li><a href="#bellman-ford-算法">Bellman-Ford 算法</a></li>
        <li><a href="#bellman-ford-算法正确性证明">Bellman-Ford 算法正确性证明</a></li>
        <li><a href="#负权回路问题">负权回路问题</a></li>
        <li><a href="#距离矢量算法">距离矢量算法</a></li>
        <li><a href="#无限计算问题">无限计算问题</a></li>
        <li><a href="#总结好距离矢量算法">总结好距离矢量算法</a></li>
      </ul>
    </li>
    <li><a href="#20滑动窗口tcp是如何进行流量控制和拥塞控制的">20｜滑动窗口：TCP是如何进行流量控制和拥塞控制的？</a>
      <ul>
        <li><a href="#tcp-协议和-udp-协议">TCP 协议和 UDP 协议</a></li>
        <li><a href="#tcp-中包的发送">TCP 中包的发送</a></li>
        <li><a href="#流量控制">流量控制</a></li>
        <li><a href="#发送端的窗口">发送端的窗口</a></li>
        <li><a href="#接收端的窗口">接收端的窗口</a></li>
        <li><a href="#流量拥塞">流量拥塞</a></li>
        <li><a href="#拥塞控制">拥塞控制</a></li>
        <li><a href="#总结-10">总结</a></li>
      </ul>
    </li>
    <li><a href="#分布式">分布式</a></li>
    <li><a href="#21分而治之mapreduce如何解决大规模分布式计算问题">21｜分而治之：MapReduce如何解决大规模分布式计算问题</a>
      <ul>
        <li><a href="#为什么发明-mapreduce-算法">为什么发明 MapReduce 算法</a></li>
        <li><a href="#map-和-reduce">Map 和 Reduce</a></li>
        <li><a href="#分布式实现">分布式实现</a></li>
        <li><a href="#执行过程">执行过程</a></li>
        <li><a href="#容错">容错</a></li>
        <li><a href="#worker-故障">worker 故障</a></li>
        <li><a href="#master-故障">master 故障</a></li>
        <li><a href="#总结-11">总结</a></li>
      </ul>
    </li>
    <li><a href="#22pagerank谷歌是如何计算网页排名的">22｜PageRank：谷歌是如何计算网页排名的</a>
      <ul>
        <li><a href="#总结-12">总结</a></li>
      </ul>
    </li>
    <li><a href="#23raft分布式系统间如何达成共识">23｜Raft：分布式系统间如何达成共识？</a>
      <ul>
        <li><a href="#总结-13">总结</a></li>
      </ul>
    </li>
    <li><a href="#24uuid如何高效生成全局的唯一id">24｜UUID：如何高效生成全局的唯一ID？</a>
      <ul>
        <li><a href="#总结-14">总结</a></li>
      </ul>
    </li>
    <li><a href="#25一致性哈希如何在集群上合理分配流量">25｜一致性哈希：如何在集群上合理分配流量？</a>
      <ul>
        <li><a href="#总结-15">总结</a></li>
      </ul>
    </li>
    <li><a href="#工程实战">工程实战</a></li>
    <li><a href="#26b-treepostgresql-的索引是如何建立的">26｜B+ Tree：PostgreSQL 的索引是如何建立的？</a>
      <ul>
        <li><a href="#总结-16">总结</a></li>
      </ul>
    </li>
    <li><a href="#27lsm-treeleveldb的索引是如何建立的">27｜LSM Tree：LevelDB的索引是如何建立的？</a>
      <ul>
        <li><a href="#总结-17">总结</a></li>
      </ul>
    </li>
    <li><a href="#28mvcc如何突破数据库并发读写性能瓶颈">28｜MVCC：如何突破数据库并发读写性能瓶颈？</a>
      <ul>
        <li><a href="#总结-18">总结</a></li>
      </ul>
    </li>
    <li><a href="#29位图如何用更少空间对大量数据进行去重和排序">29｜位图：如何用更少空间对大量数据进行去重和排序？</a>
      <ul>
        <li><a href="#总结-19">总结</a></li>
      </ul>
    </li>
    <li><a href="#30布隆过滤器如何解决redis缓存穿透问题">30｜布隆过滤器：如何解决Redis缓存穿透问题？</a>
      <ul>
        <li><a href="#总结-20">总结</a></li>
      </ul>
    </li>
    <li><a href="#31跳表redis是如何存储有序集合的">31｜跳表：Redis是如何存储有序集合的？</a>
      <ul>
        <li><a href="#总结-21">总结</a></li>
      </ul>
    </li>
    <li><a href="#32时间轮kafka是如何实现定时任务的">32｜时间轮：Kafka是如何实现定时任务的？</a>
      <ul>
        <li><a href="#总结-22">总结</a></li>
      </ul>
    </li>
    <li><a href="#33限流算法如何防止系统过载">33｜限流算法：如何防止系统过载？</a>
      <ul>
        <li><a href="#总结-23">总结</a></li>
      </ul>
    </li>
    <li><a href="#34前缀树web框架中如何实现路由匹配">34｜前缀树：Web框架中如何实现路由匹配？</a>
      <ul>
        <li><a href="#总结-24">总结</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="业务开发算法50讲-黄清昊2021-12">业务开发算法50讲 黄清昊2021-12</h1>
<h2 id="开篇词真实世界的算法和你想的不一样">开篇词｜真实世界的算法，和你想的不一样</h2>
<p>许多同学在工作中没什么机会和需求要手写一些基础的数据结构，只是偶尔想起来才做一做 LeetCode，很容易发现刚学完的知识点根本记不住，边学边忘。于是开始日常吐槽算法难学，工作中又用不到，不理解大厂面试为什么问这么多算法题，毕竟我们都知道算法面试的著名槽点就是“面试造火箭，工作拧螺丝”。</p>
<p>毕业半年左右我开始感觉日常的增删改查工作非常无聊，写简单的业务代码好像真的只是体力活。因为所在的团队偏创业团队，资源有限，流量很低，所以日常工作中探寻业务价值远多于技术价值。和同事交流，最多也就是学一学代码规范和常用的设计模式，非常没有挑战性，我逐渐失去了对技术的敬畏心。</p>
<p>我们知道衡量程序运行快慢的一个理论依据就是时间复杂度，这也是面试算法环节重要的考察点，<strong>但只考虑时间复杂度显然不够，程序的运行时、操作系统的各种开销都需要考虑到</strong>。因为在我们工作的真实世界中，算法数据结构和计算机基础知识，是紧密联系在一起的，对代码的性能产生着至关重要的影响。</p>
<p>一次面试时，我当时写的代码中有一段循环，里面开了一个比较长的数组，导致程序反复地向操作系统申请堆内存；而且我在代码中不断地对数组进行插入操作，这也会导致数组频繁扩容。<strong>正确的做法则是，事先考虑好应该申请多少空间，就可以避免持续扩容操作，从而提高程序的运行效率。</strong></p>
<p><strong>许多程序员总是以架构师为目标，在技术上热衷追求新的框架、新的架构，只关注那些看似高大上的架构设计、微服务、云原生等概念，但当架构真的出现性能瓶颈却不知道从何下手开始拆解分析。</strong></p>
<p><strong>他们学了很多，真正掌握的却很少。比如很多同学都知道 Redis 实现有序集合底层采用的是跳表，但跳表的实现细节、跳表和红黑树相比有什么优势，就很少有人真正理解了。要进行代码调优的时候，脑子里都是只了解了皮毛、但没有充分理解的知识。</strong></p>
<p>之前我维护过一个要求单机可支持百万连接的高并发长连网关，在开发时，有一个需求是需要从海量的连接中，寻找一些长期没有上下行数据的非活跃连接并移除他们，减少内存使用。</p>
<p>最开始的代码实现是非常暴力的，直接在存有所有连接信息的巨大 HashMap 中做全量扫描，依次判断每个连接是否已经满足非活跃连接的条件，显然，这会带来巨大开销，尤其当非活跃连接占比不是很高的时候。</p>
<p>于之前看过 Redis 源代码，对 LRU 背后的 hash-linked-list 数据结构非常敏感，我看到这个需求，脑海里突然闪过一个念头，如果在内存里维护一个基于最近一次上下行事件时间排序的 hash-linked-list 呢？关闭非活跃连接的时候，只需要从这个有序列表的头部开始遍历，到第一个没有数据上下行的链接之后就不再需要继续遍历了。</p>
<p>如果只分析时间复杂度的话，你会发现这两个方案，从扫描连接的开销上来说，都是 O(N) 的复杂度，因为最差情况下可能所有的连接都是非活跃的。但很显然，在我们的场景中，非活跃连接占比是很低的，基于 hash-linked-list 的实现方案扫描连接的开销，远远小于全量扫描哈希表的开销。</p>
<p>在工作中，我们只有掌握优秀算法的精髓，才能根据实际的 workload 选择合适的算法。</p>
<p>优秀算法思路值得借鉴，但在实际写的时候，可能也还会有更多值得考虑的细节。比如在引入 hash-linked-list 之后，维护整个数据结构就需要保证并发读写的线程安全，因而带来了锁的开销。</p>
<p>所以很多时候，实际的问题，我们甚至不太好简单地通过理论分析，就得出哪个解决方案是更优的，还需要进行实验对比，不断提出新的猜想和优化方案，直到系统的性能逐步趋于完美。</p>
<p>而提出这些性能调优的方案，就需要我们对基础的数据结构和常用中间件的底层原理比较了解了。虽然在一些偏业务的开发中，不见得都能亲自实现这样比较底层的数据结构，但了解它们，一定也会对我们平时的开发和问题排查带来巨大的好处。</p>
<p><strong>我们不只会讨论基础的数据结构和算法思想，更会着重掌握这些算法是如何运行在真实的物理机器上的，如何解决实际业务系统中的问题，还有具体是如何在各个稳定运行的中间件、分布式系统、基础库中实现的。</strong></p>
<p>专栏主要分为偏基础和偏实战的两部分，共 6 个篇章，精讲我们在工作中真正用得上的算法。不过正式学习之前，我们会通过一个“简单”、有趣、常用的文本差分算法为先导，探索那些就在我们身边却常常被熟视无睹的算法，体验思维的乐趣。最后会挑选出几个有趣的算法，在高手番外篇中不定期奉上。</p>
<p>数据结构篇、算法思想篇  这两个模块，包含了工程中常用的基础数据结构和算法思想，比如双向链表、动态数组、哈希表、红黑树、二分搜索、深度优先搜索等，由浅入深，推演算法的来历和特点，分析源码实现思路，不只是了解算法知识，更要理解工业级的算法实现是如何运行在真实的物理机上的。</p>
<p>操作系统篇、计算机网络篇  这两个模块，会带你学习两门非常重要的计算机基础课——操作系统和计算机网络中会用到的基础算法，同样会结合真实的网络库、操作系统的源码进行讲解。这样当你了解许多经典算法的发明背景和应用场景时，再结合操作系统和计算机网络的基础知识，你可以对算法有更深入的理解。</p>
<p>分布式篇、工程实践篇  学习高流量、高并发、高可用的现代互联网应用中各种算法的应用，解析 Redis、MySQL 和 MapReduce 等系统或者论文的经典源码。深入理解在各场景下如何拆解问题、应用算法，目的是升级编程思维，帮助你排查真实业务开发中的各种问题，做出良好的架构设计。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/f9/82/f9c1ea63246ef34911d531d9f1337d82.jpg"
        data-srcset="https://static001.geekbang.org/resource/image/f9/82/f9c1ea63246ef34911d531d9f1337d82.jpg, https://static001.geekbang.org/resource/image/f9/82/f9c1ea63246ef34911d531d9f1337d82.jpg 1.5x, https://static001.geekbang.org/resource/image/f9/82/f9c1ea63246ef34911d531d9f1337d82.jpg 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/f9/82/f9c1ea63246ef34911d531d9f1337d82.jpg"
        title="img" /></p>
<p>当然那些生产环境下稳定运行的系统源码，大多数时候非常复杂，但当你拨开云雾，搞清楚其中的算法思想，并且融汇到你的工作中时，相信我，你一定会觉得当程序员是一件非常快乐的事情。</p>
<p>而且不得不提的一点是，学习这些数据结构和算法的过程本身其实也非常有趣，练习能很好地锻炼我们的编程思维。你不仅能通过对算法的充分训练真切地体会到思维敏捷和思路清晰，而且<strong>在工作中遇到的实际问题中，你往往也能更快也更全面地考虑到各种边界情况，并比较准确、优雅地写出正确的实现。</strong></p>
<h2 id="先导篇诶这个-git-diff-好像不是很直观">先导篇｜诶，这个 git diff 好像不是很直观？</h2>
<p>相信你每天都会使用 Git，作为一款免费、开源的分布式版本控制系统，Git 最初是 Linus Torvalds 为了帮助管理 Linux 内核开源协作而开发的，随着 GitHub 的流行和 Git 本身的系统优势，它也渐渐成为我们广大研发人员日常工作中必不可少的版本管理利器。</p>
<p>在使用 Git 的过程中，你一定会常常用到 git diff 的命令，去查看这次待提交的本地代码和修改前的代码有什么区别，确定没有问题才会进行 commit 操作。像 git diff 这样求解两段文本差异的问题，我们一般称为“文本差分”问题。</p>
<p>但是不知道你有没有思考过文本差分的算法是怎么实现的呢？如果你现在静下心来思考一下，就会发现写出一个简明的文本差分算法并不是一件非常容易的事情。因为代码的文本差分展现形式可能有很多，但并不一定都有非常好的可读性。</p>
<p>而 git diff 给我们展示的，恰恰是比较符合人们阅读习惯且简明的方式，简明到让我们即使天天都在使用这个功能也不会有意识地去思考：“诶，这个 difference 生成的好像不是很清晰？是怎么做的呢？”。</p>
<p>就让我们从这样一个“简单”、有趣、常用的文本差分算法开始，探索那些其实就在我们身边却常常被熟视无睹的算法们吧。希望能给你一些启发，而且探索算法思想的过程也会非常有趣（如果你在学习这一讲的过程中觉得有点难，最后我们会揭秘原因）。</p>
<h3 id="文本差分是什么">文本差分是什么</h3>
<p>文本差分算法其实是一个历史悠久的经典算法问题，许多学者都有相关的研究，解决这个问题的思路也是百家争鸣，复杂度相差甚远。</p>
<p>而在 git diff 的实现里，其实就内置有多个不同的 diff 算法，我们今天主要介绍的是 git diff 的默认算法：Myers 差分算法，这是一个相对简单、效率高且直观的文本差分算法（<a href="http://www.xmailserver.org/diff2.pdf" target="_blank" rel="noopener noreffer">原论文</a>）。</p>
<p>在学习这个算法之前，我们得首先来定义一下什么是文本差分 (difference)，毕竟这个词本身就不是那么直观。</p>
<p>我们找原始出处，Myers 在论文中，提到了这样一句话：An edit script for A and B is a set of insertion and deletion commands that transform A into B.</p>
<p>其中有一个概念叫作 edit script，也就是编辑脚本。比如，对于源文本 A 和目标文本 B，我们一定可以通过不断执行删除行和插入行两种操作，使得 A 转化成 B，这样的一系列插入和删除操作的序列就被称作编辑脚本。**所以，文本差分算法，可以定义为用于求出输入源文本和目标文本之间的编辑脚本的算法，**广泛运用于各种需要进行文本对比的地方。</p>
<p>比如，git diff 就是一个很经典的应用场景，下图是一个真实的例子（具体的 commit 可以在这里找到）。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/1f/15/1f55ffd9267b652ed3770777d52f8b15.png?wh=1920x740"
        data-srcset="https://static001.geekbang.org/resource/image/1f/15/1f55ffd9267b652ed3770777d52f8b15.png?wh=1920x740, https://static001.geekbang.org/resource/image/1f/15/1f55ffd9267b652ed3770777d52f8b15.png?wh=1920x740 1.5x, https://static001.geekbang.org/resource/image/1f/15/1f55ffd9267b652ed3770777d52f8b15.png?wh=1920x740 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/1f/15/1f55ffd9267b652ed3770777d52f8b15.png?wh=1920x740"
        title="img" /></p>
<p>但是，两个文本之间的差分方式可能远远不止一种。比如说，对于任意两个文本 A 和 B，我们总是可以通过将源文本逐行全部删去，再逐行添加目标文本的方式来做变换，也可以通过只修改差异部分的方式，做从 A 到 B 的变换，比如上面的例子中所展示的这样。那我们如何评价不同编辑脚本之间的优劣呢？</p>
<h4 id="评价指标-1">评价指标 1</h4>
<p>第一个评价指标，其实也不难想到就是：编辑脚本的长度。我们举一个论文中的例子来讨论，后面大部分讨论也都会基于这个例子展开：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">源序列 S = ABCABBA   目标序列 T = CBABAC
</code></pre></td></tr></table>
</div>
</div><p>想要完成从 S 到 T 的变换，图中左边的编辑脚本就是前面所说的先删后添的方式，并没有体现出两个文档之间的修改点，显然不是一个很直观的变换表示；而右边的编辑脚本就明显好得多。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/3b/63/3b763007f7a7e61ae29159bb88486763.jpg?wh=666x562"
        data-srcset="https://static001.geekbang.org/resource/image/3b/63/3b763007f7a7e61ae29159bb88486763.jpg?wh=666x562, https://static001.geekbang.org/resource/image/3b/63/3b763007f7a7e61ae29159bb88486763.jpg?wh=666x562 1.5x, https://static001.geekbang.org/resource/image/3b/63/3b763007f7a7e61ae29159bb88486763.jpg?wh=666x562 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/3b/63/3b763007f7a7e61ae29159bb88486763.jpg?wh=666x562"
        title="img" /></p>
<p>直观地来说，右边的编辑脚本要比左边短的多，因为它尽可能保留了更多的原序列中的元素。所以，一种符合直觉的文本差分算法的衡量指标，就是其编辑脚本的长度，长度越短越好。我们一会要介绍的 Myers 算法，也是在求一种最短的编辑脚本（也就是 SES Shortest Edit Script）的算法。但是 SES 要怎么求呢？原论文中也提到，最短编辑距离问题也就是 SES，和最长公共子序列问题也就是 LCS 其实是一对对偶问题，如果求得其中一个问题的解等同于找到了另一个问题的解。而最长公共子序列问题，相信许多准备过面试的同学都有所了解吧。大部分算法面试题中要求的解法复杂度是 O(N*LogN)，采用动态规划就可以解决。不过呢，这并不是今天的重点，先不展开具体算法了。这里我们简短地说明一下两个问题的关联性，还是用刚才的例子：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">源序列 
S = ABCABBA length m = 7
目标序列
T = CBABAC  length n = 6

最长公共子序列(不唯一)
C = CBBA    length LC = 4 
</code></pre></td></tr></table>
</div>
</div><p>我们很容易发现最短的编辑脚本的长度就等于 m + n - 2 * LC 。其中，M 和 N 为原序列 S 和目标序列 T 的长度，LC 为最长公共子序列的长度。这是因为在从原序列到目标序列的变化过程中，两者的最长公共子序列中的元素我们都是可以保留的，只需要在编辑脚本里，按顺序分别删除原序列和插入目标序列里不在公共序列中的元素即可。</p>
<p>当然，两个序列的最长公共子序列往往也不唯一，不同的最长公共子序列都对应着不同的编辑脚本产生，但这些编辑脚本一定都是最短的。</p>
<h4 id="评价指标-2">评价指标 2</h4>
<p>那只是找到 A 到 B 的最短编辑脚本，我们就能满意了吗？并不能，因为即使编辑脚本长度一样，由于删除和插入的顺序不同，人们理解它的难度也会不同。所以，这里就需要引入第二个指标：可读性，毕竟文本的编辑脚本往往最终是要展示给用户看的。这当然是一个很笼统的讲法，我们再借用刚才的例子，来直观地比较一下不同方式的区别吧。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">源序列 
S = ABCABBA 
目标序列
T = CBABAC
 1. - A       2.  - A       3.  + C
    - B           + C           - A
      C             B             B
    - A           - C           - C
      B             A             A
    + A             B             B
      B           - B           - B
      A             A             A
    + C           + C           + C
</code></pre></td></tr></table>
</div>
</div><p>从 S 变化到 T，我们至少可以得到这三种编辑脚本，都是最短的编辑脚本。相信你仔细观察一下之后，可能会有一种感觉，就是第一种比后面两种可读性会好一些，因为删去的行和增加的行并没有彼此交叉，所以可以更清晰地看出修改的代码是哪些。下面这个例子感受可能更明显一点：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">good:   - aaa         Bad:  + ddd
        - bbb               - aaa
        - ccc               + eee
        + ddd               - bbb
        + eee               - ccc
        + fff               + fff
</code></pre></td></tr></table>
</div>
</div><p>对于整段的代码修改来说，左侧对于大部分人来说往往是更清晰的一种展示方式。编辑长度相同的前提下，左侧之所以“更清晰”的直观感受可以总结为两点：我们希望尽可能多地保留整段文本，尽可能连续地删除和插入操作，而不是彼此交叉。大部分人可能更习惯先看到原文本的删除，再看到目标文本的插入。</p>
<p>Myers 也是这么觉得的，所以他提出了一种贪心的策略，可以让我们大部分时候得到一个最短且“质量高”的编辑脚本。策略的逻辑就是，**在最短的编辑脚本里，尽量找到删除在增加前面，且尽可能多地连续删除更多行的方式。**直觉上来说，这就能避免许多交叉的修改，将整段代码的添加更直观地展现给用户；当然这也并不是绝对的，只能说在大部分情况下都更加直观一些。到底如何找到最短编辑脚本中比较直观的一个？这就是 Myers 算法的用武之地啦，下面我们就来看看 Myers 为了解决这个问题所做的独特抽象和建模，这是理解 Myers 算法的关键。</p>
<h3 id="myers-diff-algorithm-模型抽象">Myers Diff Algorithm 模型抽象</h3>
<p>正如前面提到的，从源序列 S 到目标序列 T，有两种操作，分别是删除行和插入行。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">源序列 
S = ABCABBA length m = 7
目标序列
T = CBABAC  length n = 6
</code></pre></td></tr></table>
</div>
</div><p>现在我们就需要找到一种对这两个操作和相应变换状态的抽象方式，帮助我们更好地将问题转化成可以被编程语言实现的代码。</p>
<h4 id="如何抽象---转化为图搜索问题">如何抽象 - 转化为图搜索问题</h4>
<p>Myers 采用了一种非常独特的视角，将这个问题很好地转化为了一个图上的搜索问题。具体做法是这样的：建立一个放在二维平面的网格，网格宽度为 m+1，高度为 n+1，如下图所示，在坐标系中，X 轴向右侧延伸，Y 轴则向下延伸。其中横轴代表着源序列，而纵轴代表着目标序列。我们把这张图称为编辑图。具体什么意思呢？ 我们还是看之前那个例子的编辑图：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/5d/67/5da335962eyy8b324cb8191fe7514067.jpg?wh=4220x3335"
        data-srcset="https://static001.geekbang.org/resource/image/5d/67/5da335962eyy8b324cb8191fe7514067.jpg?wh=4220x3335, https://static001.geekbang.org/resource/image/5d/67/5da335962eyy8b324cb8191fe7514067.jpg?wh=4220x3335 1.5x, https://static001.geekbang.org/resource/image/5d/67/5da335962eyy8b324cb8191fe7514067.jpg?wh=4220x3335 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/5d/67/5da335962eyy8b324cb8191fe7514067.jpg?wh=4220x3335"
        title="img" /></p>
<p>看图上的坐标， (0, 0) 这个点，代表什么操作都没有做的初始状态，而 (7, 6) 则对应了最终完整的从 S 到 T 的编辑脚本。</p>
<p>我们从 (0, 0) 出发进行图上的搜索，每次经过网格中所有的横线代表的是删除操作，如经过 (0,0) -&gt; (1,0) 的横线，代表了将 S 的第一个字符 A 删去。与之相对地，经过所有的竖线则代表着插入操作，如 (3,3) -&gt; (3,4) 代表着对 T 中的第 4 个字符 B 进行插入操作。</p>
<p>显然，网格中的这些横线或竖线的权重为 1，因为每次删除和插入操作所需要花费的操作数都是一样的，我们就记为 1。而二维网格从原点出发到每一个坐标的路径，都对应着一段不完全的编辑脚本，也代表着从原文本到目标文本某种变换的一个中间状态。</p>
<p>比如下图中从 (0,0) -&gt; (3,4) 的路径就表示着字符串 ABC -&gt; CBAB 的一种编辑方式，我们先插入 CB，然后删除 AB 再插入 AB，最后删除 C。这是完整路径中的一部分，也就是完整编辑脚本的一部分。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/22/e9/221a74f5fb77a34243684e207dcb04e9.jpg?wh=4220x3335"
        data-srcset="https://static001.geekbang.org/resource/image/22/e9/221a74f5fb77a34243684e207dcb04e9.jpg?wh=4220x3335, https://static001.geekbang.org/resource/image/22/e9/221a74f5fb77a34243684e207dcb04e9.jpg?wh=4220x3335 1.5x, https://static001.geekbang.org/resource/image/22/e9/221a74f5fb77a34243684e207dcb04e9.jpg?wh=4220x3335 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/22/e9/221a74f5fb77a34243684e207dcb04e9.jpg?wh=4220x3335"
        title="img" /></p>
<p>就此，文本差分问题成功转化成了，如何在这样的网格中找到仅允许向下和向右移动的一个从 (0,0) 出发到 (m,n) 的路径，路径的长度就代表了总共需要的操作数。</p>
<p>比如之前的，先将源序列字符逐一删除，再将目标序列逐一添加的方式，在图中的表现形式就是从 (0,0) 出发一路往右，走到 (m,0)，随后一路向下走到 (m,n)，这样的总操作数就是 m+n=13，等于路径中所有横线的数量和竖线的数量之和，这对应着众多最长的编辑脚本中的一种。</p>
<p>前面我们也说过，并不是所有出现在 S 中的字符都要删除的，可以证明所有出现在最长公共子序列中的字符，都是可以被保留下来的。那可以保留的字符，我们在图中又要如何表现呢？比如为了从 (2,0）转移到 (3,1) ，我们当然可以先经过一个竖线，再经过一个横线，对应到脚本上也就是先插入目标序列 T 中的 C，再删除源序列 S 中的 C，这显然是没有意义的操作。所以，我们应该选择跳过这步操作而保留原有字符串中的 C。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/75/dc/758320094e38f28fcbee976189a3bddc.jpg?wh=4220x3335"
        data-srcset="https://static001.geekbang.org/resource/image/75/dc/758320094e38f28fcbee976189a3bddc.jpg?wh=4220x3335, https://static001.geekbang.org/resource/image/75/dc/758320094e38f28fcbee976189a3bddc.jpg?wh=4220x3335 1.5x, https://static001.geekbang.org/resource/image/75/dc/758320094e38f28fcbee976189a3bddc.jpg?wh=4220x3335 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/75/dc/758320094e38f28fcbee976189a3bddc.jpg?wh=4220x3335"
        title="img" /></p>
<p>Myers 在图上这样描述保留字符的操作：我们在网格里加入一些以相同字符所对应的坐标为起点的斜线，比如图中 (2,0) -&gt; (3,1) 的斜线，并且经过斜线所需要的操作数应该计为 0，因为我们不需要在编辑脚本中进行插入或者删除操作。</p>
<p><strong>所以，在编辑图中，所有源序列和目标序列字符相等的坐标，如 (2,0) 和 (3,1)、(4,1) 和 (5,2) 等，我们都会有一条从上一状态 (x-1,y-1) 到这一状态 (x,y) 的斜经过，且穿过斜线路径不耗费任何操作数。</strong></p>
<p>至此，我们终于可以完美地将两个评价指标在图模型中量化出来。寻找一个最短的编辑脚本，等同于在编辑图上找到从 (0,0) 出发到 (m,n) 的最短路径。而可读性则要求我们通过一定的策略，从最短路径中找到一个更符合人们阅读习惯的增删序列。</p>
<p>还是用这个例子，你可以直观地理解在编辑图上具体的搜索过程。图中粗箭头所示的路径，即为一条最短的路径，其对编辑脚本操作如下：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/59/7b/5929587591f6a54c06fd2558f888ce7b.jpg?wh=4220x3335"
        data-srcset="https://static001.geekbang.org/resource/image/59/7b/5929587591f6a54c06fd2558f888ce7b.jpg?wh=4220x3335, https://static001.geekbang.org/resource/image/59/7b/5929587591f6a54c06fd2558f888ce7b.jpg?wh=4220x3335 1.5x, https://static001.geekbang.org/resource/image/59/7b/5929587591f6a54c06fd2558f888ce7b.jpg?wh=4220x3335 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/59/7b/5929587591f6a54c06fd2558f888ce7b.jpg?wh=4220x3335"
        title="img" /></p>
<p>由于编辑图是一个有权的图，我们所求的问题可以认为是一种特化的单源最短路问题（SSSP 问题），即求解一个有权图中，从指定源点出发到某个其他点的最短路径问题。常用的算法包括 Dijkstra、SPFA、Bellman Ford 等，这些算法复杂度比较高，我们之后会在网络篇展开讲解。回到这里的编辑图搜索问题，因为图中的边权只有 1 和 0 两种，我们当然可以找到更高效的算法来处理。</p>
<h4 id="如何解决图搜索问题">如何解决图搜索问题</h4>
<p>Myers 就通过动态规划思想很好地解决了这个问题。下面就让我们来看一下他是怎么做的，使得找到的路径既是最短的，也是在大部分情况下非常可读的。为了方便进一步表述和建模，首先学习 Myers 在论文中定义的几个重要概念。</p>
<p>D-Path
在编辑图中，路径长度对应着每一条横线或竖线需要花费的操作数之和，也就对应着编辑脚本中增删的行数。为了方便描述，我们把需要 D 步操作的路径称为 D-Path，一条 D-path 指向一个经过 D 次增或删操作的变换过程的中间状态。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/ba/59/ba7e9ba04f1608d6bb5a89f4c859f559.jpg?wh=4220x3335"
        data-srcset="https://static001.geekbang.org/resource/image/ba/59/ba7e9ba04f1608d6bb5a89f4c859f559.jpg?wh=4220x3335, https://static001.geekbang.org/resource/image/ba/59/ba7e9ba04f1608d6bb5a89f4c859f559.jpg?wh=4220x3335 1.5x, https://static001.geekbang.org/resource/image/ba/59/ba7e9ba04f1608d6bb5a89f4c859f559.jpg?wh=4220x3335 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/ba/59/ba7e9ba04f1608d6bb5a89f4c859f559.jpg?wh=4220x3335"
        title="img" /></p>
<p>Snake
斜线都是不需要操作数的。我们定义一个横线或者竖线之后紧跟着 0 条或 n 条斜线所形成的路径称为 snake，所以一条 snake 所需要的操作数为 1。而且我们规定，snake 结尾坐标后继不能为斜线，也就是如果 snake 路径中某个坐标后面有斜线，我们就会继续沿着斜线走，直到走不了为止。比如 1,0 -&gt; 2,0 -&gt; 3,1 就是一条 snake，而 1,0-&gt;2,0 就不是一条 snake。</p>
<p>Line
每个坐标都在一条从左上到右下 45 度角的斜线上。我们可以用 k=x-y 来描述这条斜线，在 m*n 的网格中，k 的取值范围为[m,-n]。比如坐标 (2,4) 和 (1,3) 在 Line(-2) 上，(3,0) 和 (5,2) 在 Line(3) 上。Myers 论文里的这张图就是对这几个概念的一个示意：</p>
<p>有了这些概念的定义之后，我们求解最短编辑脚本的目标就可以定义为要找到最短的可以抵达 (m,n) 的 D-Path。由于所有的 D-Path 都是由 (D-1)-Path 接上一条 snake 构成 （也就是说，所有的编辑脚本都是由一个更短的、指向某个中间状态的脚本，加上一次增删和若干行保留操作所产生的）。所以，很自然产生的一种想法就是从 1-Path 开始，去搜索所有和 1-Path 相接的 2-Path 看看最远能走到哪里，然后以此为基础一直递推到 D-Path，当我们在搜索过程中第一次遇到终点，也就是 (m, n) 时，就找到最短编辑脚本路径了。这样自底向上，通过先解决子问题，逐步递推出问题的解，就是典型的动态规划思想，我们之后也会专门展开讲解。</p>
<p>第二个指标可读性，就是假设有多条 D-Path 都可以抵达 (m,n)，我们如何从里面选出可读简明的路径呢？Myers 采取的是一种贪心的策略，背后的思想主要就是前面讲过的，Myers 认为更简明的 Diff 操作有以下特征：我们希望尽可能多地保留整段文本，尽可能连续删除或插入，而不是彼此交叉。大部分人可能更习惯先看到原文本的删除，再看到目标文本的插入。</p>
<p>这两点其实也非常符合我们的直觉。反映到对编辑图的搜索上也非常直观:我们在探索路径时，如果碰到斜线一定要一路沿着斜线一路往下，直到不能继续为止，只有这样我们才能尽量多地保留连续的原始文本，这就是为什么要求 snake 终点不能停留在连续斜线中间的原因。在考虑 D-Path 的时候，我们会优先从许多 (D-1)-Path 中，挑选出一条终点的横坐标更大的路径来构建。这就意味着在做选择时倾向于选删除优先于插入的方式。</p>
<p>现在你应该明白为什么要引入 snake 和 line 这样的概念了吧。核心就是斜线上的路径都是不需要产生编辑脚本长度的，因此我们可以选择在斜线上进行动态规划。好了，最后我们来学习 Myers 的动态规划算法实现细节，理解了前面的概念，算法的思路就不是特别复杂了。</p>
<h4 id="代码实现">代码实现</h4>
<p>我们用一个二维数 dp 来记录图上的搜索状态：</p>
<p>dp 的第一个维度代表着操作数，最大范围也就是我们最短编辑脚本的长度 m+n-2*LC。第二个维度是 k-Lines 的行号，在操作数为 d 时，其取值范围为[-d,d]，范围的左右边界分别代表了 d 次操作都是只插入不删除，或者只删除不插入。dp 本身的值记录为当前操作数及行号所对应的 x 坐标。</p>
<p>把之前的递推例子过程画到二维表格中大概如下图所示，横轴的数字代表着 D-Path 的 D 也就是操作数，纵轴的数字代表 k-Lines 的行号，树状图中每个节点展示的是网格中的二维坐标也都对应着某个编辑脚本的一部分：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">     |      0     1     2     3     4     5
----+--------------------------------------
    |
 4  |                             7,3
    |                           /
 3  |                       5,2
    |                     /
 2  |                 [3,1]       [7,5]
    |               /     \     /     \
 1  |           [1,0]       [5,4]      [7,6]
    |         /     \           \
 0  |     [0,0]       2,2         5,5
    |         \                       \
-1  |           0,1         4,5         5,6
    |               \     /     \
-2  |                 2,4         4,6
    |                     \
-3  |                       3,6
</code></pre></td></tr></table>
</div>
</div><p>而方括号括起来的路径代表着我们最终选择的路径，也就是之前图里箭头表示的那条路径：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/64/fe/645fe54eff53c9bc46d8ebbcc0a294fe.jpg?wh=1920x1330"
        data-srcset="https://static001.geekbang.org/resource/image/64/fe/645fe54eff53c9bc46d8ebbcc0a294fe.jpg?wh=1920x1330, https://static001.geekbang.org/resource/image/64/fe/645fe54eff53c9bc46d8ebbcc0a294fe.jpg?wh=1920x1330 1.5x, https://static001.geekbang.org/resource/image/64/fe/645fe54eff53c9bc46d8ebbcc0a294fe.jpg?wh=1920x1330 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/64/fe/645fe54eff53c9bc46d8ebbcc0a294fe.jpg?wh=1920x1330"
        title="img" /></p>
<p>我们从左到右、从下到上用两层循环依次更新二维表格。外层循环就是从左往右遍历图上的每一列，内层循环就是从下到上遍历树状图每一层的状态，也就是遍历每一条 line。操作数为 d 时，我们从行号为 -d 开始以步长为 2 遍历，一直遍历到 d。整个树的结构是二叉的，奇数步时，必然处于奇数行号，偶数步时必然处于偶数行号。这是因为从 k-Line 的第 k 条线进行一步 snake，只会有一次删除或者一次插入操作；对应到图上也就是经过一条横线或者一条竖线加若干条斜线，因而只能进入 k+1 行或者 k-1 行，所以每一个操作数对应行号的奇偶性是确定的，遍历的时候步长为 2 也就很好理解了。</p>
<p>所以总结一下就是，行号为 k、操作数为 d 的状态，只能从相邻的两行 k-1 或者 k+1，通过横线或者竖线转移过来。</p>
<p>写成状态转移方程就是 dp[d][k] = max(dp[d-1][k-1]+1，dp[d-1][k+1])。从 k-1 行过来的必然走的是横线，所以状态也就是横坐标 +1，从 k 行转移过来的走的是竖线，状态也就是横坐标会保持不变（动态规划状态不变）。这样，有多个选择的时候，我们会将状态更新为不同路径中最远的，也就是横坐标最大的一个。</p>
<p>思路很清晰，写成伪代码也非常简单啦。如果在某次循环的时候找到了终点，就会停止循环，此时也找到了一种“简明”且最短的编辑脚本，直接 return 就行。由于操作数为 D 的状态数组的计算，仅依赖了操作数为 D-1 的一层状态数组，我们可以将状态维度压缩一下，采用一维数组记录状态。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">V[1]←0 
For D ← 0 to MAX Do
  For k ← −D to D in steps of 2 
    Do If k=−D or k≠D and V[k−1] &lt; V[k+1] Then
      x ← V[k+1] 
    Else
      x ← V[k−1]+1 y ← x−k
    While x &lt; N and y &lt; M and a[x+1] = b[y+1] Do 
      (x,y) ← (x+1,y+1) 
      V[k] ← x
  If x ≥ N and y ≥ M Then
    Length of an SES is D
    Stop
</code></pre></td></tr></table>
</div>
</div><p>最后，我们来计算一下这个算法的时间复杂度，原论文花了许多篇幅在严谨的数学描述上，我们这里就写的简洁些，有兴趣的同学可以自己查阅论文进一步理解。</p>
<p>在内外两层的循环中，每一层循环都循环了 D 次，循环次数最多为总操作步数 <code>D*D</code>。循环体中，除了第 8-10 行的 while，都是 O(1) 的复杂度。所以去掉 8-10 行之后，复杂度为 O(D^2)。8-10 行的代码看似多加了一层复杂度不是常数的循环，但在做的事情就是沿着 Line，在不耗费额外操作的时候，一路沿着 snake 往下拓展，所以整体复杂度加起来不可能超过搜索范围内的所有的长度斜线，而斜线的最大长度为 min(M,N)。那么在循环范围内，8-10 行的操作带来的总的时间复杂度不会超过 O(M+N)。所以算法的整体时间复杂度是 O(D*(M+N))。大部分情况下，D 其实比 M 或者 N 要小许多，所以 Myers 算法在复杂度比 O(MM+NN) 要小很多。</p>
<h3 id="总结">总结</h3>
<p>我们学习了一种高效求文本差分的方式 Myers 算法，基于动态规划的思想和编辑图的抽象，给出了一种复杂度很低又能求出可读性很高的编辑脚本的方法。这个算法被广泛使用在各种需要求文本差分的场景里，如 Git 中的 git-diff、Android 中的 DiffUtil 等。其实，Myers 算法并不是一个非常基础的算法。我会把这篇文章作为专栏的第一篇文章，不止因为这个算法确实非常有趣，能让你提前体验一下用算法来解决实际问题的思维乐趣；更是想告诉你，算法离我们的距离比你想的可能还要更近一些。算法不只存在于各种高大上的基础设施或者艰深的论文里，而会出现在我们程序员日常开发工作中的每个角落，甚至生活的方方面面。只不过我们太习以为常，才忽略了这些算法。所以，很期待在我们并肩探索算法的这段时间里，你能对真实世界中的算法有一个新的认知，并在欣赏它们的过程中提升自己，收获乐趣。</p>
<h2 id="04栈函数调用的秘密究竟是什么">04｜栈：函数调用的秘密究竟是什么？</h2>
<p>栈这个词，相信每一个研发同学在学习编程的过程中都会经常听到。不仅仅是因为栈本身就是一种基础的、常见的数据结构，更因为栈在计算机世界里起着举足轻重的作用。在编程语言中，栈除了作为一种常用的数据结构，也常常用来表示一种叫做“调用栈”的概念，它是编程语言之所以能实现函数调用的关键所在。而在内存分配中，栈也表示一种内存分配的区域，和内存中的堆区是一种相对的概念。</p>
<p>栈区是有结构和固定大小的，区块按照次序存放，每个线程独占一个栈区，总的大小也是事先确定的；而堆区则没有固定的大小，数据可以随意存放。我们常常听到的 stack overflow 错误，也就是栈溢出错误，就是指程序在运行时，存放在栈上的数据已经多于栈区的容量，产生了容量不足的错误。相信说到这，你就更加明白为什么说栈相比于其他数据结构更经常被听到了吧。</p>
<p>其实无论是调用栈还是内存中的栈区，这两种含义都和栈数据结构的 LIFO 特性有关。如果你已经有了充分的背景知识，可以先想想这是为什么？</p>
<p>调用栈里的一个个函数到底是什么呢？我们知道，每个函数都有一个自己的作用域，但不同作用域下的变量可以有相同的变量名。比如在刚才的例子中，avg 和 add 函数中的入参变量名都是 a 和 b，它们互相不影响。这就是因为每个函数都会有一个自己的上下文，而上下文中存放着变量名和值的绑定，不同的上下文是彼此隔离的。</p>
<p>当程序每次执行到一个函数调用的时候，操作系统或者虚拟机就会在栈上分配一块区域，我们称之为栈帧。</p>
<p>简单来说，<strong>栈帧中就存放着函数执行的上下文</strong>。当前计算完成之后，我们就会将执行结果返回，并绑定到上一个栈帧内的变量里，当前栈帧的所有资源也就可以释放了。</p>
<p>这个释放过程，在操作系统或者虚拟机底层，最后都会转化成几个寄存器值的变化，成本非常低廉。事实上，各个语言在实现函数调用的时候都是不约而同地依赖调用栈去实现的，只不过 js 建立在 V8 引擎之上，栈帧里存的就可以是执行上下文，包括了变量和值的绑定等信息；而在 C 语言里可能就直接操作的几个寄存器的值，如 EAX、ESP 等，和具体的 CPU 指令集架构有关。</p>
<p>正是因为每次调用前，我们都有将上下文的信息保留在栈中，调用的计算过程并不会影响到调用前的内存空间，完美地做到了函数调用保留现场的作用；调用完成之后，我们可以延续调用前上下文中的状态，继续进行后续的计算。</p>
<p>在栈上连续的内存分配，以及函数调用完，不会再有其他地方需要函数上下文内变量的特点，让在栈上的内存管理变得简洁而高效。所以可以说，通过使用栈，我们优雅地实现了函数调用这一编程语言中最基础的核心能力。</p>
<p>在栈上连续的内存分配，以及函数调用完函数生命周期就结束，也就是不会再有其他地方需要函数上下文内变量的特点，让在栈上的内存管理变得简洁而高效；释放内存的操作和堆上完全不同，我们只需要直接改变函数栈帧指针的指向即可。所以可以说，通过使用栈，我们优雅地实现了函数调用这一编程语言中最基础的核心能力。</p>
<h2 id="06treemap红黑树真的有那么难吗">06｜TreeMap：红黑树真的有那么难吗？</h2>
<p>试想，如果能够让符号表是有序排列的，我们查找的时候是不是就不用遍历每一个元素，而可以采用二分查找之类的手段了呢？当然也要尽量降低维护这个有序排列的数据结构所花费的代价。那一种常见的用于实现有序集的数据结构就是红黑树，这也是 JDK 中 TreeMap 中 Tree 的意思。如果你有一定的 Java 开发经验，相信你一定会知道相比于 HashMap，基于红黑树的 TreeMap 的一个显著特点就是其维护的键值对是有序排列的。</p>
<p>大部分程序员应该不会有什么机会要手写红黑树，在正经面试中也绝对不会碰到手写红黑树这样的题目，所以我们掌握红黑树的本质和特性就足够了。</p>
<p>二分查找树-》平衡二分查找树-》2-3树-》红黑树</p>
<h3 id="2-3-树">2-3 树</h3>
<p>2-3 树，也是一种平衡查找树的实现，思想很简单，为了让树能更好地平衡自己，我们除了普通的 2 节点之外，还引入了一种 3 节点，这让我们在平衡树高度的时候增大了很大的灵活性。看一个典型的 2-3 树例子。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/af/5a/af78134ab437a4125ecc5363e425fc5a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/af/5a/af78134ab437a4125ecc5363e425fc5a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/af/5a/af78134ab437a4125ecc5363e425fc5a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/af/5a/af78134ab437a4125ecc5363e425fc5a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/af/5a/af78134ab437a4125ecc5363e425fc5a.jpg?wh=1920x1145"
        title="img" /></p>
<p>在 2-3 树中，2 节点，和普通二叉树的节点其实没有什么太大的区别，有一个键和两条链，分别链向左子树和右边子树。而 3 节点，则在 2 节点的基础上增加了一个键，构成了一个有两个键和三条链的结构。下图是 3 节点的示意图，左链链向了小于 a 的节点，右链链向了大于 b 的节点，中间的区域则是 a 和 b 之间的节点。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/dd/5a/dd04351185eed9dba1a711e7971da85a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/dd/5a/dd04351185eed9dba1a711e7971da85a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/dd/5a/dd04351185eed9dba1a711e7971da85a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/dd/5a/dd04351185eed9dba1a711e7971da85a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/dd/5a/dd04351185eed9dba1a711e7971da85a.jpg?wh=1920x1145"
        title="img" /></p>
<p>在 2-3 树中搜索的过程和二叉树并没有太多的区别，只是遇到 3 节点的时候，多判断一次是否介于 a、b 之间即可。设计有了， 我们看插入新元素的时候会发生什么。在插入过程中，当我们查找到了某个叶子结点发现并不存在该键时，如果遇到了 2 节点，非常好办，直接加个键将该节点升级为 3 节点即可。比较麻烦的是遇到了 3 节点，因为我们已经不能再在该节点中直接多加一个键创造一个 4 节点了，怎么办呢？其实办法也不难想，我们把当前的 4 节点多出的键向上转移。看图理解，比如要对下图中的 2-3 树插入 26 节点，那首先会沿着根节点一路查询到“19 24”子结点，发现该节点为一个 3 节点。</p>
<p>那么我们首先将 26 放入该子节点，使之成为一个 4 节点，然后将 4 节点的中间键也就是 24，提升到上一层，将其父节点替换成一个包含 24 的 3 节点。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b0/c4/b013689bfb3bb9495469c1b1fe5e51c4.jpg?wh=1920x1802"
        data-srcset="https://static001.geekbang.org/resource/image/b0/c4/b013689bfb3bb9495469c1b1fe5e51c4.jpg?wh=1920x1802, https://static001.geekbang.org/resource/image/b0/c4/b013689bfb3bb9495469c1b1fe5e51c4.jpg?wh=1920x1802 1.5x, https://static001.geekbang.org/resource/image/b0/c4/b013689bfb3bb9495469c1b1fe5e51c4.jpg?wh=1920x1802 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b0/c4/b013689bfb3bb9495469c1b1fe5e51c4.jpg?wh=1920x1802"
        title="img" /></p>
<p>如果原父节点也是一个 3 节点的话，我们就递归进行同样的操作直至根节点。最后，如果根节点也是一个 3 节点，我们就将根节点的中键提升到第一层，然后左右链分别链向原来根节点的左键和右键。以下图为例，b 键就被独立地提升为新的根节点，左右节点指向 a 和 c，而原 4 节点的中间两个链也分别成为 a 的右链和 c 的左链。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/77/78/777e31ed4873f9dfb45a705204a7ef78.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/77/78/777e31ed4873f9dfb45a705204a7ef78.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/77/78/777e31ed4873f9dfb45a705204a7ef78.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/77/78/777e31ed4873f9dfb45a705204a7ef78.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/77/78/777e31ed4873f9dfb45a705204a7ef78.jpg?wh=1920x1145"
        title="img" /></p>
<p>这样的操作可以保证整个 2-3 Tree 是一个真正意义上的平衡树。但是，因为它的实现引入了两种异构的节点，导致代码写起来相当复杂，并没有被广泛使用。</p>
<p>而红黑树，正是采用标准的二叉查找树节点附着上额外的颜色信息来表示 2-3 树的实现，每一个红色节点都和它的父亲节点一起，构成了一个 3 节点的模拟，这就是红黑树设计的本质。</p>
<h3 id="红黑树">红黑树</h3>
<p>所以，我们再把红黑树的定义拿出来，红黑树是一个满足下述几个约束且所有节点要么为红色要么为黑色的二分有序查找树：</p>
<p>根节点为黑色
相邻的节点不能同时为红色
每个节点从自身到各个能到达的叶子结点的所有路径中的黑色节点数量相等
红节点只能作为左子节点存在（这是左偏红黑树特有的要求，我们以左偏红黑树为例讲解）</p>
<p>所有这些约束，都是为了保证每一颗红黑树和 2-3 Tree 是一一对应的，相信你看下面这颗“展平”的红黑树就能理解我在说什么了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/e3/84/e366b0ed2775a57ca6d73261fa3cd284.jpg?wh=1920x1178"
        data-srcset="https://static001.geekbang.org/resource/image/e3/84/e366b0ed2775a57ca6d73261fa3cd284.jpg?wh=1920x1178, https://static001.geekbang.org/resource/image/e3/84/e366b0ed2775a57ca6d73261fa3cd284.jpg?wh=1920x1178 1.5x, https://static001.geekbang.org/resource/image/e3/84/e366b0ed2775a57ca6d73261fa3cd284.jpg?wh=1920x1178 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/e3/84/e366b0ed2775a57ca6d73261fa3cd284.jpg?wh=1920x1178"
        title="img" /></p>
<p>我们一起顺一下。一个 3 节点有两个键、三条链，那我们完全可以把一个以红节点为左子节点的黑节点和子节点一起看成一个 3 节点。在下图中，上下两个图其实就可以认为是等价的。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/85/5a/8540e5be9f98b273c2808154e96e575a.jpg?wh=1920x1178"
        data-srcset="https://static001.geekbang.org/resource/image/85/5a/8540e5be9f98b273c2808154e96e575a.jpg?wh=1920x1178, https://static001.geekbang.org/resource/image/85/5a/8540e5be9f98b273c2808154e96e575a.jpg?wh=1920x1178 1.5x, https://static001.geekbang.org/resource/image/85/5a/8540e5be9f98b273c2808154e96e575a.jpg?wh=1920x1178 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/85/5a/8540e5be9f98b273c2808154e96e575a.jpg?wh=1920x1178"
        title="img" /></p>
<p>我们再来看红黑树的 3 个普遍约束，你会发现很好理解：因为红色节点只是 3 节点的一部分，那对应到红黑树上，显然不会出现两个连续的红色结点；2-3 树上，每个节点到叶子节点的数量一定是一样的，且每个节点对应到红黑树上一定包含且只包含一个黑色节点，所以红黑树每个节点到叶子结点路径中的黑色节点数量也必然是一样的。</p>
<p><strong>唯一不一样的就是“根节点为黑色”。事实上，如果只是为了让红黑树保持平衡，我们完全可以抛弃这条规则。因为在 2-3 树中，我们也完全是可以用 3 节点作为根节点的。</strong></p>
<p>对应到红黑树中，当根节点为红色，插入新节点后很可能为了使根节点到每条路径上的黑色节点数量相等，进行变色和旋转操作，最终根节点还是会变成黑色；既然如此，我们何不直接约束根节点必须调整成黑色，方便进行插入操作呢。这样，我们就可以将每一个红黑树都映射成一个 2-3 树，也因此就获得了 2-3 树高效的平衡插入的能力，并保留了二叉树查找的简洁性。之后在理解红黑树的时候，如果你能时刻展平成 2-3 树看待，一定会觉得，哦，红黑树的实现其实也没有想象中的那么困难。最后，我们来看一些红黑树的基本操作，帮助你更好地理解红黑树和 2-3 树之间的关系。</p>
<h3 id="旋转操作的实现">旋转操作的实现</h3>
<p>红黑树的所有实现细节，其实也都是围绕着 2-3 树的 2、3 节点的诞生和转移展开的，我们就以“插入方法”的实现来具体讨论（仍以左偏红黑树为例）。红黑树中最基本的自平衡操作就是“旋转”，分为“左旋”和“右旋”两种。这两种操作主要用于处理在插入和删除时产生的右偏红节点或者连续的两个红色节点，通过调整红节点的位置，我们可以修复这些不满足约束的情况。</p>
<p>看“左旋”和“右旋”的具体操作。以左旋为例，本质上就是将某个 3 节点从以较小的键为根转移成较大的键为根，也就是从 a 为根转到 b 为根，当然同时需要把介于 a 和 b 之间的节点挂到 a 的右节点下。这样得到的新树就是以 b 为根结点的结构，并且在整个过程中，树的平衡性和有序性都没有被破坏，而原来不符合约束的右偏红节点已经被转移成“正确”的左偏红节点。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b1/ee/b1f41e08df595b65a68bdc89219810ee.jpg?wh=1920x1178"
        data-srcset="https://static001.geekbang.org/resource/image/b1/ee/b1f41e08df595b65a68bdc89219810ee.jpg?wh=1920x1178, https://static001.geekbang.org/resource/image/b1/ee/b1f41e08df595b65a68bdc89219810ee.jpg?wh=1920x1178 1.5x, https://static001.geekbang.org/resource/image/b1/ee/b1f41e08df595b65a68bdc89219810ee.jpg?wh=1920x1178 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b1/ee/b1f41e08df595b65a68bdc89219810ee.jpg?wh=1920x1178"
        title="img" /></p>
<p>现在，我们根据插入时是在“2 节点”还是“3 节点”分开讨论，看看旋转操作具体是如何用于保证约束正确的。</p>
<h4 id="2-节点插入">2 节点插入</h4>
<p>首先我们来看针对“2 节点”的插入，对应到红黑树的语境中，也就是针对普通黑色节点的插入。那显然只有两种情况，要么插入在左边，要么插入在右边。如果插入在左边，非常简单，我们可以直接将 2 节点提升为 3 节点，由于新增的是左侧的红节点，完全不会破坏树的平衡性。对应到红黑树上，就是简单地将新节点放到查找到的最后一个节点的左边。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/05/9e/0501b4d74b3e3678ac6981dbe0a85d9e.jpg?wh=1920x1178"
        data-srcset="https://static001.geekbang.org/resource/image/05/9e/0501b4d74b3e3678ac6981dbe0a85d9e.jpg?wh=1920x1178, https://static001.geekbang.org/resource/image/05/9e/0501b4d74b3e3678ac6981dbe0a85d9e.jpg?wh=1920x1178 1.5x, https://static001.geekbang.org/resource/image/05/9e/0501b4d74b3e3678ac6981dbe0a85d9e.jpg?wh=1920x1178 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/05/9e/0501b4d74b3e3678ac6981dbe0a85d9e.jpg?wh=1920x1178"
        title="img" /></p>
<p>如果插入在右边，其实是一样的，我们也将 2 节点提升成一个不符合“左偏”规则的 3 节点，然后进行一次左旋转即可。由于插入的也是红节点，并不影响树的平衡性。</p>
<h4 id="3-节点插入">3 节点插入</h4>
<p>再看插入“3 节点”，情况和操作都会复杂一些，我们根据插入的结点在 3 节点中左键的左侧、右键的右侧和两者之间分开讨论（还是左偏红黑树）。最简单的情况就是插入在右键的右侧。和 3 节点分解的方式一样，我们只需要把中间的结点提升到上一层，并左右节点变成黑色即可。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/1a/05/1aefc7f659ab42a26dc9c16bf667c705.jpg?wh=1920x1202"
        data-srcset="https://static001.geekbang.org/resource/image/1a/05/1aefc7f659ab42a26dc9c16bf667c705.jpg?wh=1920x1202, https://static001.geekbang.org/resource/image/1a/05/1aefc7f659ab42a26dc9c16bf667c705.jpg?wh=1920x1202 1.5x, https://static001.geekbang.org/resource/image/1a/05/1aefc7f659ab42a26dc9c16bf667c705.jpg?wh=1920x1202 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/1a/05/1aefc7f659ab42a26dc9c16bf667c705.jpg?wh=1920x1202"
        title="img" /></p>
<p>而另外两种情况单独看这一个节点的变化，也并不复杂，只需要插入后进行一到两次旋转操作即可。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/8a/97/8ae588c2715465299e07c0fd55fe8197.jpg?wh=1920x1389"
        data-srcset="https://static001.geekbang.org/resource/image/8a/97/8ae588c2715465299e07c0fd55fe8197.jpg?wh=1920x1389, https://static001.geekbang.org/resource/image/8a/97/8ae588c2715465299e07c0fd55fe8197.jpg?wh=1920x1389 1.5x, https://static001.geekbang.org/resource/image/8a/97/8ae588c2715465299e07c0fd55fe8197.jpg?wh=1920x1389 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/8a/97/8ae588c2715465299e07c0fd55fe8197.jpg?wh=1920x1389"
        title="img" /></p>
<p>但这样是不是就完成了所有操作呢？ 并不是。还有一个很大的问题我们没有处理，就是对 3 节点的操作中，我们虽然保证了“插入操作”对当前子树的“平衡性”没有被破坏，但由于将红色节点变成了黑色，就有可能导致当前子树的黑色节点高度比其他子树高了。所以我们还需要进行一种叫做“颜色反转”的操作。</p>
<p>每次插入时，最后一步，除了将 3 节点的左右节点都变成黑色，同时要将 3 节点的中间键变成红色，这样当前子树到各个子节点路径中的黑色节点数量就不会有变化啦。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/7c/9d/7ced30d3d05f55c832a88891cedbbf9d.jpg?wh=1920x1178"
        data-srcset="https://static001.geekbang.org/resource/image/7c/9d/7ced30d3d05f55c832a88891cedbbf9d.jpg?wh=1920x1178, https://static001.geekbang.org/resource/image/7c/9d/7ced30d3d05f55c832a88891cedbbf9d.jpg?wh=1920x1178 1.5x, https://static001.geekbang.org/resource/image/7c/9d/7ced30d3d05f55c832a88891cedbbf9d.jpg?wh=1920x1178 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/7c/9d/7ced30d3d05f55c832a88891cedbbf9d.jpg?wh=1920x1178"
        title="img" /></p>
<p>当然这个操作是需要递归进行的。因为父节点如果变成红色，也同样可能造成右偏红节点或者连续红节点这样不符合约束的情况，这其实等价于在父节点的父节点下插入了一个新的红节点。我们用类似的逻辑自下而上递归即可，递归的终点就是，遇到根节点我们将其拆分成 3 个“2 节点”，或者遇到某个 2 节点我们将其升级为“3 节点”时，我们就可以结束递归。</p>
<p>讨论好这些 case，我们就可以在整个插入节点的过程中保证不破坏“有序性”和“平衡性”了。</p>
<p>删除的操作和插入类似，感兴趣的话，你可以课后自己通过纸笔模拟一下。整个过程确实比较复杂，许多细节过一段时间可能也会有所遗忘，不过只要你理解了红黑树的本质，是在二叉树基础上对“2-3 Tree”的实现，一定能迅速回忆起红黑树的约束条件。到这里，无论是准备面试，还是帮助你了解许多用到红黑树的中间件源码来说，都已经绰绰有余了。</p>
<h3 id="操作红黑树的复杂度">操作红黑树的复杂度</h3>
<p>最后我们来稍微计算一下红黑树上检索数据的复杂度。前面我们提到，二叉搜索树检索键的最差时间复杂度取决于树的最大高度，是 O(logN)，那求红黑树上检索数据的时间复杂度就等同于求红黑树的最大高度了。我们将一个红黑树展平，并对应到 2-3 树。2-3 树是一颗平衡的树，由于每个节点只可能比二叉树多出一个键，在相同的高度下只会承载更多的元素，所以其高度不可能高于二叉平衡树的高度 logN。而红黑树只是把 2-3 树的每个“3- 节点”拆成了一黑一红两个节点，其高度不可能比 2-3 树的最大高度翻倍还多；当然你也可以从“红色节点不能相邻”这一约束得出类似的结论，毕竟本质这两者是等价的。所以，满足这样约束的红黑树的最大高度最多也就是 2*logN，因此可以得到良好的 O(logN) 的查询复杂度。插入、删除复杂度显然也只和高度有关，我们最多需要进行常数倍于树的最大深度次旋转和颜色反转操作，所以复杂度也是 O(logN)。</p>
<h2 id="07堆如何实现一个高效的优先队列">07｜堆：如何实现一个高效的优先队列？</h2>
<p>比如，一种比较暴力的思路可以是：我们依旧用线性容器存储元素。在入队的时候，我们不关心优先级的影响直接按顺序存入容器中，出队的时候，则遍历容器找到最高优先级的元素出队。由于入队的时候没有对优先级做任何处理，所以出队的元素显然可能在线性容器中任意一个位置，基于之前所学的知识，遇到节点删除的场景，用链表显然比用动态数组有更好的时间复杂度。但即使如此，每次出队时我们也需要遍历链表，所以时间复杂度为 O(N)。</p>
<p>那与之相对的，另一种同样基于链表的思路也可以是，我们每次在入队的时候进行一些额外的调整，使得整个队列一直满足优先级更高的元素在更前面的约束，这样出队的时候就比较简单。当然这样会导致入队的时候都需要进行一次类似于插入排序的操作，最差情况下也会要遍历完整个链表，时间复杂度同样为 O(N)。</p>
<p>那有没有一种入队和出队都相对来说比较高效的方式呢？答案是肯定的，只是我们需要抛弃线性的存储结构。</p>
<p>红黑树当然是可以用来实现优先级队列的一种方式，我们建红黑树的时候以优先级为 key 作为排序依据即可。入队的时候可以直接 push 入队，出队 pop 的时候先从树中找到优先级高的，也就是树的最右节点，然后移除即可。这些操作的复杂度都是 O(logN)，所以出队和入队的复杂度自然也就是 O(logN)。所以，基于红黑树的优先队列复杂度均摊下来，相比于之前基于线性表的 O(N) 复杂度，显然更胜一筹。</p>
<p>但是由于我们不会进行类似“找出优先级第 3 高的元素出队”这样的操作，其实并不需要一直维护完全的顺序信息，只是需要能在每次出队时，找到优先级最高的元素即可。那有没有更合适的选择呢？</p>
<p>相比复杂的红黑树，简明的“二叉堆”就是这样一种特别适合用来动态维护一组元素中最大或者最小值的数据结构，它也是各大语言实现优先级队列的首选。</p>
<h3 id="二叉堆">二叉堆</h3>
<p>二叉堆，这个数据结构是 1964 年斯坦福大学教授 Robert W．Floyd 和 J．Williams 在发明堆排序的时候提出，之所以想介绍一下它的历史，主要是因为 Robert W．Floyd 是一个文科出生，后来自学计算机科学，逆袭成为斯坦福终身教授的大佬。我想这多多少少能证明热爱的力量，也能给可能是非科班出身的你我一些信心吧。</p>
<p>“二叉堆”，也就是 binary heap，顾名思义，这个数据结构也是建立在一种特别的二叉树上的。它主要有两个约束：</p>
<p>二叉堆是一颗满二叉树。也就是说，除了最后一层外的每一层都没有空节点，且最后一层所有节点靠左排列，不存在从左到右中间有某些节点为空。
二叉堆中的每个节点和其子节点都有一样的偏序关系，要么大于要么小于，这两种情况分别对应大顶堆和小顶堆。所以大顶堆就要求堆中所有节点的值，一定大于其左右子树中的任何一个节点的值，也就是说顶部的节点一定是最大的，故称为大顶堆。小顶堆就正好相反。</p>
<p>有了这样的约束，可以保证根节点要么是最大的要么是最小的，也让我们在出队入队的操作里调整的成本很小，整个过程有点像冒泡排序的感觉，我们马上讲解具体的细节。</p>
<p>为了实现优先级队列，我们会用优先级，priority，来作为二叉堆节点间大小比较的依据。假设我们始终希望出队的是优先级更高的元素，那可以采用大顶堆作为优先队列的底层实现，这样每次只需要从顶部取出元素即可获得优先级最高的元素。</p>
<p>当然很重要的一点是，取出元素后显然会在树的顶部产生一个空位，我们需要进行一定的操作使得大顶堆的性质得以保全。同样，为了享受直接从顶部取出优先级最高元素的便利，我们在插入元素时也要让二叉堆的性质得以保持。</p>
<p><strong>幸运的是，正是因为二叉树是一个满二叉树，其高度约等于 LogN，其中 N 为优先队列中元素的个数。而第二条约束父子节点之间的有序关系，让我们每次做 pop 和 push 操作，只需要经过最多二叉树高度次的交换调整即可保持堆的所有特性。</strong></p>
<p>这样，我们就得到了一个入队和出队操作复杂度都为 O(LogN) 的数据结构，虽然均摊的时间复杂度和红黑树是一样的，但实现的难度却要小很多，……</p>
<h2 id="基础算法篇">基础算法篇</h2>
<h2 id="08外部排序如何为tb级数据排序">08｜外部排序：如何为TB级数据排序？</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/29/b7/29c48a9fc247438d6c94ffdf3b43a6b7.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/29/b7/29c48a9fc247438d6c94ffdf3b43a6b7.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/29/b7/29c48a9fc247438d6c94ffdf3b43a6b7.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/29/b7/29c48a9fc247438d6c94ffdf3b43a6b7.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/29/b7/29c48a9fc247438d6c94ffdf3b43a6b7.jpg?wh=1920x1145"
        title="img" /></p>
<p>O(n^2) 的选择排序、冒泡排序、插入排序，这些常用的算法相信你应该非常熟练了；几种 O(n) 的算法在工程中其实也都有实际应用，你也可以自己在网上搜索资料了解学习，最好再找几道相关算法题做一做加深印象。O(nlogn) 的三个常见算法从概念上看也不难理解，但细节实现起来还是有一些复杂度，需要花点时间刻意练习，是面试中相对重要的算法考点。</p>
<p>其中归并排序和快速排序的常用写法都可以采用递归的方式实现，背后是分治的算法思想，也就是分而治之，把大问题递归拆小然后递归得出结果。</p>
<p>而堆排序的思路和实现，在上一讲优先队列中我们详细讲过，相信你现在应该很容易用 Java 的 PriorityQueue 实现堆排序，主要思路其实就是建立一个堆，借助堆动态调整的能力，只需要将所有待排序元素依次入队，再依次出队直到堆元素全部出队为止；比如在小顶堆中，每次出队的都是当前最小的元素。</p>
<p><strong>但只是能写出这样的排序代码，往往并不足以让你解决真实世界的工程问题。</strong></p>
<p>比如有这样一个基于真实场景的经典面试题：假设现在有 1TB 的任意文本，请问如何能将其中出现的单词按照字母序排列，得到一个新的文本？</p>
<p>你也许会觉得很简单呀。我们就直接用堆排序，建立一个小顶堆，然后遍历整个文本进行分词，将每个单词都依次 push 进堆，最后再逐一出队输出到一个文本，最后就可以得到一个按字典序升序排列的文本了。</p>
<p><strong>这当然是一个正确的思路，但是，你忽略了一个至关重要的问题，就是我们的内存可能没有这么大！</strong></p>
<p>在实际工作中，我们经常会遇到内存中放不下所有数据的排序场景。</p>
<p>早期可能因为内存的容量确实很小，而现在更多是因为我们需要存储的数据越来越大了，甚至不只是内存放不下，单机的硬盘可能也不够了，需要考虑分布式环境下的排序问题，比如在一个分布式数据库中进行超大表的order by操作，这往往需要花费几分钟甚至几小时的运算才能完成。</p>
<h3 id="tb-级数据排序">TB 级数据排序</h3>
<p>这个经典的算法问题我们一般称之为外部排序，这里的“外”指的其实就是外部存储的意思。</p>
<p>读写较慢的外存，相比快速但昂贵的内存而言，有着更低廉的成本，通常是硬盘，它可以存放更大的数据。当我们不能直接在内存中进行排序，而需要借助外存去处理极大量数据的排序时，就需要使用外部排序算法了。</p>
<p>如果遇到这样的面试题，首先可以来向面试官确认一下已有的硬件环境，比如面试官可能会告诉你，你现在有 1GB 的内存可用。那么我们知道整个 1TB 的文件，至少要读 1024 次才能遍历一遍，所以直接在内存里排序显然是不现实的。</p>
<p>但是文件其实是可以一部分一部分读的，如果内存中一次放不下全部的数据，也许我们可以将文件分成若干段，分别读入内存中，并采用常见的内排序算法（比如堆排序），对这段可以在内存中存储的段落进行排序；得到若干个有序的文件段后，最后通过一些合并的方式，得到整体有序的文件。</p>
<p>当然在这个过程里会有大量的中间结果，比如那些有序的文件片段，这些我们都需要借助外存存储，这个思路就是最常见的一种外部排序的方式。其实你会发现我们刚刚描述的想法和归并排序如出一辙，归并排序也是常用的外排实现方式，只不过我们在学习它的时候，一般都是针对数组，也就是在内存中排序的场景。</p>
<h3 id="外部排序">外部排序</h3>
<p>好我们用严谨的语言来重新描述一下基于归并思想的外排过程，整体分为两个阶段：</p>
<p>部分排序阶段我们根据内存大小，将待排序的文件拆成多个部分，使得每个部分都是足以存入内存中的。然后选择合适的内排序算法，将多个文件部分排序，并输出到容量可以更大的外存临时文件中，每个临时文件都是有序排列的，我们将其称之为一个“顺段”。</p>
<p>归并阶段我们对前面的多个“顺段”进行合并，思想和归并排序其实是一样的。以 2 路归并为例，每次都将两个连续的顺段合并成一个更大的顺段。</p>
<p>因为内存限制，每次可能只能读入两个顺段的部分内容，所以我们需要一部分一部分读入，在内存里将可以确定顺序的部分排列，并输出到外存里的文件中，不断重复这个过程，直至两个顺段被完整遍历。这样经过多层的归并之后，最终会得到一个完整的顺序文件。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/ed/ce/ed5c8cfa170455d8a8ff4c3c736a0fce.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/ed/ce/ed5c8cfa170455d8a8ff4c3c736a0fce.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/ed/ce/ed5c8cfa170455d8a8ff4c3c736a0fce.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/ed/ce/ed5c8cfa170455d8a8ff4c3c736a0fce.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/ed/ce/ed5c8cfa170455d8a8ff4c3c736a0fce.jpg?wh=1920x1145"
        title="img" /></p>
<p>假设现在有含有 1000 个记录的文件，而内存最多只能读取 100 个记录。那么我们要做的第一步就是先把 1000 个记录拆成十个文件，每个文件有 100 个记录，读入后在内存中排序得到 10 个有序的临时文件，并输出到外存也就是硬盘中。然后我们进行多次归并操作，每次都把相邻的文件合并。在这个例子中可以看到只需要进行 4 轮归并，就得到了一个最终有序的文件。</p>
<h4 id="运行时间">运行时间</h4>
<p>那整个过程里，运行时间主要和哪些因素有关呢？在第一个阶段部分排序中，由于内存可以装下每个顺段的所有元素，所以几种主流的 O(nlogn) 的算法都是可以的，其中快速排序在大部分场景下是最快的，因此我们可以首选快速排序。</p>
<p>比较复杂的是归并阶段。因为内存不足以装下所有需要排序的元素，所以 O(nlogn) 的堆排和快排都已经没办法被应用在外排的场景中了，但基于分治思想的归并排序却依然可以很好地发挥作用。</p>
<p>而且相比很多其他排序方式比如选择排序、冒泡排序，归并排序 O(nlogn) 的复杂度已经是理论上相当好的复杂度了。当然在一些特定场景下我们也可以用一些线性排序算法比如桶排序来解决外部排序问题，感兴趣的同学可以自己搜索了解一下。</p>
<p><strong>但是和内排中的归并排序不同，外部排序场景下，我们还有个非常大的时间消耗就是 IO，也就是输入输出。</strong></p>
<p>相比内存中的读写操作，在磁盘中的读写是一个慢得多的过程，两者之间可能有千倍以上的时间开销差距。所以考虑外排效率时，非常重要的一点就是我们要尽量减少从磁盘中读取数据的耗时，而这主要关系要访问多少次外存。</p>
<p>那我们在外存中需要读取多少次数据呢？从图中其实可以看出来，每一层我们读取外存的数据总量其实是一样的，本质上就是将所有的数据都遍历一遍。</p>
<p>而内存大小是一样的，所以每一层中读取外存的次数也就是一样的，那么显然关系我们读取次数的多少主要就取决于所需归并的层数了。因此，<strong>我们要做的事情就是让归并的层数越低越好。</strong></p>
<h3 id="如何降低归并层数">如何降低归并层数</h3>
<p>我们先算出归并层数，以 2 路归并为例，每次合并两个连续的顺段，如果上一层有 n 个顺段，到下一层就会有 n/2 个顺段，每一层的顺段都会减少一半，直至只剩一个顺段，也就是需要的排序结果。因而，假设初始一共有 n 个顺段，那么我们大致需要 log2n 层。</p>
<p>同样的道理，如果进行 k 路归并，每一层的顺段数量都会变成上一层的 1/k，所以就大概只需要 logk(n) 层即可完成整个归并。比如一个 5 路归并的例子。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/36/42/3660c083db7a5e190822yy66ff37cb42.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/36/42/3660c083db7a5e190822yy66ff37cb42.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/36/42/3660c083db7a5e190822yy66ff37cb42.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/36/42/3660c083db7a5e190822yy66ff37cb42.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/36/42/3660c083db7a5e190822yy66ff37cb42.jpg?wh=1920x1145"
        title="img" /></p>
<p>所以，为了增加归并路数，也就是尽量增加 k。另外为了降低初始 n 个顺段的数量，我们会做的事情也很简单，就是在第一次进行逐段内排序的时候尽可能多地将数据读入内存中并进行内排。</p>
<p><strong>但是增加 k 的大小，其实也会导致每次归并的时候合并的成本变大，一个显著的问题就是在 k 路归并中，我们需要从 k 个元素中选择出最小的元素，代价比 2 路归并的更高。如果用最暴力的方式，遍历 k 个元素，每次选择最小的元素的过程将产生 O(k) 的时间复杂度，这一定程度上会抵消前面通过增加 k 减少磁盘 IO 所带来的时间提升。</strong></p>
<p>但是我们仔细想想这个问题，选择 k 个元素中的最小元素，显然有优于暴力遍历 O(k) 复杂度的算法。比如，上一讲介绍的堆就可以解决这个问题。而败者树，则是解决从 k 个元素中选取最小元素并可以动态更新的另一种方法，也是更广泛运用于多路归并中的算法，我们来学习一下它的思路。</p>
<h3 id="败者树">败者树</h3>
<p>败者树也被称为，淘汰赛树，也就是 Tournament Tree，思想来自体育比赛。我们知道在淘汰赛中，每一场比赛都有两个参与者，其中胜者可以晋级下一轮。整体可以画成一颗树的形状，如果看过足球比赛，相信你对这个图一点也不陌生。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/97/e8/97c53873407010835d7ee108225085e8.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/97/e8/97c53873407010835d7ee108225085e8.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/97/e8/97c53873407010835d7ee108225085e8.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/97/e8/97c53873407010835d7ee108225085e8.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/97/e8/97c53873407010835d7ee108225085e8.jpg?wh=1920x1145"
        title="img" /></p>
<p>败者树算法就是基于这一思想实现的，我们用叶子节点存储所有待比较的元素，对叶子结点两两比赛，在它们共同的父节点中存储失败者；然后对获胜者节点再两两比较，得到更上一层的败者，取出胜者继续往上比较，这个过程和归并的思路其实也是比较相似的；这样一层一层往上比较，最后就可以得到一颗锦标赛状的树。</p>
<p>因为除了叶子结点外的每一层的父节点存储的都是其子节点中的失败者，所以我们称其为败者树。根节点我们会稍微做一点特别的处理，除了在根结点存储失败者，同时，我们在根节点之上会悬挂上整棵树的最终获胜者。</p>
<p>我们可以给刚刚的例子画出对应的败者树，大概就是下面这个图的样子。其中根节点上的方框存储的就是整个树的胜者，也就是 1，它一定是所有元素中的最小值，和锦标赛的冠军是一个意思。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/af/20/afaf8cd198861999f23a45f65e2bc620.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/af/20/afaf8cd198861999f23a45f65e2bc620.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/af/20/afaf8cd198861999f23a45f65e2bc620.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/af/20/afaf8cd198861999f23a45f65e2bc620.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/af/20/afaf8cd198861999f23a45f65e2bc620.jpg?wh=1920x1145"
        title="img" /></p>
<p>和堆一样，我们也会需要对败者树进行类似于出队的操作；在上面的例子中，就是我们需要将 1 从败者树中取出，寻找下一个最小的元素。</p>
<p>这里有两种情况，一种是我们取出 1 之后，用一个新的元素替代 1，另一种就是取出 1 之后不再添加新的元素，分别对应某一路元素被取出之后仍有元素未取完，和该路元素已经全部取出的情况。在这两种情况中，我们其实都只需要对整个树重新比赛一次即可，只是在第二种情况里，我们会用一个无限大的数字替换 1，因为无限大的数字一定不会在这次重赛中胜出。</p>
<p>我们用一个具体的例子来讲解一下这个过程，假设取出 1 之后，我们用 8 来替换 1 原来的位置。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/c6/2b/c686d1ae17e65d09a6d2d0ebd1a6642b.jpg?wh=4162x3211"
        data-srcset="https://static001.geekbang.org/resource/image/c6/2b/c686d1ae17e65d09a6d2d0ebd1a6642b.jpg?wh=4162x3211, https://static001.geekbang.org/resource/image/c6/2b/c686d1ae17e65d09a6d2d0ebd1a6642b.jpg?wh=4162x3211 1.5x, https://static001.geekbang.org/resource/image/c6/2b/c686d1ae17e65d09a6d2d0ebd1a6642b.jpg?wh=4162x3211 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/c6/2b/c686d1ae17e65d09a6d2d0ebd1a6642b.jpg?wh=4162x3211"
        title="img" /></p>
<p>由于每个父节点存储的都是两个子节点中的失败者，所以我们只要用更新的值和父节点的值比较，也就是和之前两个子节点中的失败者比较。</p>
<p>因为原来的获胜者已经被取走了，这里的父节点现在存储的其实就是这颗子树中原来的亚军，如果我们要看这次新来的选手能否能成为新的冠军，只需要和原来的亚军进行一次比较即可；当然这次比较结束后，两者中的胜者还需要到更上一层继续比较。</p>
<p>这个过程和运动员从市队、省队一路选拔到国家队参加奥运会的过程也是颇为神似的，希望这个例子能帮助你更好地理解败者树的工作机制。整个过程写成伪代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">// 定义节点的value为具体的值；index为每一路数据的索引
// 用index.next可以取到每一路某个元素的后继元素。

function merge(L1, …, Ln)
    buildTree(heads of L1, …, Ln)
    while tree has elements
        winner := tree.winner
        output winner.value
        new := winner.index.next
        replayGames(winner, new) // Replacement selection

function replayGames(node, new)
    loser, winner := playGame(node, new) // 比较新节点和老节点的大小
    node.value := loser.value // 当前节点记录为比较中失败的节点
    node.index := loser.index
    if node != root
        replayGames(node.parent, winner) // 胜者跟父节点继续比较

function buildTree(elements)
    nextLayer := new Array()
    while elements not empty // 自下而上而上建树
        el1 := elements.take()
        el2 := elements.take()
        loser, winner := playGame(el1, el2) // 两两比较
        parent := new Node(el1, el2, loser) 
        nextLayer.add(parent) // 将获胜者放入上一层 继续
    if nextLayer.size == 1 // 只有根节点 直接返回即可
        return nextLayer 
    else
        return buildTree(nextLayer)
</code></pre></td></tr></table>
</div>
</div><h3 id="时间复杂度">时间复杂度</h3>
<p>最后我们来分析一下败者树的整体时间复杂度，我们假设一共有 k 个节点。首先，初始化的过程需要花费 O(k) 的时间，因为对于 k 个子节点，一共只需要进行 k-1 场比赛即可完成淘汰赛。然后在归并排序的每一次合并中，只需要进行 replay 操作，从新元素到根路径上逐一重赛。在每一层中，只需要进行一次比较。由于树是平衡的，从叶子结点到根路径仅包含 O(logk) 元素（这里高度的计算和之前讲解堆的推导是差不多的，你可以复习之前的章节）。所以，总的时间复杂度为 O(klog k) 。现在有了败者树的加持，多路归并排序就可以比较高效地解决外部排序的问题了。对于 1TB 任意文本的排序问题，大致思路就是：</p>
<ul>
<li>先用内排序算法，尽可能多的加载源文件，将其变成 n 个有序顺段。</li>
<li>在内存有限的前提下每 k 个文件为一组，每次流式地从各个文件中读取一个单词，借助败者树选出字典序最低的一个，输出到文件中，这样就可以将 k 个顺段合并到一个顺段中了；反复执行这样的操作，直至所有顺段被归并到同一个顺段。</li>
</ul>
<p>这里稍微补充一下，看起来我们每次从文件中只读取了一个单词，但操作系统在读文件的时候是会按页为单位读取并缓存下来的，所以某一次磁盘访问之后的若干次访问，其实都会直接命中 cache，也就是说，并不是每次从败者树中取出元素时都会真的产生磁盘 IO，请不用担心。</p>
<p>当然在工业级实现中肯定还是有很多优化空间的。比如待合并的文件比较大的时候，我们可以利用二分搜索对文件进行分段，并行地合并，相关研究也比较多，感兴趣你可以自行搜索了解。</p>
<h3 id="总结-1">总结</h3>
<p>随着互联网的发展，数据量一直在稳步的提升，许多算法问题都不能只简单地考虑内存中可以存储，甚至单机磁盘可以存储的情况了。相信我们今天学习的外排算法思想，一定会给你一些解决此类问题的启发，希望你可以举一反三在实际生产中也能将算法更好地运用在有各种限制的真实环境中。</p>
<p>借鉴内排中归并排序的想法，我们可以实现一个多路归并的外排算法，解决内存空间不足的问题。但也因为涉及外部存储，需要重点考虑 IO 的成本。通过尽可能多地利用内存中的排序，得到尽量少的初始顺段，以及选择合适的多路归并参数，我们就可以做到外存访问次数尽量少了。</p>
<p>多路归并，可以通过堆或者败者树实现，这里我也给你贴一道力扣上的<a href="https://leetcode.cn/problems/merge-k-sorted-lists/" target="_blank" rel="noopener noreffer">算法题</a>供你练习。</p>
<h2 id="10搜索算法-一起来写一个简单的爬虫">10｜搜索算法： 一起来写一个简单的爬虫？</h2>
<p>讲一讲平时常用的广度优先搜索算法 BFS 和深度优先搜索算法 DFS。</p>
<p>它们是两种最常见的暴力搜索算法，在面试中也相当常见，前者的实现需要用到我们之前讲解的队列这一数据结构，后者则是递归思想最常用的场景之一。在工程中它们也发挥着巨大的作用。比如，DFS 在前端开发中 DOM 树相关的操作里就非常常见，我们可以用它来实现对 DOM 树的遍历，从而对比两颗 DOM 树的差异，这就是 React 中虚拟 DOM 树算法的关键点之一。</p>
<h3 id="bfs-和-dfs">BFS 和 DFS</h3>
<p>BFS 和 DFS，作为两种最暴力、也相当常用的搜索策略，最大的特点就是无差别地去遍历搜索空间的每一种情况，因此但凡是可以抽象成图上的问题，基本上都可以考虑用 BFS、DFS 去做。只不过效率可能不是最优的，所以我们也常常称之为暴力搜索算法，在各大刷题网站题解区中，你应该常常能见到“暴搜”这样的关键词，说的一般就是 DFS 和 BFS 这两种算法。</p>
<p>所以，在爬虫这样本来就需要无差别遍历全部空间的场景下可以说是非常合适的了。至于 DFS 和 BFS 具体选择哪一种，我们可以结合一个具体的爬虫场景来分析。如果让你手写一个爬虫，从豆瓣上爬取一个用户关注的所有用户，是不是很简单？只要直接遍历某个用户的关注者列表就可以了，除了需要处理一些鉴权和页面解析的问题，没有什么复杂的地方。</p>
<p>那我们升级一下挑战，爬取这个用户关注的人的所有关注的人，也就是和这个用户有二度关系的所有用户，你要怎么实现呢？如果不是二度，而是让你查找三度关系，也就是找出需要三跳的所有用户，你的代码能否很简单地通过配置就完成这件事呢？</p>
<p>这其实就是一个非常适合用 DFS 和 BFS 解决的问题，因为它天然就是一个需要无差别遍历所有图上节点的问题。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/2f/4b/2f60f4ec427e8acb573216626f882c4b.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/2f/4b/2f60f4ec427e8acb573216626f882c4b.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/2f/4b/2f60f4ec427e8acb573216626f882c4b.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/2f/4b/2f60f4ec427e8acb573216626f882c4b.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/2f/4b/2f60f4ec427e8acb573216626f882c4b.jpg?wh=2312x1379"
        title="img" /></p>
<p>你可以把豆瓣用户看成节点，用户之间的关注关系就是边，它们一起构成了一个复杂的社交网络。相信你也听过社交网络中的“六度分割理论”，说的就是世界上任何一个人和你之间的距离不会超过 6 度，描述了社交网络的小世界特性。这种网络关系也是许多人在研究的。</p>
<h3 id="bfs实现">BFS实现</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">py
    # 这里我们需要一个合适的 douban html parser
    def crawl(self, startUrl: str) -&gt; List[str]:        
        urls = deque()
        urls.append(startUrl)
        res = set()
        
        degree = 0
        N = 2
        
        while urls:
            # 遍历层数超过N层，停止遍历
            if degree &gt; N: break 
            # 用于记录下一层的节点
            next_degree_urls = deque()
            # 遍历当前层 
            while urls:
              u = urls.popleft()
              if u in set: continue
              for url in doubanHtmlParser.getFollowings(u):
                  next_degree_urls.append(url)
              res.add(u)
  
            urls = next_degree_urls
            # 当前层元素全部出队；进入下一层遍历，记录遍历层数的变量加1
            degree = degree + 1

</code></pre></td></tr></table>
</div>
</div><h3 id="dfs实现">DFS实现</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">py
    # 结果集 用于存放所有N度关系以内的用户
    res = set()
    N = 2 # 记录找N度关系以内的所有用户；N=2即找2度关系以内的用户
    def crawl(startUrl, degree):  
        # 如果已经超过N度关系，我们不用继续遍历      
        if degree &gt; N : return
        # 如果已经搜索过，我们也不用继续搜索
        if startUrl in res : return
        # 将当前搜索的用户主页加入结果集
        res.add(startUrl)
        for url in doubanHtmlParser.getFollowings(startUrl):
          # 遍历关注的所有用户，注意需要将度数增加1
          crawl(url, degree+1)
</code></pre></td></tr></table>
</div>
</div><h3 id="总结-2">总结</h3>
<p>作为两个相当常用的暴力搜索算法，BFS 和 DFS 比较适合用来解决图规模不大，或者本身就需要无差别遍历搜索空间的每一种情况的问题；这两者的时间空间复杂度是相当的。而至于 DFS 和 BFS 具体选择哪一种，我也总结出一些自己的经验，供你参考。</p>
<p>BFS 因为是由内向外地毯式地搜索，所以首次搜索到目标位置的时候一定是源点到目标位置的最短路径，所以求最短路径类的问题往往可以用 BFS 解决。当然，这里的“最短路径”是有条件的，只有在图中所有边权重相等时首次搜索到的才是最短路径；另一类边权不等的图上的最短路径求解问题我们之后会单独讲解。</p>
<p>而 DFS 实现起来比 BFS 更简单，且由于递归栈的存在，让我们可以很方便地在递归函数的参数中记录路径，所以需要输出路径的题目用 DFS 会比较合适。毕竟想用 BFS 实现相同的路径记录，除了需要在 queue 中记录节点，还需要关联到此节点的路径才可以，占用的空间比 DFS 高得多。</p>
<p>一般情况下我们都可以优先使用 DFS 实现，但这完全建立在我个人觉得 DFS 写起来更简单的前提下。而在需要求解路径本身的问题中，强烈建议你采用 DFS 作为搜索算法的实现。</p>
<h2 id="11字符串匹配如何实现最快的grep工具">11｜字符串匹配：如何实现最快的grep工具</h2>
<p>GNU Grep 则是 grep 命令的一个工业级实现，在项目官方 Readme 中作者是这样介绍它的：This is GNU grep, the “fastest grep in the west” (we hope).</p>
<p>作者 Mike Haertel 自己写了一封<a href="https://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html" target="_blank" rel="noopener noreffer">邮件</a>解释 GNU Grep 为什么这么快，主要有两点：它避免了检查每一个 byte对于被检查的 byte，只需要执行非常少的指令</p>
<p>第一点的主要优化就在于 GNU Grep 用到了非常知名的字符串匹配算法：Boyer Moore 算法，也就是我们常说的 BM 算法，它是目前已知的在大多数工业级应用场景中最快的字符串匹配算法，因而被广泛应用在各种需要搜索关键词的软件中，许多文档编辑器快捷键 ctrl+f 对应的搜索功能都是基于这个算法实现的。</p>
<p>那第二点呢，就是当你发现查询的速度已经优化到足够好时，也需要让 IO 的速度更快一些，查询所需的指令也更少一些，这里可以优化的地方就更多了。</p>
<p>比如由于 grep 是按行查找的，许多版本的 grep 实现都会去遍历查找\n 换行符先进行分行，但 GNU Grep 则是将搜索文本直接读入一个缓冲区优先查找目标字符串，只有命中时才会在命中位置的前后进行换行符的查找；又比如，GNU Grep 提供了基于 mmap 映射内存到文件的参数，可以减少一些内存拷贝的时间开销。具体的细节还有很多，比较繁琐，有兴趣的同学可以自行查阅 Mike Haertel 的邮件。</p>
<p>通常在字符串不长的时候，不同的匹配算法之间的效率差异不大。Brute-Force 算法的实现和理解都非常简单，不容易出错，完美地符合了 KISS（Keep it simple, stupid）原则，也就是让代码尽量简单从而避免出错。所以 BF 算法在真实开发的环境中出镜率很高，在日常工作中如果有手写字符串匹配的需求，你也可以考虑这种方式。</p>
<p>KMP 算法将前缀的信息利用到了极致，用匹配串自身的信息建立了一张部分匹配表，在每次失配的时候可以用来加速模式串，而不是每次都只向后移动一位。其算法逻辑整体比较复杂</p>
<p>而 GNU Grep 中用到的 BM（Boyer Moore）算法，不仅理解起来容易很多，实际应用时性能也更好，它同样是基于预处理来避免不必要的重复匹配。但 BM 算法引入了两条很好懂的规则，“坏字符”和“好后缀”规则，并采用从后往前的匹配顺序进行匹配，构思非常巧妙。</p>
<p>其中模式串 p 是 EXAMPLE，主串 s 是 HERE IS A SIMPLE EXAMPLE。</p>
<p>坏字符规则
先来看第一条规则：“坏字符”规则，描述的是主串上的失配字符，目的就是为了跳过一些肯定不可能成立的匹配位置。在 BM 算法中，我们同样将 s 和 p 对齐，开始遍历匹配，但匹配的顺序和 BF 算法不同，采用从后往前匹配的方式。这其实是一种非常巧妙的设计，你马上可以看到它配合坏字符规则使用时有着绝佳的效果。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/06/c7/06149aa63e9yya45e22f3dedea5301c7.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/06/c7/06149aa63e9yya45e22f3dedea5301c7.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/06/c7/06149aa63e9yya45e22f3dedea5301c7.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/06/c7/06149aa63e9yya45e22f3dedea5301c7.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/06/c7/06149aa63e9yya45e22f3dedea5301c7.jpg?wh=2312x1379"
        title="img" /></p>
<p>所以在例子中，第一次尝试匹配，首先会把 p[6]的“E”和 s[6]的“S”匹配，发现它们不匹配，所以这里的“S”就是一个坏字符。那此时我们有两种选择，一种就是直接将模式串往后移动一位尝试继续匹配，这就和之前 BF 算法的想法差不多，没有利用到模式串中任何先验的信息。而另一种呢，就是 BM 的做法了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/60/3b/60e54463301257abc4f75fb8db85723b.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/60/3b/60e54463301257abc4f75fb8db85723b.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/60/3b/60e54463301257abc4f75fb8db85723b.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/60/3b/60e54463301257abc4f75fb8db85723b.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/60/3b/60e54463301257abc4f75fb8db85723b.jpg?wh=2312x1379"
        title="img" /></p>
<p>我们先看失配的坏字符“S”在模式串 p 中是否有出现，如果没有出现，那说明模式串其实不可能和这个位置有重叠，可以直接跳过这段位置，从主串的下一个位置开始匹配。在例子中，“S”显然不属于模式串 EXAMPLE，我们就应该跳过“S”继续匹配，这样就大大加速了匹配的过程。同样在下一步匹配时，因为主串的“P”和模式串的末尾“E”不匹配，但失配的“P”在模式串中就有出现，我们可以将模式串中最后一次出现的“P”和主串中的“P”对齐，同样从模式串尾开始匹配。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/3c/b9/3c1ff31210fb788a18a8b9c1ff468db9.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/3c/b9/3c1ff31210fb788a18a8b9c1ff468db9.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/3c/b9/3c1ff31210fb788a18a8b9c1ff468db9.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/3c/b9/3c1ff31210fb788a18a8b9c1ff468db9.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/3c/b9/3c1ff31210fb788a18a8b9c1ff468db9.jpg?wh=2312x1379"
        title="img" /></p>
<p>至此，坏字符的主要内涵就全部展示出来了，也就是，每次失配的时候，我们需要将匹配串往后移动 （失配位置下标 - 失配字符最右出现的位置下标） 位；如果失配字符不存在，则位置为 -1。这里你可能会有个疑问，为什么是最右的位置呢，不应该是记录上一次出现的位置吗？我的理解是，如果在每个位置都存储相比于当前位置的上一次失配字符出现的位置，存储开销会大得多；而如果只存每个字符最右出现的位置，我们所需要的只是一个字符集大小的哈希表，用一个长度为 256 的数组即可实现。当然，这个公式会导致我们有时候求出的移动值可能是负的，让模式串反而向前移动了。比如在 BBBBBB 和 ABB 匹配时，第一次失配的坏字符 B，会让匹配串往后移动（0-2=）-2 位，导致前移。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/39/e7/399c7046392324fa8bae68248e06d5e7.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/39/e7/399c7046392324fa8bae68248e06d5e7.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/39/e7/399c7046392324fa8bae68248e06d5e7.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/39/e7/399c7046392324fa8bae68248e06d5e7.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/39/e7/399c7046392324fa8bae68248e06d5e7.jpg?wh=2312x1379"
        title="img" /></p>
<p>那往前移显然是没有意义的，因为当前位置之前的匹配可能我们已经全部排除了；所以当移动位数出现负数时，我们也要让模式串至少往后移动一位，这点通过对基于坏字符的移动值和 1 取 max 操作即可实现。而在这种时候，我们另一条规则“好后缀”也就可以发挥作用了。</p>
<p>好后缀规则</p>
<p>我们继续来看刚刚的例子。在 SIMPLE 和 EXAMPLE 的匹配中，我们发现“MPLE”都匹配得上，但主串中的“I”和模式串中的“A”出现了失配。那这里的“MPLE”，我们就会称之为好后缀；同样“PLE”、“LE”、“E”其实也都是好后缀。此时如果应用之前的坏字符规则，我们应该将模式串往后移动（2-(-1)=）3 位，因为“I”在模式串中不存在。但是，有没有办法利用已经匹配上的好后缀“MPLE”的信息，往后移动更多位呢？</p>
<p>当然是可以的，我们只要看匹配上的好后缀“MPLE”及它的子串“PLE”、“LE”、“E”是否之前也出现在模式串中即可。这里只有子串“E”之前也出现在了模式串中，所以我们可以直接把模式串移动至和这里主串的“E”对齐即可，这样我们向后移动了 6 位，显然比坏字符规则跳过了更多不可能的情况。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/7d/81/7d108b48c017acc6b83b62d6eeb50281.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/7d/81/7d108b48c017acc6b83b62d6eeb50281.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/7d/81/7d108b48c017acc6b83b62d6eeb50281.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/7d/81/7d108b48c017acc6b83b62d6eeb50281.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/7d/81/7d108b48c017acc6b83b62d6eeb50281.jpg?wh=2312x1379"
        title="img" /></p>
<p>总结起来，好后缀规则移动的方式就是，找到好后缀在模式串中最右的匹配位置，总计向后移动（模式串字符长度 - 1 - 好后缀在模式串上次出现的最右位置）位。以 EXAMPLE 为例，好后缀“E”在模式串中上一次出现的下标是 0，整个字符串长度为 7，所以向后移动（7-1-0）6 个位置。这里还需要注意一点，好后缀匹配的时候，只有最长的好后缀被允许出现在模式串的中间位置；其余子串只能匹配在模式串的前缀中。比如下面的例子，主串中的“A”和模式串中的“C”失配，“MABC”是最长好后缀，但之前并没有出现在模式串中。</p>
<p>我们不能直接将模式串直接移到“MABC”之后，因为这样会错过好后缀子串“ABC”的匹配点。但同样我们也不用匹配红色虚线框中的“ABC”，因为“MABC”没有匹配上，后面所有的 MABC 的子后缀匹配肯定只能发生在模式串的前缀中。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/15/58/158a9ac35bfb30c0cd48e06fc22ff558.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/15/58/158a9ac35bfb30c0cd48e06fc22ff558.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/15/58/158a9ac35bfb30c0cd48e06fc22ff558.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/15/58/158a9ac35bfb30c0cd48e06fc22ff558.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/15/58/158a9ac35bfb30c0cd48e06fc22ff558.jpg?wh=2312x1379"
        title="img" /></p>
<p>好后缀和坏字符规则其实都是可以单独使用的；BM 算法，为了尽可能多地跳过不可能匹配的字符，会选择两条规则中的较大移动值来往后移动。而且这两个规则和主串都没有关系，只和模式串自身有关，我们显然可以通过预处理得到两个规则的偏移表，来加速整个模式匹配的过程。</p>
<p>好了，现在讲完了 BM 算法“好后缀”、“坏字符”的两个规则和从后往前匹配的策略，我们一起来把例子匹配完成吧。在查表发现好后缀的规则能跳过更多的位置后，我们选择将模式串往后移动了 6 位。这时“P”和  “E”没有匹配成功，我们采用坏字符规则，拿着坏字符“P”，找到模式串中出现的“P”位于 p[4]，向后移动 (6-4=) 2 位和主串的“P”对齐。从尾部往前遍历匹配，此时，我们发现所有的字符都匹配上了，因而找到了一个完全匹配的位置。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/fc/60/fc1yy27fd7c2d28346b56d6a88cc6260.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/fc/60/fc1yy27fd7c2d28346b56d6a88cc6260.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/fc/60/fc1yy27fd7c2d28346b56d6a88cc6260.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/fc/60/fc1yy27fd7c2d28346b56d6a88cc6260.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/fc/60/fc1yy27fd7c2d28346b56d6a88cc6260.jpg?wh=2312x1379"
        title="img" /></p>
<p><strong>具体实现</strong></p>
<p>相信你现在已经大体理解整个 BM 算法的思路了，但正所谓，“细节是魔鬼”，BM 算法从概念上理解其实并不是很难，但真要手写实现还是比较困难的，不熟练的时候 debug 很容易花费很多的时间。为了方便起见，我们就用 Python 来实现这个算法。具体实现我们可以分为三个大块：“坏字符”最右位置计算、“好后缀”偏移表计算、在主串上的搜索实现。</p>
<p>坏字符最右位置计算
“坏字符”的部分是最简单的，只需要开一个 dict，遍历一次模式串，找到每个字符出现在模式串中的最右侧的那个位置即可。事实上，我们可以用一个[0,256]的数组来替代 HashMap 以提高性能，大部分工业级实现也都是这样做的。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">def get_bc(pattern):
    bc = dict() # 记录每个badchar最右出现的位置
    for i in range(len(pattern) - 1):
        char = pattern[i]
        bc[char] = i + 1
    return bc
</code></pre></td></tr></table>
</div>
</div><p>由于遍历的时候我们会不断地覆写 dict，所以最后遍历完成，就能得到每个 badchar 在模式串中最右侧的位置。</p>
<p>好后缀偏移表计算
“好后缀”的部分相对来说比较复杂，尤其是工业级的实现对性能要求很高，代码有很多 trick，非常不易于理解，这里我们做一些简化的处理；而且在大部分时候，由于模式串比主串要短的多，即使预处理时间复杂度稍微高一些，问题也不是很大。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">def get_gs(pattern):
    gs = dict()
    gs[&#39;&#39;] = len(pattern)

    # suf_len 用于标记后缀长度
    for suf_len in range(len(pattern)):
        suffix = pattern[len(pattern) - suf_len - 1:]
        # j 用于标记可用于匹配的位置
        for j in range(len(pattern) - suf_len - 1):
            substr = pattern[j:j + suf_len + 1]
            if suffix == substr:
                gs[suffix] = len(pattern) - j - suf_len - 1

    for suf_len in range(len(pattern)):
        suffix = pattern[len(pattern) - suf_len - 1:]
        if suffix in gs: continue
        gs[suffix] = gs[suffix[1:]]

    gs[&#39;&#39;] = 0
    return gs
</code></pre></td></tr></table>
</div>
</div><p>我们同样开一个 dict，用于标记失配时每个字符串应该往后移动多少，也就是对应的好后缀应该和之前哪个子串或者前缀匹配。怎么做呢？一种比较暴力的做法就是遍历所有可能的后缀，然后从前往后看这个后缀是否在模式串中的其他位置也出现了，后面遍历的会覆盖之前的记录，所以记录下来的就是最右的匹配位置。记得前面说过如果一个后缀在模式串中不存在，我们不能直接跳过整个字符串，因为该后缀的子串还可能和模式串中的前缀重合。比如例子中的“MPLE”后缀虽然不再存在于“EXAMPLE”中，但是其子串“E”与“EXAMPLE”的前缀“E”是重叠的。所以在后缀不存在的时候，还需要检查一下其子后缀是否在 dict 有对应的匹配，如果有的话，也应该采用；这个通过一次循环赋值即可实现，对应到代码里就是第 14 到 17 行。我这里实现的时间复杂度为 O(m^3)，你可以自己推导一下，也欢迎去留言区讨论。</p>
<p>匹配过程
有了好后缀的偏移表和坏字符的最右位置，我们就可以来实现整个匹配的过程了。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">py
def bm(string, pattern, bc, gs):
    # i 用于标记当前模式串和主串哪个位置左对齐。
    i = 0 
    # j 用于标记当前模式串匹配到哪个位置；从右往左遍历匹配。
    j = len(pattern)

    while i &lt; len(string) - len(pattern) and (j &gt; 0):
            # 从右往左匹配每个位置
            a = string[i + j - 1]
            b = pattern[j - 1]
            if a == b: # 匹配的上，继续匹配前一位
                j = j - 1
            else: # 匹配不上，根据两个规则的预处理结果进行快速移动
                i = i + max(gs.setdefault(pattern[j:], len(pattern)), j - bc.setdefault(a, 0))
                j = len(pattern)
            # 匹配成功返回匹配位置
            if j == 0:
                return i
    # 匹配失败返回 None
    return -1
    
if __name__ == &#39;__main__&#39;:
    string = &#39;here is a simple example &#39; 
    pattern = &#39;example&#39;

    bc = get_bc(pattern)  # 坏字符表
    gs = get_gs(pattern)  # 好后缀表

    print(gs)

    x = bm(string, pattern, bc, gs)

    print(x)
</code></pre></td></tr></table>
</div>
</div><p>参照详细的注释，整个过程和前面讲解的原理是一一对应的，你可以配合代码一起理解。 完整的代码我放到了<a href="https://github.com/wfnuser/Algorithms/blob/main/Boyer-Moore/bm.py" target="_blank" rel="noopener noreffer">GitHub</a>上。</p>
<p>时间复杂度
Boyer-Moore 算法，在最好情况下复杂度可以达到 O(n/m)，在字符集比较大的时候，坏字符和好后缀规则可以帮助我们快速跳过大部分不必要的查询，达到接近最好的时间复杂度的概率是比较大。但 BM 算法的最坏时间复杂度估计就是一个很难的数学问题了，许多学者都尝试做过相关的证明，目前我知道相对精细的比较上限次数的估计是 Guibas 和 Odlyzko 给出的 3n，你感兴趣的话可以阅读原始论文了解。因而和 KMP 一样，BM 算法的理论时间复杂度也在 O(m+n) 之内，但由于字符集比较大的时候，BM 常常能达到更好的时间复杂度，所以在实际应用中得到了更广泛的使用。</p>
<h3 id="总结-3">总结</h3>
<p>我们来总结一下 BM 算法的特性。BM 算法，最大的特点就是利用了对目标串的预处理，用空间换时间，避免了许多不必要的比较，预处理的方式主要来自于对“坏字符”和“好后缀”两条规则的观察，因为这两个规则和主串都没有关系，只和模式串自身有关，显然可以通过预处理得到两个规则的偏移表，来加速整个模式匹配的过程。总的来说，BM 算法不难理解但实现起来有一定复杂度，感兴趣的同学可以自行练习。不过这一个特定的字符串匹配算法的学习其实还是次要的，空间换时间和预处理的思想你可以好好感受。</p>
<h2 id="13哈夫曼树http20是如何更快传输协议头的">13｜哈夫曼树：HTTP2.0是如何更快传输协议头的？</h2>
<p>HTTP 是当今最广为使用的互联网传输协议，我们都听说过 HTTP/1.0、HTTP/2.0、SPDY、HTTP/3.0 等概念，但是对这几者之间的区别能如数家珍的同学却不多，比如 HTTP/2.0 在编码方面做了什么样的改进，比 HTTP/1.1 的传输更快呢？我们今天就来学习一下 HTTP/2.0 为了提高传输效率而引入的用于头部压缩的杀招：HPACK。</p>
<p>HPACK 应用了静态表、动态表和哈夫曼编码三种技术，把冗余的 HTTP 头大大压缩，常常可以达到 50% 以上的压缩率。其中的哈夫曼编码，底层主要就依赖了我们今天会重点学习的哈夫曼树，这也是广泛运用在各大压缩场景里的算法。在展开讲解 HTTP/2.0 中的 HPACK 到底是怎么工作的，我们首先要来思考一下为什么要压缩 HTTP 的头，或者说，压缩到底又是什么呢？</p>
<h3 id="压缩技术">压缩技术</h3>
<p>我们都知道压缩技术诞生已久，在各种文件尤其是多媒体文件里，应用非常广泛，能帮助节约信息的存储空间和网络传输时间。</p>
<p>之所以能压缩，主要原因就是我们存储的信息往往是有模式和冗余的。以文本为例，大量单词的重复或者大量的空格，都是我们可以压缩的空间。原文件大小与压缩后文件大小的比值，我们就叫做压缩比，是衡量压缩算法有效性非常直观的指标。</p>
<p>压缩技术也分为有损压缩和无损压缩两种。</p>
<p>有损压缩，我们允许数据一定程度上的丢失，它在多媒体文件里更加流行，比如 JPEG、MP3 就是非常典型的两种数据有损压缩的方式。压缩多媒体数据时，我们允许一定程度的丢失。主要是因为对图像或者音频文件来说，数据一定程度上的丢失并不一定会很影响用户的主观感受。比如压缩图片时，有一种方式会把颜色的种类减少，让图片每个像素的编码位数降低，从而就实现了图片的压缩，但是从人的视觉上说影响可能并不是特别大。所以有损压缩的衡量指标就不止压缩比，还需要考虑人的主观感受了。</p>
<p><strong>但是互联网大部分应用中所用的通信协议，都不应该关心业务数据本身，要做的只是保证数据可以按照一定的方式准确、无误，并且尽量高效地从发送端传输到接收端，有损压缩显然是不可接受的。比如最常用的 HTTP，就不会关心具体传输的内容是什么，自然不可能对数据做有损压缩。</strong></p>
<p>所以在 HPACK 里，我们采用的当然也是无损压缩策略。
现在搞清楚了压缩技术的背景，在那 HTTP 里引入压缩技术是否有意义呢？毕竟如果压缩比不是很高，引入这样的设计，只会导致相关协议的客户端和服务端实现的复杂性提高，得不偿失。</p>
<h3 id="引入-hpack-的价值">引入 HPACK 的价值</h3>
<p>早期采用 HTTP 的互联网应用，只涉及数据的展示，所以我们最初设计 HTTP 的时候没有引入状态，但是后期随着 Web2.0 的繁荣发展，网站不再只是展示这么简单，会和用户产生更多的交互，让用户产生内容，于是也引入了“登录”等有状态的功能。</p>
<p>要基于 HTTP 实现相关应用，我们常用的做法就是把用于鉴权的令牌或者其他“状态”携带在 HTTP 头里，在客户端和服务端之间来回传递。出于安全需要，这种鉴权的令牌往往非常冗长，http header 常常比 http body 还要大，这就带来了很大的开销。所以 HTTP/2.0 通过引入 HPACK 压缩协议头，就带来了很大的价值。</p>
<p>而且 HTTP/1.1 之前的 HTTP 协议传输的内容很简单，可以认为就是一串文本在互联网上直接传递，没有任何编码，这也给我们的压缩算法带来了很大的压缩空间。</p>
<h3 id="hpack-的压缩效果">HPACK 的压缩效果</h3>
<p>既然 HTTP 中引入压缩技术很有意义，那我们就先来看看压缩之后的效果到底有多大吧。h2load 是网上开源的一个对 HTTP/2.0 做 benchmark 的工具，我们可以在系统上安装它，来访问某些网站，直观地感受一下 HPACK 技术带来的 HTTP 头的大小变化：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/93/cf/93dfe106f6yye5ab79a085f1d5a82bcf.png?wh=1334x912"
        data-srcset="https://static001.geekbang.org/resource/image/93/cf/93dfe106f6yye5ab79a085f1d5a82bcf.png?wh=1334x912, https://static001.geekbang.org/resource/image/93/cf/93dfe106f6yye5ab79a085f1d5a82bcf.png?wh=1334x912 1.5x, https://static001.geekbang.org/resource/image/93/cf/93dfe106f6yye5ab79a085f1d5a82bcf.png?wh=1334x912 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/93/cf/93dfe106f6yye5ab79a085f1d5a82bcf.png?wh=1334x912"
        title="img" /></p>
<p>可以看到，采用了 HTTP/2.0 之后，直接压缩了 HTTP 头 33% 的空间，效果显著。那 HPACK 具体是如何做的呢？我们现在就来一探究竟。</p>
<h4 id="1hpack-中的静态表">1.HPACK 中的静态表</h4>
<p>首先我们来看一下 HPACK 的第一个手段：静态表，它其实就是对 HTTP 头报文里最常见的文本进行了一种编码。静态表也是非常常用的压缩手段。HTTP/2.0 一共对 61 个常用的头，以及头和值的组合做了编码。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/d6/7f/d631868ef8210c57d3bec37e03f8717f.png?wh=1600x949"
        data-srcset="https://static001.geekbang.org/resource/image/d6/7f/d631868ef8210c57d3bec37e03f8717f.png?wh=1600x949, https://static001.geekbang.org/resource/image/d6/7f/d631868ef8210c57d3bec37e03f8717f.png?wh=1600x949 1.5x, https://static001.geekbang.org/resource/image/d6/7f/d631868ef8210c57d3bec37e03f8717f.png?wh=1600x949 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/d6/7f/d631868ef8210c57d3bec37e03f8717f.png?wh=1600x949"
        title="img" /></p>
<p>比如 HTTP 的几种请求方法，GET、POST 等，都编码到了一张范围为 1-61 的索引表里，这样原来的&quot;:method GET&quot;等字符串需要的空间就小多了。</p>
<h4 id="2hpack-中的动态表">2.HPACK 中的动态表</h4>
<p>但是只是如此的话，我们能压缩的报文就非常有限了，怎么办呢？我们应该还允许客户端和服务端，通过通信的方式，维护一张动态的“字典”，这样用索引号就可以代表一串很长的文本，减少在这次 HTTP/2 连接里反复出现的一些自定义字段的载荷。比如，这些字段就是很好的例子：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">:authority wfnuser
:cookies xxxxxx
</code></pre></td></tr></table>
</div>
</div><p>尤其是常常用来保留用户身份凭证的cookies，因为安全性和加密算法的需要，它们往往设计的比较长，很多时候甚至导致 header 的长度比 body 还要长。在 http/1.1 之前的协议里，每次通信都需要传递冗长且重复的信息，显然会带来巨大的开销。动态表就很好地解决了这个问题。</p>
<h3 id="3hpack-中的哈夫曼编码">3.HPACK 中的哈夫曼编码</h3>
<p>其实只用动态表和静态表已经可以做到很好的压缩 header 了，但是受限于静态表和动态表的大小，我们并不能用它们压缩任意字符。哈夫曼编码，就是对静态表和动态表能力的一种补充，HPACK 在引入了哈夫曼编码之后，可以达到对 HTTP 报文高达 30%-80% 的压缩率。那我们首先来了解一下哈夫曼编码是什么。</p>
<h4 id="哈夫曼编码">哈夫曼编码</h4>
<p>其实，哈夫曼思想非常简单，就是让出现概率更高的字符用更短的编码表示，出现概率低一些的字符则用更长的编码表示。</p>
<p>这句话乍一听可能不太好理解，什么叫更短的编码呢，或者说什么是编码呢？我们日常在用的 ASCII 编码就是对字符串的一种编码，每个字符都被编码到 0-127 的范围里，这也是在绝大部分编程语言里，一个 char 类型的字符只占用一个字节的原因；当然，一个字节实际可以表示 0-255 种可能，ASCII 编码规范本身没有定义 128-255 的范围，所以各大厂商都可以有自己的扩展定义去表示更多的字符。所以 ASCII 作为一种典型的每个字符都等长编码的编码方法，有没有办法被压缩呢？是可以的。</p>
<p>比如，在自然语言场景里，我们知道字母 e 可能是最常出现的字符，如果用更短的编码去表示 e，而用其他更长的编码表示其他字符，就可以达到压缩文本编码长度的效果。不过这里还有个问题，用等长编码比如 ASCII 编码，我们解码的时候直接 8 位、8 位的读，就很容易解出编码前的字符串，但如果用变长编码，我们就需要处理解码歧义的问题。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/32/9a/32ae813f1a71f54c5e271e2974f8e19a.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/32/9a/32ae813f1a71f54c5e271e2974f8e19a.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/32/9a/32ae813f1a71f54c5e271e2974f8e19a.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/32/9a/32ae813f1a71f54c5e271e2974f8e19a.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/32/9a/32ae813f1a71f54c5e271e2974f8e19a.jpg?wh=2312x1379"
        title="img" /></p>
<p>比如在字符串“ABCD”里，我们假设把 A 用 0 编码、B 用 1 编码、C 用 10 编码、D 用 11 编码。“ABCD”可以编码成二进制编码为“011011”，没问题，但如果中间不加任何分隔符，你并不能知道这个编码结果是由“ABCD”产生的还是由“ABBABB”产生的。如果加了分隔符，分隔符本身也会引入额外的编码成本，甚至可能导致一个负向的优化。为了解决这个问题，学生时代的哈夫曼（huffman）在 1952  年提出了最优前缀码的算法，也就是广泛应用在压缩领域的哈夫曼编码，它除了用更短的编码表示出现概率更高的字母，还引入了一个约束：不同的字符编码间不能彼此成为对方的前缀。这条约束在解码的时候完美地避免了歧义的问题。比如刚刚如果把 A 编码成 0、B 编码成 10、C 编码成 110、D 编码成 111，这就是一种符合约束的前缀码编码方式。ABCD 就会编码成 010110111，一定只有一种解码方式。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/4b/63/4bc77ae733c0e653d620eb429bd42163.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/4b/63/4bc77ae733c0e653d620eb429bd42163.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/4b/63/4bc77ae733c0e653d620eb429bd42163.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/4b/63/4bc77ae733c0e653d620eb429bd42163.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/4b/63/4bc77ae733c0e653d620eb429bd42163.jpg?wh=2312x1379"
        title="img" /></p>
<p>那在不能成为对方前缀的约束下，具体如何根据出现频率选择合适的编码方式呢？哈夫曼采用了贪心的算法思想：用一棵二叉树来标记每个字符的编码方式，左分支代表 0、右分支代表 1，所有需要编码的字符都对应二叉树的叶子节点，根结点到该叶子结点的路径就代表着该字符的编码方式。由于各节点是独立的不可能重复，每个字符又都唯一对应着一个叶子节点，所以它们一定不会互相成为对方的前缀。下面我们要做的就是找到这样一个可以达到最大压缩效率的二叉树。</p>
<h4 id="贪心的哈夫曼树">贪心的哈夫曼树</h4>
<p>让我们举一个例子来理解哈夫曼树的编码方式。假设要对 a b c d e f 进行编码，它们在需要编码的文本中出现的频率分别是 5 9 12 13 16 45。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    a           5
    b           9
    c           12
    d           13
    e           16
    f           45
</code></pre></td></tr></table>
</div>
</div><p>那么如何编码可以让整个文本编码出来的二进制所占空间最少呢？最开始，我们先把每个字符都看成一个独立的二叉树节点，节点中同时包含了字符信息和频率信息。然后，从中选两个出现频率最少的节点，a 和 b，我们把这两个节点合并成一棵子树，也就是用一个父节点的左右节点指针分别链向 a 和 b 两个节点，把两者的频率之和作为父节点的频率。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/de/6a/dee506a76e6c1df873ac2bece984df6a.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/de/6a/dee506a76e6c1df873ac2bece984df6a.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/de/6a/dee506a76e6c1df873ac2bece984df6a.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/de/6a/dee506a76e6c1df873ac2bece984df6a.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/de/6a/dee506a76e6c1df873ac2bece984df6a.jpg?wh=2312x1379"
        title="img" /></p>
<p>之后，我们把这个频率为 14 的树放回所有的节点里（14 12 13 16 45），再从中继续选择最小的两个节点 c 和 d 合并成一棵新的树。更新之后的所有节点就是下面这些，其中 a、b、c、d 节点都被替换成了新的合成节点：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    (a, b)      14
    (c, d)      25
    e           16
    f           45
</code></pre></td></tr></table>
</div>
</div><p>不断进行这样的操作，最终就可以得到这样一棵树：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/f1/ce/f14f482a590bbe76b6d35a89e5ef34ce.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/f1/ce/f14f482a590bbe76b6d35a89e5ef34ce.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/f1/ce/f14f482a590bbe76b6d35a89e5ef34ce.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/f1/ce/f14f482a590bbe76b6d35a89e5ef34ce.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/f1/ce/f14f482a590bbe76b6d35a89e5ef34ce.jpg?wh=2312x1379"
        title="img" /></p>
<p>假设树的左链代表 0，右链代表 1，a b c d e f 对应的编码为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    f          0
    c          100
    d          101
    a          1100
    b          1101
    e          111
</code></pre></td></tr></table>
</div>
</div><p>看完这个过程，相信你对为什么这样编码也有一些想法了，它非常直观，我们来一起研究一下。</p>
<p>首先为了不用额外的分隔符，一种让解码不产生歧义的办法就是引入前缀码规则，对应到树上就是每个字符都编码成根节点到某个叶子节点的路径。然后为了“出现频率最高的字符用最短的方式编码”的策略，显然，我们需要让出现频率最高的树出现在最短的路径里，出现频率最低的树则放到更长的路径里。</p>
<p>因为每次将两颗树合并到一起时，都会导致这两颗树里所有叶子节点的高度加 1，也就是其中所有的字符编码长度都会 +1，所以，为了达到最优编码的目标，我们会从出现频率最低的节点开始合并。最后我们合并完新的树，也要把新树的频率变成这两颗树的频数之和，它代表了这颗树下所有字符出现的频率。</p>
<p><strong>这样每次找出最低的两个树合并，就必然能得到一个整体最优的编码方式，也就是哈夫曼编码的思路了。</strong></p>
<p>这背后的思想其实就是贪心算法，也就是在每一次决策时都采取在当前状态下最优的选择，从而得到整体最优解的算法。当然，也不是所有的场景都能使用贪心算法的，比如经典的背包问题，采用贪心算法虽然能得到局部最优解，但就不能得到全局最优解。而哈夫曼树则是一个贪心算法发挥作用的很好的例子。</p>
<h4 id="哈夫曼树实现">哈夫曼树实现</h4>
<p>现在有了思路，相关的实现其实就非常简单了。先说编码的部分，实质就是要建立这样一棵基于贪心算法的哈夫曼树。二叉树的相关概念相信你已经非常熟悉了，所以这里的核心就是如何做到每次都可以快速选出频率最低的两棵树。</p>
<p>怎么做呢？相信你已经想到了，我们之前学的堆就是用来维护动态序列中最小值的利器。假设一共要对 N 个节点进行编码，堆中最多有 N 个节点，每次合并涉及两次取出元素和一次放回元素，时间复杂度都是 O(logN)，整体时间复杂度为 O(N*logN)。翻译成 C++ 代码，我写了比较详细的注释供你参考：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++">       <span class="kt">void</span> <span class="nf">buildHuffmanTree</span><span class="p">(</span><span class="n">string</span> <span class="n">text</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="c1">// 利用hashmap对字符串进行频率计数
</span><span class="c1"></span>    <span class="n">unordered_map</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="kt">int</span><span class="o">&gt;</span> <span class="n">freq</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">char</span> <span class="nl">ch</span><span class="p">:</span> <span class="n">text</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">freq</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
  
    <span class="c1">// 用堆去动态维护所有树中最小的两颗
</span><span class="c1"></span>    <span class="n">priority_queue</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">*</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">*&gt;</span><span class="p">,</span> <span class="n">comp</span><span class="o">&gt;</span> <span class="n">pq</span><span class="p">;</span>
  
    <span class="c1">// 将所有的字符都初始化成为哈夫曼树的一个叶子节点
</span><span class="c1"></span>        <span class="c1">// 并推入优先队列
</span><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="nl">pair</span><span class="p">:</span> <span class="n">freq</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">pq</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">getNode</span><span class="p">(</span><span class="n">pair</span><span class="p">.</span><span class="n">first</span><span class="p">,</span> <span class="n">pair</span><span class="p">.</span><span class="n">second</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">));</span>
    <span class="p">}</span>
  
    <span class="c1">// 每次取出最小的两个合并 直至优先队列只剩一个节点
</span><span class="c1"></span>    <span class="k">while</span> <span class="p">(</span><span class="n">pq</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="c1">// 最小的两个节点出队
</span><span class="c1"></span>      <span class="n">Node</span> <span class="o">*</span><span class="n">left</span> <span class="o">=</span> <span class="n">pq</span><span class="p">.</span><span class="n">top</span><span class="p">();</span> <span class="n">pq</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
      <span class="n">Node</span> <span class="o">*</span><span class="n">right</span> <span class="o">=</span> <span class="n">pq</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>  <span class="n">pq</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
  
      <span class="c1">// 建立一个内部节点，以这两个最小的树为左右节点
</span><span class="c1"></span>        <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">left</span><span class="o">-&gt;</span><span class="n">freq</span> <span class="o">+</span> <span class="n">right</span><span class="o">-&gt;</span><span class="n">freq</span><span class="p">;</span>
      <span class="n">pq</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">getNode</span><span class="p">(</span><span class="sc">&#39;\0&#39;</span><span class="p">,</span> <span class="n">sum</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">));</span>
    <span class="p">}</span>
  
    <span class="c1">// 优先队列中最后一个元素为整棵树的根节点
</span><span class="c1"></span>    <span class="n">Node</span><span class="o">*</span> <span class="n">root</span> <span class="o">=</span> <span class="n">pq</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
  <span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div><p>好，到这里我们就构建好了一棵哈夫曼树了。基于它，我们可以很方便地通过对哈夫曼树的遍历做到对字符串的编码和解码，进而实现压缩的效果。具体的实现都贴在<a href="https://github.com/wfnuser/Algorithms/tree/main/Huffman%20Tree" target="_blank" rel="noopener noreffer">GitHub</a>仓库中了。</p>
<p>学习完哈夫曼编码，HPACK 中用于压缩的最后一个杀招你也就学会了。HPACK 采用的是静态 huffman 编码，HTTP/2.0 协议制定者利用一个很大的 HTTP Header 的 sample，统计了所有字符出现的频率，并基于此构建了一个 huffman 编码表，需要内置在服务端和客户端里，最多能带给我们大约 37.5% 的压缩率。</p>
<h3 id="总结-4">总结</h3>
<p>今天关于 HPACK 的讲解到这里就结束了，我们做个简单的小结。HPACK 是 HTTP/2.0 为了降低 HTTP payload 大小从而提高传输效率的杀招，应用了静态表、动态表和哈夫曼编码三种技术，把冗余的 HTTP 头信息大大压缩，常常可以达到 50% 以上的压缩率。前两招静态表和动态表的思想其实非常常见。比如在设计消息系统时，微服务架构下经常涉及消息在不同系统间传递的需求，如果只是为了定位消息而不用真的读取消息体，我们完全可以把消息编码成“消息 ID + 消息体”的格式，存储在数据库或者其他缓存系统中，这样，在系统间传递的时候只需要传递 ID 即可，等真的需要取出消息体的时候，再到数据库等系统里读取具体内容。这可以大大减少系统通信的开销，背后其实就是类似动态表的思想，你可以举一反三。第三招哈夫曼编码，引入不同的字符编码间不能彼此成为对方前缀的约束下，使用哈夫曼树来编码。哈夫曼树基于贪心的思想，以及用树对编码进行抽象的想法，也非常精巧，也值得你好好学习一下。</p>
<h2 id="操作系统">操作系统</h2>
<h2 id="14调度算法操作系统中的进程是如何调度的">14｜调度算法：操作系统中的进程是如何调度的？</h2>
<p>之前我们已经学习了大部分常用的数据结构和一些经典的算法思想，从今天开始，我们将正式迈入算法在真实世界的应用，感受计算机先辈们在解决实际问题时天马行空的智慧之光。希望带给你思维乐趣的同时，也能给你解决实际工作里的问题带来一些启示。就让我们从操作系统开始说起，作为计算机软件的基石，它是计算机软硬件交汇的关键所在。当然，操作系统同样是一个非常大的话题，不同历史时期的操作系统都背负着不同的使命。发展至今，随便一个可用的操作系统都有几千万行的代码，上上下下用到的算法肯定也非常多，我们不可能全部涉及，这次会挑出几个关键的算法或者设计来讲解，包括：计算机进程调度算法、内存页面置换算法和日志文件系统。我们今天要学习的就是进程调度算法，也就是 Process Scheduling Algorithms。</p>
<p>在许多中间件、语言设计甚至日常开发的业务系统中遇到问题时，我们常常会参考操作系统中成熟的解决办法，进程调度就是这样一种常常被借鉴的场景，在不少语言的线程或者协程机制的设计里都有应用。那操作系统的进程调度到底是如何设计的呢？话不多说，我们开始今天的学习。</p>
<h3 id="进程是什么">进程是什么？</h3>
<p>在聊进程调度算法之前，我们先简单复习一些操作系统相关的基础概念。首先，我们要明白进程是什么？我想“Process”最早被翻译成“进程”，应该指的就是“正在进行的程序”的意思。我们知道计算机是可以同时进行很多任务的，比如你现在可能就边开着浏览器阅读这篇文章，边打开着微信软件随时可以处理好友的消息。你的计算机就像一个真正的时间管理大师一样，并发而有条不紊地处理着各种复杂的任务。但事实上，每个 CPU 核在同一时间只能同时运行一个程序，那计算机是如何做到看起来可以同时执行很多任务的呢？</p>
<p>这里就需要用到进程、线程之类的抽象了，这也是早期计算机引入多进程的主要目的，让你的计算机看起来可以同时执行不同的任务。我们通常会把不同的程序分配给不同的独立进程去执行，让计算机基于一定的策略，把 CPU 的计算时间调度给不同的进程使用；但因为进程间切换的时间一般比较短，并不能达到人们能感知到的阈值，所以用户在使用计算机的时候就会觉得多个程序或者任务是同时，也就是并发，执行的。如果你在 Linux 系统上运行一下ps命令，就可以看到你的计算机当前正在运行的许多进程了：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/c8/14/c8dcb1b07e65893dcd3bfd6a1e919614.png?wh=1920x684"
        data-srcset="https://static001.geekbang.org/resource/image/c8/14/c8dcb1b07e65893dcd3bfd6a1e919614.png?wh=1920x684, https://static001.geekbang.org/resource/image/c8/14/c8dcb1b07e65893dcd3bfd6a1e919614.png?wh=1920x684 1.5x, https://static001.geekbang.org/resource/image/c8/14/c8dcb1b07e65893dcd3bfd6a1e919614.png?wh=1920x684 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/c8/14/c8dcb1b07e65893dcd3bfd6a1e919614.png?wh=1920x684"
        title="img" /></p>
<p>可以看到进程都会被分配一个 PID，也就是进程的标识符。而每个进程在执行程序的时候显然也要访问内存，也需要自己的程序计数器等资源，操作系统都会给每个进程独立分配这些资源。如果把操作系统比作一家公司的 CEO，进程就像这家公司的员工，每个员工当然需要被分配有自己独立的办公设备，而许多任务，就像是客户的需求。为了让这些员工可以有条不紊地完成这些需求，当然也就需要一定的调度算法。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/c4/0a/c4c76030ffyy7d46ef451c471673010a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/c4/0a/c4c76030ffyy7d46ef451c471673010a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/c4/0a/c4c76030ffyy7d46ef451c471673010a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/c4/0a/c4c76030ffyy7d46ef451c471673010a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/c4/0a/c4c76030ffyy7d46ef451c471673010a.jpg?wh=1920x1145"
        title="img" /></p>
<p>怎么实现调度呢？我们首先要介绍进程状态这个概念。其实就相当于每个员工当前的工作状态，我们只有知道各员工是空闲还是正在工作，才能科学分配需求，以高效完成更多任务。</p>
<h3 id="进程状态">进程状态</h3>
<p>以 Linux 内核为例，进程的状态还是比较多的，它们都被定义在 include/linux/sched.h 下，#define 是 C 语言宏相关的语法，你不熟悉的话，简单理解成左边的是变量名，右边的是变量名对应的值就好了：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">#define TASK_RUNNING                    0
#define TASK_INTERRUPTIBLE              1
#define TASK_UNINTERRUPTIBLE            2
#define __TASK_STOPPED                  4
#define __TASK_TRACED                   8

#define EXIT_DEAD                       16
#define EXIT_ZOMBIE                     32
#define EXIT_TRACE                      (EXIT_ZOMBIE | EXIT_DEAD)

#define TASK_DEAD                       64
#define TASK_WAKEKILL                   128
#define TASK_WAKING                     256
#define TASK_PARKED                     512
#define TASK_NOLOAD                     1024
#define TASK_NEW                        2048
#define TASK_STATE_MAX                  4096
</code></pre></td></tr></table>
</div>
</div><p>注意这里的 state 都是一个可以被表示成 2 的幂次的数字，这其实是一种常见的 bitset 的表示方式，方便用位运算判断状态，之后讲解布隆过滤器的时候我们再讨论。进程状态，本质上就是为了用有限的计算机资源合理且高效地完成更多的任务。我们就看一种简化的模型来学习，把操作系统进程的状态分为 3 类：READY (就绪的) 、 RUNNING（运行的）、BLOCK（阻塞的）。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/2e/c7/2e353cb4824f52d2e7e5315efa0653c7.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/2e/c7/2e353cb4824f52d2e7e5315efa0653c7.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/2e/c7/2e353cb4824f52d2e7e5315efa0653c7.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/2e/c7/2e353cb4824f52d2e7e5315efa0653c7.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/2e/c7/2e353cb4824f52d2e7e5315efa0653c7.jpg?wh=1920x1145"
        title="img" /></p>
<p>RUNNING 就是程序正在执行的状态，非常好理解，READY 和 BLOCK 要涉及程序执行中一块比较重要的耗时来源 IO。因为程序运行除了计算之外，也经常需要与外界进行交互，比如等待用户输入一串文本、或者往显示器上输出一副画面，或者从网卡接受一些数据等等，这些操作，我们一般称为 IO，也就是输入输出。计算机执行程序的时候是单进程的，如果需要等待一个 IO 操作才能执行后续指令，那在 IO 数据返回前，整个 CPU 就不会执行任何有意义的计算了，也就是只能放在那边空跑。用公司 - 员工的例子就是某个员工被一个任务阻塞了，其他员工也都只能闲着，什么都干不了，这显然不是一个好的策略。如果有了多进程就不一样了。一个正在运行的进程，如果需要等待一个 IO 操作才能执行后续命令，我们就让这个进程的状态变成阻塞的。操作系统就会把当前阻塞的进程调度开，换一个可以被执行的也就是就绪的进程去运行，被调度执行的新进程现在就成为一个运行中的进程了，而那个被调度到一边的进程 I/O 结束后，也就会重新进入就绪状态。</p>
<p>过程切换就像这样：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/dd/17/ddfaa0a4a7b6f838f4dbac2457610817.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/dd/17/ddfaa0a4a7b6f838f4dbac2457610817.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/dd/17/ddfaa0a4a7b6f838f4dbac2457610817.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/dd/17/ddfaa0a4a7b6f838f4dbac2457610817.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/dd/17/ddfaa0a4a7b6f838f4dbac2457610817.jpg?wh=1920x1145"
        title="img" /></p>
<p>这是进程的第二个意义：可以提高程序的性能，让我们不必再空等 IO 的耗时，尽可能多地利用 CPU 的计算资源。好，复习完进程相关的一些基本概念，我们进入今天的主题，调度算法。</p>
<h3 id="调度算法">调度算法</h3>
<p>一个合理的调度算法对 CPU 的利用率、程序的总体运行效率、不同任务间的公平性起着决定性的作用，这并不是一件容易的事情，因为 CPU 的算力是各进程所需的资源，但它非常有限，于是人们发明了许多不同的调度策略。考虑到不同任务的耗时和优先级两项指标，一般可以分为两大类策略：</p>
<p>非抢占式调度 抢占式调度</p>
<p>我们还是用公司 - 员工的例子来简单解释一下这两大类调度策略。公司有许多客户的需求待处理，每个员工负责一个客户的需求，但都需要用到计算机来处理自己的需求，当然不同需求的解决时间可能不同；但是公司现在只有一台计算机，这时某个员工使用这台计算机，就好像操作系统用 CPU 执行某个进程。我们的本质问题“如何用有限的计算机资源合理且高效地完成更多的任务”，现在其实就变成了如何在耗时不同的任务间合理切换进程。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/5c/b4/5ca872628f8e432035767da184dae5b4.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/5c/b4/5ca872628f8e432035767da184dae5b4.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/5c/b4/5ca872628f8e432035767da184dae5b4.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/5c/b4/5ca872628f8e432035767da184dae5b4.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/5c/b4/5ca872628f8e432035767da184dae5b4.jpg?wh=1920x1145"
        title="img" /></p>
<p>一个非常简单的想法就是让所有员工排队用这台计算机，轮到的这个员工一直使用到自己的所有工作都处理完，才让给下一个同事。这就是非抢占式调度的思路，操作系统调度到某个进程之后，不会对进程做任何干预，直到该进程阻塞或者结束，才会切换到其他就绪的进程。但如果轮到的这个员工处理完自己的工作需要 2 小时，但后几名员工都只需要几分钟，这个排序效率就不够好了。</p>
<p>考虑到这种问题，就有了抢占式调度的策略，操作系统调度到某个进程之后会给它分配一个时间片，如果超过时间片还没有结束或者中途被阻塞，该进程会被操作系统挂起，调度其他进程来执行其他程序。这就好比在公司里加了一个协调者，如果有员工用电脑时间太长，就让他先暂停一会重新排队，先把计算机分配给其他同事。这里进程的切换主要依赖操作系统的时钟中断，是一个比较复杂的机制，涉及计算机硬件，感兴趣的同学可以搜索时钟中断了解相关知识。显然，抢占式调度会有更好的公平性，不容易让资源永远被个别耗时长的程序长期霸占，而让其他任务迟迟得不到运行的机会，被饿死；<strong>但抢占式调度也带来了更多的切换次数，这会造成更高的上下文切换的成本。</strong></p>
<p>就好像不同员工如果用同一个电脑工作，那每次员工被调度开的时候，肯定要保存自己的工作状态，比如保存自己操作的一些数据并关闭文档；下一个员工来的时候，也要恢复自己之前的工作状态。这些都会产生成本。进程的切换也是一样的，我们需要保留程序运行的状态，然后重新恢复另一个进程的运行状态，像虚拟地址空间映射也需要做相应的转换以保证进程间的隔离性。如果频繁切换就会让 CPU 真正用于计算的时间比例降低。</p>
<p>所以我们很难一概而论说哪种调度方式就是更好的，一般来说：非抢占式调度，更适合调度可以忍受延迟执行的普通进程。抢占式调度，更适合调度交互性要求高的实时进程。</p>
<p>操作系统的应用场景和任务类型很多，有些场景实时性要求就更高。像在自动驾驶场景中，一些碰撞检测或者视觉信号的检测关乎驾驶员和行人的生命安全，显然不能让它们随意被其他播放音乐之类的任务阻塞。我们一定要让这些高优先级的任务可以随时抢占优先使用 CPU，而一些批处理之类的后台任务可以按照先来先到的顺序慢慢执行。接下来，我们就以 Linux 中进程调度的实现为例，讲一讲基于这两类调度策略的一些常用调度算法；当然，由于操作系统中的真实源码实现涉及 Linux 对进程的管理和存储方式，不是一两节课能讲完的需要你自己研究，所以我们会用伪代码来讲解核心思路。</p>
<h3 id="linux-的进程">Linux 的进程</h3>
<p>按相同的思路，Linux 进程其实也分为两类，一类是有实时交互需要的，它们需要尽快返回结果，不能一直得不到执行；另一类则是普通进程，大部分优先级要求不高，可以忍受更长时间的得不到执行。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/31/36/3121fa47ebb3e9cb08cdb815e2056836.jpg?wh=1920x1290"
        data-srcset="https://static001.geekbang.org/resource/image/31/36/3121fa47ebb3e9cb08cdb815e2056836.jpg?wh=1920x1290, https://static001.geekbang.org/resource/image/31/36/3121fa47ebb3e9cb08cdb815e2056836.jpg?wh=1920x1290 1.5x, https://static001.geekbang.org/resource/image/31/36/3121fa47ebb3e9cb08cdb815e2056836.jpg?wh=1920x1290 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/31/36/3121fa47ebb3e9cb08cdb815e2056836.jpg?wh=1920x1290"
        title="img" /></p>
<p>我们先来看实时交互进程中的调度算法。</p>
<h3 id="round-robin-算法">Round-Robin 算法</h3>
<p>一种最经典的实现就是 Round-Robin 调度算法，这种算法也常常作为服务器负载均衡的算法，其主要特点就是比较简单且比较公平。具体做法非常好理解，Round-Robin 本身从字面意义上来说就带有循环的意思，所以顾名思义，我们固定时间片段的长度，然后把所有的进程用一个队列维护，每个进程只能最多执行时间片的最大长度，比如 50ms，如果还没执行完或者因为 IO 等原因阻塞，就得换下一个进程执行了。</p>
<p><strong>实时进程调度的算法衡量指标之一就是平衡性</strong>，因为有实时交互需要的进程不能一直得不到执行，需要雨露均沾。比如在图形化的交互任务中，平衡性比较好的调度算法，往往就不会出现有一些计算密集型的任务过多占用 CPU 导致用户体验到卡顿的情况。所以 Round-Robin 算法最大的优势就是不会存在某个进程执行时间太长，每个程序都可以有机会得到较早的执行。看 Round-Robin 的例子，一共有 ABCDE5 个进程，arrival time 代表进程产生的时间，service time 代表进程总共需要执行的时间，单位就是时间片的长度。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/1d/8f/1d40cb1029debf1f0dc78e4474ab108f.jpg?wh=1920x1290"
        data-srcset="https://static001.geekbang.org/resource/image/1d/8f/1d40cb1029debf1f0dc78e4474ab108f.jpg?wh=1920x1290, https://static001.geekbang.org/resource/image/1d/8f/1d40cb1029debf1f0dc78e4474ab108f.jpg?wh=1920x1290 1.5x, https://static001.geekbang.org/resource/image/1d/8f/1d40cb1029debf1f0dc78e4474ab108f.jpg?wh=1920x1290 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/1d/8f/1d40cb1029debf1f0dc78e4474ab108f.jpg?wh=1920x1290"
        title="img" /></p>
<p>可以看到，在整个操作系统运行的时间里，这些进程都是轮流执行的，不会一直等待。那我们选择的时间片是不是越短越好呢？当然不是。前面说过进程切换是有开销的，每次切换都需要保存程序运行的状态，并将新的状态装载进寄存器中，这些都需要时间，这个时间大约需要 1ms。如果我们极端一点假设每个时间片只有 2ms，那么每次切换到新的进程，大约需要花费 1ms 恢复现场和保留现场，那真正留给计算机计算的时间只占了总 CPU 运行时间的 50%，这显然是一个极大的浪费，可能直接导致系统上所有的程序运行速度直接拖慢一倍！<strong>一般来说，为了平衡公平性和效率，在目前的硬件架构下，常见的时间片长度为 30-50ms。</strong></p>
<p>Round-Robin 算法的相应逻辑翻译成伪代码也非常简单：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">time_slot = 50
cur_time = 0 // 用于表示运行的时间
tasks = new queue() // 用于存储所有的进程
while (!tasks.empty()) {
  task = tasks.pop() // 选出队列前的进程运行
  if (task.time &gt; 50) { // 如果运行时间超过时间片长度，需要挂起当前进程
    tastk.time -= 50
    tasks.insert(task) // 并将该进程重新放回队列中重新排队等待下一次调度
    cur_time += time_slot
  } else {
    cur_time += task.time
  }
}
</code></pre></td></tr></table>
</div>
</div><p>当然真实的上下文切换是由时钟中断所触发的，并且如果出现阻塞，当前进程也会直接被调度走，就不在代码中演示了。在实时进程调度算法中，常用的还有高响应比优先调度 HRRN 算法和多级反馈队列调度 MFQ 算法等，简单介绍一下感兴趣可以自己搜索相关资料学习：HRRN 算法是一个非抢占式调度算法，按照“等待时间 / 执行时间”作为优先级排列，每次选择优先级最高的进程执行，直至完成。MFQ 算法比较复杂，建立了多个等级的队列，优先级高的队列中的进程总是优先得到调度且时间片短；优先级低的队列则不太容易调度，但调度到可以运行的时间片也更长一些。</p>
<h3 id="普通进程调度">普通进程调度</h3>
<p>我们再来看看实时性要求没有那么强的普通进程是如何被调度的。在这种场景下，我们通常关注的指标主要有两个：吞吐量，系统单位时间内完成的任务数量。周转时间，每个任务从提交到完成的时间。</p>
<p>常见的算法也都比较简单，主要有三种：FCFS 先到先服务算法、SJF 最短任务优先算法、SRTF 最短剩余时间优先算法，这三种算法都是非抢占式的。</p>
<h4 id="fcfs">FCFS</h4>
<p>FCFS（First Come First Serve）是最简单也最直接的，其实它和我们学过的队列很像。按照进程产生的顺序将它们放到一个队列中，每次调度的时候，直接取队列中第一个进程执行，这是一个非抢占式算法，所以直到这个任务完成或者被阻塞前，我们都会一直执行这个任务；如果这个任务被阻塞了，就重新将它加回队尾重新排队。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/73/e0/737347db194fe09a9d8cb7616926c0e0.jpg?wh=1920x1290"
        data-srcset="https://static001.geekbang.org/resource/image/73/e0/737347db194fe09a9d8cb7616926c0e0.jpg?wh=1920x1290, https://static001.geekbang.org/resource/image/73/e0/737347db194fe09a9d8cb7616926c0e0.jpg?wh=1920x1290 1.5x, https://static001.geekbang.org/resource/image/73/e0/737347db194fe09a9d8cb7616926c0e0.jpg?wh=1920x1290 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/73/e0/737347db194fe09a9d8cb7616926c0e0.jpg?wh=1920x1290"
        title="img" /></p>
<p>但不好的地方就是对短任务不是很公平，如果短任务之前有长任务，长任务就会一直执行，这样一来短任务的周转时间就被拉长了，即使完成它的时间其实很短。整体的平均周转时间也就变得比较差。</p>
<h4 id="sjf">SJF</h4>
<p>有了 FCFS 的基础，我们自然想到，让短任务更优先执行，是不是就能降低平均周转时间了呢？这就是 SJF（Shortest Job First）的思路，SJF 在从队列取出任务的时候，按照作业时间把待作业的任务排序，优先调度最短可以完成的任务。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cf/y1/cf402659ebbe49dd21e9dee8e859cyy1.jpg?wh=1920x1290"
        data-srcset="https://static001.geekbang.org/resource/image/cf/y1/cf402659ebbe49dd21e9dee8e859cyy1.jpg?wh=1920x1290, https://static001.geekbang.org/resource/image/cf/y1/cf402659ebbe49dd21e9dee8e859cyy1.jpg?wh=1920x1290 1.5x, https://static001.geekbang.org/resource/image/cf/y1/cf402659ebbe49dd21e9dee8e859cyy1.jpg?wh=1920x1290 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cf/y1/cf402659ebbe49dd21e9dee8e859cyy1.jpg?wh=1920x1290"
        title="img" /></p>
<p>SJF 因为按各任务的需要时长排序，可能导致长任务一直得到不到执行，会被饿死，而因为最短可完成时长没有把有 IO 的情况纳入计算，也就出现了下一个 SRTF 算法。</p>
<h4 id="srtf">SRTF</h4>
<p>SRTF（Shortest Remaining Time First）从思想上来说和 SJF 差不多，只不过放回队列的时候按照作业剩余时间排序，优先调度剩余完成时间最短的任务。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cc/c3/ccd22253b7b08ba6cd96f359a86e5ac3.jpg?wh=1920x1290"
        data-srcset="https://static001.geekbang.org/resource/image/cc/c3/ccd22253b7b08ba6cd96f359a86e5ac3.jpg?wh=1920x1290, https://static001.geekbang.org/resource/image/cc/c3/ccd22253b7b08ba6cd96f359a86e5ac3.jpg?wh=1920x1290 1.5x, https://static001.geekbang.org/resource/image/cc/c3/ccd22253b7b08ba6cd96f359a86e5ac3.jpg?wh=1920x1290 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cc/c3/ccd22253b7b08ba6cd96f359a86e5ac3.jpg?wh=1920x1290"
        title="img" /></p>
<p>因为都是非抢占式的调度，在没有 IO 的时候，SRTF 其实和 SJF 的机制是一样的，只不过它可以把有 IO 的情况也纳入到考虑范畴中，如果任务因为阻塞主动调度开，我们再次出队的时候不会再傻傻的按照任务总时长进行排序，而是按照剩余需要的时长进行排序，尽量提高调度整体的吞吐量。同样，SRTF 基于时长的排序策略也一定程度上放弃了公平性，和 SJF 一样，可能导致长任务一直得到不到执行。当然，其实还有许多特定场景的调度算法。比如有些系统中，我们会关心某些任务的截止时间，如果任务快到截止时间了，我们需要优先完成接近截止时间的任务。</p>
<h3 id="总结-5">总结</h3>
<p>我们讲了几个主要的 CPU 调度算法，大致可以分为抢占式调度和非抢占式调度两大类，分别更加适合调度交互性要求高的实时进程和可以忍受延迟执行的普通进程。在实时交互进程中，有简单且较公平的 Round-Robin 调度算法，在普通进程调度时，有非抢占式的 FCFS 先到先服务算法、SJF 最短任务优先算法、SRTF 最短剩余时间优先算法。不同的调度算法，有不同的使用场景，很难说哪个算法一定比另一个更好，不同的算法只是在公平性、效率、吞吐量、等待时间等因素间做了不同的取舍，我们要根据实际的需要选择合适的调度算法。而在许多操作系统之外的场景，相关的调度思想也有许多应用。比如服务器的负载均衡等场景下，我们就可以采用公平的 Round-Robin 算法进行类似的轮训请求；甚至在前端领域也有应用；比如，React 的 fiber 机制也是源于操作系统的进程调度，它很好地解决了 React 网页应用可能因为一些 diff 等需要 cpu 密集计算的操作所带来的卡顿现象，让单线程的 JS 运行时有了“多线程”般的神奇能力。</p>
<h2 id="15lru在虚拟内存中页面是如何置换的">15｜LRU：在虚拟内存中页面是如何置换的？</h2>
<p>今天我们继续讲解操作系统中另一个常用的算法， LRU 算法（Least recently used），也就是最近最少使用页面置换算法。这是操作系统中常用的内存置换策略之一，在内存有限的情况下，需要有一种策略帮助我们把此刻要用到的外存中的数据置换到内存里。该算法也同样适用于许多类似的缓存淘汰场景，比如数据库缓存页置换、Redis 缓存置换等。在开始讲解 LRU 算法本身之前，我们先来了解一下这个算法在操作系统中到底解决了什么问题。</p>
<h3 id="操作系统的缓存淘汰">操作系统的缓存淘汰</h3>
<p>我们知道，计算机是建立在物理世界上的，底层的存储计算需要依赖许多复杂的硬件：比如内存、磁盘、纷繁的逻辑电路等。所以**操作系统的一大作用就是，通过虚拟和抽象为应用开发者提供了一套操作硬件的统一接口，**而分页机制的发明，就是为了不需要让用户过度操心物理内存的管理和容量。通过虚拟内存和分页机制，用户可以在一个大而连续的逻辑地址和非连续的物理地址之间，建立起映射。其中，物理地址既可以真的指向物理内存，也可以指向硬盘或者其他可以被寻址的外部存储介质。用户的程序可以使用比物理内存容量大得多的连续地址空间；而计算机在运行程序的时候，也不再需要把进程所有信息都加载到内存里，只加载几个当前需要的页就可以了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/0c/08/0ceee08361f2d79eda633e9yyc3ca208.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/0c/08/0ceee08361f2d79eda633e9yyc3ca208.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/0c/08/0ceee08361f2d79eda633e9yyc3ca208.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/0c/08/0ceee08361f2d79eda633e9yyc3ca208.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/0c/08/0ceee08361f2d79eda633e9yyc3ca208.jpg?wh=1920x1145"
        title="img" /></p>
<p>但是内存容量并不是无限的，访问到不在内存中的其他页，硬件会触发“缺页”中断，操作系统会在内存中选出一个页，把它替换为需要访问的目标页。这样我们才能访问到需要的数据。如果你对操作系统的内存管理机制感兴趣，推荐阅读<a href="https://book.douban.com/subject/26912767" target="_blank" rel="noopener noreffer">CSAPP</a>。这种场景在各种需要缓存的系统中也很常见。比如知名的缓存中间件 Redis，就是利用内存读取数据的高效性，去缓存其他可能更慢的数据源的数据，以达到更快的 IO 速度，也用到了缓存置换算法。毕竟任何系统的存储空间都不是无限的，当我们缓存的数据越来越多，必然需要置换掉其中一部分数据。而如何选择一个合适的页面（或缓存内容）来替换，就是我们今天的重点 LRU 算法主要讨论的内容。带着这个问题，我们开始今天的学习。</p>
<h3 id="置换策略">置换策略</h3>
<p>具体怎么样的置换策略是更合理的呢？我们主要观察的指标是缓存命中率：在整个系统的生命周期里对比数据访问时，可以直接从缓存中读到的次数和数据访问的总次数。命中率越高，就代表越多数据可以直接从缓存中获取到，系统更少访问成本更高的存储，系统的整体时延就会降低。以操作系统为例，命中率高，就意味着我们发生缺页中断和从外存中获取数据的次数会减少，而访问内存的速度比访问外存要快得多，CPU 利用率当然也就会更高。在操作系统中，页面置换策略其实有很多种，你可能也知道一些，比较常见的包括 FIFO（先进先出）、LFU（最不经常使用）、LRU（最近最少使用）等。页面置换算法，在上世纪六七十年代曾经是学术界讨论的热点。其中 LRU 是实际应用最广的策略，因为它有着比较高的命中率并且实现非常简单，在虚拟内存系统中效果非常好。主要思想就是，<strong>当我们需要置换内存的时候，首先去替换最久没有被访问过的数据，这能很好利用数据的时间局部性</strong>，因为我们倾向认为最近被访问过的数据，在整个系统的生命周期里，有更大机会被访问到。</p>
<p>当然，LRU 也不都是最优的，比如在特定负载的网络代理缓存场景下，很可能使用 LRU 就并不是一个最佳选择，因为网络负载很可能在不同的时候变化很大。但是毫无疑问，LRU 在内存管理上有着绝佳的应用。下面我们结合具体例子来看看这几个页面置换策略的区别。</p>
<h3 id="时间局限性与页面置换算法">时间局限性与页面置换算法</h3>
<p>刚才提到的，时间局部性，是一个比较抽象的描述，为了更直观地讨论这些策略帮助你理解这个概念，这里用一个序列表示操作系统依次访问的页面，序列里的每个元素代表需要访问的页码。假设整个物理内存最多只能放 3 页，当页数超过 3，并访问内存中不存在的数据，就会触发缺页中断。我们把页面的访问序列叫做“引用序列”，之后的讨论都会建立在下面这个广为流传的引用序列例子上来展开，s 表示这个序列，s[i]表示第 i 次访问的页码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">7 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 7 0 1
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/2b/f6/2b91dbdc83047b5a587b496b573e6af6.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/2b/f6/2b91dbdc83047b5a587b496b573e6af6.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/2b/f6/2b91dbdc83047b5a587b496b573e6af6.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/2b/f6/2b91dbdc83047b5a587b496b573e6af6.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/2b/f6/2b91dbdc83047b5a587b496b573e6af6.jpg?wh=1920x1145"
        title="img" /></p>
<h3 id="随机页面置换算法">随机页面置换算法</h3>
<p>既然发生缺页中断时，我们需要确定一个主存中需要被替换的页，那么一种很自然而然的想法就是通过软硬件的随机发生器选择一个页面替换。也就是第一种策略，随机页面置换算法。这种思想非常简单也易于实现，但是很显然，这种算法并不令人很满意。因为它没有用到任何历史访问记录的信息，而历史信息是很有用的，也是我们唯一能用于优化命中率的依据。另外，这个算法导致同一个引用序列的产生的缺页中断次数是不稳定的，这会导致系统的性能不稳定，所以我们也不太会在实际系统中见到这样的策略。</p>
<h3 id="最优页面置换算法">最优页面置换算法</h3>
<p>现在来看第二种策略，最优页面置换算法。这能让我们更好地理解为什么需要使用历史访问信息来帮助优化命中率。从这个名字也能看出来，这个算法是一种最优的解法，但只是理论上存在的“上帝”算法，因为它的工作方式是，<strong>在替换页面的时候，永远优先替换内存中最久不被访问的那个页面，尽可能晚地触发缺页中断</strong>。第一行就是引用序列，从高到低顺次排列的三个方块就代表三个缓存页，其中绿色的块代表新替换上的页面。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/d4/de/d405722c73512e781ffdecb94df163de.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/d4/de/d405722c73512e781ffdecb94df163de.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/d4/de/d405722c73512e781ffdecb94df163de.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/d4/de/d405722c73512e781ffdecb94df163de.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/d4/de/d405722c73512e781ffdecb94df163de.jpg?wh=1920x1145"
        title="img" /></p>
<p>在例子中，我们访问 s[10] = 0 时，就可以把内存中的 4 替换掉，因为 4 在之后的访问中没有出现过。按照类似的策略，观察后续少出现的页码，尽量少触发缺页中断。所以一共只需要触发 9 次缺页中断。很明显，<strong>这并不是一个真的能被实现的算法，因为当运行程序时，并没有很好的办法去预测之后访问的页码是哪些</strong>，唯一能做的就是尽量从历史的访问记录里推测出，哪些页码可能会很长一段时间不被访问。总的来说，这个仅存在于理论上的算法主要的意义就是可以为我们衡量其他算法的好坏做一个参考。</p>
<h3 id="fifo-算法">FIFO 算法</h3>
<p>既然要利用历史记录，你是不是很自然想到放得久的数据先置换出去，也就是 First In, First out。这也就是我们要介绍的第三种策略，FIFO，先进先出算法。先进先出，这个词相信你一点也不陌生，我们在第 3 讲介绍队列数据结构的时候也有提到，队列的基本特征就是先进先出。在页面置换中，先进先出的策略是这样工作的：<strong>在每次缺页中断时，替换当前物理内存中最早被加入缓存的页</strong>。实现也很简单，可以通过一个循环链表来存储所有页。这看似比较符合直觉，但在操作系统的实际应用中表现很差。我们结合刚才引用序列的例子来看，可以画出这样的示意图：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/4a/fb/4aef317eef0858fe46014acc029c18fb.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/4a/fb/4aef317eef0858fe46014acc029c18fb.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/4a/fb/4aef317eef0858fe46014acc029c18fb.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/4a/fb/4aef317eef0858fe46014acc029c18fb.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/4a/fb/4aef317eef0858fe46014acc029c18fb.jpg?wh=1920x1145"
        title="img" /></p>
<p>可以看到，我们进行了 15 次缺页中断，和最优解相比多了很多次置换。比如在序列是 s[4…6] = 0 3 0 的时候，这里的 0 因为出现的比较早，在 s[5]时被替换成 3 后，又遇到马上要读取 0 的情况，又要做一次缺页中断的操作。所以对于符合直觉的 FIFO 算法，先加入的页面可能会被多次访问，如果经常让更早被加入但访问频繁的页面被淘汰，显然不是一个很好的策略。这意味着我们<strong>不但要用历史数据，还要更好地设计利用的方式，让策略更接近于最优算法。</strong></p>
<h3 id="lru-算法">LRU 算法</h3>
<p>今天的主角 LRU 最近最少使用算法，就是这样一种直观简单、实际检验效果也非常好的页面置换策略。通过刚才的几个例子，结合你实际使用体验，会发现在操作系统的场景下，<strong>引用序列有明显的局部相关性，每个出现的页码有比较高的概率会在相邻的一段时间里反复出现。</strong></p>
<p>上一个 FIFO 算法的一大失误就在于没有考虑局部性，当一个页码多次出现时，FIFO 并没有将这个信息记录并反映到淘汰页面的选择策略里，所以可能就会淘汰了一个近期出现过，但是之后又很快就会再次出现的页码。既然我们不能预测未来，简单替换最早的页码也不好用，那么一种很自然的想法就是，**如果某个页码在过去访问过，就尽量晚点去淘汰它。**我们可以选择内存中最近最少使用的页码进行替换，这也正是 LRU 的策略。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cc/51/ccb8c05efd5b89d7ccbbfab8e8874451.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/cc/51/ccb8c05efd5b89d7ccbbfab8e8874451.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/cc/51/ccb8c05efd5b89d7ccbbfab8e8874451.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/cc/51/ccb8c05efd5b89d7ccbbfab8e8874451.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cc/51/ccb8c05efd5b89d7ccbbfab8e8874451.jpg?wh=1920x1145"
        title="img" /></p>
<p>比如在获取数据 3 时，我们在 LRU 中替换的是最久没有被访问的 1，而在 FIFO 中我们替换了 0。但是，0 刚访问过，理论上来说之后访问的概率也会更高，不过在 FIFO 策略下，因为 0 是最早进入的被替换了，就导致了后面访问 0 时产生了一次缺页中断。相比于 FIFO，同样的例子我们只进行了 12 次缺页中断。采用 LRU 算法，大多数时候会比 FIFO 和随机策略有更好的性能。</p>
<h3 id="实现思路">实现思路</h3>
<p>既然有了基本的想法，我们就要想办法高效地实现它了。Linux 源码比较艰深且涉及的背景知识比较多，这里我们选择自己动手实现简单 LRU 的方式来进行源码级讲解。对于从指定页获取数据的操作，可以用一个 HashMap 来模拟，可以用 key 代表页面号，用 value 代表页面中具体的数据。</p>
<p><strong>所以问题可以更通用地抽象为设计一个数据结构，提供 get 和 put 两个接口</strong>。get 的时候输入一个 key，我们可以快速地访问 key 所对应的 value；put 的时候设置某个 key 对应的 value。<strong>同时这个数据结构初始化时需要设定一个 capaticy</strong>，当数据结构中的 key 数量超过 capacity 时，按照淘汰最近最少使用元素的策略进行替换，使得数据结构中最多只有 capacity 个 key-value 对。</p>
<p>之所以说是一种更通用的抽象，就是因为这不止适用于页面置换场景，也适用于许多其他缓存场景，比如在 Redis 中你就可以看到<a href="https://github.com/redis/redis-doc/blob/master/topics/lru-cache.md" target="_blank" rel="noopener noreffer">类似的数据结构</a>。对应在页面置换场景下，每次缺页中断就相当于，对该数据结构进行了 key 为指定页码的 put 操作，而 capacity，自然就是物理内存能存放的最多页数啦。为了高效地实现内存置换算法，我们大致有两个需求：</p>
<p>找到一种数据结构，使得我们可以随时快速地找到最近最少访问的页码。在每次缺页中断替换页面的时候，维护这个数据结构不会带来太多额外的成本。</p>
<p>幸运的是，LRU 的 get 和 put 的操作都是可以在 O(1) 的时间复杂度内实现的。下面我们就来看看用什么数据结构可以满足这样的需求。</p>
<h3 id="数据结构选择">数据结构选择</h3>
<p>先说 get 的部分，想在 O(1) 时间内根据 key 获取 value，很自然就会想到之前提到的哈希表。<strong>通过维护哈希表，就可以在 O(1) 时间内判断某个 key 是否存在 LRU 中，或者访问到该 key 对应的 value</strong>。但我们还要保证最近最少使用的替换策略，要想办法记录下内存中数据访问的先后关系，才可以保证最近访问过的，要比更早之前访问过的后淘汰。一种很自然的想法就是维护一个基于最近访问时间的有序列表。这当然有很多种实现方式。比如我们可以维护一个数组，从前到后依次存放最近访问过到最久没有访问过的 key。可是这样每次 get 的时候，我们就需要把数组中某个位置的 key 移动到数组的开始位置，并把后续的元素全部顺移一位。根据我们之前学到的知识，这样整体移动数组的操作的复杂度是 O(N)。那么应该怎么做呢？</p>
<p>相信好好学习前面专栏的同学已经想到了，<strong>双链表就可以实现，在 O(1) 内，删除节点并移动到指定位置的操作</strong>。我们可以构建一个双链表，让链表元素按照访问时间顺序从前到后依次排列。通过双链表 + 哈希表，就可以完美实现 LRU 基于最近访问时间排序的有序列表，这两种数据结构的组合非常常见，也有人称之为 LinkedHashMap。</p>
<h3 id="代码实现-1">代码实现</h3>
<p>下面我们来看具体的代码，这次选择语法简明、性能优秀的 Golang 作为实现语言。首先是基础的数据结构的定义。我们声明一个 LRU 的结构体，它包括以下三个成员标量：</p>
<p>size 是 LRU 的容量。innerList 是一个 Golang 内置的双链表，来表示基于最近访问时间排序的序列。innerMap 是一个 hashmap，Golang 同样提供了内置实现，我们主要用它来存储 key-value 对。</p>
<p>再定义一个 entry，表示在 innerList 中链表节点的数据结构，它同时记录了 key 和 value 的信息。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    type LRU struct {
    size      int
    innerList *list.List
    innerMap  map[int]*list.Element
  }
  
  type entry struct {
    key   int
    value int
  }

</code></pre></td></tr></table>
</div>
</div><p>然后实现 get，我们可以从 map 中基于 key 获取元素的信息，如果不存在，就直接返回不存在。因为要保证 LRU 的链表始终按照最近访问时间排序，get 之后，我们当然需要把当前 key 对应的链表节点移动到链表的最开始，所以，在 hashmap 中，可以选择直接记录链表中的节点元素。借助于 Golang 内置的双链表，只需要调用 MoveToFront 就可以简短地实现这一逻辑。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">  func (c *LRU) Get(key int) (int, bool) {
    if e, ok := c.innerMap[key]; ok {
      c.innerList.MoveToFront(e)
      return e.Value.(*entry).value, true
    }
    return -1, false
  }
</code></pre></td></tr></table>
</div>
</div><p>最后来看一下 put 操作。相比于 get 操作，代码逻辑会稍显复杂一些，同样代码会有两个支路。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">  func (c *LRU) Put(key int, value int) (evicted bool) {
    if e, ok := c.innerMap[key]; ok {
      c.innerList.MoveToFront(e)
      e.Value.(*entry).value = value
      return false
    } else {
      e := &amp;entry{key, value}
      ent := c.innerList.PushFront(e)
      c.innerMap[key] = ent
  
      if c.innerList.Len() &gt; c.size {
        last := c.innerList.Back()
        c.innerList.Remove(last)
        delete(c.innerMap, last.Value.(*entry).key)
        return true
      }
      return false
    }
  }
</code></pre></td></tr></table>
</div>
</div><p>我顺着代码简单说明一下逻辑。如果 put 的元素在 LRU 中已经存在，首先根据 innerMap 找到链表中的节点，移动到最前，并修改其中的 value 值就可以了。同样，这种情况在页面置换的场景下并不会出现。</p>
<p><strong>而如果 LRU 中不存在指定 key 对应的记录，我们就需要在链表开头插入该节点，并在容量不足的时候，淘汰一个最近最少使用的节点</strong>。这段逻辑其实也非常简单，由于链表已经是基于访问时间从近到远有序排列的了，我们直接删除链表尾部元素就行。</p>
<p>当然也需要同步在 innerMap 中删除对应的记录，否则就会有类似于内存泄漏的问题，innerMap 中的内存占用就会越来越多且永远没有机会释放。而我们需要做的也仅仅是在删除链表末尾节点前，记录下该节点对应的 key 的值，并调用 Golang 内置的 delete 方法。到这里我们就实现了最近最少访问算法所需的数据结构，它广泛运用于在实际系统里，我自己在网络组件的开发中就用到了类似的数据结构，去主动关闭超过一定数量的闲置链接，节约了大量的系统资源。</p>
<h3 id="总结-6">总结</h3>
<p>通过分页和虚拟内存的抽象，操作系统解放了用户对内存管理和容量的心智负担。当缓存的数据越来越多，如何选择一个合适的页面或缓存内容来替换，就是缓存置换算法的用武之地。页面置换策略有多种，包括随机置换、FIFO、LRU 等，非常重要且常见的 LRU 通过利用引用列表的局部相关性，提高了页面的命中率。 LRU 的实现也并不是非常复杂，但需要对链表和哈希表有很好的理解才行，所以我们一定要认真打好数据结构和算法的基础。LRU 不但是面试的常见考点，实际开发也相当常用。我在工作中就有手写过类似的数据结构，用于清理最久没有数据包上下行的非活跃链接。建议你用自己熟悉的语言实现一遍，在实现的时候，要记得多考虑一些并发场景下可能会产生的问题。</p>
<h2 id="16日志型文件系统写入文件的时候断电了会发生什么">16｜日志型文件系统：写入文件的时候断电了会发生什么？</h2>
<p>今天我们就来聊一聊操作系统最常见的外存——磁盘的问题。我们知道计算机的内存一旦断电，数据就会全部丢失，所以如果需要持久化一些数据，磁盘就是必不可少的硬件，甚至在计算机上运行的整个操作系统的大部分代码逻辑，其实也是存储在磁盘中的。计算机要和磁盘打交道，就需要用到文件系统。文件系统，其实就是操作系统中用于管理文件的子系统，它通过建立一系列诸如文件、目录，以及许多类似于 inode 这样的元数据的数据结构，把基础的文件访问能力抽象出来，给用户提供了一套好用的文件接口。和一般的数据结构和算法主要考虑性能不同，文件系统还需要考虑一件非常重要的事情——数据的可持久化。因为文件系统一定要保证，计算机断电之后整个文件系统还可以正常运作，只要磁盘没有损坏，上面的数据在重新开机之后都可以正常访问。</p>
<p>这件事听起来感觉很简单，但是真正实践起来可要难得多，在过去几十年里为了解决各种各样不同的问题，文件系统层出不穷，今天我们就来讨论其中一个问题：<strong>写文件写到一半断电了，或者因为各种各样的原因系统崩溃了，系统重启之后文件是否还能被正常地读写呢？如果不能的话，我们应该怎么办呢</strong>？这个问题，我们一般叫崩溃一致性问题（crash-consistent problem）。目前最流行的解决方案是 Linux 中的 Ext3 和 Ext4 文件系统所采用的日志方案，也就是 journaling，而 Ext3 和 Ext4 自然也就是所谓的日志型文件系统。</p>
<h3 id="崩溃一致性">崩溃一致性</h3>
<p>在讲解问题的具体解决方案之前，我们还是得先来认真审视一下崩溃一致性问题的本质：<strong>写文件的时候我们具体做了哪些事情呢？崩溃后为什么可能会产生一致性问题</strong>？这自然也就关系到文件在系统中到底是如何存储的了。不过，不同的文件系统对文件的组织方式千差万别，我们会以 Ext4 中的存储方式为例，带你简单了解演化了许多年之后现在主流的文件系统是如何存储数据的。目前最主流的持久化存储介质还是磁盘。限于磁盘的物理结构，它读写的最小单位是扇区，大小是 512B，但是每次都只读一个扇区，不利于读写效率的提升；所以文件系统普遍会把多个扇区组成一个块，也就是 block。在 Ext4 中，逻辑块的大小是 4KB，包含 8 个扇区。我们的数据自然也就是放在这一个个数据块上的。不过和内存一样，<strong>磁盘空间大小虽然大的多，但仍然是有限的，我们需要为不同的文件划分出自己的区域</strong>，也就是数据具体要存储在哪些块上的。为了更灵活地存储文件、更高效地利用磁盘空间、更快速地访问到每个文件的数据存储在哪些块上，Linux 的做法是把文件分成几块区域：至少包括超级块、索引节点区、数据块区。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/db/9a/dbe36ee8745fdb52b7953e13fb50809a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/db/9a/dbe36ee8745fdb52b7953e13fb50809a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/db/9a/dbe36ee8745fdb52b7953e13fb50809a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/db/9a/dbe36ee8745fdb52b7953e13fb50809a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/db/9a/dbe36ee8745fdb52b7953e13fb50809a.jpg?wh=1920x1145"
        title="img" /></p>
<p>超级块，是文件系统中的第一个块，用来存放文件系统本身的信息，比如可以用于记录每块区域的大小；索引节点区，每个文件对应索引节点区中的一个块，我们称为索引节点，也就是 Inode，存放每个文件中所用到的数据块的地址，Inode 也是元数据主要存储的地方；数据块区，也就是 Data Blocks，这里是真实数据存放的区域，一个文件的 inode 可能存有多个指向数据块的指针。</p>
<p>另外，为了标记哪些 Inodes 和 Data Blocks 可以被使用，操作系统还建立了两块存放 Bitmap 的区域。这样我们就可以非连续地表示各种大小的文件了，因为在索引节点上就会有很多指针链到数据区的不同区块；我们也就可以快速地获取文件所需要的数据内容了，只要在访问文件的时候根据索引节点中的指针和操作系统的磁盘调度算法，读取文件中数据块中的内容即可。</p>
<h3 id="引入元数据的问题">引入元数据的问题</h3>
<p>但是在文件系统中引入了元数据带来了灵活性的同时，也带来了问题。现在每个文件都对应一个 Inode，它记录了所有数据块的位置，可以预想到，之后在修改、创建文件的时候，除了修改数据块区的内容，也需要修改文件的元数据和 Bitmaps。比如，当我们往某个文件里追加数据，很可能就需要创建新的数据块把数据写入其中，并且在 Inode 上追加一个指向这个数据块的指针。总之这么看，<strong>每次写文件的操作其实都是一个操作序列，而不是一个单一的操作</strong>。但是，磁盘在同一时间里肯定只能接受一次读写的请求，因此文件系统就引入了崩溃一致性问题。这很好理解，我们看一个具体的例子。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/2e/20/2e5e7befb06b024741d5fdc0fbaf7420.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/2e/20/2e5e7befb06b024741d5fdc0fbaf7420.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/2e/20/2e5e7befb06b024741d5fdc0fbaf7420.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/2e/20/2e5e7befb06b024741d5fdc0fbaf7420.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/2e/20/2e5e7befb06b024741d5fdc0fbaf7420.jpg?wh=1920x1145"
        title="img" /></p>
<p>已知我们写一个文件至少会碰到 Bitmaps、Inodes 和 Data Blocks 三块数据的修改，在不会遇到崩溃的时候，我们可能就像这张图一样顺利修改了每个部分，此时文件系统没有任何问题。但假设，修改完 Inodes 了，我们把 Inodes 中某个指针指向了一段即将要存放数据内容的数据块，此时如果遭遇了断电，Data Blocks 上的内容是未知的，很可能是很早之前别的程序写过的数据，我们可以认为此时上面的数据是脏的垃圾数据。等系统恢复，我们重新去读取文件数据的时候，会发现也没有什么有效的依据供我们检验文件是否正常。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cc/fb/ccf6227b5cacab6975c67395d75328fb.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/cc/fb/ccf6227b5cacab6975c67395d75328fb.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/cc/fb/ccf6227b5cacab6975c67395d75328fb.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/cc/fb/ccf6227b5cacab6975c67395d75328fb.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cc/fb/ccf6227b5cacab6975c67395d75328fb.jpg?wh=1920x1145"
        title="img" /></p>
<p>在这种情况下，Inodes 指向的文件内容和我们的预期就会不一致，从而产生文件损坏的情况。其实和我们平时说的事务性、原子性是类似的场景。这也只是不一致的一种情况。事实上，因为操作系统会对磁盘读写的顺序做调度，以提高读写的效率，我们其实不能知道这几个写磁盘的独立步骤确切的执行顺序。不过可以想见，在其他几种写 Inodes、Data Blocks 和 Bitmaps 的顺序下，<strong>如果没有执行完全部步骤就遭遇了断电等情况，文件系统在大部分时候仍然都会进入不正确的状态，这就是崩溃一致性问题</strong>，如果你感兴趣可以模拟其他几种情况。</p>
<h3 id="如何解决">如何解决</h3>
<p>现在，我们搞清楚了崩溃一致性问题的本质，自然就要尝试解决它。历史上比较流行的解决方案有两种：一种是早期操作系统普遍采用的 FSCK 机制（file system check），另一种就是我们今天主要学习的日志机制（journaling file system）。我们先从早期的 FSCK 机制学起。</p>
<h4 id="解决方案-1fsck">解决方案 1：FSCK</h4>
<p>FSCK 机制的策略很简单：错误会发生，没关系，我们挂载磁盘的时候检查这些错误并修复就行。比如，检查发现 Inodes 和 Bitmaps 不一致的时候，我们选择相信 Inodes，而更新 Bitmaps 的状态；或者当两个 Inodes 都指向同一个 block 时，我们会把其中明显是异常的一个 Inodes 移除。但因为崩溃，毕竟有一部分信息是丢失了的，所以很多时候我们也没有办法智能地解决所有问题，尤其是前面说的 Inodes 指向脏数据的情况，事实上这种情况下，FSCK 没有办法做任何事情，因为它本质上只是让文件系统元数据的状态内部保持一致而已。但是，这还不是 FSCK 最大的问题。</p>
<p>FSCK 真正的问题是，每次出现问题需要执行 FSCK 的时候的时间非常久。因为需要扫描全部磁盘空间，并对每种损坏的情况都做校验，才能让磁盘恢复到一个合法的状态，对普通的家用电脑来说，很可能需要长达几十分钟甚至几小时的时间。所以，现在 FSCK 基本上已经不再流行，取而代之的就是日志型文件系统。</p>
<h4 id="解决方案-2journaling">解决方案 2：Journaling</h4>
<p>日志型文件系统这个方案，其实是从 DBMS 也就是数据库系统中借鉴而来的。journaling file system 的核心思想是鼎鼎大名的预写日志 WAL 也就是 write-ahead logging，这个也正是数据库系统中用于实现原子事务的主要机制，也很好理解，毕竟事务和文件系统一样，都需要保证一致性。那具体是怎么做的呢？</p>
<p>思想也很简单，就是每次在真正更新磁盘中的数据结构之前，我们把要做的操作先记录下来，然后再执行真正的操作，这也就是先写日志，WAL 中 write-ahead 的意思。这样做的好处在于，如果真的发生错误的时候，没有关系，我们回去查阅一下日志，按照日志记录的操作从头到尾重新做一遍就可以了。这样我们通过每次写操作时增加一点额外的操作，就可以做到任何时候遭遇崩溃，都可以有一个修复系统状态的依据，从而永远能恢复到一个正确的状态。对于文件系统的布局，我们也只是需要增加一块区域用于存放日志就行，改动不是很大，这块区域我们叫做日志区（Journal）。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/00/8d/0003032e2ea1bb710533c19405fe2f8d.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/00/8d/0003032e2ea1bb710533c19405fe2f8d.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/00/8d/0003032e2ea1bb710533c19405fe2f8d.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/00/8d/0003032e2ea1bb710533c19405fe2f8d.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/00/8d/0003032e2ea1bb710533c19405fe2f8d.jpg?wh=1920x1145"
        title="img" /></p>
<p>那 Journal 区里到底要存放点什么样的内容呢？这里会涉及一次完整的写文件对磁盘的一系列操作，你不熟悉的话也没有关系，就当这是几个独立的操作就行。<strong>我们核心就是要实现：希望可以通过某种记录日志的方式，让这些操作一旦决定被提交，即使后续对磁盘上元数据和数据块上数据结构的改动进行到一半，系统断电了，仍然可以根据这个日志恢复出来。</strong></p>
<p>那要怎么做呢？和数据库一样，我们为了让一系列操作看起来具有原子性，需要引入“事务”的概念。我们每次进行一次对文件的写操作，除了会先在预写日志中，记录对 Inodes 的修改记录、对 Bitmaps 的修改记录，以及对具体数据块的修改记录之外，还会同时在这几条记录的前后，分别引入一个事务开始记录和一个事务结束记录。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/47/92/477680186c827738e076726c9c24e992.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/47/92/477680186c827738e076726c9c24e992.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/47/92/477680186c827738e076726c9c24e992.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/47/92/477680186c827738e076726c9c24e992.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/47/92/477680186c827738e076726c9c24e992.jpg?wh=1920x1145"
        title="img" /></p>
<p>第一个写入的记录是 TxB，也就是 Transaction Begin 记录，最后一个写入的记录就是 TxE 也就是 Transaction End 记录，<strong>在 TxE 记录完成后，就意味着整个写文件的操作全过程都被记录在案了，我们把这个步骤叫做 Journal Write</strong>。从而，日志的组织形式就是由这样一个个事务拼接而成，日志的首尾是 TxB 和 TxE 块，中间是具体对元数据和数据块修改的记录块。当我们完成 Journal Write 操作之后，就可以放心大胆地把这些实际的元数据或文件数据覆写到磁盘上对应的数据结构中了，这个步骤我们叫做 checkpointing。当这个步骤也成功完成，我们就可以说整个写文件的操作被完成了，在全部成功的情况下当然没什么特别的，<strong>但整个设计的关键之处就在于，面对任意时刻崩溃的情况，我们也能把文件系统恢复到某一合法状态的能力。</strong></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/e7/8e/e7859d16930576ceb6f9158d21c2228e.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/e7/8e/e7859d16930576ceb6f9158d21c2228e.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/e7/8e/e7859d16930576ceb6f9158d21c2228e.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/e7/8e/e7859d16930576ceb6f9158d21c2228e.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/e7/8e/e7859d16930576ceb6f9158d21c2228e.jpg?wh=1920x1145"
        title="img" /></p>
<p>我们具体看看崩溃出现的时候，引入了 journaling 的文件系统会有什么不同吧。</p>
<p>如果崩溃出现在 journal write 步骤中假设崩溃是出现在 TxE 块完成写操作之前，那其实对系统也没有任何影响。因为相当于事务没有被成功提交，而我们写的是日志，对文件本身也没有任何实际影响。当系统断电又恢复之后，只要发现某个事务 ID 没有对应的 TxE 块，说明这个事务没有提交成功，不可能进入 checkpointing 阶段，丢弃它们对文件系统没有任何不良影响，只是相当于上次写文件的操作失败了而已。</p>
<p>如果崩溃刚好发生在 journal write 结束之后不管是刚刚写完 TxE，还是已经进入了 checkpointing 的某一步，我们的处理也都是一样的。既然事务已经被提交，系统断电恢复之后，我们也不用关心之前到底 checkpointing 执行到了哪一步，比如是已经更新了 inodes？还是 bitmaps？都没有任何影响，直接按照日志重做一遍就可以，最坏的下场也不过就是重新执行了一遍执行过的操作。</p>
<p>顾名思义，这种重做一遍的日志我们也把它称为 redo logging，它也是一种最基本、最常见的日志记录方式。不只在文件系统中，在数据库等场景下也使用非常广泛。</p>
<h3 id="总结-7">总结</h3>
<p>我们就通过引入预写日志的手段，完美解决了操作系统文件状态在崩溃后可能不一致的问题，相比于从头到尾扫描检查的 FSCK 机制。预写日志，在每次写操作的时候引入一些额外的写成本，让文件系统始终得以始终处于一种可以恢复到一致的状态，如果崩溃，只需要按照日志重放即可。当然我们其实还有很多优化可以做。比如，可以进行批量日志的更新，把多个独立的文件写操作放到一个事务里提交，提高吞吐量；或者记录日志的时候只记录元数据，而不记录文件写操作的大头数据块等等。如果你仔细看 Linux 文件系统的实现就会发现，做的优化非常多，集结了许多前人的智慧，我们可以从中领略到很多思想，也许有一天在你的工作中，这些想法就会成为你解决一些问题的关键。以我们今天学习的“日志”思想为例。我曾经在一家做安全硬件的公司实习，当时就有个需求要写一段代码用单片机往一个类似闪存的芯片里写一些状态，包含好几个独立的字段，每个字段都需要顺序地写，也就是说要分好几次独立的操作去写。但是，单片机是可能随时可以掉电的，我们如何保证这个闪存中的状态是正确的，而不是状态的某几个字段是上次写的，某几个字段是这次写的呢？其实这个问题我们就可以用类似日志的思想去解决。一种可行的方式就是，在闪存中开辟一段额外的空间，先预写日志，用 TxB 和 TxE 来标记一次完整的状态，每次启动时候先检查日志，把最新的状态覆写到指定的地址区域即可。当然事实上解决的办法要更简单一些，也更省空间，欢迎在留言区和我一起讨论。</p>
<h2 id="计算机网络">计算机网络</h2>
<h2 id="17选路算法dijkstra是如何解决最短路问题的">17｜选路算法：Dijkstra是如何解决最短路问题的？</h2>
<p>在掌握操作系统中的一些经典算法之后，我们来学习计算机的另一大基础课——计算机网络中的算法。计算机网络，当然也是一个历史悠久的科研方向，可以说之所以现在计算机世界如此繁荣，计算机网络发挥着巨大的作用，是整个互联网世界的基石。复杂的计算机网络中自然也产生了许多算法问题，比如许多经典的图论算法都是在计算机网络的研究背景中诞生的。在这一章我们会挑选几个有趣的问题一起讨论，主要涉及两种场景，计算机网络网络层的选路算法、传输层协议 TCP 中的滑动窗口思想。今天我们先来学习选路算法，有时它也被称为路由算法，“路由”这个词相信你应该很熟悉，没错，说的就是路由器里的路由。</p>
<h3 id="路由">路由</h3>
<p>我们知道，计算机网络的作用，就是通过把不同的节点连接在一起从而交换信息、共享资源，而各个节点之间也就通过网络形成了一张拓扑关系网。比如在一个局域网下，节点 A 要给节点 B 发送一条消息，如果 A 和 B 并没有直接通过网络相连，可能就需要经过其他路由设备的几次转发，这时我们需要在整个网络拓扑图中找到一条可到达的路径，才能把消息发送到目的地。每台路由器都是一台网络设备，也就是网络中的一个节点，在其中就保存有一张路由表，每次网卡收到包含目标地址的数据包（packet）时，就会根据路由表的内容决定如何转发数据。你的电脑也是一个网络上的一个节点，我们在 Mac 上通过命令就可以看到自己节点的路由表：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">netstat -nr
</code></pre></td></tr></table>
</div>
</div><p>我本地获取到的路由表如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Routing tables

Internet:
Destination        Gateway            Flags        Netif Expire
default            192.168.1.1        UGSc           en0
127                127.0.0.1          UCS            lo0
127.0.0.1          127.0.0.1          UH             lo0
169.254            link#6             UCS            en0      !
192.168.1          link#6             UCS            en0      !
192.168.1.1/32     link#6             UCS            en0      !
192.168.1.1        f4:1c:95:6d:c0:e8  UHLWIir        en0   1125
192.168.1.7/32     link#6             UCS            en0      !
192.168.1.7        3c:22:fb:94:7:cf   UHLWI          lo0
192.168.1.8        22:6:ba:99:db:c5   UHLWIi         en0    847
192.168.1.11       f6:f0:14:1b:9f:68  UHLWIi         en0   1002
192.168.1.12       ae:ea:e4:f2:a4:69  UHLWI          en0   1063
224.0.0/4          link#6             UmCS           en0      !
224.0.0.251        1:0:5e:0:0:fb      UHmLWI         en0
239.255.255.250    1:0:5e:7f:ff:fa    UHmLWI         en0
255.255.255.255/32 link#6             UCS            en0      !
</code></pre></td></tr></table>
</div>
</div><p>路由表的每一行都代表一条路由规则，至少会包括两个信息，也就是路由表的前 2 列：目标网络地址（Destination）：标示 IP 包要去往的目标网络下一跳地址（Gateway）：与当前路由器相邻的路由器，命中这条规则的数据包应该经由这个路由器转发去往最终目的地</p>
<p>这里的后 3 列我也顺带简单介绍一下，flag 是路由的一些信息，netif 指的是网络物理接口，expire 代表过期时间，你感兴趣的话可以去查阅 Linux 手册详细了解。因为每个数据包里包含了目标地址，所以路由器工作的基本原理就是，网卡基于路由表匹配数据包对应的规则，转发到下一跳的路由器直至抵达终点就可以了。</p>
<h3 id="路由表">路由表</h3>
<p>那这个路由表怎么来呢？主要有两种方式。一种就是我们手动管理配置。Linux 提供了简单的配置命令，既可以根据路由 IP 配置路由表，也可以基于一定的策略配置，查阅 Linux 手册即可。这种方式也被称为静态路由表，最早期的网络就是这样由网络管理员手动配置的。但如果网络结构发生变化，手工修改的成本就非常高。为了解决这种问题，第二种方式——动态路由表就应运而生，它可以根据协议在网络中通过节点间的通信自主地生成，网络结构变化时，也会自动调整。而生成动态路由表的算法，就是我们的选路算法。所以，<strong>选路算法所做的事情就是，构建一个动态路由表，帮每个数据包都选择一条去目标 IP 最快的路径</strong>。那在路由选路问题中，什么是最快路径呢？</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/12/c0/12f070830974f3b6aee9d86a22c0dec0.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/12/c0/12f070830974f3b6aee9d86a22c0dec0.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/12/c0/12f070830974f3b6aee9d86a22c0dec0.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/12/c0/12f070830974f3b6aee9d86a22c0dec0.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/12/c0/12f070830974f3b6aee9d86a22c0dec0.jpg?wh=1920x1145"
        title="img" /></p>
<p>我们知道信息在网络上传输肯定是需要经过物理传输的，各设备之间的距离以及不同设备本身的网络连接情况都是不同的，都会影响节点间传输的时间。如果我们把不同节点之间的通信时间当作距离，<strong>整个拓扑图上搜索最快路径的过程，其实就等价于求图上的最短路问题</strong>。求解最短路的算法，相信你也学过不少了，比如基于 BFS 的 SPFA、基于贪心思想的 Dijkstra、基于动态规划思想的 Bellman-Ford 等算法。这些算法在选路问题中也有应用，最经典的两种就是基于 Dijkstra 实现的链路状态算法和基于 Bellman-Ford 实现的距离矢量算法。今天我们就来先学习鼎鼎大名的 Dijkstra 算法，看看它是如何解决最短路问题的（链路状态算法和距离矢量算法在后两讲学习）。</p>
<h3 id="dijkstra-算法">Dijkstra 算法</h3>
<p>Dijkstra 算法是一个非常经典的求解单源最短路 (Single Source Shortest Path) 问题的算法，但它有一个巨大的限制：只能用于没有权重为负的边的图。在分析这一限制之前，我们还是先来严谨地定义一下最短路问题。假设我们有一张图 G=(V,E)，图中共有 v 个节点，它们之间有 e 条无向边。其中，各节点的集合用 V 表示，边的集合用 E 表示，边权 weight 就代表该边两点之间的距离。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/37/63/376c6c2ac008950944f971712f703963.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/37/63/376c6c2ac008950944f971712f703963.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/37/63/376c6c2ac008950944f971712f703963.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/37/63/376c6c2ac008950944f971712f703963.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/37/63/376c6c2ac008950944f971712f703963.jpg?wh=1920x1145"
        title="img" /></p>
<p>单源最短路问题就是要在这张图上求出从源点 s 到图上任意其他点的距离最短的路径，一条路径的长度 / 距离大小就是这条路径上所有边的权重和。具体怎么做呢？估计你也想到了，一个比较直觉的思路就是贪心思想，我们从离 s 最近的点开始记录，然后找次之的点、再次之点，逐步推进。</p>
<p>我们先找出距离源点 s 最近的节点它一定是和 s 直接相连的节点中距离最近的一个，这是因为所有和 s 构成二度关系的节点都会经过一个和 s 直接相连的节点，距离不会短于这个直接相连的节点，所以这个节点一定是所有节点中到 s 距离最近的节点，我们把这第一个节点记录为 v1。</p>
<p>然后再找出距离 s 次近的节点这时刚找到的 v1 就有可能成为次短路径的一部分了，我们需要在和 s、v1 直接相邻的节点中，再次找出除了 v1 之外到 s 距离最短的节点，它一定是剩余节点中到 s 最近的节点。</p>
<p>依次类推，就可以求出 s 到所有节点的最短路径了Dijkstra 算法其实就是这样做的，它引入了一种叫做最短路径树的构造方法。按照刚才说的基于贪心的思想逐步找出距源点 s 最近、次近的点，就能得到一个 G 的子图，里面包含了 s 及所有从 s 出发能到达的节点，它们以 s 为根一起构成了一颗树，就是最短路径树。找到了这颗树，我们自然也就求出了 s 到所有节点的最短距离和路径了。</p>
<h3 id="思路">思路</h3>
<p>为了把我们刚才直觉的想法用编程语言更精确的描述出来，需要引入一种叫做“松弛（relax）”的操作，结合例子来讲解这个过程。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/1d/a0/1df55e2995c7a84yy5ef39d5fffdcca0.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/1d/a0/1df55e2995c7a84yy5ef39d5fffdcca0.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/1d/a0/1df55e2995c7a84yy5ef39d5fffdcca0.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/1d/a0/1df55e2995c7a84yy5ef39d5fffdcca0.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/1d/a0/1df55e2995c7a84yy5ef39d5fffdcca0.jpg?wh=1920x1145"
        title="img" /></p>
<p>假设现在有了一张有向图 G，其中包含了 0、1、2、3、4 这 5 个节点，节点之间的边权代表距离，都标在图上了，比如节点 0 和节点 1 之间的边权 / 距离是 2。假设 0 节点是源点 s，我们如何构造出这棵以 s 为根的最短距离树 T 呢？</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/87/a7/87a4ff4fd05614b61647dc59021842a7.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/87/a7/87a4ff4fd05614b61647dc59021842a7.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/87/a7/87a4ff4fd05614b61647dc59021842a7.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/87/a7/87a4ff4fd05614b61647dc59021842a7.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/87/a7/87a4ff4fd05614b61647dc59021842a7.jpg?wh=1920x1145"
        title="img" /></p>
<p>整个构造过程是一步步从原点向外扩张的，我们可以用一个数组 dis 标记源点 s 到其他节点的距离。由于刚开始树 T 中只有根节点 s，此时：大部分不和 s 直接相邻的节点到 s 的距离都是未知的，我们可以暂时记录为 Inf，代表无限大；和 T 直接相邻的节点就是我们的候选节点，在最开始时也就是 s 的所有邻节点。我们每次从中选择距离 s 最短的一个节点加入树 T 中，只需要遍历所有节点到 s 的距离就可以得到这个节点，我们记作 u。</p>
<p>比如对于节点 0 而言，1 就是目前候选集里到 s 最近的节点。那每次挑出最短节点 u 加入 T 中之后，T 的候选集显然就多了一些选择，u 的所有相邻的节点以及它们到树的距离都可以被发现了。但 u 的邻节点 v，到源点 s 的距离有两种可能。</p>
<p>第一种情况 dis[v] = Inf，代表这个节点 v 还没有被加入过候选集中，也就是之前和源点 s 不直接相邻。比如图中从 1 节点搜索 4 节点的时候就是这种情况。我们可以把 v 加入 T 中，并记录 dis[v] = dis[u]+edge[u][v]，这很显然是目前发现的、能到 v 的最短距离，但它依旧有可能在后续遍历过程时被更新，我们叫做“松弛操作”。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/ed/73/edc14abe7bc2dc2fef2b91a16dcef873.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/ed/73/edc14abe7bc2dc2fef2b91a16dcef873.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/ed/73/edc14abe7bc2dc2fef2b91a16dcef873.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/ed/73/edc14abe7bc2dc2fef2b91a16dcef873.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/ed/73/edc14abe7bc2dc2fef2b91a16dcef873.jpg?wh=1920x1145"
        title="img" /></p>
<p>第二种情况 dis[v]!=inf，这说明 v 已经被加入到候选集中了，也意味着之前有其他路径可以到达 v。这个时候，我们要比较一下经由 u 到达 v 是不是一条更短的路径，判断 dis[u]+edge[u][v] 是否小于 dis[v]，如果小于就要更新 dis[v] = dis[u] + edge[u][v]。比如图中从 1 节点搜索 3 节点的时候就是这种情况。</p>
<p>更新的操作其实就是“松弛”，不过我个人觉得“松弛”不是一个很好理解的说法，因为松弛操作实际上是让这条路径变得更短，不过因为 Dijkstra 是用“relax”来描述这个更新操作的；所以我们也翻译成松弛操作。我们再来一起结合例子梳理一遍搜索的全过程。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/21/fd/2177883e997b4a2d9ee4d0ee17a143fd.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/21/fd/2177883e997b4a2d9ee4d0ee17a143fd.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/21/fd/2177883e997b4a2d9ee4d0ee17a143fd.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/21/fd/2177883e997b4a2d9ee4d0ee17a143fd.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/21/fd/2177883e997b4a2d9ee4d0ee17a143fd.jpg?wh=1920x1145"
        title="img" /></p>
<p>在整个构造过程中会依次把 0、1、3、2、4 节点入队，入队时，它们都是候选集到 s 中距离最短的节点。在没有负边的情况下，这就保证了剩余的节点距离一定长于这个节点，也就不会出现入队之后节点距离仍然需要更新的情况，每个加入树中节点的距离在加入的那一刻就已经被固定了。入队的时候，我们也探索到了一些可能和树相接且到 s 更近的节点，需要对它们进行“松弛”，并加入候选集合。比如 0-3 节点的距离开始是 7：但在 1 节点加入候选集之后，我们就可以经由 1 去往 3，这时 3 到 0 的距离就会被更新为 5，而不再是 7 了；这个时候 3 节点（0-1-3）已经是所有剩余节点中到 s 最近的节点了，我们把它加入树中，dis[3]=5 也不会有机会再被其他节点更新了。</p>
<h3 id="代码">代码</h3>
<p>理解了这个过程，翻译成代码也就比较简单了，力扣上的743 网络延迟时间就是一道典型的最短路应用题，有多种解法。这个题正好是建立在网络的场景下的，求从源点 s 出发把消息广播到所有节点的时间，节点之间的边就代表着网络传输的延时，也就是求 s 到图上所有节点最短距离的最大值。用我们今天学的 Dijkstra 算法就可以求解，实现代码贴在这里供你参考：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">class Solution {
public:
    int networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int n, int k) {
        // 标记未被探索的节点距离
        const int inf = INT_MAX / 2;
        // 邻接表
        vector&lt;vector&lt;int&gt;&gt; g(n, vector&lt;int&gt;(n, inf));
        // 构图
        for (auto time: times) {
            g[time[0] - 1][time[1] - 1] = time[2];
        }

        vector&lt;int&gt; dist(n, inf); // 所有节点未被探索时距离都初始化为无穷
        vector&lt;bool&gt; used(n, false); // 标记是否已经被加入树中
        dist[k - 1] = 0; // 记录原点距离为0
        
        for (int i = 0; i &lt; n; ++i) {
            int x = -1;
            // 找出候选集中到S距离最短的节点
            for (int y = 0; y &lt; n; ++y) {
                if (!used[y] &amp;&amp; (x == -1 || dist[y] &lt; dist[x])) {
                    x = y;
                }
            }
            // 加入树中
            used[x] = true;
            // 基于x 对所有x的邻节点进行松弛操作
            for (int y = 0; y &lt; n; ++y) {
                dist[y] = min(dist[y], dist[x] + g[x][y]);
            }
        }
        
        // 取出最短路中的最大值
        int ans = *max_element(dist.begin(), dist.end());
        return ans == inf ? -1 : ans;
    }
};
</code></pre></td></tr></table>
</div>
</div><p>代码中的 dist 用于标记距离，used 用于标记树中的节点，每次我们都会从候选节点中挑选出到 s 最短的节点，并基于它对其邻节点进行“松弛”操作；等整个最短路问题求解完毕，最后再从所有距离中取出最大值就可以了。时间复杂度也很好分析，整个代码中一共有两层循环，外层循环就是每次把一个节点加入树中，一共进行 n 次；内层循环有两段，分别用于找出最短节点和对所有邻居进行“松弛”操作，最多也不会超过 2*n 次计算。所以，整体时间复杂度为 O(n^2)。</p>
<h3 id="总结-8">总结</h3>
<p>网络路由算法，核心就是在动态变化的网络中，基于探测和寻找最快传输路径的想法，帮助路由器建立路由表，让每个数据包都可以快速且正确地传播到正确目的地。首先我们需要想办法解决最短路的问题，Dijkstra 就是这样一种在没有负边的图中求解单源最短路的算法，基于贪心的思想，我们构造一颗最短路径树就可以求出从源点到网络中所有节点的最短路径了。核心的就是松弛操作，每次加入一个最短节点之后，我们还需要基于它去探索一遍和它相临的节点是否距离更短，比如从不可达变成可达，或者从一条更长的路变成一条更短的路。Dijkstra 算法实现起来还是有一定难度的，你可以多去力扣上找几道题目练手检验一下学习效果；另一个有效的检验方式就是参考费曼学习法，你可以试着给你的朋友讲一下为什么 Dijkstra 算法不支持负边，这也是 Dijkstra 算法非常重要的一个约束，如果能讲清楚你也就理解精髓了。有了 Dijkstra 算法，我们也就可以求解网络路由中的最短路问题了。后两讲学习我们将学习最经典两种路由的算法：基于 Dijkstra 算法实现的链路状态算法、基于 Bellman-Ford 实现的距离矢量算法。</p>
<h2 id="18选路算法链路状态算法是如何分发全局信息的">18｜选路算法：链路状态算法是如何分发全局信息的</h2>
<p>上一讲，我们介绍了网络中选路算法的背景和单源最短路问题的经典算法 Dijkstra 算法，还记得为什么网络中需要选路算法吗？计算机网络很复杂，但核心作用就是把不同的节点连接在一起，交换信息、共享资源，每个节点自己会维护一张路由表，选路算法所做的事情就是：构建出一张路由表，选择出到目标节点成本最低通常也是最快的路径。而 Dijkstra 算法是求解单源最短路问题的经典算法，基于贪心的思想，我们从源点开始，一步步搜索最近路径，构造一颗最短路径树。它在网络路由问题中的应用就是我们今天要学习的链路状态算法。具体如何解决网络路由问题呢？带着这个问题，我们马上开始今天的学习。</p>
<h3 id="网络路由问题">网络路由问题</h3>
<p>我们知道路由器最大的作用就是转发决策，动态路由算法的作用就是，帮助路由节点在动态变化的网络环境下建立动态变化的路由表，而每个路由表记录，本质就是当前节点到目标节点的最短路。</p>
<p>链路状态算法的思路就是：先在每个节点上都通过通信构建出网络全局信息，再利用 Dijkstra 算法，计算出在当前网络中从当前节点到每个其他节点的最短路，从而把下一跳记录在路由表中。对于最短路问题，我们可以用之前学过的转化为图问题的思路，把网络抽象成一个有向图，也就是网络拓扑图。图中每个节点就是一台台路由设备，而节点之间的边的权重（边权）就代表着某种通信成本，我们一般叫链路成本，它有很多种定义方式，比如：</p>
<p>网络通信时间，最常用的成本衡量标准，选出了最短路也就意味着选出了网络当前时刻下，从源节点到目标节点延时最低的数据传输路线。带宽或者链路负载，有时候也会作为成本的度量，带宽大负载低的路径成本就低，反之成本更高；在这种构建方式下，选出的是带宽比较充裕的路线，用户往往可以享受到更快的带宽速度。</p>
<p>后面我们会以网络通信时间也就是链路延时作为链路成本的策略来讨论，其他指标核心的问题解决思想是类似的。这里你可能会问了，为什么网络是一个有向图呢？道理很简单，我们以延时作为边权的场景为例，两个节点双向通信的速度很可能是不一样的，所以自然是一个单向图。有了拓扑图的定义，我们如何在每个节点中都构建出这样一张带有整个网络信息的图呢？这个问题还是没有解决。在这个动态路由问题里，所有的节点其实都只是网络中的一部分，不同于静态路由的管理员直接有全局的上帝视角，动态路由下的每个节点能真正触达的信息，也只有和自己直接相邻的节点传来的 0 和 1。所以，要构建网络，我们自然也只有通过通信的方式了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/de/9a/dee13429284da262677dcde29f4b4f9a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/de/9a/dee13429284da262677dcde29f4b4f9a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/de/9a/dee13429284da262677dcde29f4b4f9a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/de/9a/dee13429284da262677dcde29f4b4f9a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/de/9a/dee13429284da262677dcde29f4b4f9a.jpg?wh=1920x1145"
        title="img" /></p>
<p>在各种网络选路协议中，OSPF 协议采用的就是链路状态算法，它把链路状态信息的获取分成了 4 个主要步骤：发现节点、测量链路成本、封装链路状态包、发送链路状态包。</p>
<h3 id="发现节点">发现节点</h3>
<p>节点想要获取全局的链路信息，显然只能通过和邻居间交换自己知道的信息，才有可能构建出全局的网络图。那第一步当然是要发现和自己相邻的所有节点，并在本地维护这个邻居信息。发现节点具体怎么做呢？其实也很简单，就是直接向网络广播一条hello消息，我们称为hello包。所有能直接收到这条消息的一定都是一跳的邻居。协议规定，收到这条消息的节点必须回应一条 Response 消息，告知自己是谁。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/6d/f4/6d3f79f85385a40ab91bc7fca110e9f4.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/6d/f4/6d3f79f85385a40ab91bc7fca110e9f4.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/6d/f4/6d3f79f85385a40ab91bc7fca110e9f4.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/6d/f4/6d3f79f85385a40ab91bc7fca110e9f4.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/6d/f4/6d3f79f85385a40ab91bc7fca110e9f4.jpg?wh=1920x1145"
        title="img" /></p>
<p>所以每个节点只要统计自己发出 hello 后收到的回应数量，就可以知道自己和哪几个节点相邻，也知道了它们的地址之类的信息，保存在本地就可以了。</p>
<h3 id="测量链路成本">测量链路成本</h3>
<p>现在每个路由器都有了自己的邻居信息，接下来要做的就是衡量边权也就是链路成本。每个节点想要衡量自己和邻居之间的传输成本，没什么别的办法，试一下就行了。协议规定，每个节点向自己的邻居发送一个特殊的 echo 包，邻居收到之后，必须原封不动地把 echo 再返回给发出 echo 的节点，这样，每个节点只需要统计一下自己从发出 echo 到收到 echo 的时间差，就可以用它来估计和邻居之间的网络传输时延了，从而也就可以计算出链路状态算法所需要的链路成本了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/df/15/df081e4805372fff841622559c273f15.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/df/15/df081e4805372fff841622559c273f15.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/df/15/df081e4805372fff841622559c273f15.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/df/15/df081e4805372fff841622559c273f15.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/df/15/df081e4805372fff841622559c273f15.jpg?wh=1920x1145"
        title="img" /></p>
<p>当然由于网络传输是不稳定的，我们会多次测量，取出均值，这样的时间我们有时也叫 RTT，round-trip-time。如果你经常打游戏，可能会在测速工具或者游戏界面中看到过这个词，RTT 是最常见的用于衡量网络时延情况的指标，在许多系统里都会用到。我在工作中维护过的长连接网关就有一个这样的需求，要求采样统计消息时延作为监控指标，我们当时就会定期在应用层面上发送 echo 包，统计来回时间，以达到监控网络情况的效果。</p>
<h3 id="封装链路状态包">封装链路状态包</h3>
<p>现在，每个路由器都知道自己到所有邻居节点的链路成本了。要让每个节点都能构建出整个网络图，显然需要让自己知道的信息尽快扩散出去，也尽快收集别人的信息来拼接出整个路由的拓扑图。这就要求我们把每个节点已知的信息封装成一个数据包，然后在网络中广而告之。这个数据包我们就叫做链路状态包，链路状态包中至少要包含几个字段呢？</p>
<p>首先是本机 ID，指出链路状态包的发送方，说明当前节点是谁；其次，我们前两步获得的已有链路信息当然也要写上，也就是找的到邻居列表和当前节点到每个邻居的链路成本（前面测出来的通信时延）。另外我们知道网络是在时刻动态变化的，考虑到包的有效性问题，每个包不可能是永久有效的，过了一段时间之后就应该让这个包自动失效。所以还需要一项生存期，标记这个包中的成本记录有效的时间窗口。<strong>除此之外，OSPF 协议还引入了一个关键字段：序号，标示当前状态包是发送方发出的第几个包</strong>。因为在网络中传输内容时，出于各种原因可能会产生错序的情况，这个序号就能帮助接收方衡量这个包是老的包还是新的包。其实，序号这种思想贯穿了计算机网络各个层次协议的设计，在许多应用场景下也会通过序号，帮助我们进行消息传递的排序或者去重。在 OSPF 协议中 4 项内容是这样组织的，本机 ID、序号、生存期、邻居｜成本，你可以看这张图：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/73/9f/73d6373992031a1c06745babae8e4f9f.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/73/9f/73d6373992031a1c06745babae8e4f9f.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/73/9f/73d6373992031a1c06745babae8e4f9f.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/73/9f/73d6373992031a1c06745babae8e4f9f.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/73/9f/73d6373992031a1c06745babae8e4f9f.jpg?wh=1920x1145"
        title="img" /></p>
<h3 id="发送链路状态包">发送链路状态包</h3>
<p>有了链路状态包，那最后一个步骤自然是发送这些包。为了确保所有的包都能被可靠地传输到每个节点，避免出现各个节点路由构建不一致等问题，我们采用泛洪的方式进行传输。<strong>泛洪，也是在计算机网络中常用的一种传播消息的机制，类似广播，每个节点都会把自己封装好的包和收到的包，发送或转发给所有除了该包发送方的节点。</strong></p>
<p>这样，经过一小段时间的传播，每个节点就可以收到整个网络内所有其他节点的邻居信息，从而也就相当于有了一个拓扑图中邻接表的全部信息，自然就可以在内存中构建出一张完整的带有边权的有向图了。构造方式和我们之前讲解拓扑排序中构造图的过程是很类似的，你不熟悉的话也可以回去复习一下。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/b9/68/b97b3de96aa93a504c7836195a337d68.jpg?wh=1920x1330"
        data-srcset="https://static001.geekbang.org/resource/image/b9/68/b97b3de96aa93a504c7836195a337d68.jpg?wh=1920x1330, https://static001.geekbang.org/resource/image/b9/68/b97b3de96aa93a504c7836195a337d68.jpg?wh=1920x1330 1.5x, https://static001.geekbang.org/resource/image/b9/68/b97b3de96aa93a504c7836195a337d68.jpg?wh=1920x1330 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/b9/68/b97b3de96aa93a504c7836195a337d68.jpg?wh=1920x1330"
        title="img" /></p>
<h3 id="计算路由">计算路由</h3>
<p>现在每个节点都有了这样一张有向图，每个节点自然就可以利用之前我们讲解的 Dijkstra 算法，在有向图中计算出自己到网络中任何其他所有节点的最短路径。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">A的最短路
A-&gt;B
A-&gt;B-&gt;D
A-&gt;B-&gt;D-&gt;E
A-&gt;B-&gt;D-&gt;E-&gt;F
A-&gt;C
</code></pre></td></tr></table>
</div>
</div><p>以拓扑图中 A 节点到其他节点的最短路计算为例，我们可以很容易得到每个节点的路由表：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">A的路由表
Destination Gateway  
    B          B
    C          C
    D          B
    E          B
    F          B
</code></pre></td></tr></table>
</div>
</div><p>比如从 A 到 E 的最短路径是 A、B、D、E，那么在路由表中，只需要记录到 E 的下一跳是 B 就可以了。每个节点都进行类似的过程，数据包就可以在这些节点各自构建的路由表的基础上正确地传输了。总的来说，OSPF 协议中的链路状态算法通过 4 步，先在每个节点上都通过通信构建出网络全局信息，再利用 Dijkstra 算法，计算出当前网络中从当前节点到每个其他节点的最短路，把下一跳记录在路由表中。但到目前为止，我们还没有看到链路状态算法路由动态性的体现。</p>
<h3 id="链路状态的动态性">链路状态的动态性</h3>
<p>链路状态算法之所以是动态路由算法，还有很重要一个点就是链路状态是可以根据网络的变化自动调整的。这就要涉及今天要重点学习的最后的一个知识点了：链路状态包是什么时候发送的？链路状态发送主要有两个时机：</p>
<p>一是我们会指定一个周期，让每个路由器都定时向外泛洪地发送链路状态包，比如 30s 一次。有点像心跳机制，如果长时间没有收到某个节点的链路状态包，这个节点随着之前的包中的生存期到期，就会被认为是失效节点，不会再被路由算法选作传输路线了。另一个就是当每次发生重大变化，比如节点上下线、网络情况变动等等，相关节点有可能的话也会主动向外快速扩散这些消息，让网络尽快得到动态的修正。</p>
<p>这样简单的策略是非常强大的，以链路延时为成本的链路状态算法甚至可以非常智能地避免网络的阻塞。我们看个例子。构建网络拓扑图之后，t0 时刻，发现 A 和许多其他节点去往 H 的路由都是通过 G 转发最快，那这个时候，大量的信息都会发送到 G 路由节点中待转发。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/48/a4/480309ab501d9b965f0c23b2032551a4.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/48/a4/480309ab501d9b965f0c23b2032551a4.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/48/a4/480309ab501d9b965f0c23b2032551a4.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/48/a4/480309ab501d9b965f0c23b2032551a4.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/48/a4/480309ab501d9b965f0c23b2032551a4.jpg?wh=1920x1145"
        title="img" /></p>
<p><strong>但计算机网络中有个“拥塞”的情况，每个节点在单位时间里能处理的信息是有限的，剩余的信息转发就需要排队，总传输时间也就变得更长了</strong>。所以，当 G 节点处理的消息越来越多时，G 节点就很容易进入拥塞的状态，经过 G 转发的链路成本也都会飙升。但是没有关系，我们的动态路由算法很快就会发现这件事情，G 自己就会更新到 H 的链路成本，比如从 4 变成 7，那再稍后的 t1 时刻，路由 A 到 H 的路由选择就从 AGH 变成了 ABEFH，不再经过 G 转发了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/30/b5/30c9711a8079e431eb447c47f6dfd3b5.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/30/b5/30c9711a8079e431eb447c47f6dfd3b5.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/30/b5/30c9711a8079e431eb447c47f6dfd3b5.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/30/b5/30c9711a8079e431eb447c47f6dfd3b5.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/30/b5/30c9711a8079e431eb447c47f6dfd3b5.jpg?wh=2312x1379"
        title="img" /></p>
<h3 id="总结-9">总结</h3>
<p>至此，整个链路状态动态路由算法我们就学完了。动态路由算法中基于 Dijkstra 算法的链路状态算法，核心思路就是通过节点间的通信，获得每个节点到邻居的链路成本信息，进而在每个节点里都各自独立地绘制出全局路由图，之后就可以基于我们上一讲学过的 Dijkstra 算法构建出路由表了。每个节点虽然有了全局的信息，但在路由表中我们依然只需要管好自己就行，只要每个节点都履行好自己的转发义务，数据包就可以正确有效地在动态变化的网络中传输了。链路状态中为了解决不同的问题引入了许多手段。比如，状态包通过周期和发生变化时的发送，可以让整个路由表动态地被更新、给包加序列号进行消息传递的排序或者去重，避免过期的信息因为延迟导致误更新、通过定期发送 echo 包统计来回时间，来测量网络时延监控网络情况等等。这些思想在许多场景下也多有应用，你可以好好体会。</p>
<h2 id="19选路算法距离矢量算法为什么会产生无穷计算问题">19｜选路算法：距离矢量算法为什么会产生无穷计算问题？</h2>
<p>动态路由问题相信你已经理解了，上两讲我们也一起学习了解决这个问题的一种经典选路算法——基于 Dijkstra 算法思想的链路状态算法，核心就是每个节点，通过通信收集全部的网络路由信息，再各自计算。如果说链路状态算法的思想是全局的、中心化的，我们今天要学习的距离矢量算法就是本地的、非中心化的，交换信息的数据量会比链路状态少很多。因为在基于距离矢量算法下的选路协议下，节点之间只用交换到网络中每个其他节点的距离信息，不用关心具体链路，也就是我们所说的距离矢量，而不是泛洪地转发整个网络中每条边的信息。具体是如何做到的呢？这背后计算最短路的核心思想就是 Bellman-Ford 算法。</p>
<h3 id="bellman-ford-算法">Bellman-Ford 算法</h3>
<p>我们就先来学习 Bellman-Ford 算法，它同样是一种反复执行“松弛”操作去计算源点 S 到网络中其他节点距离最短路径的算法，所以学过 Dijkstra 算法的思想，我们再理解 BellmanFord 算法是比较简单的。不过，和 Dijkstra 用到的贪心思想不同，Bellman-Ford 算法采用的是动态规划（dynamic programming）的思想。首先用同样的数学语言来描述整个图，图 G=(V,E) 包含 V 个顶点 E 条边，源点是 s，weight 表示节点之间的距离，weight[u][v]表示节点 u 和节点 v 之间的距离，distance[u]表示从 s 到 u 的最短距离，在整个算法过程中我们会不断地更新也就是松弛这个距离 distance[u]的值。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/6e/ce/6eb9440fd991116929ef63cff06986ce.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/6e/ce/6eb9440fd991116929ef63cff06986ce.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/6e/ce/6eb9440fd991116929ef63cff06986ce.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/6e/ce/6eb9440fd991116929ef63cff06986ce.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/6e/ce/6eb9440fd991116929ef63cff06986ce.jpg?wh=1920x1145"
        title="img" /></p>
<p>Bellman-Ford 的核心思路就是我们遍历所有的边 e=(u,v) ，并进行松弛操作，也就是判断 distance[v]是否小于 distance[u]+weight[u][v]，如果是的话，就把 distance[v]设为 distance[u]+weight[u][v]，这也标志着在这次遍历中，我们为 v 找到了一条从 s 出发抵达 v 更近的路线。为了保证正确计算出从源点 s 到每个其他顶点的最短路径，怎么做呢？其实也很简单，我们只要把这个遍历松弛的过程重复（V-1）次，也就是图上除了自己之外的顶点数量次。这样，在每次遍历所有边松弛的过程中，distance[v]被计算正确的节点都会增加，最终，我们就可以得到所有节点的最短路径（如果你对这个方法有疑惑，我们稍后会梳理证明过程）。相比 Dijkstra 算法每次贪心地找最短节点进行松弛的方式，Bellman-Ford 直接多轮遍历所有边的松弛方式显然可以适应更广的应用场景。比如现在负边就不再是一个困扰了，我们不再需要考虑每个节点加入最短距离树之后，可能会因为存在负边而被重新更新距离的情况。和 Dijkstra 算法一样，Bellman-Ford 中第 i 轮松弛结束之后，可以确定至少有 i 个节点到原点的最短路被确定了，但我们不再知道（当然也没有必要知道）是哪一个了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/00/69/008c9bb6f501a6b622869bcf07cfc969.jpg?wh=2312x1379"
        data-srcset="https://static001.geekbang.org/resource/image/00/69/008c9bb6f501a6b622869bcf07cfc969.jpg?wh=2312x1379, https://static001.geekbang.org/resource/image/00/69/008c9bb6f501a6b622869bcf07cfc969.jpg?wh=2312x1379 1.5x, https://static001.geekbang.org/resource/image/00/69/008c9bb6f501a6b622869bcf07cfc969.jpg?wh=2312x1379 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/00/69/008c9bb6f501a6b622869bcf07cfc969.jpg?wh=2312x1379"
        title="img" /></p>
<p>这个代码其实比 Dijkstra 算法要好实现许多，这里我写了一个版本（伪代码）供你参考，我们一起来梳理一下思路：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">function BellmanFord(list vertices, list edges, vertex source) is
    // This implementation takes in a graph, represented as
    // lists of vertices (represented as integers [0..n-1]) and edges,
    // and fills two arrays (distance and predecessor) holding
    // the shortest path from the source to each vertex
    distance := list of size n
    predecessor := list of size n
    
    // Step 1: initialize graph
    for each vertex v in vertices do
        distance[v] := inf             // Initialize the distance to all vertices to infinity
        predecessor[v] := null         // And having a null predecessor
    
    distance[source] := 0              // The distance from the source to itself is, of course, zero
    // Step 2: relax edges repeatedly
    
    repeat |V|−1 times:
         for each edge (u, v) with weight w in edges do
             if distance[u] + w &lt; distance[v] then
                 distance[v] := distance[u] + w
                 predecessor[v] := u

    return distance, predecessor
</code></pre></td></tr></table>
</div>
</div><p>整体就是两步：第一步，对图的初始化。和 Dijkstra 算法一样，我们需要用 distance 数组去记录每个节点的距离，用 predecessor 记录每个节点最短路中的前驱节点，方便输出最短路径。在刚开始还没有进行遍历松弛的时候，把距离都设为无限大，前驱节点设为空就行。第二步，循环松弛操作。就是我们刚刚说的，一共进行 V-1 次，每次循环中都遍历所有的边，进行松弛操作。不过注意，每次松弛成功，也需要更新前置节点。</p>
<p>可以看到，代码写起来其实比 Dijkstra 要简单很多，这也是建立在更高的时间复杂度代价下的，Bellman-Ford 的整体时间复杂度是 O(V*E)，大部分实际场景下，边的数量比节点数量大的多，所以时间复杂度要比 Dijkstra 算法差很多。当然好处在于可以处理图中有负边的情况。代码的部分还是比较好理解的。Bellman-Ford 算法正确性的证明还是要稍微花一点功夫，会涉及一点数学的证明，如果你觉得理解困难的话，可以多找几个例子好好模拟几遍遍历松弛的过程，观察一下每一轮遍历之后，距离变化的情况，相信还是可以掌握的。</p>
<h3 id="bellman-ford-算法正确性证明">Bellman-Ford 算法正确性证明</h3>
<p>我们来严格证明一下为什么只要对进行 V-1 轮的所有边的松弛操作，就一定可以得到所有节点到原点的最短路径。整体证明可以通过数学归纳法实现。数学归纳法我们简单复习一下，核心就是两步，第一步要证明 i=1 的时候某个结论成立；第二步要证明如果结论在 i=n 时成立，那么 i=n+1 的情况也成立，这样就能证明整个结论的正确性。首先，在 Bellman-Ford 算法中我们知道进行完第一轮遍历之后，一定能得到从源点出发到其他任意节点通过长度最多为 1 的（1 跳）路径中最短的距离。那我们假设在进行完第 i 轮遍历之后，可以得到从原点出发到其他任意节点通过长度最多为 i 的（i 跳）路径中最短的距离，判断进行第 i+1 轮松弛时，是否能得到从原点出发到其他任意节点通过长度最多为 i+1 的（i+1 跳）路径中最短的距离呢？答案是肯定的。因为长度为 i+1 的路径只能从长度为 i 的路径演化而来，假设从 s 到某个节点 v 的路径中，存在长度为 i+1 的路径比长度小于等于 i 的路径更近，假设这条路径的第 i 跳是 u，那遍历所有边，一定能基于此前到 u 最短的路径，加上 u-&gt;v 这条边，得到 s-&gt;v 的最短路径。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/75/22/75ca9c0bf75215b518722d6dff366022.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/75/22/75ca9c0bf75215b518722d6dff366022.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/75/22/75ca9c0bf75215b518722d6dff366022.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/75/22/75ca9c0bf75215b518722d6dff366022.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/75/22/75ca9c0bf75215b518722d6dff366022.jpg?wh=1920x1145"
        title="img" /></p>
<h3 id="负权回路问题">负权回路问题</h3>
<p>在一个没有负权回路的图中，也就是不存在某个回路中边的权重之和是负值的情况，显然，从 s 出发到任意节点 v 的最短路径，经过的边数量最多就是 V-1，因为最短路径不可能经过同一个点两次。所以，我们通过 V-1 轮松弛，可以得到从 s 出发到任意节点的边数量小于等于 V-1 的路径中最短的路径，自然也就得到了 s 到任意节点的最短路径。讲到这里，也就引出了在 Bellman-Ford 算法中的一个限制：没法处理存在负权回路的情况。有时候 Bellman-Ford 的这一特性也可用来检测负权回路在图中是否存在，做法就是进行第 V 次循环，正常情况下这第 V 次循环不会再有任何边的距离被更新，但是如果有边的距离被更新了，就说明在图里一定有负权回路。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">    // Step 3: check for negative-weight cycles
    for each edge (u, v) with weight w in edges do
        if distance[u] + w &lt; distance[v] then
            error &#34;Graph contains a negative-weight cycle&#34;
</code></pre></td></tr></table>
</div>
</div><p>当然，在网络选路算法的场景下，我们肯定是没有负边的，也就没有必要担心负权回路的问题了。</p>
<h3 id="距离矢量算法">距离矢量算法</h3>
<p>好，现在我们已经了解了 Bellman-Ford 的思想，如何用它来解决选路算法中的最短路问题呢？类似链路状态算法的通信，网络中各节点间同样是需要通过彼此的信息交换获得最短路径的信息，但这次我们只关心网络中各节点和自己的邻居们的路径长度，不用获取全局的网络拓扑结构信息。举个例子帮助你理解。现在我们希望从上海坐汽车去北京，但没有全局的地图（来源百度地图）不知道怎么走更短，只能打电话问相邻城市的好朋友。如果我们要找出一条最短的路径有两种办法。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/a0/03/a02d83c54dd70f8386fb7e28666da903.png?wh=1016x1420"
        data-srcset="https://static001.geekbang.org/resource/image/a0/03/a02d83c54dd70f8386fb7e28666da903.png?wh=1016x1420, https://static001.geekbang.org/resource/image/a0/03/a02d83c54dd70f8386fb7e28666da903.png?wh=1016x1420 1.5x, https://static001.geekbang.org/resource/image/a0/03/a02d83c54dd70f8386fb7e28666da903.png?wh=1016x1420 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/a0/03/a02d83c54dd70f8386fb7e28666da903.png?wh=1016x1420"
        title="img" /></p>
<p>一种就是让所有人都问自己邻居城市的朋友，收集好所有的公路信息，然后传播给自己邻居城市的朋友；这样经过一段时间，我们就可以从邻居那里获得整个地图各站间的全部信息，从而可以自己研究出一条最短路径，这个思想就是链路状态法。而另一种就是我们只是问邻居，你那有汽车能到北京吗？假设到上海距离一样的两个城市常州和苏州都可以抵达北京，一个到北京 700km，另一个到北京 800km，那我们可能就会选择短的那条经过常州的线路。而常州和苏州怎么知道自己可以到达北京呢，也是基于类似的方式从自己邻居城市的朋友那知道的。这个思路其实和距离矢量法本质上是一样的。所谓的“距离矢量”其实就是在每个节点都维护这样一张距离表：它是一个矩阵，每一行都可以代表一个目标节点，每一列是经过每个邻居到达这个目标节点的最短距离。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/9e/30/9edb1f946d6c9ebb07706b9e2ba2f730.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/9e/30/9edb1f946d6c9ebb07706b9e2ba2f730.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/9e/30/9edb1f946d6c9ebb07706b9e2ba2f730.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/9e/30/9edb1f946d6c9ebb07706b9e2ba2f730.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/9e/30/9edb1f946d6c9ebb07706b9e2ba2f730.jpg?wh=1920x1145"
        title="img" /></p>
<p>选路的时候，我们就会从每行中选择一个经过邻居节点成本最低的邻居，作为路由表的下一跳。比如选择从 E 到达 D 的路径，我们对比 E 经过 A 到 D、E 直接到达 D 的路径，距离分别是第四行的第一列和第四行的第三列，显然 E 直接到达 D 是一条更短的路径，所以路由表下一跳的选择自然也会是 D。整个算法也是迭代进行的，每个节点都会不断地从邻居那里获得最新的距离信息，然后尝试更新自己的距离矩阵，如果发现自己的距离矩阵有变化，才会通知邻居。这样也能避免许多不必要的通信成本。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/50/80/504d2735e752b30505bedce61ecc0e80.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/50/80/504d2735e752b30505bedce61ecc0e80.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/50/80/504d2735e752b30505bedce61ecc0e80.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/50/80/504d2735e752b30505bedce61ecc0e80.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/50/80/504d2735e752b30505bedce61ecc0e80.jpg?wh=1920x1145"
        title="img" /></p>
<p>参考这个体现算法逻辑的流程图，相信你也一定能意识到为什么我们说这个算法是建立在 Bellman-Ford 算法思想上的了，其实节点间彼此传递信息的时候，在做的就是松弛操作，等所有的节点都稳定下来，也就相当于进行了 V-1 轮松弛操作，这个时候所有节点的距离矢量就会进入稳定没有变化的状态，整个算法也就进入了收敛状态。</p>
<h3 id="无限计算问题">无限计算问题</h3>
<p>但是因为每个节点都没有全局的拓扑结构，距离矢量有一个巨大的问题，就是在一些情况下会产生无限计算的可能。比如图中的例子，假设 A、B、C、D 四个节点已经在某一时刻建立了稳定的距离矢量，ABC 三个节点到 D 都会经过 C 节点。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/2e/b5/2ec56b8192a7c51df013aa29f4ed73b5.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/2e/b5/2ec56b8192a7c51df013aa29f4ed73b5.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/2e/b5/2ec56b8192a7c51df013aa29f4ed73b5.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/2e/b5/2ec56b8192a7c51df013aa29f4ed73b5.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/2e/b5/2ec56b8192a7c51df013aa29f4ed73b5.jpg?wh=1920x1145"
        title="img" /></p>
<p>此时如果 C-&gt;D 节点突然中断了，会发生什么呢？C 发现自己到 D 的路径走不通了，就会问自己的邻居 B：你那边可以到 D 吗？这个时候 B 的距离表是没有变化的，结果 B 发现自己可以到 D 距离为 2，就会告诉 C：可以从我这走距离是 2。但是因为距离矢量算法没有任何信息告诉 B 其实它到 D 的路径就需要经过 C，于是，C 就会把自己到 D 的路径信息更新为新的，B 到 D 的距离加上 C 到 B 的距离，也就是 2+1。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cc/0b/cc7a98ccc48c1d1dd976b877c297a60b.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/cc/0b/cc7a98ccc48c1d1dd976b877c297a60b.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/cc/0b/cc7a98ccc48c1d1dd976b877c297a60b.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/cc/0b/cc7a98ccc48c1d1dd976b877c297a60b.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cc/0b/cc7a98ccc48c1d1dd976b877c297a60b.jpg?wh=1920x1145"
        title="img" /></p>
<p>而更新之后，B 又会收到消息，你的邻居 C 距离矩阵变化了，从而把自己 B 到 D 的距离更新为 3+1。这样的过程会反复执行，于是通往 D 的距离会无限增加。这个问题就是路由环路问题，也被称为无限计算问题。解决思路也比较多，比较常见的做法就是设定一个跳数上限。比如在 RIP 协议中 16 跳就是一个常用的上限，如果路径跳数多于 16，我们就会把这个路径看成不可达的，这个时候我们可以让发现某个节点不可达的节点，暂时不要相信其他节点发来的距离矢量，从而避免路由环路问题的无限计算问题。当然，如果有节点和网络断开连接，但在跳数没有到达上限之前，还是会进行大量无谓的计算。</p>
<h3 id="总结好距离矢量算法">总结好距离矢量算法</h3>
<p>到这里就学完了，我们结合链路状态算法简单对比一下。首先，距离矢量算法和链路状态算法背后分别是基于 Bellman-Ford 算法和 Dijkstra 算法实现的。距离矢量算法背后的 Bellman-Ford 本质就是对所有边无差别的松弛操作，迭代地进行很多轮，是本地的、非中心化的算法。节点之间不用交换全部的路由拓扑信息，只需要交换到其他节点的最短距离，就可以让距离矢量算法逐步正确选出最短的路径，直至收敛；节点之间的通信也不需要是同步的，邻居节点的距离矢量在什么时间更新、以什么次序抵达都可以，不会影响选路的正确性。但是在状态链路算法中完全不同，每个节点都需要通过信息交换获取全部的路由信息，然后各自独立地计算最短路径。虽然带来了更大通信开销，但同时也更加保证了计算的健壮性，不会出现环路计算这样的问题。这两种基础选路算法值得你好好体会其中的思想，可以说现在绝大部分选路算法都是在它们的基础上改进的。另外背后的 Dijkstra 和 Bellman-Ford 算法也是算法竞赛中的常考题，在各大互联网公司的笔试题中也逐渐开始出现，你可以到力扣上找一些题目练习。</p>
<h2 id="20滑动窗口tcp是如何进行流量控制和拥塞控制的">20｜滑动窗口：TCP是如何进行流量控制和拥塞控制的？</h2>
<p>过去几讲，我们一起讨论了最短路算法在网络中的应用，学习了从 Dijkstra 算法思想发展而来的链路状态选路算法，以及从 Bellman-Ford 算法思想发展而来的距离矢量算法。链路状态算法的每个节点，通过通信，都构建了完整的网络拓扑图，然后根据 Dijkstra 算法独立地计算最短路径，并依据计算结果维护动态路由表；距离矢量算法，则是通过节点间的通信了解邻居到每个不同节点的距离，以此作为选路依据，所以链路上传输的压力比链路状态算法小了很多，但也因为没有全局的信息，网络出现故障时很容易陷入无穷计算问题。在计算机网络发展以来，类似单源最短路问题的图论算法应用，除了这两大经典算法，其实还有很多，比如最小生成树问题、网络流问题等等，它们都在不同的场景下发挥着巨大的作用，但我们要知道，图论算法也只是解决了网络传输中和“拓扑结构”相关的一小部分问题。</p>
<p>这些算法并不足以让我们的数据在环境复杂的网络上稳定传输，也并没有办法去控制流量传输的快慢，来避免接受方对数据处理不过来，或者网络上数据包太多产生拥塞的情况。为了解决传输本身的问题，自然也有一些经典的算法思想和协议被提出来，TCP 中的滑动窗口、拥塞窗口就是经典的例子。在学习具体算法之前，我们先简单复习一下 TCP 协议做到了什么。</p>
<h3 id="tcp-协议和-udp-协议">TCP 协议和 UDP 协议</h3>
<p>TCP 作为最常用的两大传输层协议之一，无疑是久经生产环境检验的。传输层有两个我们广泛使用的协议：UDP 协议、TCP 协议，我们一般会说前者是面向无连接的，后者是面向连接的。这里的“连接”具体是什么意思呢？简单来说，UDP 协议是一种没有状态的协议，节点之间如果采用 UDP 协议通信，两个节点能做的就是在 UDP 协议上发送一个个数据包，协议本身不会关心这些包之间的关系，所以在复杂的网络下，包的顺序和可达性都是没有保证的，应用层需要自己处理这些包的丢失和乱序问题。</p>
<p>当然，UDP 协议也因此可以设计的非常轻量，所以在网络传输本来就比较稳定的内网环境下，或者对丢包可以容忍但对时延要求较高的场景下，UDP 协议有许多应用。而 TCP 很不一样，它在节点之间建立了真正的连接的概念。相信你肯定听过 TCP 的三次握手吧，UDP 就没有这个过程，三次握手完成时，TCP 连接就建立了；结束通信的时候，通信双方往往也需要主动断开连接。TCP 的传输基于字节流，也引入了状态，明确记录着每个包是否发送、是否被接受到、包本身的序列号等状态；所以，TCP 为我们提供了可靠有序的传输能力，也被设计的相当复杂。TCP 协议不止考虑了包的可靠传输，同时也兼顾了效率，更提供了对流量控制和拥塞避免的能力，滑动窗口和拥塞窗口就是为了这两个目的而设计的。那 TCP 的具体是如何做到让网络中的包传输可靠且效率高的呢？</p>
<h3 id="tcp-中包的发送">TCP 中包的发送</h3>
<p>一个包在网络中发送出去，其实就像古时候你给别人用信鸽寄了一封信一样，在外界环境非常复杂的情况下，你完全没有把握这封信能不能真的送达收信人那边，除非有一天你收到了收信人的回信。类似的，在复杂网络环境下，TCP 为了能保证每个包真的送达了，并且接收端收到包的顺序和发送端是一致的，我们每发出一个包，自然也需要一个类似回信的机制。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/c1/d5/c1c706c86938683bf47e6dfd166848d5.jpg?wh=1498x594"
        data-srcset="https://static001.geekbang.org/resource/image/c1/d5/c1c706c86938683bf47e6dfd166848d5.jpg?wh=1498x594, https://static001.geekbang.org/resource/image/c1/d5/c1c706c86938683bf47e6dfd166848d5.jpg?wh=1498x594 1.5x, https://static001.geekbang.org/resource/image/c1/d5/c1c706c86938683bf47e6dfd166848d5.jpg?wh=1498x594 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/c1/d5/c1c706c86938683bf47e6dfd166848d5.jpg?wh=1498x594"
        title="img" /></p>
<p>这个回信也就是 ACK 包，每个包发送的时候会有一个序列号，接收端回 ACK 包的时候会把序列号 +1 发送回来，发送端如果没有收到某个包的 ACK 包，会在一段时间之后尝试重新发送，直到收到 ACK 为止。这其实也是在网络和各种分布式系统中能确保消息可达的唯一方式。那问题来了，我们为了确保消息保序可达，难道每次发送一个新的包，都等待上一个包的 ACK 回来之后才能发送吗？这样一来一回的效率显然是很低的，也就是每经过一个 RTT 的时间，我们只能发送一个包，假设一个 RTT 是 100ms，那在一秒中我们甚至只能发送 10 个包，这完全是不可接受的。其实我们在等待 ACK 的时候没有必要停止后续包的发送，因为网络传输虽然不稳定，但大部分包往往还是可达的，这样我们就可以获得数倍的传输效率提升。如果真的不幸遇到了丢包，接收端 ACK 姗姗来迟的时候，也就告诉了我们某个序列号之前的所有包全部收到，我们再根据一定的策略，尝试重新发送对应丢失的包就可以了。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/yy/02/yydf3be24ebe4e0f99c131affbf3ed02.jpg?wh=1498x871"
        data-srcset="https://static001.geekbang.org/resource/image/yy/02/yydf3be24ebe4e0f99c131affbf3ed02.jpg?wh=1498x871, https://static001.geekbang.org/resource/image/yy/02/yydf3be24ebe4e0f99c131affbf3ed02.jpg?wh=1498x871 1.5x, https://static001.geekbang.org/resource/image/yy/02/yydf3be24ebe4e0f99c131affbf3ed02.jpg?wh=1498x871 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/yy/02/yydf3be24ebe4e0f99c131affbf3ed02.jpg?wh=1498x871"
        title="img" /></p>
<p>所以自然而然的，发送方需要缓存已发出但尚未收到 ACK 的包，接收方收到包但没有被用户进程消费之前也得把收到的包留着。但是，缓存是有大小限制的，程序消费数据和链路传输数据的能力也是有限的，发送端和接受端都需要一种机制来限制可发送或者可接收数据的最大范围。于是，滑动窗口和拥塞窗口应运而生。这两个算法核心都是为了防止像网络中发送的包太多。不同的是两者的目的，滑动窗口机制，可以用来控制流量，防止接收方处理不过来消息；同样基于窗口机制的拥塞控制算法，则用来处理网络上数据包太多的情况，以避免网络中出现拥塞。</p>
<h3 id="流量控制">流量控制</h3>
<p>我们先来看看如何用滑动窗口控制流量。这里说流量控制，主要就是为了防止接收方处理数据的速度跟不上发送方，避免随着时间推移，数据自然溢出接收方的缓冲区。虽然协议可以保证发送方没有收到 ACK，最终会重试重新发送，但如果需要大量反复发送冗余的数据，所占用的网络资源就被白白浪费了，在网络资源很紧缺的时候，这也会造成网络环境的恶化。TCP 控制流量的方式也很简单，就是滑动窗口机制。接收端会建立一个滑动窗口，由接收方向发送方通告，TCP 首部里的 window 字段就是用来表示窗口大小的，窗口表示的就是接收方目前能接收的缓冲区的剩余大小。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/5c/dc/5c2062c93db157984cf4b3be75c3d7dc.png?wh=438x158"
        data-srcset="https://static001.geekbang.org/resource/image/5c/dc/5c2062c93db157984cf4b3be75c3d7dc.png?wh=438x158, https://static001.geekbang.org/resource/image/5c/dc/5c2062c93db157984cf4b3be75c3d7dc.png?wh=438x158 1.5x, https://static001.geekbang.org/resource/image/5c/dc/5c2062c93db157984cf4b3be75c3d7dc.png?wh=438x158 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/5c/dc/5c2062c93db157984cf4b3be75c3d7dc.png?wh=438x158"
        title="img" /></p>
<p>但是发送方也会根据这个通告窗口的大小建立自己的滑动窗口。为了兼顾效率和可靠性，在发送方，所有未收到 ACK 的消息虽然可以发送，但是在收到 ACK 之前是一定要在缓冲区中保存的。我们一起来看一下。</p>
<h3 id="发送端的窗口">发送端的窗口</h3>
<p>发送窗口根据三个标准来划分：是否发送、是否收到 ACK、是否在接收方通告处理范围内，分成了四个部分。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/63/50/634d8b4f2fa99291ed72bcf80e6bc250.jpg?wh=1920x1129"
        data-srcset="https://static001.geekbang.org/resource/image/63/50/634d8b4f2fa99291ed72bcf80e6bc250.jpg?wh=1920x1129, https://static001.geekbang.org/resource/image/63/50/634d8b4f2fa99291ed72bcf80e6bc250.jpg?wh=1920x1129 1.5x, https://static001.geekbang.org/resource/image/63/50/634d8b4f2fa99291ed72bcf80e6bc250.jpg?wh=1920x1129 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/63/50/634d8b4f2fa99291ed72bcf80e6bc250.jpg?wh=1920x1129"
        title="img" /></p>
<p>第一部分就是已经发送且收到 ACK 的部分，这一块我们知道已经成功发送，所以不需要在缓冲区保留了。第二部分是已发送但尚未收到 ACK 的部分。第三部分是还没有发送，但是还在接收方通告窗口也就是处理范围内的数据，这块我们也可以称为可用窗口；第二、第三部分一起构成了我们的整个发送窗口。最后一部分则是我们需要发送，但已经超过接收方通告窗口范围的部分，这一部分在没有收到新的 ACK 之前，发送方是不会发送这些数据的。通过这个限制，发送的数据就一定不会超过接收方的缓冲区了。</p>
<p>但如果发送方一直没有收到 ACK，随着数据不断被发送，很快可用窗口就会被耗尽。在这种情况下，发送方也就不会继续发送数据了，这种发送端可用窗口为零的情况我们也称为“零窗口”。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/82/ba/820e30d38ff913e36610b1a871e55dba.jpg?wh=1920x1129"
        data-srcset="https://static001.geekbang.org/resource/image/82/ba/820e30d38ff913e36610b1a871e55dba.jpg?wh=1920x1129, https://static001.geekbang.org/resource/image/82/ba/820e30d38ff913e36610b1a871e55dba.jpg?wh=1920x1129 1.5x, https://static001.geekbang.org/resource/image/82/ba/820e30d38ff913e36610b1a871e55dba.jpg?wh=1920x1129 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/82/ba/820e30d38ff913e36610b1a871e55dba.jpg?wh=1920x1129"
        title="img" /></p>
<p>正常来说，等接收端处理了一部分数据，又有了新的可用窗口之后，就会再次发送 ACK 报文通告发送端自己有新的可用窗口（因为发送端的可用窗口是受接收端控制的）。但是，万一要是 ACK 消息在网络传输中正好丢包了，那发送端还能感知到接收端窗口的变化吗？其实是不会的，在这个情况下，接收端就会一直等着发送端发送数据，而发送端也还会以为接收端仍然处于零窗口的状态，这样一直互相等待，就好像进入了死锁状态。解决办法也很简单，我们可以再引入一个零窗口定时器，如果发送端陷入零窗口的状态，就会启动这个定时器，去定时地询问接收端窗口是否可用了，这也是在分布式系统中常见的处理丢包的方式之一。</p>
<h3 id="接收端的窗口">接收端的窗口</h3>
<p>相对发送端来说，接收端要简单的多，主要就分为已经接收并确认的数据和未收到但可以接收的数据，这一部分也就是接收窗口；剩下的就是缓冲区放不下的区域，也就是不可接收的区域。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/8f/50/8ffceab0920305f11e12fe45c2946250.jpg?wh=1920x1129"
        data-srcset="https://static001.geekbang.org/resource/image/8f/50/8ffceab0920305f11e12fe45c2946250.jpg?wh=1920x1129, https://static001.geekbang.org/resource/image/8f/50/8ffceab0920305f11e12fe45c2946250.jpg?wh=1920x1129 1.5x, https://static001.geekbang.org/resource/image/8f/50/8ffceab0920305f11e12fe45c2946250.jpg?wh=1920x1129 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/8f/50/8ffceab0920305f11e12fe45c2946250.jpg?wh=1920x1129"
        title="img" /></p>
<p>如果进程读取缓冲区速度有所变化，接收端可能也会改变接收窗口的大小，每次通告给发送端，就可以控制发送端的发送速度了。这就是所谓的滑动窗口，也就是流量控制机制。而之所以是滑动窗口，也很好理解，随着 ACK 或者进程读取数据，窗口也会顺次往后移动。比如在发送端的窗口中，如果我们在某次通信中收到了一条 ACK 消息，表示 36 之前的消息都已经被收到了，那么整个可用的窗口就会顺次往右移动。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/28/ee/28b5235e4c093b05376bfc1289b0b4ee.jpg?wh=1920x1129"
        data-srcset="https://static001.geekbang.org/resource/image/28/ee/28b5235e4c093b05376bfc1289b0b4ee.jpg?wh=1920x1129, https://static001.geekbang.org/resource/image/28/ee/28b5235e4c093b05376bfc1289b0b4ee.jpg?wh=1920x1129 1.5x, https://static001.geekbang.org/resource/image/28/ee/28b5235e4c093b05376bfc1289b0b4ee.jpg?wh=1920x1129 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/28/ee/28b5235e4c093b05376bfc1289b0b4ee.jpg?wh=1920x1129"
        title="img" /></p>
<p>总的来说，滑动窗口（流量控制机制）解决了发送端消息可能淹没接收端，导致处理跟不上的情况。</p>
<h3 id="流量拥塞">流量拥塞</h3>
<p>那 TCP 协议如何解决流量拥塞的情况呢？也就是网络中由于大量包传输，导致吞吐量下降甚至为 0 的情况。这和我们的道路交通很像，当车流越来越大的时候，整体的行车速度可能会不断下降，导致拥堵，最后吞吐量反而不如车少的时候。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/cf/6b/cf30f1508bbf10e3a9db838f56df926b.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/cf/6b/cf30f1508bbf10e3a9db838f56df926b.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/cf/6b/cf30f1508bbf10e3a9db838f56df926b.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/cf/6b/cf30f1508bbf10e3a9db838f56df926b.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/cf/6b/cf30f1508bbf10e3a9db838f56df926b.jpg?wh=1920x1145"
        title="img" /></p>
<p>在实际网络中，因为大量的包传输，可能导致中间某些节点的缓冲区满载，从而多余的包被丢弃，需要重新发送，情况越发恶化，最差的时候，网络上的包都是重传的包并且反复地丢弃；整个网络传输能力甚至可以降低为 0。这当然是一个很严重的问题，TCP 协议同样提出了另外一个叫拥塞窗口的机制，很好地解决了这个问题。具体是怎么做的呢？我们一起来看一下。拥塞控制</p>
<h3 id="拥塞控制">拥塞控制</h3>
<p>网络中每个节点不会有全局的网络通信情况，唯一能发现的就是自己的部分包丢了，这种时候它就有理由怀疑网络环境劣化，可能产生了拥塞。TCP 是一个比较无私的协议，在这种情况下，会选择减少自己发送的包。当网络上大部分通信协议传输层都采用的是 TCP 协议时，在出现拥塞的情况下，大部分节点都会不约而同地减少自己传输的包，这样网络拥塞情况就会得到极大的缓解，一直处于比较好的网络状态。所以我们就需要在发送端定义一个窗口 CWND（congestion window），也就是拥塞窗口；发送端能发送的最多没有收到 ACK 的包，也不会超过拥塞窗口的范围。</p>
<p>引入拥塞控制机制的 TCP 协议，发送端最大的发送范围是拥塞窗口和滑动窗口中小的一个。拥塞窗口会动态地随着网络情况的变化而进行调整，大体上的策略是如果没有出现拥塞，我们扩大窗口大小，否则就减少窗口大小。具体是如何实现的呢？经典拥塞控制算法主要包括四个部分：
慢启动 拥塞避免 拥塞发生 快速恢复</p>
<p>我们一个个来看。首先是慢启动，在不确定拥塞是否会发生的时候，我们不会一上来就发送大量的包，而是会采用倍增的方式缓慢增加窗口的大小，窗口大小从 1 开始尝试，然后尝试 2、4、8、16 等越来越大的窗口。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/d5/8a/d5b79c7a1c4eb16be465e9a7e28fea8a.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/d5/8a/d5b79c7a1c4eb16be465e9a7e28fea8a.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/d5/8a/d5b79c7a1c4eb16be465e9a7e28fea8a.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/d5/8a/d5b79c7a1c4eb16be465e9a7e28fea8a.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/d5/8a/d5b79c7a1c4eb16be465e9a7e28fea8a.jpg?wh=1920x1145"
        title="img" /></p>
<p>整个慢启动的过程看起来就像图中这样，指数型的增加拥塞窗口的大小。这样，倍增的方式窗口就会很快扩大；我们会在窗口大到一定程度时，减慢增加的速度，转成线性扩大窗口的方式，也就是每次收到新的 ACK 没有丢包的话只比上次窗口增大 1。整个过程看起来就像这样：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/fe/7b/fedc491aaa6f9797abcf8231c6ed9f7b.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/fe/7b/fedc491aaa6f9797abcf8231c6ed9f7b.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/fe/7b/fedc491aaa6f9797abcf8231c6ed9f7b.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/fe/7b/fedc491aaa6f9797abcf8231c6ed9f7b.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/fe/7b/fedc491aaa6f9797abcf8231c6ed9f7b.jpg?wh=1920x1145"
        title="img" /></p>
<p>这两个慢启动阶段和拥塞避免阶段的分界点，我们就叫“慢启动门限（ssthresh）”。随着窗口进一步缓慢增加，终于有一天，网络还是遇到了丢包的情况，我们就会假定这是拥塞造成的。这个时候我们一方面会进行超时重传或者快速重传，另一方面也会把窗口调整到更小的范围。超时重传，往往意味着拥塞情况更严重，我们的策略也会更激进一些，会直接将 ssthresh 设置为重传发生时窗口大小的一半，而窗口大小直接重置为 0，再进入慢启动阶段。像这样：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/18/e3/188691ece41fcde20a3f34ed3faed8e3.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/18/e3/188691ece41fcde20a3f34ed3faed8e3.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/18/e3/188691ece41fcde20a3f34ed3faed8e3.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/18/e3/188691ece41fcde20a3f34ed3faed8e3.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/18/e3/188691ece41fcde20a3f34ed3faed8e3.jpg?wh=1920x1145"
        title="img" /></p>
<p>快速重传，如果我们连续 3 次收到同样序号的 ACK，包还能回传，说明这个时候可能只是碰到了部分丢包，网络阻塞还没有很严重，我们就会采用柔和一点的策略，也就是快速恢复策略。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/06/ec/068652391d574e588465c1a8ce98a1ec.jpg?wh=1920x1145"
        data-srcset="https://static001.geekbang.org/resource/image/06/ec/068652391d574e588465c1a8ce98a1ec.jpg?wh=1920x1145, https://static001.geekbang.org/resource/image/06/ec/068652391d574e588465c1a8ce98a1ec.jpg?wh=1920x1145 1.5x, https://static001.geekbang.org/resource/image/06/ec/068652391d574e588465c1a8ce98a1ec.jpg?wh=1920x1145 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/06/ec/068652391d574e588465c1a8ce98a1ec.jpg?wh=1920x1145"
        title="img" /></p>
<p>我们会先把拥塞窗口变成原来的一半，ssthresh 也就设置成当前的窗口大小，然后开始执行拥塞避免算法。有些实现也会把拥塞窗口直接设置为 ssthresh+3，本质上区别不大。</p>
<h3 id="总结-10">总结</h3>
<p>总体而言，TCP 就是通过滑动窗口、拥塞窗口这两个简单的窗口实现了流量控制和拥塞控制。滑动窗口由接收端控制，向发送端通告，这样就可以保证发送端发出的包数量上限是明确的，也就不会存在淹没接收端导致来不及处理的情况。拥塞窗口由发送端控制，它会根据网络中的情况动态的调整，通过慢启动、拥塞避免、拥塞发生、快速恢复四个算法，就可以很好地调整窗口的大小。和滑动窗口一起限制了发送端最大的发送范围，从而保证了拥塞在网络上不会发生。</p>
<h2 id="分布式">分布式</h2>
<h2 id="21分而治之mapreduce如何解决大规模分布式计算问题">21｜分而治之：MapReduce如何解决大规模分布式计算问题</h2>
<p>从今天开始，我们就真正开始学习算法在工业界应用了。和前面的章节不同，分布式系统篇的很多算法，一般都是由工程师们提出来的，为了解决一些大规模网络应用中的实际问题，比如为了解决海量网页排名而发明的 pagerank 算法、为了解决分布式系统中共识问题的 Raft 算法、常用的负载均衡算法一致性哈希等等。因为都是在实际的工程场景下被发明出来的，这些算法，在现在的互联网架构中也经常能看到它们的身影，所以学习这些算法以及其背后解决的问题对我们的实际工作是有很大益处的。话不多说，我们开始今天的学习——谷歌提出的 MapReduce 算法，知名的开源项目 Hadoop 其实就是对 MapReduce 的工业级实现之一。</p>
<h3 id="为什么发明-mapreduce-算法">为什么发明 MapReduce 算法</h3>
<p>想要掌握一个解决实际生产环境中问题的算法或者框架，我们当然应该先来了解一下相关算法的诞生背景。MapReduce 算法，作为谷歌知名的三驾马车之一，是早期谷歌对大规模分布式计算的最佳实践。他们当时（2004 年）发表了相关的论文，很清晰地描述了提出这个算法的目的。当时的谷歌已经有很大的业务量了，每天都需要处理海量的数据，也有许多不同的业务场景，所以工程师们实现了数以百计的数据处理程序，用来实现网页抓取、日志汇总分析、计算倒排索引等任务。这些任务大部分本身倒也不是很复杂，但因为需要面对巨大的数据量，单机的程序显然没有办法应对谷歌的数据规模，这些程序只能是分布式的运行。我们知道，在分布式环境上运行的程序都会比较复杂，需要考虑各种问题，比如不同环境下可能出现的异常、数据如何分发到各个机器上、计算完成之后又如何汇总等等。</p>
<p>要是每个业务方都针对这些雷同的问题，各自实现一遍处理这些问题的逻辑，显然是非常低效的。所以为了解决这个问题，谷歌的工程师提出了一种新的、通用的、抽象模型 MapReduce，让业务开发人员不再需要关心并行计算、数据冗余、负载均衡等和分布式系统本身相关的细节了。</p>
<h3 id="map-和-reduce">Map 和 Reduce</h3>
<p>那为什么起名叫 MapReduce 呢？其实 map 和 reduce，在一些函数式编程语言中，是十分常用的概念，比如在 Lisp 里 map 和 reduce 都是作为原语存在的，历史非常悠久。谷歌的分布式计算框架也只是借鉴了其中的思想。我们就以 js 为例子，先来看看在一般编程语言中的 map 和 reduce 都是什么样的操作。假设一个 number 数组中，我们希望统计出数值大于 5 的那些数向上取整的和。这个问题很简单，常规的写法自然是遍历整个数组，写一个 if-else 判断出大于 5 的数，然后用一个变量做累计求和。但是这个写法引入了状态，在循环里你既需要关心 filter 的逻辑，又要关心累计求和的逻辑，不够清晰。而比较函数式的写法是这样的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">function(arr) {
  arr
  .filter(a =&gt; a &gt; 5)
  .map(a =&gt; Math.ceil(a))
  .reduce((acc, i) =&gt; acc + i);
}
</code></pre></td></tr></table>
</div>
</div><p>通过 filter \ map \ reduce 等原语，我们把控制逻辑和计算逻辑分离地非常清楚。这虽然是一个单机且简单的程序，但是大多数的运算和业务逻辑，其实都是可以通过这样简单的 map 和 reduce 函数来实现的。因为一个很复杂的计算，也无非就是对某些数据据进行一系列规则的变换，转化成另一些数据。如果我们把输入数据表示成一个 key\value 对的集合，输出数据也表示成一个 key\value 对的集合。 那么我们只需要通过两种操作就可以完成绝大部分转换。一是对输入的每个 (key, value) 进行某种变换，得到和输入集合规模一样的新集合，但每个值都按照指定的规则进行变换。这个新集合，既可以作为最终的输出结果，也可以作为中间的结果供后续转换操作使用。这个就是 map。二是对 (key, value) 进行一些合并的计算。通常来说就是把某个 key 的不同 value，按照某种规则合并起来，从而得到一个比输入规模更小的 (key, value) 集合。这样的操作就是 reduce。以刚才统计和的程序为例：</p>
<p>向上取整，需要通过 map 来实现（每个值都按规则变换）；过滤 5 以上的数字是通过 filter 来实现的，这本质上也是一种 reduce 的操作，输入一个集合，合并的时候返回一个列表，但 reduce 计算的时候，只有符合 &gt;5 条件的元素才会被加入累计的值里；最后的求和，也是通过 reduce 实现。传入的函数就是一个普通的加法运算，对应的 reduce 操作就会自动对整个集合进行求和了。</p>
<p>除了这个例子，还有很多适用于互联网应用的场景，谷歌的同学当时在论文里就给出了一些例子。比如：分布式 Grep 程序，可以用于对大量数据的模式匹配，比如查询日志中某些模式出现的数量。统计 URL 访问频数，把所有的访问记录用 map 函数处理成 (url, 1)，再用 reduce 函数对 url 相同的记录，累计计数。网络连接逆向，把 (source, target) map 为 (target, source) ，再用 reduce 把 target 相同的记录中的 source，合并成列表，得到 (target, list(source))。倒排索引，把文本分词，得到 (word, document) 的集合，并对同样的词进行 reduce 操作，得到（word, list(document)），这样就可以用来给搜索引擎加速查询。</p>
<p>这些例子，本身都不是特别复杂。如果我们就用单机系统去实现，相信你用传统的循环控制、开全局变量的方式，去实现这些逻辑都是没有问题的。当然如果用 map\reduce 这样的原语去实现，你的代码逻辑会更清晰，我个人也更推荐你这么写。而且现在各大语言也都开始引入函数式编程的特性，比如 Java 8 的 stream 就是一种对函数式编程能力的部分释放，如果感兴趣你可以系统学习一下相关 API 的使用和背后函数式编程的思想。</p>
<h3 id="分布式实现">分布式实现</h3>
<p>但是，谷歌的 MapReduce 当然不只是一种编程思想，而是一个真正意义上的分布式计算的框架和系统。毕竟对于谷歌来说，那些问题虽然简单，但所需要应对的数据量是单机远远存储不下，也计算不了的。所以我们需要把整个 map 和 reduce 的过程搬运到一个分布式的系统中来实现。所用的机器也都是普通的商用机器，不一定非常稳定，集群规模到达一定程度的时候，机器或者网络出现异常是在所难免的。这些问题自然也都是谷歌需要考虑的。那么，MapReduce 到底是如何运作的呢？想要任务在 MapReduce 机器上顺利执行，大体上来说就是要做到把数据分区，交给不同的机器执行，在要汇总的时候也需要有办法进行数据的汇总，并且要有一定应对故障的能力。</p>
<p>当然了，整个 MapReduce 系统是要有一套全局共享的存储系统的，这就是谷歌鼎鼎大名的三驾马车中的另一架 GFS（Google File System）的作用，MapReduce 也是建立在这个存储系统之上的，感兴趣的同学可以自行查阅相关资料了解。我们一起来看当用户发起 MapReduce 任务时，会发生什么。</p>
<h3 id="执行过程">执行过程</h3>
<p>任务发起后，程序首先会把输入文件分成 M 个数据段，每个数据段大小可控，通常为 16MB；然后，整个集群就会快速地分发需要执行的计算任务给到各个节点，让这些节点可以进行计算任务。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://static001.geekbang.org/resource/image/87/09/8765662a15270d6d4e2bc1c73e9b5c09.jpg?wh=4254x2252"
        data-srcset="https://static001.geekbang.org/resource/image/87/09/8765662a15270d6d4e2bc1c73e9b5c09.jpg?wh=4254x2252, https://static001.geekbang.org/resource/image/87/09/8765662a15270d6d4e2bc1c73e9b5c09.jpg?wh=4254x2252 1.5x, https://static001.geekbang.org/resource/image/87/09/8765662a15270d6d4e2bc1c73e9b5c09.jpg?wh=4254x2252 2x"
        data-sizes="auto"
        alt="https://static001.geekbang.org/resource/image/87/09/8765662a15270d6d4e2bc1c73e9b5c09.jpg?wh=4254x2252"
        title="img" /></p>
<p>在这里有一个很常见的设计，<strong>我们会让众多进程中的一个成为 master 进程，由它来进行任务的调度，其他进程都是 worker 进程，进行实际的计算任务</strong>。master 会把 M 个 map 任务和 R 个 reduce 任务分配给空闲的进程。对于 map 任务，worker 在读取输入数据之后，根据任务内容进行相应的 map 计算，由 map 函数输出中间的结果缓存在内存中；然后 worker 会通过分区函数，把中间结果定期落盘，分离在 r 个区域；这些区域的信息会传递给 master，以待后续 reduce 使用。对于 reduce 任务， worker 会收到 master 传来的中间结果的位置信息，通过 RPC 读取相应节点中间结果。由于 reduce 是按照不同的 key 进行聚合操作，所以读取完数据之后会做排序，再按照 reduce 函数进行结果的计算。这里计算出的结果同样会被分区追加到对应的分区文件里。当 map 和 reduce 程序全部执行完成，用户程序会收到通知，读取最终的计算结果。</p>
<h3 id="容错">容错</h3>
<p>整个执行过程是比较复杂的，在分布式系统下，一个工业级的应用，必须要考虑容错问题。一是因为和超级计算机不同，互联网应用通常使用比较廉价的机器，然后通过大规模的部署来提高计算能力和稳定性；二是我们的服务也需要长时间在线，不能每次出现故障都由管理员手动恢复。所以容错灾备是互联网应用的基础能力，MapReduce 需要很好地处理机器的故障。在 MapReduce 场景下，故障主要包括 worker 故障和 master 故障。</p>
<h3 id="worker-故障">worker 故障</h3>
<p>worker 是实际负责计算的节点。在计算场景下，如果任意一个 worker 正在处理的任务失败，不进行任何处理，整个计算任务就会因为部分失败而全部失败，所有 worker 全部完成任务才能得到完整的数据处理结果。所幸，我们有一个全局的控制节点 master，它能很好发现 worker 的故障，并适时地进行任务的重新调度。具体做法也是在网络中很常见的定时 ping 操作。master 会周期性地给 worker 发送 ping 请求，如果 worker 正常就会回复，所以如果 master 一段时间没有收到回复，会把这个 worker 标记为失效 worker，相关的任务也会被设置为空闲状态，进而分配给其他空闲的 worker。如果 Map 的任务异常，由于 Map 任务的中间结果都存储在本地节点中，当节点异常时，我们就需要重新执行该节点上已经完成的 Map 任务；而 reduce worker，因为完成任务之后会直接输出到全局文件系统中，不需要重新执行已经完成的 reduce 的任务，只需要重新执行这次失败的任务即可。引入 master 节点，对 worker 节点进行监控和重新调度的机制，在分布式系统中是非常常见的，你可以好好掌握。</p>
<h3 id="master-故障">master 故障</h3>
<p>现在 master 能很好地帮助我们解决 worker 的故障了，那如果 master 出现了故障又该怎么办呢？一种最简单的方式是周期性的把 master 相关的状态信息保存到磁盘中，形成一个个检查点。如果 master 任务失败了，我们就从最近的一个检查点恢复当时的执行状态，全部重新执行。另外一些比较常用的手段，比如可以对 master 引入 backup 节点，如果一个节点挂了，我们马上把备份的节点拿来当新的主节点使用，这样恢复的速度就会快很多。但谷歌的工程师当时的选择更简单一些，就是直接终止这个程序，让用户感知到并重新提交任务，其实不能说是最好的解决方案。</p>
<h3 id="总结-11">总结</h3>
<p>MapReduce 在整个互联网世界取得了巨大的成功，第一次将大规模的分布式计算用简洁易用的 API 抽象出来，封装了并行处理、数据分发、容错、负载均衡等繁琐的技术细节，把面对海量数据的应用开发人员解放出来，解决了许多不同类型的问题。可以说后面的所有分布式计算框架比如 Hadoop、Spark、Flink 等等都是建立在 Google MapReduce 工作的基础上的。系统设计，非常重要的一点就是对容灾能力的支持，主要就要分为故障检测和故障恢复两个步骤。对于检测来说，引入一个控制节点对其他节点进行监控是一个非常有效的手段，通过定时的心跳，控制节点就很容易发现其他节点的异常；而故障恢复的一个有效手段就是定时设置 checkpoint，定期记录下运行正确时系统的状态，这样异常发生的时候就可以快速恢复，重新执行需要的计算。</p>
<h2 id="22pagerank谷歌是如何计算网页排名的">22｜PageRank：谷歌是如何计算网页排名的</h2>
<h3 id="总结-12">总结</h3>
<p>今天我们学习了谷歌三驾马车之二 PageRank 算法，核心是利用网页之间的链接关系，通过迭代的方式计算网页的权重，帮助谷歌获得了更好的搜索质量，打败了竞争对手。PageRank 的应用非常多，比如一个很常见的，它可以用来帮助微博挖掘平台上有影响力的大 V。这些应用往往都需要大量的计算资源，MapReduce 或者 Spark 这样的分布式计算平台，可以很好地帮助我们屏蔽底层的技术细节而将研发人员的精力都放在业务开发之上。其中为了解决 Spider Traps，增加跳转因子的思想也很常见。比如，各种广告系统或者推荐系统，在广告或者内容没有历史数据的时候，我们就会为这些内容提供一些试探流量。这背后的思想其实和跳转因子也是类似的。相信当类似业务需要出现时，现在你可以想到解决方案了。</p>
<h2 id="23raft分布式系统间如何达成共识">23｜Raft：分布式系统间如何达成共识？</h2>
<h3 id="总结-13">总结</h3>
<p>Raft 协议，除了各种协议细节，今天学习的几个比较有价值的技巧对你工作也很有帮助。我们为了避免票选被多个同时称为 cadidate 的节点平分，进入无限循环，可以在选举超时时间里引入随机性，避免多个节点继续在同一时间发起票选请求。分布式系统多个节点存在时，往往会采用奇数的节点，这样就可以通过少数服从多数的机制，在集群中保证同一时间只会有一个主节点了。Raft 将复杂问题拆解成多个明确清晰的子问题，分而治之，也是一种系统设计的哲学，你可以好好体会。Raft 算法逻辑还是比较清晰的，但是有很多细节和边界问题需要我们反复琢磨，不自己动手实践一遍，理解程度一定还是比较有限，所以这里也推荐 MIT 6.824，供你练手学习，Lab 就是基于 Raft 和 Golang 语言实现一个简单的分布式 KV 存储（18 年我做过一次，当时有几个 case 没有跑过，就弃坑了，但整体还是收获很大，而且过程颇为有趣，祝你也能研究顺利）。</p>
<h2 id="24uuid如何高效生成全局的唯一id">24｜UUID：如何高效生成全局的唯一ID？</h2>
<h3 id="总结-14">总结</h3>
<p>主流的几种生成分布式唯一 ID 的方案我们今天就都学习完了，思路基本上都比较直接，大体分为两种思路：需要引入额外的系统生成 ID、在业务侧本地通过规则约束独立生成 ID。单点生成器和基于数据库的实现都是第一种，UUID 和 Snowflake 则都是在本地根据规则约束独立生成 ID，一般来说也应用更加广泛。你可以好好回顾感受学到的几个问题解决思想，备份节点来提高可用性、批量读写来提高系统性能、本地计算来避免性能瓶颈。之后，你自己引入外部数据库或者其他系统的时候，也要多多考虑是否会在引入的系统上发生问题和性能瓶颈。</p>
<h2 id="25一致性哈希如何在集群上合理分配流量">25｜一致性哈希：如何在集群上合理分配流量？</h2>
<h3 id="总结-15">总结</h3>
<p>我们今天学习了负载均衡的问题和常用的策略。对于有多个节点的服务，其他服务或者客户端在访问这个服务的时候，我们希望能够比较均衡地分配流量，发挥集群的最大价值，也不容易出现单点服务过载。最直接的思路就是轮询和随机分配。但在请求和服务有状态的时候，简单基于轮询和随机的策略就失效了，这个时候我们就需要想办法把有状态的请求稳定的指向同一台机器，保证上下文的连续性，当然，同时也需要能起到均衡的效果。这个时候，我们可以采用一致性哈希算法，利用请求标识，比如请求的参数或者客户端 ID 等等，把请求稳定的分配到同一台节点，保持上下文的连续性；而相比于直接进行哈希的方式，把请求和节点都映射到同一个哈希环，并顺次寻找最近的节点，可以让我们尽可能少的减少不必要的重哈希，只是把失效节点所负责的请求，较为平均地分配到其他节点之上。</p>
<h2 id="工程实战">工程实战</h2>
<h2 id="26b-treepostgresql-的索引是如何建立的">26｜B+ Tree：PostgreSQL 的索引是如何建立的？</h2>
<h3 id="总结-16">总结</h3>
<p>今天我们一起学习了非常经典的索引实现方式，利用空间换时间的思路，通过为数据表建立额外的有序索引结构，做到大大加速查询的效果。由于数据库需要经常对数据进行增删改，我们的索引数据结构要能高效地变动，而且数据库本身海量的数据也意味着，索引结构不会只存在内存中，需要在二级存储中存储。相比于传统的二叉搜索树，通过 B+ 树，我们可以让整个树状结构变得更加矮胖，而磁盘的预读特性每次都可以加载一整个节点中全部的键，到内存进行二分查找，这样我们只需要通过 3～5 次的磁盘 IO 就可以查询加了索引的字段，非常高效。B+ 树，相比于 B- 树的主要特点就是，只在叶子结点存储数据，而且叶子节点间用首尾相连的指针串联成双向链表，可以获得良好的范围查询的效果，背后的本质就是索引和数据的分离，这同样是非常值得好好体会的一种思想。</p>
<h2 id="27lsm-treeleveldb的索引是如何建立的">27｜LSM Tree：LevelDB的索引是如何建立的？</h2>
<h3 id="总结-17">总结</h3>
<p>今天我们学习了一个相对简化的 modern LSM tree 的实现，分为内存和磁盘上的数据结构两部分：内存上的部分，memtable、immutable memtable，比较简单，用通用的有序集合存储即可，跳表、红黑树都是非常不错的选择；磁盘上的数据结构，SSTable，也不复杂，就是一段段连续按 key 有序存储的段，唯一需要做的就是后台启动一个程序不断地进行多路归并，得到分层的有序存储结构。</p>
<p>为了提高查询效率，我们引入了稀疏索引和布隆过滤器。其中稀疏线性索引，在 Kafka 的章节我们已经学习了，布隆过滤器很快也会介绍，核心就是可以帮助我们快速过滤掉一些肯定在数据库中不存在的字段。整个 LSM Tree 的实现还是比较复杂的，重点体会批量写对性能的提高，在你的工作中有一天也许会做出类似的优化。另外相信你也能感受到，从本篇开始常常提到之前学过的一些思想和算法，这也是这些大型系统之所以难以掌握的原因之一，涉及很多基础算法知识。不过当你能把它们串联起来灵活运用，也就不会觉得特别难啦；相信这些思想对你工作中的系统设计也会有很大的帮助。</p>
<h2 id="28mvcc如何突破数据库并发读写性能瓶颈">28｜MVCC：如何突破数据库并发读写性能瓶颈？</h2>
<h3 id="总结-18">总结</h3>
<p>数据库的事务和其对应的隔离等级，是目前主流数据库的基本性质，我们在工作中用到的机会相当多。首先我们要理解清楚事务的基本概念，包括不同隔离等级下出现的幻读、脏读等等的问题，才能帮助你正确地使用数据库，在合适的时候选择加锁保证业务的正确性。MVCC 的多版本控制策略也是今天的重点学习内容，相比于悲观的加锁实现隔离性的方式，MVCC 基于 undo_log 和版本链的乐观控制并发的方式，可以为我们提供更好的性能，本质是通过快照读，完全不加锁而满足隔离性。MVCC 可见性的判断规则，也不要死记硬背，你可以借助最后的例子仔细琢磨，多问自己几个问题检验一下，比如在 T1 和 T2 之间假设还有一个事务 D，也对数据进行了修改，并在事务 A 开始之前就结束了，会对事务 A 的读操作产生什么样的影响呢？事务 B 和事务 C 又会发生什么样的情况呢？它们两个都会修改成功吗？如果你想清楚了这些问题，相信很快就能理解 MVCC 的工作机制。</p>
<h2 id="29位图如何用更少空间对大量数据进行去重和排序">29｜位图：如何用更少空间对大量数据进行去重和排序？</h2>
<h3 id="总结-19">总结</h3>
<p>Bitmap 位图，本质上就是一种通过二进制位来记录状态的数据结构。比基于硬件特性设计、用一个字节来存储 bool 类型的方式，提高了 8 倍的存储效率，可以用更少的空间来表示状态。Bitmap 在大量数据去重和排序的场景下很有用，比如大量 QQ 号的去重问题；在内存资源敏感、需要标记状态的场景下也很常见，比如文件系统中存储某个 block 是否被占用的状态，用到的就是 Bitmap。在数据库中，我们也可以在枚举类型的属性上建立位图索引，为属性的每个取值建立一个位图，从而可以大大提高多条件过滤查询的效率。事实上，之后会讲到的布隆过滤器，底层也是基于位图的思想，如果你的工作中有去重的需要，也不妨考虑一下采用位图实现的方式，说不定就能大大提高系统的性能。</p>
<h2 id="30布隆过滤器如何解决redis缓存穿透问题">30｜布隆过滤器：如何解决Redis缓存穿透问题？</h2>
<h3 id="总结-20">总结</h3>
<p>今天我们一起学习了非常知名且常用的数据结构，bloom filter。在 Bitmap 和 HashMap 的基础上，布隆过滤器，通过对每个元素进行某种散射式的 Hash，把状态记录在 Bitmap 中，高效且成本低地为我们提供了在大量数据中判断某个元素是否存在的神奇能力。当然，相比于朴素的 HashMap，省来的空间也不是完全没有代价，在布隆过滤器中，我们只能断言一个元素一定不存在，但没有断言时，元素可能存在也可能不存在。不过在选取合适的 Bitmap 数组大小和 Hash 计算次数之后，可以很容易地把误判率控制在低于 5% 的水平，依旧可以给我们带来很大的性能提升。在 Redis 中，就常常用来缓解缓存穿透的现象，从而提高系统的吞吐和稳定性。</p>
<h2 id="31跳表redis是如何存储有序集合的">31｜跳表：Redis是如何存储有序集合的？</h2>
<h3 id="总结-21">总结</h3>
<p>今天我们一起学习了 Redis 中有序集合的底层实现：跳表，作为字典类数据结构，它有着和红黑树、哈希表都不同的实现方式。跳表，和红黑树一样，都提供了 O(N) 的空间复杂度，O(logN) 的插入、查询、删除的时间复杂度，但实现起来比红黑树简单很多，通过引入随机性，我们只需要搜索并记录路径，就可以在保持跳表查询效率的同时，快捷地插入元素。这个操作比红黑树的旋转操作要简单很多。虽然单点查询的效率确实不如哈希表，但跳表可以很好地支持范围查询，只要找到对应的范围节点，然后顺次在链表上遍历就可以了，这一点比红黑树也有明显优势。可以认为在大部分方面，跳表都是非常有优势的有序集合实现方式，引入随机性从期望上保证效率、降低维护成本的思想也值得你好好体味。在力扣上的1206. 设计跳表就是一个实现跳表的题目，你可以去上面试一试，平台给你提供了丰富的用例，能帮助你快速判断实现的正确性。</p>
<h2 id="32时间轮kafka是如何实现定时任务的">32｜时间轮：Kafka是如何实现定时任务的？</h2>
<h3 id="总结-22">总结</h3>
<p>今天我们一起学习了延时队列的底层实现方式和应用场景。JDK 中的 DelayedQueue，以及借助 Redis 中 ZSET 的实现方式，两者总体思路比较相似，都是通过某种数据结构，来维护按任务执行时间排列的任务集合，然后定时或者轮询地去判断最接近过期的任务是否已经过期，选择执行或者继续等待。当然单机的 JDK 可以更好地利用系统内置的定时机制，避免轮询的成本，不过也因为单机本身的限制，不能很好的扩展来支持海量的数据场景。第三种实现方式，时间轮，是一个巧妙又高效的设计。牺牲了一定精度，但通过在内存中以循环队列的方式维护任务，降低了任务并行插入的锁竞争，也减少了取出任务的时间复杂度，特别适用于大量定时任务存在的场景，也因此成为 Kafka 实现延时队列的一种常用方式。总体来说，这几种方式各有利弊，你可以好好体会一下其中的差异，结合自己的业务场景做一些选型的思考。</p>
<h2 id="33限流算法如何防止系统过载">33｜限流算法：如何防止系统过载？</h2>
<h3 id="总结-23">总结</h3>
<p>我们学习了四种常见的限流算法：基于计数的限流算法、基于滑动窗口的限流算法、漏桶算法、令牌桶算法。从递进的顺序来看，你很可能会觉得令牌桶算法要比前面的算法都好，而时间窗口是一种不够优秀的算法。但事实上，这几种算法其实都有各自的长处。计算机的世界里到处都是 trade off，魔法并不存在，要始终铭记在权衡方案时，如果我们在某些方面获得了一些好处，那就一定要警觉在另一些方面是否付出了一些代价，以及代价是否可承受。比如，滑动窗口，虽然会产生一定的尖峰，且需要比较大的内存开销，但是一旦请求来了，要么会被立刻拒绝，要么会被立刻响应，不会有太大的延时。而漏桶会维护一个队列，导致没有被拒绝的请求，真正被执行的时间可能会比较靠后，这就可能产生较大的时延，在时间敏感的场景下，漏桶就不太合适。在一些令牌桶的实现中，也会有一个队列缓冲部分没有令牌的请求，这些请求的处理也同样会产生比较大的时延。所以，令牌桶和漏桶其实更适合后台任务这样可以接受一定时延的场景。在不同的场景下，我们可以选择不同的限流实现，当然在生产环境中相比于自己动手实现，采用成熟的中间件或者类库，当然是更稳妥的选择。Google 的 Guava 库就提供了基于令牌桶的实现，Nginx 和 Resty 这样的网关代理组件也都有相关的实现，可以择优选用。</p>
<h2 id="34前缀树web框架中如何实现路由匹配">34｜前缀树：Web框架中如何实现路由匹配？</h2>
<h3 id="总结-24">总结</h3>
<p>前缀树，采用了独特的树状存储结构，是一种高效的有序集合的实现，通常集合元素存储的是字符串。但是不同于 treemap 直接在节点中存储键，前缀树在节点中存储的是某个串的一个组成单元，对于字符串来说通常就是一个字符；集合中的每个元素由节点在树中的位置来标记，根结点到每个标记为 key 的节点的路径，构成了集合中的所有元素。也正是因为这样的特性，前缀树天然就做到了对集合的字典序的维护，特别适合各种前缀匹配的场景，在字符串检索、敏感词过滤、搜索推荐、词频统计等场景中多有应用。我们 Web 框架动态路由的功能也多是基于 trie 树实现的。另外力扣上就有一道实现前缀树的题目，你可以试着做一做。</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2022-10-08 19:55:40&nbsp;<a class="git-hash" href="https://github.com/dillonzq/LoveIt/commit/08d4d6cf8a78e5a1cb353b041919a9e49a704d6a" target="_blank" title="commit by JF-011101(2838264218@qq.com) 08d4d6cf8a78e5a1cb353b041919a9e49a704d6a: feat">
                                    <i class="fas fa-hashtag fa-fw"></i>08d4d6c</a></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://jefofrank.xyz/algorithm_business/" data-title="Algorithm_business"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://jefofrank.xyz/algorithm_business/"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Reddit" data-sharer="reddit" data-url="https://jefofrank.xyz/algorithm_business/"><i class="fab fa-reddit fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="https://jefofrank.xyz/algorithm_business/" data-title="Algorithm_business"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://jefofrank.xyz/algorithm_business/" data-title="Algorithm_business"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="https://jefofrank.xyz/algorithm_business/" data-title="Algorithm_business"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/baidu.svg"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/vim/" class="prev" rel="prev" title="Vim"><i class="fas fa-angle-left fa-fw"></i>Vim</a>
            <a href="/algorithm_facialmeridians/" class="next" rel="next" title="Algorithm_facialMeridians">Algorithm_facialMeridians<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.89.0">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/jf-011101" target="_blank">Jefo</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span><span class="icp-splitter">&nbsp;|&nbsp;</span><br class="icp-br"/>
                    <span class="icp"><a href="https://beian.miit.gov.cn/">赣ICP备2022007470号-1</a></span></br>
                <span id="busuanzi_container_site_pv">
                    访问量 <span id="busuanzi_value_site_pv"></span> 次
                </span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_uv">
                    访客数 <span id="busuanzi_value_site_uv"></span> 人次
                </span>
                </br><script>
                    function siteTime() {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = 2021;
                        var startMonth = 3;
                        var startDate = 27;
                        var startHour = 19;
                        var startMinute = 15;
                        var startSecond = 11;
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);
                        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                            minutes);
                        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                            diffMinutes * minutes) / seconds);
                        if (startYear == todayYear) {
                            
                            document.getElementById("sitetime").innerHTML = "已安全运行 " + diffDays + " 天 " + diffHours +
                                " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                        } else {
                            
                            document.getElementById("sitetime").innerHTML = "已安全运行 " + diffYears + " 年 " + diffDays +
                                " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                        }
                    }
                    setInterval(siteTime, 1000);
                </script>
                    <span id="sitetime">载入运行时间...</span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://jefos-blog.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/typeit@7.0.4/dist/typeit.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"data":{"id-1":"绿叶律动","id-2":"绿叶律动"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"J0OW8CCKJZ","algoliaIndex":"JF-2","algoliaSearchKey":"3b4a19e831c95174aca4c03fcdf95f5c","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"],"id-2":["id-2"]},"duration":-1,"speed":100}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
