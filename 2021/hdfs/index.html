<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>BigData_base_03 | Jefo</title><meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="robots" content="noodp" />
<meta name="Description" content="Qizheng的个人博客"><link rel="prev" href="https://qizhengzou.github.io/2021/hadoop/" /><link rel="next" href="https://qizhengzou.github.io/2021/sql/" /><link rel="canonical" href="https://qizhengzou.github.io/2021/hdfs/" />
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="BigData_base_03"/>
<meta name="twitter:description" content="深入理解HDFS 关于数据存储方法的说明 本地文件系统 关系数据库（MySQL，Oracle，MS SQL Server等） NoSQL数据库：MongoD"/>
<script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "BigData_base_03",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/qizhengzou.github.io\/2021\/hdfs\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/qizhengzou.github.io\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "big_data","wordcount":  3284 ,
        "url": "https:\/\/qizhengzou.github.io\/2021\/hdfs\/","datePublished": "2021-11-08T19:28:38\u002b08:00","dateModified": "2021-11-08T19:28:38\u002b08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
                "@type": "Organization",
                "name": "qizheng",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/qizhengzou.github.io\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"description": ""
    }
    </script><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/css/lib/fontawesome-free/all.min.css"></head>
    <body><script>
            window.isDark = (window.localStorage && window.localStorage.getItem('theme')) === 'dark';
            window.isDark && document.body.classList.add('dark-theme');
        </script><div class="wrapper"><nav class="navbar">
    
        <div class="top-scroll-bar"></div>
    
    <div class="navbar-container">
        <div class="navbar-header animated bounceIn">
            <a href="https://qizhengzou.github.io">Jefo</a>
        </div>
        <div class="navbar-menu"><a class="menu-item" href="https://qizhengzou.github.io/posts" title="">Posts</a><a class="menu-item" href="https://qizhengzou.github.io/tags" title="">Tags</a><a class="menu-item" href="https://qizhengzou.github.io/categories" title="">Categories</a><a class="menu-item" href="https://qizhengzou.github.io/about" title="">About</a><a href="javascript:void(0);" class="theme-switch"><i class="fas fa-adjust fa-rotate-180 fa-fw" title="Switch Theme"></i></a>
        </div>
    </div>
</nav><nav class="navbar-mobile">
    
        <div class="top-scroll-bar"></div>
    
    <div class="navbar-container">
        <div class="navbar-header">
            <div class="navbar-header-title animated bounceIn">
                <a href="https://qizhengzou.github.io">Jefo</a>
            </div>
            <div class="menu-toggle" id="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="navbar-menu" id="mobile-menu"><a class="menu-item" href="https://qizhengzou.github.io/posts" title="">Posts</a><a class="menu-item" href="https://qizhengzou.github.io/tags" title="">Tags</a><a class="menu-item" href="https://qizhengzou.github.io/categories" title="">Categories</a><a class="menu-item" href="https://qizhengzou.github.io/about" title="">About</a><a href="javascript:void(0);" class="theme-switch"><i class="fas fa-adjust fa-rotate-180 fa-fw" title="Switch Theme"></i></a>
        </div>
    </div>
</nav><main class="main">
                <div class="container"><article class="page"><h1 class="post-title animated flipInX">BigData_base_03</h1><div class="post-meta"><i class="far fa-calendar-alt fa-fw"></i>published on&nbsp;<time datetime=2021-11-08>2021-11-08</time>&nbsp;
            <i class="fas fa-pencil-alt fa-fw"></i>about 3284 words&nbsp;<span class="post-category"><i class="far fa-folder fa-fw"></i>included in&nbsp;<a href="https://qizhengzou.github.io/categories/school-courses/">School courses</a>&nbsp;</span></div><div class="post-toc" id="post-toc">
                <h2 class="post-toc-title">Contents</h2>
                <div class="post-toc-content"><nav id="TableOfContents">
  <ul>
    <li><a href="#深入理解hdfs">深入理解HDFS</a>
      <ul>
        <li><a href="#深入理解hdfs的存储模型">深入理解HDFS的存储模型</a>
          <ul>
            <li><a href="#hdfs的逻辑存储模型文件系统">HDFS的逻辑存储模型：文件系统</a></li>
            <li><a href="#hdfs的逻辑存储模型数据块">HDFS的逻辑存储模型：数据块</a></li>
            <li><a href="#分布式文件块存储的优点">分布式文件块存储的优点</a></li>
          </ul>
        </li>
        <li><a href="#深入理解hdfs的组件">深入理解HDFS的组件</a></li>
        <li><a href="#hdfs的读写流程与容错恢复机制">HDFS的读写流程与容错恢复机制</a>
          <ul>
            <li><a href="#hdfs写数据">HDFS写数据</a></li>
            <li><a href="#hdfs读数据">HDFS读数据</a></li>
            <li><a href="#hdfs通信协议">HDFS通信协议</a></li>
            <li><a href="#hdfs的容错与恢复机制">HDFS的容错与恢复机制</a></li>
          </ul>
        </li>
        <li><a href="#总结与知识拓展">总结与知识拓展</a>
          <ul>
            <li><a href="#hdfs基本原理">HDFS基本原理</a></li>
            <li><a href="#hdfs特点">HDFS特点</a></li>
            <li><a href="#hdfs体系结构的局限性">HDFS体系结构的局限性</a></li>
            <li><a href="#其它常用的分布式文件存储系统">其它常用的分布式文件存储系统</a></li>
            <li><a href="#hadoop的典型应用">Hadoop的典型应用</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div>
            <div class="post-toc-mobile" id="post-toc-mobile">
                <details>
                    <summary>
                        <div class="post-toc-title">
                            <span>Contents</span>
                            <span><i class="details icon fas fa-angle-down"></i></span>
                        </div>
                    </summary>
                    <div class="post-toc-content"><nav id="TableOfContentsMobile">
  <ul>
    <li><a href="#深入理解hdfs">深入理解HDFS</a>
      <ul>
        <li><a href="#深入理解hdfs的存储模型">深入理解HDFS的存储模型</a>
          <ul>
            <li><a href="#hdfs的逻辑存储模型文件系统">HDFS的逻辑存储模型：文件系统</a></li>
            <li><a href="#hdfs的逻辑存储模型数据块">HDFS的逻辑存储模型：数据块</a></li>
            <li><a href="#分布式文件块存储的优点">分布式文件块存储的优点</a></li>
          </ul>
        </li>
        <li><a href="#深入理解hdfs的组件">深入理解HDFS的组件</a></li>
        <li><a href="#hdfs的读写流程与容错恢复机制">HDFS的读写流程与容错恢复机制</a>
          <ul>
            <li><a href="#hdfs写数据">HDFS写数据</a></li>
            <li><a href="#hdfs读数据">HDFS读数据</a></li>
            <li><a href="#hdfs通信协议">HDFS通信协议</a></li>
            <li><a href="#hdfs的容错与恢复机制">HDFS的容错与恢复机制</a></li>
          </ul>
        </li>
        <li><a href="#总结与知识拓展">总结与知识拓展</a>
          <ul>
            <li><a href="#hdfs基本原理">HDFS基本原理</a></li>
            <li><a href="#hdfs特点">HDFS特点</a></li>
            <li><a href="#hdfs体系结构的局限性">HDFS体系结构的局限性</a></li>
            <li><a href="#其它常用的分布式文件存储系统">其它常用的分布式文件存储系统</a></li>
            <li><a href="#hadoop的典型应用">Hadoop的典型应用</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav></div>
                </details>
            </div><div class="post-content"><a class="post-dummy-target" id="深入理解hdfs"></a><h2>深入理解HDFS</h2>
<p>关于数据存储方法的说明</p>
<ul>
<li>本地文件系统</li>
<li>关系数据库（MySQL，Oracle，MS SQL Server等）</li>
<li>NoSQL数据库：MongoDB，Redis，Neo4j、其它OSS等</li>
<li>分布式文件系统：大数据存储的重要方法</li>
</ul>
<a class="post-dummy-target" id="深入理解hdfs的存储模型"></a><h3>深入理解HDFS的存储模型</h3>
<a class="post-dummy-target" id="hdfs的逻辑存储模型文件系统"></a><h4>HDFS的逻辑存储模型：文件系统</h4>
<ul>
<li>以“文件”为基本的逻辑存储单位，形成文件系统</li>
<li>分级的文件系统：其命名空间包含目录、文件
<ul>
<li>用户可象使用普通文件系统一样创建、删除目录和文件，在目录间转移文件、重命名文件</li>
</ul>
</li>
<li>整个HDFS集群中只有一个统一的命名空间（由一个名称节点管理）</li>
</ul>
<a class="post-dummy-target" id="hdfs的逻辑存储模型数据块"></a><h4>HDFS的逻辑存储模型：数据块</h4>
<ul>
<li>每个HDFS文件以一个或多个数据块进行存储（每个块64MB/128MB）</li>
<li>块的大小远远大于普通文件系统，可以最小化寻址开销</li>
</ul>
<a class="post-dummy-target" id="分布式文件块存储的优点"></a><h4>分布式文件块存储的优点</h4>
<ul>
<li>支持大文件存储</li>
<li>加快数据存取速度：
<ul>
<li>单个文件的分布式块存取</li>
<li>多个文件分布式并行读取</li>
</ul>
</li>
<li>保证数据可靠性</li>
<li>简化了存储系统设计</li>
</ul>
<a class="post-dummy-target" id="深入理解hdfs的组件"></a><h3>深入理解HDFS的组件</h3>
<p>HDFS采用了主从（Master/Slave）体系结构，易于实现和管理<br>
第二名称节点（Secondary NameNode）:</p>
<ul>
<li>用来保存名称节点中HDFS元数据的备份，并减少名称节点重启时间</li>
<li>一般是单独运行在一台机器上。</li>
</ul>
<p>数据节点（Data Node）:</p>
<ul>
<li>数据节点负责数据的存储和读取</li>
<li>“主动汇报”：定期向名称节点发送自己所存储的块的列表</li>
<li>数据节点中的数据块会被保存在各自节点的本地Linux文件系统中</li>
</ul>
<p>HDFS客户端：</p>
<ul>
<li>HDFS客户端是用户操作HDFS最常用的方式，HDFS在部署时都提供了客户端</li>
<li>HDFS客户端是一个库，暴露了HDFS文件系统接口，这些接口隐藏了HDFS实现中的大部分复杂性</li>
<li>客户端提供一个类似于POSIX（可移植操作系统界面）的文件系统接口，因此用户在编程时无需知道Namenode和Datanode也可实现其功能。</li>
</ul>
<p>HDFS读写接口（Java）：</p>
<ul>
<li>FileSystem是一个通用文件系统的抽象基类，可以被分布式文件系统继承，所有可能使用Hadoop文件系统的代码，都要使用这个类</li>
<li>Hadoop为FileSystem这个抽象类提供了多种具体实现，DistributedFileSystem就是FileSystem在HDFS文件系统中的具体实现</li>
<li>FileSystem的open()方法返回的是一个输入流FSDataInputStream对象，在HDFS文件系统中，具体的输入流就是DFSInputStream；FileSystem中的create()方法返回的是一个输出流FSDataOutputStream对象，在HDFS文件系统中，具体的输出流就是DFSOutputStream。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">Configuration conf = new Configuration();
FileSystem fs = FileSystem.get(conf);
FSDataInputStream in = fs.open(new Path(uri));
FSDataOutputStream out = fs.create(new Path(uri));
</code></pre></td></tr></table>
</div>
</div><a class="post-dummy-target" id="hdfs的读写流程与容错恢复机制"></a><h3>HDFS的读写流程与容错恢复机制</h3>
<a class="post-dummy-target" id="hdfs写数据"></a><h4>HDFS写数据</h4>
<p>HDFS数据读写过程——写数据请求:</p>
<ul>
<li>首先，client请求NameNode，要将文件（可能需分为多个块）写入到HDFS。</li>
<li>NameNode会给client赋予写权限，并为client提供可以写入数据的DataNode的IP
地址。NameNode在选择可写入数据的DN的规则是: 结合了DN的健康状态、复制因
子、机架感知等因素</li>
<li>假如复制因子是3(默认值)，那么会为每个block返回三个IP地址。</li>
<li>整体的数据复制流程分三个阶段:1.流水线建立；2.复制数据；3.关闭流水线</li>
</ul>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108200150.png" alt="" class="lazyload"></figure></p>
<p>写数据——流水线(pipeline)机制:</p>
<ul>
<li>创建流水线：Client通过连接各个块的ip列表来为每个块创建流水线</li>
<li>块写入：Client向流水线中写入块数据</li>
<li>关闭流水线：当数据块复制到所有DN后，按ip地址列表相反方向，依次反馈写入成功信息至Client，最终Client再反馈给NameNode以更新元数据信息</li>
</ul>
<a class="post-dummy-target" id="hdfs读数据"></a><h4>HDFS读数据</h4>
<p>HDFS数据读写过程——读数据请求：</p>
<ul>
<li>Client请求NameNode要读取文件。</li>
<li>NameNode根据自己的元数据信息，反馈给client一个DataNode的列表(包含所有
的块)。</li>
<li>Client连接DataNode，读取块数据，合并成文件</li>
</ul>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108200507.png" alt="" class="lazyload"></figure></p>
<a class="post-dummy-target" id="hdfs通信协议"></a><h4>HDFS通信协议</h4>
<ul>
<li>HDFS是一个部署在集群上的分布式文件系统，因此很多数据需通过网络进行传输</li>
<li>所有的HDFS通信协议都是构建在TCP/IP协议基础之上的</li>
<li>客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与
名称节点进行交互</li>
<li>名称节点和数据节点之间则使用数据节点协议进行交互</li>
<li>客户端与数据节点的交互是通过RPC（Remote Procedure Call）来实现的。在设
计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。</li>
</ul>
<a class="post-dummy-target" id="hdfs的容错与恢复机制"></a><h4>HDFS的容错与恢复机制</h4>
<ul>
<li>HDFS的容错假设：“硬件出错看作一种常态，而不是异常”</li>
<li>以“检测节点和数据错误并进行自动恢复”为主要目标</li>
<li>主要包括以下几种情形：
<ul>
<li>名称节点出错</li>
<li>数据节点出错</li>
<li>数据出错</li>
</ul>
</li>
</ul>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108200809.png" alt="" class="lazyload"></figure></p>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108200859.png" alt="" class="lazyload"></figure></p>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108201106.png" alt="" class="lazyload"></figure></p>
<a class="post-dummy-target" id="总结与知识拓展"></a><h3>总结与知识拓展</h3>
<a class="post-dummy-target" id="hdfs基本原理"></a><h4>HDFS基本原理</h4>
<p>基本原理：</p>
<ul>
<li>将文件切分成等大的数据块，分别存储到多台机器上。</li>
<li>每个数据块存在多个备份。</li>
<li>将数据切分、容错、负载均衡等功能透明化。</li>
<li>可将HDFS看成是一个巨大、具有容错性的磁盘。</li>
</ul>
<a class="post-dummy-target" id="hdfs特点"></a><h4>HDFS特点</h4>
<ul>
<li>总体而言，HDFS实现了：
<ul>
<li>兼容廉价的硬件设备</li>
<li>流数据读写</li>
<li>大数据集的存储访问</li>
<li>简单的文件模型</li>
<li>强大的跨平台兼容性</li>
</ul>
</li>
<li>HDFS特殊的设计，在实现上述优良特性的同时，也使得自身具有一些应用局限性
<ul>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
</li>
</ul>
<a class="post-dummy-target" id="hdfs体系结构的局限性"></a><h4>HDFS体系结构的局限性</h4>
<ul>
<li>HDFS只设置唯一个名称节点，这样做虽然大大简化了系统设计，但也带来了一
些明显的局限性，具体如下：
<ul>
<li>命名空间的限制：名称节点是保存在内存中的，因此，名称节点能够容纳的对象（文件、块）的个数会受到内存空间大小的限制。</li>
<li>性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量。</li>
<li>隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离。</li>
<li>集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用</li>
</ul>
</li>
</ul>
<a class="post-dummy-target" id="其它常用的分布式文件存储系统"></a><h4>其它常用的分布式文件存储系统</h4>
<ul>
<li>GFS (Google File System): Google公司为了满足本公司需求而开发的基于
Linux的专有分布式文件系统</li>
<li>Lustre:大规模的、安全可靠的，具备高可用性的集群文件系统，它是由SUN公司
开发和维护的</li>
<li>TFS (Taobao File System):面向互联网服务的分布式文件系统，主要针对海量
的非结构化数据，为淘宝提供海量小文件存储</li>
<li>Ceph、MooseFS、GlusterFS、GridFS等</li>
<li>Google Colossus FS/Facebook Tectonics FS/SeaweedFS</li>
</ul>
<p><figure><img src="/svg/loading.min.svg" data-sizes="auto" data-src="https://raw.githubusercontent.com/QizhengZou/Drawing_bed/main/20211108201545.png" alt="" class="lazyload"></figure></p>
<a class="post-dummy-target" id="hadoop的典型应用"></a><h4>Hadoop的典型应用</h4>
<ul>
<li>百度
<ul>
<li>百度在2012年其总的集群规模达到近十个，单集群超过2800台机器节点，Hadoop机器总数有上万台机器，总的存储容量超过100PB，已经使用的超过74PB，每天提交的作业数目有数千个之多，每天的输入数据量已经超过7500TB，输出超过1700TB。</li>
<li>百度的Hadoop集群主要应用包括
<ul>
<li>数据挖掘与分析、日志分析平台、数据仓库系统、推荐引擎系统、用户行为分析系统</li>
</ul>
</li>
</ul>
</li>
<li>阿里巴巴
<ul>
<li>阿里巴巴的Hadoop集群截至2012年大约有3200台服务器，大约300000物理CPU核心，总内存100TB，总的存储容量超过60PB，每天的作业数目超过150000个，每天hive query查询大于6000个，每天扫描数据量约为7.5PB，每天扫描文件数约为4亿，存储利用率大约为80%，CPU利用率平均为65%，峰值可以达到80%。阿里巴巴的Hadoop集群拥有150个用户组、4500个集群用户，为淘宝、天猫、一淘、聚划算、CBU、支付宝提供底层的基础计算和存储服务</li>
<li>阿里巴巴的Hadoop集群主要应用包括
<ul>
<li>搜索支撑、广告系统、数据平台系统、量子统计、淘数据、推荐引擎系统、搜索排行榜</li>
</ul>
</li>
</ul>
</li>
<li>腾讯
<ul>
<li>腾讯也是使用Hadoop最早的中国互联网公司之一，截至2012年年底，腾讯的Hadoop集群机器总量超过5000台，最大单集群约为2000个节点，并利用Hadoop-Hive构建了自己的数据仓库系统TDW，同时还开发了自己的TDW-IDE基础开发环境。腾讯的Hadoop为腾讯各个产品线提供基础云计算和云存储服务</li>
<li>腾讯的Hadoop服务于其下各种产品
<ul>
<li>腾讯社交广告平台、QQ、QQ音乐等</li>
</ul>
</li>
</ul>
</li>
</ul>
</div><div class="post-copyright" id="post-footer">          
            <p class="copyright-item">
                <span>Author:&nbsp;</span>
                <span>qizheng</span>
            </p>

            <p class="copyright-item">
                <span>Updated on:&nbsp;</span>
                <span>2021-11-08</span>
            </p>

            <p class="copyright-item"></p>

            <p class="copyright-item"></p>

            <p class="copyright-item"></p>
        </div>
        <br>

        <div class="post-info-more">
            <section><span class="tag">
                            <a href="https://qizhengzou.github.io/tags/big_data/"><i class="fas fa-tag fa-fw"></i>&nbsp;big_data</a>&nbsp;
                        </span></section>
            <section>
                <span><a href="javascript:window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="https://qizhengzou.github.io">Home</a></span>
            </section>
        </div>
        
        <div class="post-nav"><a href="https://qizhengzou.github.io/2021/hadoop/" class="prev" rel="prev" title="BigData_base_02"><i class="fas fa-angle-left fa-fw"></i>BigData_base_02</a>
                <a href="https://qizhengzou.github.io/2021/sql/" class="next" rel="next" title="Mysql_base_03">Mysql_base_03<i class="fas fa-angle-right fa-fw"></i></a></div><div class="post-comment"></div>
    </article></div>
            </main><footer class="footer">
    <div class="copyright">
        <div class="copyright-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://qizhengzou.github.io/about/" target="_blank">qizheng</a> | </span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreffer">Hugo</a> & <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="external nofollow noopener noreffer">LoveIt</a></div>
    </div>
</footer></div><a href="#" class="dynamic-to-top" id="dynamic-to-top" data-scroll>
            <span>&nbsp;</span>
        </a><script src="/js/lib/jquery/jquery.slim.min.js"></script><script src="/js/lib/lazysizes/lazysizes.min.js"></script><script src="/js/lib/smooth-scroll/smooth-scroll.polyfills.min.js"></script><script>window.scroll = new SmoothScroll('[data-scroll]', {speed: 300, speedAsDuration: true});</script><link rel="stylesheet" href="/css/lib/katex/katex.min.css"><script src="/js/lib/katex/katex.min.js"></script><script defer src="/js/lib/katex/auto-render.min.js"></script><link rel="stylesheet" href="/css/lib/katex/copy-tex.min.css"><script defer src="/js/lib/katex/copy-tex.min.js"></script><script defer src="/js/lib/katex/mhchem.min.js"></script><script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "\\(", right: "\\)", display: false },
                    { left: "\\[", right: "\\]", display: true },{ left: "$", right: "$", display: false },]
            });
        });
    </script><script src="/js/blog.min.js"></script></body>
</html>